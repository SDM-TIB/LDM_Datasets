[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "The OpenAI Gym is an evaluation platform for general agents, providing a set of environments for testing reinforcement learning algorithms.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "OpenAI",
            "Gym",
            "Evaluation platform"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Marc G. Bellemare",
            "Yavar Naddaf",
            "Joel Veness",
            "Michael Bowling"
        ],
        "dcterms:description": "The Arcade Learning Environment is an evaluation platform for general agents, providing a set of classic arcade games for testing reinforcement learning algorithms.",
        "dcterms:title": "Arcade Learning Environment",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Arcade games",
            "Reinforcement learning",
            "Evaluation platform"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A. Rusu",
            "Joel Veness",
            "Marc G. Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K. Fidjeland",
            "Georg Ostrovski"
        ],
        "dcterms:description": "DQN is a deep reinforcement learning algorithm that uses a deep neural network to learn the Q-function, which estimates the expected return of a state-action pair.",
        "dcterms:title": "DQN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Network",
            "Reinforcement learning",
            "Q-function"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Tom Schaul",
            "John Quan",
            "Ioannis Antonoglou",
            "David Silver"
        ],
        "dcterms:description": "Prioritized experience replay is a technique used in reinforcement learning to improve the efficiency of training algorithms by prioritizing experiences based on their importance.",
        "dcterms:title": "Prioritized Experience Replay",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1511.05952",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithmic Techniques"
        ],
        "dcat:keyword": [
            "Experience replay",
            "Prioritization",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "David Silver",
            "Guy Lever",
            "Nicolas Heess",
            "Thomas Degris",
            "Daan Wierstra",
            "Martin Riedmiller"
        ],
        "dcterms:description": "Deterministic policy gradient algorithms are a class of reinforcement learning algorithms that optimize the policy by iteratively updating the parameters of the policy based on the gradient of the policy with respect to the action.",
        "dcterms:title": "Deterministic Policy Gradient Algorithms",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithms"
        ],
        "dcat:keyword": [
            "Policy gradient",
            "Deterministic learning",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Richard S. Sutton",
            "Andrew G. Barto"
        ],
        "dcterms:description": "Markov decision processes are mathematical models that describe the interactions between agents and their environments, providing a framework for decision-making in reinforcement learning.",
        "dcterms:title": "Markov Decision Process",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Mathematics"
        ],
        "dcat:keyword": [
            "Markov decision process",
            "Reinforcement learning",
            "Decision-making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Hado Van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "dcterms:description": "Double Q-learning is a reinforcement learning algorithm that uses two separate Q-networks to learn the value function of an action in a Markov decision process.",
        "dcterms:title": "Double Q-Learning",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithms"
        ],
        "dcat:keyword": [
            "Double Q-learning",
            "Reinforcement learning",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ziyu Wang",
            "Tom Schaul",
            "Matteo Hessel",
            "Hado Hasselt",
            "Marc Lanctot",
            "Nando Freitas"
        ],
        "dcterms:description": "Dueling Network Architectures for Deep Reinforcement Learning is a method that combines two neural networks to learn the value function and advantage function in a reinforcement learning context.",
        "dcterms:title": "Dueling Network Architectures",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Dueling networks",
            "Deep reinforcement learning",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ronald J. Williams"
        ],
        "dcterms:description": "Simple statistical gradient-following algorithms for connectionist reinforcement learning are methods that use statistical methods to optimize the parameters of a reinforcement learning algorithm.",
        "dcterms:title": "Simple Statistical Gradient-Following Algorithms",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithms"
        ],
        "dcat:keyword": [
            "Gradient-following",
            "Reinforcement learning",
            "Statistical methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]