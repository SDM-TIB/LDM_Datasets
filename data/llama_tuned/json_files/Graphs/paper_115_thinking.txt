

<think>
To extract datasets from the research paper titled "Sentiment Analysis for Troll Detection on Weibo" by Zidong Jiang et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.First, I will read through the **abstract, introduction, and datasets sections** to identify any datasets mentioned. The abstract discusses the use of sentiment analysis and user activity data on Sina Weibo, indicating that datasets are likely involved.Next, I will focus on the **datasets section** (section 4) where the authors describe the datasets used in their research. Here, they mention three datasets:1. **Chinese Segmentation Dataset**: This dataset is derived from the SIGHAN 2005 Competition for Chinese sentence processing. It includes training, testing, and validation data, totaling approximately 860,000 segmented Chinese sentences.2. **Sentiment Analysis Dataset**: This dataset consists of 16,548 sentences with positive sentiment and 18,574 sentences with negative sentiment, sourced from Chinese online shopping, movie, and book reviews. The authors also mention that they crawled about 5 million Sina Weibo posts to obtain additional data for their sentiment model, resulting in 2,325,644 sentences with positive sentiment and 960,899 sentences with negative sentiment.3. **Troll Detection Dataset**: This dataset includes user information and corresponding comments from Sina Weibo accounts, totaling 31,980 comments. The authors manually labeled the data for rows 1, 2, 3, and 6 as troll or non-troll comments.Now, I will check the **References section** to find the full citations for these datasets:- For the **Chinese Segmentation Dataset**, the citation is: > Thomas Emerson. *The second international Chinese word segmentation bakeoff*. https://pdfs.semanticscholar.org/65e9/0d9f6754d32db464f635e7fdec672fad9ccf.pdf, 2005.- For the **Sentiment Analysis Dataset**, the citation is: > Rui Wang. *SnowNLP Python package*. https://github.com/isnowfy/snownlp, 2018.- For the **Troll Detection Dataset**, the citation is: > Linqing Liu, Yao Lu, Ye Luo, Renxian Zhang, Laurent Itti, and Jianwei Lu. *Detecting smart spammers on social network: A topic model approach*. In Proceedings of the NAACL Student Research Workshop, pages 45a50, San Diego, California, 2016. Association for Computational Linguistics.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets used in the research paper, along with their respective citations.
</think>