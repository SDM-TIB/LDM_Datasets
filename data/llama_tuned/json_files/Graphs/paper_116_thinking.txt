

<think>
To extract datasets from the research paper titled "PRIN: Point-wise Rotation Invariant Features" by Yang You et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors conducted experiments on the **ShapeNet part dataset** and **ModelNet40**, which suggests these are the datasets used.Next, I will look for specific details about these datasets in the **experiments section**. Here, the authors provide descriptions of the datasets:1. **ShapeNet part dataset**: This dataset contains 16,881 shapes from 16 categories, each annotated with expert verified part labels from 50 different labels. The authors mention that they sampled 2048 points per shape for both PRIN and SPRIN.2. **ModelNet40**: This dataset is a 3D shape classification dataset with 12,308 shapes from 40 categories. The authors state that they used the corresponding point clouds dataset provided by PointNet for their experiments.I will also check the **References section** to find the full citations for these datasets:- For **ShapeNet part dataset**, the citation is: > L. Yi, V. G. Kim, D. Ceylan, I.-C. Shen, M. Yan, H. Su, C. Lu, Q. Huang, A. Sheffer, and L. Guibas. *A scalable active framework for region annotation in 3D shape collections*. SIGGRAPH Asia, 2016.- For **ModelNet40**, the citation is: > Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao. *3D ShapeNets: A deep representation for volumetric shapes*. In Proceedings of the IEEE conference on computer vision and pattern recognition, 2015.Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>