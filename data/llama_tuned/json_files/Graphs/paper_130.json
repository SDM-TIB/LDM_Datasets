[
    {
        "dcterms:creator": [
            "W. Kay",
            "J. Carreira",
            "K. Simonyan",
            "B. Zhang",
            "C. Hillier",
            "S. Vijayanarasimhan",
            "F. Viola",
            "T. Green",
            "T. Back",
            "P. Natsev",
            "M. Suleyman",
            "A. Zisserman"
        ],
        "dcterms:description": "A large-scale action recognition benchmark which contains around 300K videos from 400 action categories. Each video clip is cropped from the raw YouTube video and the duration is 10 seconds. All the videos are grouped into three subsets for training, validation, and testing.",
        "dcterms:title": "Kinetics400",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A. R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "A dataset consisting of 13,320 videos from 101 action classes, split into about 9.5K and 3.7K videos in training and testing sets, respectively.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Kuehne",
            "H. Jhuang",
            "E. Garrote",
            "T. Poggio",
            "T. Serre"
        ],
        "dcterms:description": "A widely used action recognition dataset that includes 7K videos from 51 action categories, split into training and testing sets.",
        "dcterms:title": "HMDB51",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human motion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. C. Heilbron",
            "V. Escorcia",
            "B. Ghanem",
            "J. C. Niebles"
        ],
        "dcterms:description": "A large-scale human activity understanding benchmark consisting of 19,994 videos from 200 activity categories, divided into training, validation, and testing sets.",
        "dcterms:title": "ActivityNet",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Understanding",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human activity",
            "Large-scale benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Activity Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "L. Huang",
            "X. Zhao",
            "K. Huang"
        ],
        "dcterms:description": "A large high-diversity benchmark for generic object tracking in the wild, containing over 10K real-world videos with manually labeled bounding boxes.",
        "dcterms:title": "GOT-10K",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Object tracking",
            "Real-world videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wu",
            "J. Lim",
            "M.-H. Yang"
        ],
        "dcterms:description": "A widely adopted dataset for object tracking, containing 100 video sequences for evaluation.",
        "dcterms:title": "OTB-100",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Object tracking",
            "Evaluation benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Tracking"
        ]
    }
]