[
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD contains 536 Wikipedia articles and more than 100K questions posed about the articles by crowd-workers. The dataset is used for evaluating question generation models.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Generation"
        ],
        "dcat:keyword": [
            "Question generation",
            "Wikipedia articles",
            "Crowd-sourced questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "Li Deng"
        ],
        "dcterms:description": "MS MARCO contains passages retrieved from web documents and questions that are anonymized versions of BING queries. The dataset is used for evaluating reading comprehension models.",
        "dcterms:title": "MS MARCO",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1611.09268",
        "dcat:theme": [
            "Natural Language Processing",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Web queries",
            "Anonymized questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    }
]