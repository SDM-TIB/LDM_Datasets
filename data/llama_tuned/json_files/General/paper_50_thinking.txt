

<think>
To extract datasets from the research paper titled "Attention over Heads: A Multi-Hop Attention for Neural Machine Translation" by Shohei Iiday et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses the proposed multi-hop attention mechanism and mentions the use of parallel data from the IWSLT2017 and WMT17 shared tasks, indicating that datasets are involved.Next, I will focus on the **experiments section** (section 3), where the authors describe the datasets used for training and evaluation. Here, they explicitly mention the datasets:1. **IWSLT2017**: This dataset is used for German-to-English translation tasks, containing approximately 160K training, 7.3K validation, and 6.7K test sentence pairs.2. **WMT17**: This dataset is also used for German-to-English translation tasks, with a training dataset containing approximately 5.9M sentence pairs.Now, I will check the **References section** to find the full citations for these datasets:- For **IWSLT2017**, the citation is: > IWSLT 2017. *IWSLT 2017 Evaluation Campaign*. Available at: https://sites.google.com/site/iwsltevaluation2017/- For **WMT17**, the citation is: > WMT 2017. *WMT 2017 Translation Task*. Available at: http://www.statmt.org/wmt17/translation-task.htmlAfter gathering this information, I will compile the dataset entries, ensuring that I include the full citations as required. This will provide a clear and structured overview of the datasets used in the research paper, ready for further processing or review.
</think>