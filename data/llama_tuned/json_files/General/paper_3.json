[
    {
        "dcterms:creator": [
            "M. Rajpurkar",
            "J. Zhang",
            "K. Lopyrev",
            "P. Liang"
        ],
        "dcterms:description": "SQUAD is a dataset containing 100,000+ questions for machine comprehension of text, where crowdsourcing workers were shown Wikipedia paragraphs and were asked to author questions about their content.",
        "dcterms:title": "SQUAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Text comprehension",
            "Crowdsourcing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "A. Trischler",
            "T. Wang",
            "X. Yuan",
            "J. Harris",
            "A. Sordoni",
            "P. Bachman",
            "K. Suleiman"
        ],
        "dcterms:description": "NEWSQA is a dataset that includes CNN articles and questions generated by crowd-sourcing workers, where they were asked to author questions about the content of the articles.",
        "dcterms:title": "NEWSQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Text comprehension",
            "Crowdsourcing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "M. Dunn",
            "L. Sagun",
            "M. Higgins",
            "U. Guney",
            "V. Cirik",
            "K. Cho"
        ],
        "dcterms:description": "SEARCHQA is a dataset that includes trivia questions taken from Jeopardy! and contexts retrieved from Google search engine, with an average of 50 snippets per question.",
        "dcterms:title": "SEARCHQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Trivia questions",
            "Google search"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "M. Joshi",
            "E. Choi",
            "D. Weld",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "TRIVIAQA is a large-scale dataset for reading comprehension that includes trivia questions crawled from the web, with various sources for the questions and contexts.",
        "dcterms:title": "TRIVIAQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Trivia questions",
            "Web crawling",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Yang",
            "P. Qi",
            "S. Zhang",
            "Y. Bengio",
            "W. W. Cohen",
            "R. Salakhutdinov",
            "C. D. Manning"
        ],
        "dcterms:description": "HOTPOTQA is a dataset for diverse, explainable multi-hop question answering, where crowd-sourcing workers were shown pairs of related Wikipedia paragraphs and asked to author questions.",
        "dcterms:title": "HOTPOTQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-hop reasoning",
            "Wikipedia",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "J. Bao",
            "N. Duan",
            "Z. Yan",
            "M. Zhou",
            "T. Zhao"
        ],
        "dcterms:description": "CQ is a dataset that contains real Google web queries crawled from Google Suggestions, originally constructed for querying the KB Freebase.",
        "dcterms:title": "CQ",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Google web queries",
            "Knowledge base",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Talmor",
            "J. Berant"
        ],
        "dcterms:description": "CWQ is a dataset that involves crowd-sourcing workers answering compositional formal queries against Freebase, requiring multi-hop reasoning.",
        "dcterms:title": "CWQ",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Compositional queries",
            "Freebase",
            "Multi-hop reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Welbl",
            "P. Stenetorp",
            "S. Riedel"
        ],
        "dcterms:description": "WIKIHOP is a dataset that includes entity-relation pairs from Freebase, focusing on multi-hop reasoning across documents.",
        "dcterms:title": "WIKIHOP",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Entity-relation pairs",
            "Multi-hop reasoning",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Abujabal",
            "R. S. Roy",
            "M. Yahya",
            "G. Weikum"
        ],
        "dcterms:description": "COMQA is a community-sourced dataset for complex factoid question answering with paraphrase clusters.",
        "dcterms:title": "COMQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Factoid questions",
            "Paraphrase clusters",
            "Community-sourced"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "D. Dua",
            "Y. Wang",
            "P. Dasigi",
            "G. Stanovsky",
            "S. Singh",
            "M. Gardner"
        ],
        "dcterms:description": "DROP is a reading comprehension benchmark requiring discrete reasoning over paragraphs, focusing on quantitative reasoning.",
        "dcterms:title": "DROP",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Quantitative reasoning",
            "Discrete reasoning",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    }
]