

<think>
To extract datasets from the research paper titled "VAE-PGN based Abstractive Model in Multi-stage Architecture for Text Summarization" by Hyungtak Choi et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors evaluate their model on the **TL;DR challenge**, which suggests that a specific dataset is involved.Next, I will focus on the **experiments section** (section 4.1), where the authors explicitly mention the datasets used for evaluation. Here, they describe two datasets:1. **TL;DR Reddit corpus**: This dataset consists of approximately 3 million content-summary pairs mined from Reddit. It is used for the TL;DR challenge.2. **CNN/Daily Mail corpus**: This dataset contains pairs of online news articles and their summaries, with approximately 287,000 training pairs, 13,368 validation pairs, and 11,490 testing pairs.Now, I will check the **References section** to find the full citations for these datasets:- For the **TL;DR Reddit corpus**, the citation is: > Michael Volske, Martin Potthast, Shahbaz Syed, and Benno Stein. *TL;DR: Mining Reddit to Summarize*. In Proceedings of the Workshop on New Frontiers in Summarization, pages 59a63, Copenhagen, Denmark, 2017.- For the **CNN/Daily Mail corpus**, the citation is: > Karl Moritz Hermann, Tomás Kociský, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Teach-Suleyman, and Phil Blunsom. *Neural Machine Translation of Rare Words with Specialized Tokenizers*. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics, pages 1a10, 2015.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a clear and structured overview of the datasets used in the research paper.
</think>