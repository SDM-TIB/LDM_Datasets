

<think>
To extract datasets from the research paper titled "Stacking With Auxiliary Features for Visual Question Answering" by Nazneen Fatema Rajani and Raymond J. Mooney, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract discusses the use of the VQA dataset, which indicates that a dataset is involved.Next, I will focus on the **introduction** where the authors mention the VQA dataset in the context of their work. They reference the VQA 2016 challenge and the Visual Genome dataset, which suggests that these datasets are crucial for their experiments.In the **methods section**, the authors provide more details about the datasets used. They explicitly state that the VQA dataset consists of images taken from the MS COCO dataset, which is a well-known dataset for object detection and segmentation. They also mention that the VQA dataset includes three questions and answers per image, obtained through Mechanical Turk.Now, I will check the **references section** to find the full citations for these datasets:1. For the **VQA dataset**, the citation is: > Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra, C. Lawrence Zitnick, and Devi Parikh. *VQA: Visual Question Answering*. In The IEEE International Conference on Computer Vision (ICCV2015).2. For the **MS COCO dataset**, the citation is: > Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr DollÃ¡r, and C Lawrence Zitnick. *Microsoft COCO: Common objects in context*. In European Conference on Computer Vision (ECCV2014).3. Additionally, the authors reference the **Visual Genome dataset**, which is also relevant to their work. The citation for this dataset is: > Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, et al. *Visual Genome: Connecting language and vision using crowdsourced dense image annotations*. International Journal of Computer Vision (IJCV) 123(1):32a73, 2017.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets used in the research paper, along with their respective citations.
</think>