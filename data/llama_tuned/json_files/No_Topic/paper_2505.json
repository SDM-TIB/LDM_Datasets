[
    {
        "dcterms:creator": [
            "J. Ferryman"
        ],
        "dcterms:description": "The PETS09-S2L1 sequence consists of 799 frames of 768 × 576 pixels recorded at 7 frames per second with medium crowd density. The ground truth (GT) data from [45, 46, 47] is used for evaluating the tracking results on PETS09-S2L1.",
        "dcterms:title": "PETS09-S2L1",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Crowd density",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "J. Ferryman"
        ],
        "dcterms:description": "The PETS09-S2L2 sequence consists of 442 frames with the same resolution and frame rate as the PETS09-S2L1 sequence, but it contains heavy crowd density and illumination changes. The ground truth (GT) data from [45, 46, 47] is used for evaluating the tracking results on PETS09-S2L2.",
        "dcterms:title": "PETS09-S2L2",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Crowd density",
            "Illumination changes",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "G. Shu",
            "A. Dehghan",
            "O. Oreifej",
            "E. Hand",
            "M. Shah"
        ],
        "dcterms:description": "The UCF-PL dataset consists of 998 frames of 1920 × 1080 pixels recorded at 29 frames per second with medium crowd density, long-term occlusions, and targets of similar appearance. The detection results of the part-based pedestrian detector proposed in [14] are used for evaluation based on the GT data provided by [48].",
        "dcterms:title": "UCF-PL",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Crowd density",
            "Occlusions",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wu",
            "X. Tong",
            "Y. Zhang",
            "H. Lu"
        ],
        "dcterms:description": "The Soccer sequence consists of 155 frames of 960 × 544 pixels recorded at 3 to 5 frames per second. The GT data provided by [13] are used for evaluation.",
        "dcterms:title": "Soccer",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Occlusions",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "B. Benfold",
            "I. Reid"
        ],
        "dcterms:description": "The Town Center dataset consists of 4500 frames of 1080 × 1920 pixels recorded at 25 frames per second. The dataset contains medium crowd density, heavy occlusions, and scale changes. Two categories of GT annotations are provided based on the full body and head regions of pedestrians. The aggregated channel feature (ACF) detector proposed in [38] is used for performance evaluation.",
        "dcterms:title": "Town Center",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Crowd density",
            "Occlusions",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "S. Sivaraman",
            "M. Trivedi"
        ],
        "dcterms:description": "The Urban and Sunny sequences from the LISA 2010 dataset contain car images of 704 × 480 collected at 30 frames per second from a camera mounted on a moving vehicle. The GT data are provided by [44]. The challenging factors include the effect of camera vibration, illumination changes, and target scale changes.",
        "dcterms:title": "Urban and Sunny sequences from LISA 2010",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Vehicle tracking",
            "Illumination changes",
            "Tracking performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    }
]