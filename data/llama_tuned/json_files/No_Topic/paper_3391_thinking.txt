

<think>
To extract datasets from the research paper titled "Complex Word Identification Using Character n-grams" by Maja Popović, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and data sections** to identify any datasets mentioned. The abstract discusses the use of character n-grams for complex word identification, which suggests that datasets are involved, particularly in the context of the Complex Word Identification (CWI) task.Next, I will focus on the **data section** where the authors describe the datasets used for their experiments. They mention that the organisers of the shared CWI task provided training and testing sets for three languages: English, German, Spanish, and French. This indicates that there are specific datasets associated with these languages.In the **data section**, the authors provide detailed descriptions of the datasets:1. **English Dataset**: This dataset consists of a mixture of professionally written news (News), non-professionally written news (WikiNews), and Wikipedia articles (Wiki). The dataset is annotated by 20 people, with each sentence annotated by 10 native and 10 non-native speakers.2. **German Dataset**: This dataset contains data taken from German Wikipedia pages, annotated by 10 people, a mixture of native and non-native speakers.3. **Spanish Dataset**: Similar to the German dataset, this one also contains data from Spanish Wikipedia pages, also annotated by 10 people, a mixture of native and non-native speakers.4. **French Dataset**: This dataset includes data from French Wikipedia pages, also annotated by 10 people, a mixture of native and non-native speakers.5. **Cross-Lingual Dataset**: This dataset is specifically designed for cross-lingual CWI and includes data from English, German, Spanish, and French, with annotations from a mixture of native and non-native speakers.Now, I will check the **References section** to find the full citations for these datasets. The authors reference the following papers for the datasets:- For the **English Dataset**, the citation is: > Seid Muhie Yimam, Chris Biemann, Shervin Mallasi, Gustavo Paetzold, Lucia Specia, Sanja EStajner, Ana Ás Tack, and Marcos Zampieri. *A Report on the Complex Word Identification Shared Task 2018*. In Proceedings of the 13th Workshop on Innovative Use of NLP for Building Educational Applications, pages 341a348, New Orleans, Louisiana, June 5, 2018.- For the **German Dataset**, the citation is: > Seid Muhie Yimam, Sanja EStajner, Martin Riedl, and Chris Biemann. *CWI3G2 - Complex Word Identification Task across Three Text Genres and Two User Groups*. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 401a407, Taipei, Taiwan.- For the **Spanish Dataset**, the citation is: > Seid Muhie Yimam, Sanja EStajner, Martin Riedl, and Chris Biemann. *Multilingual and Cross-Lingual Complex Word Identification*. In Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP2017, pages 813a822, Varna, Bulgaria.- For the **French Dataset**, the citation is: > Seid Muhie Yimam, Sanja EStajner, Martin Riedl, and Chris Biemann. *Multilingual and Cross-Lingual Complex Word Identification*. In Proceedings of the International Conference Recent Advances in Natural Language Processing, RANLP2017, pages 813a822, Varna, Bulgaria.After gathering this information, I will compile the dataset entries, ensuring that each dataset is clearly described and includes the full citation for reference. This will provide a comprehensive overview of the datasets used in the research paper.
</think>