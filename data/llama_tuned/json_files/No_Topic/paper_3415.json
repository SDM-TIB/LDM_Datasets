[
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "A dataset consisting of over 400,000 question pairs, where each question pair is annotated with a binary value indicating whether the two questions are paraphrases of each other.",
        "dcterms:title": "Quora Question Pairs",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Paraphrase detection",
            "Natural language inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Paraphrase Identification",
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Jon Gauthier",
            "Abhinav Rastogi",
            "Raghav Gupta",
            "D. Christopher Manning",
            "Christopher Potts"
        ],
        "dcterms:description": "A natural language inference dataset containing 570,152 sentence pairs, each labeled with one of the following relationships: entailment, contradiction, neutral, where 'is' usually discarded.",
        "dcterms:title": "SNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Sentence pairs",
            "Natural language inference",
            "Entailment",
            "Contradiction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A natural language inference dataset containing 392,702 pairs for training, 9,815 matched pairs, and 9,832 mismatched pairs for development and testing.",
        "dcterms:title": "MultiNLI",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Sentence pairs",
            "Natural language inference",
            "Matched and mismatched pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A reading comprehension dataset where the answer to each question is a span of text from the corresponding passage.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question answering",
            "Span extraction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reading Comprehension",
            "Question Answering"
        ]
    }
]