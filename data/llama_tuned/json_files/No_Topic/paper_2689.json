[
    {
        "dcterms:creator": [
            "Samuel Ryb",
            "Marten Van Schijndel"
        ],
        "dcterms:description": "AnaLog is a natural language inference task designed to probe models for analytical and deductive logical reasoning capabilities. It contains a total of 24,000 items, where each item consists of a premise, a hypothesis, and their logical relation: entailment/non-entailment.",
        "dcterms:title": "AnaLog",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/dmg-illc/analog",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Logical Reasoning",
            "NLI",
            "Deductive Reasoning",
            "Analytical Reasoning"
        ],
        "dcat:landingPage": "https://github.com/dmg-illc/analog",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference",
            "Logical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel Ryb",
            "Marten Van Schijndel"
        ],
        "dcterms:description": "The LAKNLI dataset is used as a basis for the AnaLog dataset, providing a foundation for logical reasoning tasks.",
        "dcterms:title": "LAKNLI",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Logical Reasoning",
            "NLI",
            "Deductive Reasoning",
            "Analytical Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference",
            "Logical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Najoung Kim",
            "Roma Patel",
            "Adam Poliak",
            "Alex Wang",
            "Patrick Xia",
            "R. Thomas McCoy",
            "Ian Tenney",
            "Alexis Ross",
            "Tal Linzen",
            "Benjamin Van Durme",
            "Samuel R. Bowman",
            "Ellie Pavlick"
        ],
        "dcterms:description": "SuperGLUE is a multi-task benchmark and analysis platform for natural language understanding systems, providing a comprehensive evaluation framework.",
        "dcterms:title": "SuperGLUE",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Natural Language Understanding",
            "Benchmarking",
            "Multi-task Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Jidong Tian",
            "Yitian Li",
            "Wenqing Chen",
            "Liqiang Xiao",
            "Hao He",
            "Yaohui Jin"
        ],
        "dcterms:description": "LogicNLI is a dataset designed for evaluating the ability of models to perform logical reasoning through natural language inference.",
        "dcterms:title": "LogicNLI",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Logical Reasoning",
            "NLI",
            "Deductive Reasoning",
            "Analytical Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference",
            "Logical Reasoning"
        ]
    }
]