[
    {
        "dcterms:creator": [
            "Edward Grefenstette",
            "Mehrnosh Sadrzadeh"
        ],
        "dcterms:description": "The GS11 dataset consists of 200 sentence pairs where the two sentences in each pair have the same subject and object but differ in the verb. Each pair was ranked by human evaluators on a 1-7 similarity scale to distinguish between senses of an ambiguous verb.",
        "dcterms:title": "GS11",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Verb Disambiguation"
        ],
        "dcat:keyword": [
            "Verb disambiguation",
            "Sentence pairs",
            "Semantic similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Verb Disambiguation"
        ]
    },
    {
        "dcterms:creator": [
            "Dimitrijs Milajevs",
            "Dimitri Kartsaklis",
            "Mehrnosh Sadrzadeh",
            "Matthew Purver"
        ],
        "dcterms:description": "The KS14 dataset consists of 72 subject-verb-object sentences arranged into 108 sentence pairs. Each pair has a gold standard semantic similarity score on a 1-7 scale, with no lexical overlap among the subject, object, or verb.",
        "dcterms:title": "KS14",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentence Similarity"
        ],
        "dcat:keyword": [
            "Sentence similarity",
            "Semantic similarity",
            "Verb-verb-object sentences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Similarity"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The dataset consists of an October 2013 download of Wikipedia, tokenized using Stanford CoreNLP, lemmatized with the MorphNLP lemmatizer, and parsed using the C&C parser.",
        "dcterms:title": "Wikipedia Corpus",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Data"
        ],
        "dcat:keyword": [
            "Wikipedia",
            "Tokenization",
            "Lemmatization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]