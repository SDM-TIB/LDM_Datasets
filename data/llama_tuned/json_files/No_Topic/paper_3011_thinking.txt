

<think>
To extract datasets from the research paper titled "Facial Expression Recognition by De-expression Residue Learning" by Huiyuan Yang, Umur Ciftci, and Lijun Yin, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors used "seven public facial expression databases," which suggests that specific datasets will be detailed later in the paper.Next, I will focus on the **experiments section** where the authors explicitly list the datasets used for evaluation. They mention the following datasets:1. **CK+**: A widely used dataset for evaluating facial expression recognition, containing 593 video sequences from 123 subjects.2. **Oulu-CASIA**: This dataset includes data captured under different illumination conditions, with 480 video sequences from 80 subjects.3. **MMI**: Comprising 236 image sequences from 31 subjects, labeled for six basic facial expressions.4. **BU-3DFE**: A 3D facial expression database containing 2,500 pairs of static 3D face models and texture images from 100 subjects.5. **BP4D+**: A multimodal spontaneous emotion corpus that includes synchronized 3D, 2D, thermal, physiological data sequences from 140 subjects.Now, I will check the **References section** to gather the full citations for each dataset:- For **CK+**, the citation is: > P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews. *The extended Cohn-Kanade dataset (CK+): A complete dataset for action unit and emotion-specified expression*. In Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, pages 94a101. IEEE, 2010.- For **Oulu-CASIA**, the citation is: > G. Zhao, X. Huang, M. Taini, S. Z. Li, and M. PietikÃ¤inen. *Facial expression recognition from near-infrared videos*. Image and Vision Computing, 29(9):607a619, 2011.- For **MMI**, the citation is: > M. Pantic, M. Valstar, R. Rademaker, and L. Maat. *Web-based database for facial expression analysis*. In Multimedia and Expo, 2005. ICME 2005. IEEE International Conference on, pages 5app. IEEE, 2005.- For **BU-3DFE**, the citation is: > L. Yin, X. Chen, Y. Sun, T. Worm, and M. Reale. *A high-resolution 3D dynamic facial expression database*. In Automatic Face & Gesture Recognition, 2008. FGa08. 8th IEEE International Conference on, pages 1a6. IEEE, 2008.- For **BP4D+**, the citation is: > Z. Zhang, J. M. Girard, Y. Wu, X. Zhang, P. Liu, U. Ciftci, S. Canavan, M. Reale, A. Horowitz, H. Yang, et al. *Multi-modal spontaneous emotion corpus for human behavior analysis*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3438a3446, 2016.After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will provide a comprehensive overview of the datasets used in the research paper, ready for further processing or review.
</think>