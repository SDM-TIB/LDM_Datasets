

<think>
To extract datasets from the research paper titled "A MARVS Analysis of Two Chinese Near-Synonymous Verbs of Jumping Based on Chinese Corpora" by Yingying Peng, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, methods, and results sections** to identify any datasets mentioned. The abstract indicates that the study utilizes two large Chinese corpora, which suggests that datasets are involved.Next, I will focus on the **introduction** to gather more context about the datasets. The authors mention that they analyze two Chinese near-synonymous verbs, **beng4** and **tiao4**, and that they use two large Chinese corpora for this analysis. This suggests that the datasets are crucial for the study.In the **methods section**, the authors explicitly mention the datasets used:1. **CCL corpus**: This corpus is developed by the center for Chinese Linguistics of Beijing University and contains 783,463,175 Chinese characters. It is used to extract instances of the verbs **beng4** and **tiao4** along with their contexts.2. **Chinese Gigaword2**: This corpus is a large dataset with more than 800 million POS-tagged words from three varieties of Mandarin Chinese. It is also utilized in the study to analyze the verbs **beng4** and **tiao4**.Now, I will check the **References section** to find the full citations for these datasets:- For the **CCL corpus**, the citation is: > Zhan, W., Guo, R., Chang, B., Chen, Y., & Chen, L. (2019). The building of the CCL corpus: its design and implementation. Corp. Ling, 6, 77a86.- For the **Chinese Gigaword2**, the citation is: > Huang, C.-R. (2009). Tagged Chinese Gigaword version 2.0, ldc2009t14. Linguistic Data Consortium.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a clear and comprehensive overview of the datasets used in the research paper.
</think>