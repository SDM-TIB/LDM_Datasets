

<think>
To extract datasets from the research paper titled "More Efficient Topic Modelling Through a Noun Only Approach" by Fiona Martin and Mark Johnson, I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract indicates that the study involves a news corpus, which suggests that a dataset is involved, but I need to find specific names.Next, I will focus on the **data and methods section**. Here, the authors explicitly mention the datasets used for their experiments. They refer to a **San Jose Mercury News (SJMN) corpus**, which is derived from the **Tipster corpus**. This is a clear indication of the datasets used in their research.In the **data and methods section**, the authors provide details about the SJMN corpus, stating that it consists of 90,257 articles and contains 35.8 million words. They also mention that part-of-speech tagging identified 12.9 million nouns, which is significant for understanding the dataset's structure.Now, I will check the **references section** to find the full citation for the Tipster corpus, as it is the source of the SJMN dataset. The citation for the Tipster corpus is:- For the **Tipster corpus**, the citation is: > Harman, D., & Liberman, M. (1993). TIPSTER. LDC93T3A. DVD catalog. LDC93T3D. https://catalog.ldc.upenn.edu/LDC93T3D.Finally, I will compile the dataset entries, ensuring that I include the full citation for the Tipster corpus as it is the source of the SJMN dataset. This will provide a clear and comprehensive overview of the datasets used in the research paper.
</think>