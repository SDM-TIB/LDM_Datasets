

<think>
To extract datasets from the research paper titled "Construction of English-French Multimodal Affective Conversational Corpus from TV Dramas" by Sashi Novitasari et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.First, I will read through the **abstract, introduction, and corpus construction sections** to identify any datasets mentioned. The abstract indicates that the authors constructed a multimodal affective conversational corpus based on TV dramas, which suggests that datasets related to TV dramas or conversational data may be involved.Next, I will focus on the **corpus construction section** (section 3) where the authors describe the datasets used. They mention that the corpus was constructed from **American TV dramas**, specifically using 40 episodes with approximately 600 utterances per episode. This indicates that the dataset is derived from TV dramas, but I need to look for specific dataset names or references.In the **corpus construction details**, the authors state that they used **speech data from the original and French-dubbed versions of the TV series**, which includes audio-visual data, text, and parallel text subtitles. This suggests that the dataset is a collection of conversational data from TV dramas, but I need to find the exact name of the dataset or any relevant references.Now, I will check the **References section** to find any citations related to the datasets mentioned. The authors reference several other datasets in the context of affective computing and multimodal corpora, which may be relevant to the construction of their corpus. I will look for any datasets that are explicitly mentioned or implied in the references.In the references, I find the following datasets that may be relevant:1. **HUMAINE Database**: A multimodal corpus that consists of natural and induced data showing emotion in various contexts.2. **SEMAINE Database**: An emotion-rich conversational database constructed by recording interactions between a sensitive artificial listener and users.3. **ATR basic travel expression corpus (BTEC)**: A corpus used for developing broad-coverage speech translation systems.4. **Formosa Speech Database**: A multilingual corpus for Taiwanese-Hakka-Mandarin, created by recording 49 hours of speech.5. **Flickr30K Entities**: A dataset used for multilingual image descriptions, which is relevant to the context of the paper.After identifying these datasets, I will ensure to note the details provided in the paper, such as the number of utterances, the languages involved, and any specific annotations or features mentioned. This will help in creating a comprehensive overview of the datasets used in the research.Finally, I will compile the dataset entries, ensuring that each dataset is accurately described and includes the full citation from the references. This will provide a clear and structured output for further analysis or use.
</think>