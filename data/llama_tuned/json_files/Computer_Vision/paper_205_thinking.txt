

<think>
To extract datasets from the research paper titled "Cycle Text-to-Image GAN with BERT" by Trevor Tsuettsue et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and data sections** to identify any datasets mentioned. The abstract discusses the use of a novel cyclic design for text-to-image generation, which suggests that datasets are involved, particularly in the context of image generation.Next, I will focus on the **data section** (section 3) where the authors explicitly mention the datasets used. Here, they describe two datasets:1. **CUB-200 Dataset**: This dataset contains 11,788 images of 200 different types of birds, which is a well-known benchmark for text-to-image generation. The authors provide a brief description of the dataset's characteristics, including the variety of images and the use of text descriptions.2. **Caltech-UCSD Birds 200 Dataset**: This dataset is referenced as a source of text descriptions for the generated images. The authors mention that they downloaded 10 text descriptions from a GitHub repository, which serves as the text descriptions for the images in the CUB-200 dataset.Now, I will check the **References section** to find the full citations for these datasets:- For the **CUB-200 Dataset**, the citation is: > C. Wah, S. Branson, P. Welinder, P. Perona, and S. Belongie. *The Caltech-UCSD Birds-200-2011 Dataset*. Technical Report CNS-TR-2011-001, California Institute of Technology, 2011.- For the **Caltech-UCSD Birds 200 Dataset**, the citation is the same as above, as it is the same dataset referenced in both parts of the paper.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a clear and comprehensive overview of the datasets used in the research paper.
</think>