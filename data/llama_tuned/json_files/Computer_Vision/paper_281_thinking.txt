

<think>
To extract datasets from the research paper titled "Weakly-Supervised Caricature Face Parsing Through Domain Adaptation" by Wenqing Chu et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract discusses the need for labeled data for caricature face parsing, which suggests that datasets are involved.Next, I will focus on the **introduction** where the authors mention the use of "numerous labeled datasets for face parsing." This indicates that datasets are crucial for their experiments.In the **methods section**, the authors explicitly list the datasets used for their experiments:1. **HELEN Dataset**: This dataset contains 2330 face photos with labeled facial components. It is used as the source domain for domain adaptation.2. **WebCaricature Dataset**: This dataset consists of 6042 caricatures collected from the web, which serves as the target domain. The authors note that they manually annotated 100 caricatures from this dataset for evaluation.Now, I will check the **references section** to retrieve the full citations for these datasets:- For the **HELEN Dataset**, the citation is: > Brandon M Smith, Li Zhang, Jonathan Brandt, Zhe Lin, and Jianchao Yang. *Exemplar-based face parsing*. In CVPR, 2013.- For the **WebCaricature Dataset**, the citation is: > Jing Huo, Wenbin Li, Yinghuan Shi, Yang Gao, and Hu-jun Yin. *Webcaricature: a benchmark for caricature recognition*. In BMVC, 2018.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations as required. This will provide a clear and comprehensive overview of the datasets used in the research paper.
</think>