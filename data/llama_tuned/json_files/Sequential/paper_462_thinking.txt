

<think>
To extract datasets from the research paper titled "Quasi Bidirectional Encoder Representations from Transformers for Word Sense Disambiguation" by Michele Bevilacqua and Roberto Navigli, I will follow a systematic approach to ensure I capture all relevant datasets accurately.First, I will read through the **abstract, introduction, and experimental setup sections** to identify any datasets mentioned. The abstract discusses the introduction of a new architecture for Word Sense Disambiguation (WSD) and mentions the use of evaluation datasets, indicating that datasets are involved.Next, I will focus on the **experimental setup section** (Section 4.1) where the authors describe their training and evaluation processes. Here, they mention using the **English UMBC corpus** for training the QBERT model, which is a significant dataset for WSD tasks. They also refer to various evaluation datasets, specifically naming **Senseval-2, Senseval-3, SemEval-07, SemEval-13, SemEval-15, and their concatenation (ALL)**. These datasets are crucial for evaluating the performance of their proposed model.In the **evaluation tasks section**, the authors confirm the use of these datasets for their experiments, reinforcing their importance in the study.Now, I will check the **References section** to find the full citations for these datasets:1. **English UMBC corpus**: The citation is: > Lushan Han, Abhay L. Kashyap, Tim Finin, and Jonathan Weese. *Textual Similarity Systems*. Joint Conference on Computational Semantics, 2013.2. **Senseval-2**: The citation is: > Philip Edmonds and Scott Cotton. *SENSEVAL-2: Overview*. In Proceedings of SENSEVAL-2, 2001.3. **Senseval-3**: The citation is: > Benjamin Snyder and Martha Palmer. *The English all-words task*. In Proceedings of SENSEVAL-3, 2004.4. **SemEval-07**: The citation is: > Sameer Pradhan, Edward Loper, Dmitriy Dligach, and Martha Palmer. *SemEval-2007 Task-English Lexical Sample, SRL and All*. In Proceedings of SemEval 2007, 2007.5. **SemEval-13**: The citation is: > Roberto Navigli, David Jurgens, and Daniele Vannella. *SemEval-2013 Task 12: Multilingual Word Sense Disambiguation*. In Proceedings of SemEval, 2013.6. **SemEval-15**: The citation is: > Andrea Moro and Roberto Navigli. *SemEval-2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking*. In Proceedings of SemEval, 2015.7. **Word-in-Context (WiC) task**: The citation is: > Mohammad Taher Pilehvar and Jos√© Camacho-Collados. *WiC: the word-in-context dataset for evaluating context-sensitive meaning representations*. In Proceedings of NAACL-HLT, 2019.After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will provide a comprehensive overview of the datasets used in the research paper.
</think>