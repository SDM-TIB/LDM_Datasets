

<think>
To extract datasets from the research paper titled "Adversarial Learning with Contextual Embeddings for Zero-resource Cross-lingual Classification and NER" by Phillip Keung et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses the use of multilingual BERT for zero-resource cross-lingual classification and NER tasks, which suggests that datasets are involved.Next, I will focus on the **experiments section** where the authors describe their methodology and the datasets used for evaluation. In this section, they mention two specific datasets:1. **MLDoc Corpus**: This dataset is used for multilingual document classification tasks. The authors specify that it is a 4-class classification problem based on a balanced subset of the Reuters NewsRCV1 and RCV2 datasets.2. **CoNLL 2002/2003 NER Corpus**: This dataset is utilized for named entity recognition tasks. The authors mention that they used the English portion of this corpus for their experiments.I will also check the **References section** to retrieve the full citations for these datasets:- For the **MLDoc Corpus**, the citation is: > Holger Schwenk and Xian Li. *A corpus for multilingual document classification in eight languages*. In Proceedings of the Language Resources and Evaluation Conference (LREC), 2018.- For the **CoNLL 2002/2003 NER Corpus**, the citation is: > Erik F. Sang and Fien De Meulder. *Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition*. In Proceedings of the Conference on Computational Natural Language Learning (CoNLL), 2003.After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets used in the research paper, along with their respective citations.
</think>