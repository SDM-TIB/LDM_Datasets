[
    {
        "dcterms:creator": [
            "Ciprian Chelba",
            "Tomas Mikolov",
            "Mike Schuster",
            "Qi Ge",
            "Thorsten Brants",
            "Phillipp Koehn",
            "Tony Robinson"
        ],
        "dcterms:description": "A large dataset containing one billion words used for measuring progress in statistical language modeling.",
        "dcterms:title": "One Billion Word dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1312.3005",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Statistical language modeling",
            "Word representation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D Manning"
        ],
        "dcterms:description": "A large annotated corpus for learning natural language inference, providing approximately 550K hypothesis/premise pairs.",
        "dcterms:title": "Stanford Natural Language Inference (SNLI) corpus",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Annotated corpus",
            "Textual entailment"
        ],
        "dcat:landingPage": "https://nlp.stanford.edu/projects/snli/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    }
]