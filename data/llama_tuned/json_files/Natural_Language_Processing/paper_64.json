[
    {
        "dcterms:creator": [
            "A. Das",
            "S. Kottur",
            "K. Gupta",
            "A. Singh",
            "D. Yadav",
            "J. M. Moura",
            "D. Parikh",
            "D. Batra"
        ],
        "dcterms:description": "The VisDial dataset is built upon dialogs consisting of pairs of a question and an answer about an image that are provided in the form of natural language texts.",
        "dcterms:title": "VisDial",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Visual Dialog",
            "Question-Answer Pairs",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Dialog",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "C. Hori",
            "H. Alamri",
            "J. Wang",
            "G. Wichern",
            "T. Hori",
            "A. Cherian",
            "T. K. Marks",
            "V. Cartillier",
            "R. G. Lopes",
            "A. Das"
        ],
        "dcterms:description": "The Audio Visual Scene-aware Dialog Dataset is designed for end-to-end audio visual scene-aware dialog using multimodal attention-based video features.",
        "dcterms:title": "Audio Visual Scene-aware Dialog Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Dialog",
            "Multimodal Interaction"
        ],
        "dcat:keyword": [
            "Audio-Visual Dialog",
            "Scene-aware Dialog",
            "Multimodal Interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Dialogue Generation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Kottur",
            "J. M. Moura",
            "D. Parikh",
            "D. Batra",
            "M. Rohrbach"
        ],
        "dcterms:description": "CLEVR-Dialog is a diagnostic dataset for multi-round reasoning in visual dialog, designed to evaluate visual dialog systems.",
        "dcterms:title": "CLEVR-Dialog",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Visual Dialog",
            "Multi-round Reasoning",
            "Diagnostic Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Dialog",
            "Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L. J. Li",
            "D. A. Shamma"
        ],
        "dcterms:description": "Visual Genome is a dataset that connects language and vision using crowdsourced dense image annotations.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Annotation",
            "Visual Understanding"
        ],
        "dcat:keyword": [
            "Image Annotation",
            "Crowdsourced Data",
            "Visual Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "H. De Vries",
            "F. Strub",
            "S. Chandar",
            "O. Pietquin",
            "H. Larochelle",
            "A. Courville"
        ],
        "dcterms:description": "GuessWhat?! is a dataset built upon goal-oriented dialogs held by two agents to identify unknown objects in an image through a set of yes/no questions.",
        "dcterms:title": "GuessWhat?!",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Visual Dialog",
            "Object Detection",
            "Goal-oriented Dialog"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Object Detection",
            "Visual Dialog"
        ]
    },
    {
        "dcterms:creator": [
            "A. Das",
            "S. Kottur",
            "K. Gupta",
            "A. Singh",
            "D. Yadav",
            "J. M. Moura",
            "D. Parikh",
            "D. Batra"
        ],
        "dcterms:description": "The VisDial v0.9 dataset is used for visual dialog tasks, containing dialogues with question-answer pairs and captions.",
        "dcterms:title": "VisDial v0.9",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Visual Dialog",
            "Question-Answer Pairs",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Dialog",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "C. Hori",
            "H. Alamri",
            "J. Wang",
            "G. Wichern",
            "T. Hori",
            "A. Cherian",
            "T. K. Marks",
            "V. Cartillier",
            "R. G. Lopes",
            "A. Das"
        ],
        "dcterms:description": "The Audio Visual Scene-aware Dialog Dataset is designed for end-to-end audio visual scene-aware dialog using multimodal attention-based video features.",
        "dcterms:title": "Audio Visual Scene-aware Dialog Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Dialog",
            "Multimodal Interaction"
        ],
        "dcat:keyword": [
            "Audio-Visual Dialog",
            "Scene-aware Dialog",
            "Multimodal Interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Dialogue Generation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "P. Sharma",
            "N. Ding",
            "S. Goodman",
            "R. Soricut"
        ],
        "dcterms:description": "Conceptual Captions is a cleaned, hypernymed, image alt-text dataset for automatic image captioning.",
        "dcterms:title": "Conceptual Captions",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Captioning",
            "Hypernymed Dataset",
            "Automatic Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    }
]