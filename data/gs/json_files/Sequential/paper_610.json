[
    {
        "dcterms:creator": [
            "Giovanni Da San Martino",
            "Alberto Barron-Cedeno",
            "Preslav Nakov"
        ],
        "dcterms:description": "The dataset for the SLC Task used in all of our experiments is provided by the organisers of NLP4IF. This data comes in the form of news articles given in TXT format. Each article starts with the title followed by an empty line and news-article body with the Labels for each article provided in a separate file. The dataset is divided into training and development set where the labels are distributed as {propaganda, non-propaganda}. The training set consists of 16,965 examples of which 4,720 contain one or more propagandistic fragments and the remaining (12,245) do not.",
        "dcterms:title": "SLC Task Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Propaganda Detection"
        ],
        "dcat:keyword": [
            "News articles",
            "Propaganda",
            "Classification",
            "Machine Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Binary Classification"
        ]
    }
]