[
    {
        "dcterms:creator": [
            "Genevieve Gorrell",
            "Kalina Bontcheva",
            "Leon Derczynski",
            "Elena Kochkina",
            "Maria Liakata",
            "Arkaitz Zubiaga"
        ],
        "dcterms:description": "RumourEval 2019 provides a dataset of labelled threads from Twitter and Reddit where each source post mentions a rumor. The dataset is used for classifying the type of interaction between a rumorous social media post and a reply post, as well as predicting the veracity of a given rumor.",
        "dcterms:title": "RumourEval 2019",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Rumor Detection",
            "Social Media Analysis"
        ],
        "dcat:keyword": [
            "Rumor veracity",
            "Social media",
            "Twitter",
            "Reddit",
            "Stance classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Rumor classification",
            "Veracity prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Leon Derczynski",
            "Kalina Bontcheva",
            "Maria Liakata",
            "Rob Procter",
            "Geraldine Wong Sak Hoi",
            "Arkaitz Zubiaga"
        ],
        "dcterms:description": "RumourEval 2017 is a dataset used for determining rumor veracity and support for rumors, providing labeled instances for various social media posts.",
        "dcterms:title": "RumourEval 2017",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Rumor Detection",
            "Social Media Analysis"
        ],
        "dcat:keyword": [
            "Rumor veracity",
            "Social media",
            "Stance classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Rumor classification",
            "Veracity prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Matthew E. Peters",
            "Mark Neumann",
            "Mohit Iyyer",
            "Matt Gardner",
            "Christopher Clark",
            "Kenton Lee",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "ELMo is a deep contextualized word representation model that provides embeddings for words in context, allowing for improved performance in various NLP tasks, including those related to social media.",
        "dcterms:title": "ELMo",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Word embeddings",
            "Contextualized representations",
            "Deep learning"
        ],
        "dcat:landingPage": "https://allennlp.org/elmo",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text representation",
            "NLP tasks"
        ]
    }
]