[
    {
        "dcterms:creator": [
            "R. Klinger",
            "O. de Clercq",
            "S. M. Mohammad",
            "A. Balahur"
        ],
        "dcterms:description": "The dataset for emotion recognition shared task consists of tweets where emotion word was removed. The dataset contains six different categories: anger, disgust, fear, joy, sadness, and surprise. The train dataset contains approximately 150 thousands of tweets and test contains more than 30 thousands of tweets.",
        "dcterms:title": "Emotion Recognition Shared Task Dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Emotion classification",
            "Tweets",
            "Sentiment analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Emotion Recognition",
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Pennington",
            "R. Socher",
            "C. D. Manning"
        ],
        "dcterms:description": "GloVe embeddings are pre-trained word embeddings that capture global word-word co-occurrence statistics from a corpus, allowing for effective representation of words in a continuous vector space.",
        "dcterms:title": "GloVe word embeddings",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "https://nlp.stanford.edu/projects/glove/",
        "dcat:theme": [
            "Word Embeddings",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word representation",
            "Vector space",
            "Pre-trained embeddings"
        ],
        "dcat:landingPage": "https://nlp.stanford.edu/projects/glove/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Representation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Peters",
            "M. Neumann",
            "M. Iyyer",
            "M. Gardner",
            "C. Clark",
            "K. Lee",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "ELMo embeddings provide deep contextualized word representations that capture both the syntax and semantics of words in context, allowing for improved performance in various NLP tasks.",
        "dcterms:title": "ELMo embeddings",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://tfhub.dev/google/elmo/2",
        "dcat:theme": [
            "Word Embeddings",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Contextual embeddings",
            "Deep learning",
            "NLP"
        ],
        "dcat:landingPage": "https://tfhub.dev/google/elmo/2",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Representation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Cer",
            "Y. Yang",
            "S.-y. Kong",
            "N. Hua",
            "N. Limtiaco",
            "R. St John",
            "N. Constant",
            "M. Guajardo-Cespedes",
            "S. Yuan",
            "C. Tar"
        ],
        "dcterms:description": "The Universal Sentence Encoder (USE) provides sentence embeddings that can be used for various NLP tasks, enabling the representation of sentences in a fixed-size vector format.",
        "dcterms:title": "Universal Sentence Encoder (USE)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://tfhub.dev/google/universal-sentence-encoder/2",
        "dcat:theme": [
            "Sentence Embeddings",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Sentence representation",
            "NLP",
            "Deep learning"
        ],
        "dcat:landingPage": "https://tfhub.dev/google/universal-sentence-encoder/2",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Representation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Conneau",
            "D. Kiela",
            "H. Schwenk",
            "L. Barrault",
            "A. Bordes"
        ],
        "dcterms:description": "InferSent is a model for learning universal sentence representations from natural language inference data, providing embeddings that can be used for various NLP tasks.",
        "dcterms:title": "InferSent",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentence Embeddings",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Universal sentence representations",
            "NLP",
            "Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Representation"
        ]
    }
]