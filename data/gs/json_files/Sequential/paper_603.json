[
    {
        "dcterms:creator": [
            "Valerio Basile",
            "Cristina Bosco",
            "Elisabetta Fersini",
            "Debora Nozza",
            "Viviana Patti",
            "Francisco Rangel",
            "Paolo Rosso",
            "Manuela Sanguinetti"
        ],
        "dcterms:description": "A dataset for the multilingual detection of hate speech against immigrants and women in Twitter, used in the SemEval 2019 Task 5.",
        "dcterms:title": "SemEval 2019 Task 5",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Hate Speech Detection"
        ],
        "dcat:keyword": [
            "Hate speech",
            "Twitter",
            "Multilingual",
            "Detection",
            "Immigrants",
            "Women"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Binary Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Armand Joulin",
            "Edouard Grave",
            "Piotr Bojanowski",
            "Tomas Mikolov"
        ],
        "dcterms:description": "A tool for obtaining word representations used for text classification, which provides efficient vectorization of words.",
        "dcterms:title": "fastText",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification"
        ],
        "dcat:keyword": [
            "Word representation",
            "Text classification",
            "Vectorization"
        ],
        "dcat:landingPage": "https://fasttext.cc/docs/en/english-vectors.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Steven Bird",
            "Ewan Klein",
            "Edward Loper"
        ],
        "dcterms:description": "A toolkit for natural language processing in Python, used for tokenizing and processing text data.",
        "dcterms:title": "NLTK",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Tokenization",
            "Text processing",
            "Python"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]