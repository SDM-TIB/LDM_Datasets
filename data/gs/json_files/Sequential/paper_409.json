[
    {
        "dcterms:creator": [
            "Bill Dolan",
            "Chris Quirk",
            "Chris Brockett"
        ],
        "dcterms:description": "The MRPC corpus contains pairs of sentences that are labeled as paraphrases or not, used for paraphrase identification tasks.",
        "dcterms:title": "MRPC",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Paraphrase corpus",
            "Sentence pairs",
            "Semantic equivalence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Shankar Iyer",
            "Nikhil Dandekar",
            "Korn√©l Csernai"
        ],
        "dcterms:description": "The Sampled Quora dataset consists of randomly sampled question pairs from Quora, used for paraphrase identification.",
        "dcterms:title": "Sampled Quora",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "data.quora.com",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Paraphrase corpus",
            "Quora"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Nitin Madnani",
            "Joel Tetreault",
            "Martin Chodorow"
        ],
        "dcterms:description": "The PAN dataset contains paraphrase pairs used for evaluating paraphrase identification systems.",
        "dcterms:title": "PAN",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Paraphrase pairs",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD is a machine comprehension dataset containing questions and answers based on Wikipedia articles.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Comprehension"
        ],
        "dcat:keyword": [
            "Question answering",
            "Machine comprehension",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "Adversarial SQuAD is an extension of the SQuAD dataset that includes adversarial examples to evaluate reading comprehension systems.",
        "dcterms:title": "Adversarial SQuAD",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Comprehension"
        ],
        "dcat:keyword": [
            "Adversarial examples",
            "Question answering",
            "Robustness evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Marco Marelli",
            "Luisa Bentivogli",
            "Marco Baroni",
            "Raffaella Bernardi",
            "Stefano Menini",
            "Roberto Zamparelli"
        ],
        "dcterms:description": "SICK-E is a dataset for evaluating semantic relatedness and textual entailment on full sentences.",
        "dcterms:title": "SICK-E",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Relatedness"
        ],
        "dcat:keyword": [
            "Semantic relatedness",
            "Textual entailment",
            "Sentence evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Relatedness",
            "Textual Entailment"
        ]
    },
    {
        "dcterms:creator": [
            "Eneko Agirre",
            "Carmen Banea",
            "Claire Cardie",
            "Daniel Cer",
            "Mona Diab",
            "Aitor Gonzalez-Agirre",
            "Weiwei Guo",
            "Inigo Lopez-Gazpio",
            "Montse Maritxalar",
            "Rada Mihalcea"
        ],
        "dcterms:description": "STS-15 is a dataset for measuring semantic textual similarity between sentence pairs.",
        "dcterms:title": "STS-15",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Semantic textual similarity",
            "Sentence pairs",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Eneko Agirre",
            "Carmen Banea",
            "Daniel Cer",
            "Mona Diab",
            "Aitor Gonzalez-Agirre",
            "Rada Mihalcea",
            "German Rigau",
            "Janyce Wiebe"
        ],
        "dcterms:description": "STS-16 is a dataset for evaluating semantic textual similarity, including monolingual and cross-lingual evaluation.",
        "dcterms:title": "STS-16",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Semantic textual similarity",
            "Monolingual evaluation",
            "Cross-lingual evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Marco Marelli",
            "Luisa Bentivogli",
            "Marco Baroni",
            "Raffaella Bernardi",
            "Stefano Menini",
            "Roberto Zamparelli"
        ],
        "dcterms:description": "SICK-R is a dataset for evaluating semantic relatedness and textual entailment on full sentences.",
        "dcterms:title": "SICK-R",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Relatedness"
        ],
        "dcat:keyword": [
            "Semantic relatedness",
            "Textual entailment",
            "Sentence evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Relatedness",
            "Textual Entailment"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Cer",
            "Mona Diab",
            "Eneko Agirre",
            "Inigo Lopez-Gazpio",
            "Lucia Specia"
        ],
        "dcterms:description": "The STS Benchmark is a dataset for evaluating semantic textual similarity across multiple languages.",
        "dcterms:title": "STS Benchmark",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Semantic textual similarity",
            "Multilingual evaluation",
            "Cross-lingual evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    }
]