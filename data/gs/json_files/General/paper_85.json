[
    {
        "dcterms:creator": [
            "J. Devlin",
            "M.-W. Chang",
            "K. Lee",
            "K. Toutanova"
        ],
        "dcterms:description": "BERT is a pre-trained model that utilizes deep bidirectional transformers for language understanding, achieving state-of-the-art results in various NLP tasks.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Transformers",
            "Language Understanding",
            "Pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "D. Vilar",
            "M. Popovi´c",
            "H. Ney"
        ],
        "dcterms:description": "The Europarl v7 corpus is a multilingual parallel corpus extracted from the proceedings of the European Parliament, used for training and evaluating machine translation systems.",
        "dcterms:title": "Europarl v7 corpus",
        "dcterms:issued": "2006",
        "dcterms:language": "Multilingual",
        "dcterms:identifier": "http://www.statmt.org/europarl/v7",
        "dcat:theme": [
            "Machine Translation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Parallel Corpus",
            "Machine Translation",
            "European Parliament"
        ],
        "dcat:landingPage": "http://www.statmt.org/europarl/v7",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "K. Clark",
            "U. Khandelwal",
            "O. Levy",
            "C. D. Manning"
        ],
        "dcterms:description": "Data provided by Clark et al. (2019) consists of sequences extracted from Wikipedia, used for analyzing BERT's attention mechanisms.",
        "dcterms:title": "Data provided by Clark et al. (2019)",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "BERT",
            "Attention Analysis",
            "Wikipedia"
        ],
        "dcat:landingPage": "https://github.com/clarkkev/attention-analysis",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Attention Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "D. Vilar",
            "M. Popovi´c",
            "H. Ney"
        ],
        "dcterms:description": "The Gold alignment dataset is used for evaluating the accuracy of word alignments in machine translation systems.",
        "dcterms:title": "Gold alignment dataset",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "https://www-i6.informatik.rwth-aachen.de/goldAlignment/",
        "dcat:theme": [
            "Machine Translation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word Alignment",
            "Machine Translation",
            "Evaluation Dataset"
        ],
        "dcat:landingPage": "https://www-i6.informatik.rwth-aachen.de/goldAlignment/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Alignment"
        ]
    }
]