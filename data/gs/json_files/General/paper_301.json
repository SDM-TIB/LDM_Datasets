[
    {
        "dcterms:creator": [
            "Martin d’Hoffschmidt",
            "Wacim Belblidia",
            "Tom Brendlé",
            "Quentin Heinrich"
        ],
        "dcterms:description": "FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 25,000+ samples for the 1.0 version and 60,000+ samples for the 1.1 version.",
        "dcterms:title": "FQuAD1.0",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Reading comprehension",
            "Question answering",
            "Wikipedia"
        ],
        "dcat:landingPage": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcterms:hasVersion": "1.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Martin d’Hoffschmidt",
            "Wacim Belblidia",
            "Tom Brendlé",
            "Quentin Heinrich"
        ],
        "dcterms:description": "FQuAD is a French Native Reading Comprehension dataset of questions and answers on a set of Wikipedia articles that consists of 60,000+ samples for the 1.1 version, which includes additional samples annotated with more demanding guidelines.",
        "dcterms:title": "FQuAD1.1",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Reading comprehension",
            "Question answering",
            "Wikipedia"
        ],
        "dcat:landingPage": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcterms:hasVersion": "1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD1.1 is a dataset for machine comprehension of text, consisting of over 100,000 questions based on a set of Wikipedia articles.",
        "dcterms:title": "SQuAD1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://www.aclweb.org/anthology/D16-1264",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Machine comprehension",
            "Question answering",
            "Wikipedia"
        ],
        "dcat:landingPage": "https://www.aclweb.org/anthology/D16-1264",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD2.0 is an extension of SQuAD1.1 that includes unanswerable questions, allowing for a more challenging evaluation of machine comprehension.",
        "dcterms:title": "SQuAD2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Unanswerable questions",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Adam Trischler",
            "Tong Wang",
            "Xingdi Yuan",
            "Justin Harris",
            "Alessandro Sordoni",
            "Philip Bachman",
            "Kaheer Suleman"
        ],
        "dcterms:description": "NewsQA is a machine comprehension dataset that consists of questions based on news articles, designed to evaluate reading comprehension models.",
        "dcterms:title": "NewsQA",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1611.09830",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "News articles",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1611.09830",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Siva Reddy",
            "Danqi Chen",
            "Christopher D. Manning"
        ],
        "dcterms:description": "CoQA is a conversational question answering challenge dataset that consists of questions and answers in a conversational format.",
        "dcterms:title": "CoQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "http://arxiv.org/abs/1808.07042",
        "dcat:theme": [
            "Conversational AI",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Conversational dataset",
            "Question answering",
            "Machine comprehension"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1808.07042",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Eunsol Choi",
            "He He",
            "Mohit Iyyer",
            "Mark Yatskar",
            "Wen-tau Yih",
            "Yejin Choi",
            "Percy Liang",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "QuAC is a dataset for question answering in context, designed for information-seeking dialogue.",
        "dcterms:title": "QuAC",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "http://arxiv.org/abs/1808.07036",
        "dcat:theme": [
            "Conversational AI",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Contextual dataset",
            "Question answering",
            "Dialogue systems"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1808.07036",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William W. Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D. Manning"
        ],
        "dcterms:description": "HotpotQA is a dataset for diverse, explainable multi-hop question answering, requiring reasoning across multiple documents.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop questions",
            "Explainable AI",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Seungyoung Lim",
            "Myungji Kim",
            "Jooyoul Lee"
        ],
        "dcterms:description": "KorQuAD is a Korean QA dataset for machine reading comprehension, consisting of 70,000+ samples.",
        "dcterms:title": "KorQuAD",
        "dcterms:issued": "2019",
        "dcterms:language": "Korean",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Korean dataset",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pavel Eﬁmov",
            "Leonid Boytsov",
            "Pavel Braslavski"
        ],
        "dcterms:description": "SberQuAD is a Russian reading comprehension dataset consisting of 50,000+ samples.",
        "dcterms:title": "SberQuAD",
        "dcterms:issued": "2019",
        "dcterms:language": "Russian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Russian dataset",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yiming Cui",
            "Ting Liu",
            "Wanxiang Che",
            "Li Xiao",
            "Zhipeng Chen",
            "Wentao Ma",
            "Shijin Wang",
            "Guoping Hu"
        ],
        "dcterms:description": "CMRC 2018 is a span-extraction dataset for Chinese machine reading comprehension, consisting of 20,000+ question and answer pairs.",
        "dcterms:title": "CMRC 2018",
        "dcterms:issued": "2019",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "https://www.aclweb.org/anthology/D19-1600",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Chinese dataset",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "https://www.aclweb.org/anthology/D19-1600",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Keraron Rachel",
            "Lancrenon Guillaume",
            "Bras Mathilde",
            "Allary Frédéric",
            "Moyse Gilles",
            "Scialom Thomas",
            "Soriano-Morales Edmundo-Pavel",
            "Jacopo Staiano"
        ],
        "dcterms:description": "PIAF is a native French question-answering dataset consisting of 3,835 question and answer pairs.",
        "dcterms:title": "PIAF",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Question answering",
            "Machine comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]