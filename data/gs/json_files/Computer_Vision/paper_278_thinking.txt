To extract datasets from the research paper titled "Model-based Hand Pose Estimation for Generalized Hand Shape with Appearance Normalization" by Jan Wöhlke et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by reviewing the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract indicates that the authors evaluate their method on the **Hands 2017 challenge dataset** and the **NYU dataset**, which suggests that these are the primary datasets used in their research.

Next, I will look for specific details about these datasets in the **experiments** or **evaluation** sections. In the introduction, the authors mention that they extensively test their approach on the **Hands 2017 challenge dataset** and the **NYU dataset**. This confirms that these datasets are central to their evaluation.

In the **evaluation section**, the authors provide more context about the datasets:
1. **Hands 2017 Challenge Dataset**: This dataset is described as being composed of parts of the Big Hand 2.2M dataset and the First-person Hand Action Dataset (FHAD). It contains 957,032 depth images of five different hands for training and 295,510 depth images of ten different hand shapes for testing.

2. **NYU Dataset**: This dataset contains 72,757 training images of a single subject's hand and 8,252 test images that include a second hand shape besides the one from the training set.

Now, I will check the **References section** to find the full citations for these datasets. The citations are as follows:

- For the **Hands 2017 Challenge Dataset**, the citation is:
  > S. Yuan, Q. Ye, B. Stenger, S. Jain, and T.-K. Kim. *BigHand2.2M Benchmark: Hand Pose Dataset and State of the Art Analysis*. In IEEE Conference on Computer Vision and Pattern Recognition, pages 2605–2613, 2017.

- For the **NYU Dataset**, the citation is:
  > J. Tompson, M. Stein, Y. Lecun, and K. Perlin. *Real-time Continuous Pose Recovery of Human Hands Using Convolutional Networks*. ACM Transactions on Graphics, vol. 33, no. 5, p. 169, 2014.

With this information, I can now summarize the datasets in a structured manner, ensuring that I include the full citations as required. This will provide a clear and comprehensive overview of the datasets utilized in the research.