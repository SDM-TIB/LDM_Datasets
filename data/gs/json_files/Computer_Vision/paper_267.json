[
    {
        "dcterms:creator": [
            "K. Ito"
        ],
        "dcterms:description": "The LJSpeech dataset consists of 24 hours of English speech from a single speaker, used for training and evaluating text-to-speech models.",
        "dcterms:title": "LJSpeech",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "https://keithito.com/LJ-Speech-Dataset/",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "English speech",
            "single speaker",
            "text-to-speech",
            "speech synthesis"
        ],
        "dcat:landingPage": "https://keithito.com/LJ-Speech-Dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "S. King",
            "L. Wihlborg",
            "W. Guo"
        ],
        "dcterms:description": "The Blizzard Challenge 2017 dataset is used for evaluating text-to-speech systems and consists of various speech samples.",
        "dcterms:title": "Blizzard17",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "speech samples",
            "evaluation",
            "text-to-speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "J. Kominek",
            "A. W. Black"
        ],
        "dcterms:description": "The ARCTIC dataset consists of speech recordings designed for speech synthesis research, featuring multiple speakers.",
        "dcterms:title": "ARCTIC",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "speech synthesis",
            "multiple speakers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "D. Baker"
        ],
        "dcterms:description": "The CSMSC dataset is a Chinese Standard Mandarin Speech Corpus used for speech synthesis research.",
        "dcterms:title": "CSMSC",
        "dcterms:issued": "2017",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "https://www.data-baker.com/open_source.html",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Mandarin",
            "speech synthesis"
        ],
        "dcat:landingPage": "https://www.data-baker.com/open_source.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "K. Itou",
            "M. Yamamoto",
            "K. Takeda"
        ],
        "dcterms:description": "The JNAS dataset is a Japanese speech corpus designed for large vocabulary continuous speech recognition research.",
        "dcterms:title": "JNAS",
        "dcterms:issued": "1999",
        "dcterms:language": "Japanese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Japanese speech",
            "speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition",
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "R. Sonobe",
            "S. Takamichi",
            "H. Saruwatari"
        ],
        "dcterms:description": "The JSUT corpus is a free large-scale Japanese speech corpus for end-to-end speech synthesis.",
        "dcterms:title": "JSUT",
        "dcterms:issued": "2017",
        "dcterms:language": "Japanese",
        "dcterms:identifier": "arXiv:1711.00354",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Japanese speech",
            "end-to-end synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "S. Takamichi",
            "K. Mitsui",
            "Y. Saito"
        ],
        "dcterms:description": "The JVS corpus is a free Japanese multi-speaker voice corpus.",
        "dcterms:title": "JVS",
        "dcterms:issued": "2019",
        "dcterms:language": "Japanese",
        "dcterms:identifier": "arXiv:1908.06248",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "multi-speaker",
            "Japanese speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "H. Zen",
            "V. Dang",
            "R. Clark"
        ],
        "dcterms:description": "LibriTTS is a corpus derived from LibriSpeech for text-to-speech synthesis.",
        "dcterms:title": "LibriTTS",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1904.02882",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "text-to-speech",
            "English speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "I. Solak"
        ],
        "dcterms:description": "The M-AILABS speech dataset is a collection of speech data for various applications.",
        "dcterms:title": "M-AILABS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "speech data",
            "various applications"
        ],
        "dcat:landingPage": "https://www.caito.de/2019/01/the-m-ailabs-speech-dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "K. Park"
        ],
        "dcterms:description": "The TWEB dataset is a large, single-speaker speech dataset in English.",
        "dcterms:title": "TWEB",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "single speaker",
            "English speech"
        ],
        "dcat:landingPage": "https://www.kaggle.com/bryanpark/the-world-english-bible-speech-dataset",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Q. T. Do",
            "C. M. Luong"
        ],
        "dcterms:description": "VAIS-1000 is a Vietnamese speech synthesis corpus.",
        "dcterms:title": "VAIS1000",
        "dcterms:issued": "2017",
        "dcterms:language": "Vietnamese",
        "dcterms:identifier": "http://dx.doi.org/10.21227/H2B887",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Vietnamese speech",
            "speech synthesis"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.21227/H2B887",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    }
]