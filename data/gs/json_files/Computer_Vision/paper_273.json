[
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding, including various tasks such as sentiment analysis, natural language inference, and textual similarity evaluation.",
        "dcterms:title": "General Language Understanding Evaluation (GLUE)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "NLP tasks",
            "benchmark",
            "evaluation",
            "transfer learning"
        ],
        "dcat:landingPage": "https://gluebenchmark.com/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Understanding",
            "Sentiment Analysis",
            "Natural Language Inference",
            "Textual Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset used for pre-training deep bidirectional transformers for language understanding, consisting of a large amount of unlabeled text.",
        "dcterms:title": "English Wikipedia",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "text corpus",
            "language model",
            "pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset consisting of a collection of books used for pre-training deep bidirectional transformers for language understanding.",
        "dcterms:title": "BookCorpus",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "text corpus",
            "language model",
            "pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset for natural language inference tasks, part of the GLUE benchmark.",
        "dcterms:title": "MNLI (Multi-Genre Natural Language Inference)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Inference"
        ],
        "dcat:keyword": [
            "natural language inference",
            "NLI",
            "GLUE benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset consisting of pairs of questions from Quora, used to evaluate the ability to determine if two questions are semantically equivalent.",
        "dcterms:title": "QQP (Quora Question Pairs)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "question pairs",
            "semantic similarity",
            "GLUE benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset for sentiment analysis, part of the GLUE benchmark.",
        "dcterms:title": "SST-2 (Stanford Sentiment Treebank)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "sentiment analysis",
            "GLUE benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset for evaluating linguistic acceptability of sentences, part of the GLUE benchmark.",
        "dcterms:title": "CoLA (Corpus of Linguistic Acceptability)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistic Acceptability"
        ],
        "dcat:keyword": [
            "linguistic acceptability",
            "GLUE benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Linguistic Acceptability"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset for question answering based on natural language inference, part of the GLUE benchmark.",
        "dcterms:title": "QNLI (Question Natural Language Inference)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "question answering",
            "natural language inference",
            "GLUE benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    }
]