[
    {
        "dcterms:creator": [
            "Arda Senocak",
            "Tae-Hyun Oh",
            "Junsik Kim",
            "Ming-Hsuan Yang",
            "In So Kweon"
        ],
        "dcterms:description": "A dataset for sound source localization in visual scenes, consisting of single frames sampled from videos.",
        "dcterms:title": "Flickr SoundNet",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Localization"
        ],
        "dcat:keyword": [
            "Sound localization",
            "Visual scenes",
            "Audio-visual correspondence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Sound Source Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Honglie Chen",
            "Weidi Xie",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A large-scale audio-visual dataset containing over 200k clips for 309 different sound categories, where the object that emits sound is often visible in the corresponding video clip.",
        "dcterms:title": "VGG-Sound",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Learning"
        ],
        "dcat:keyword": [
            "Audio-visual dataset",
            "Sound categories",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Localization"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A new benchmark providing high-quality bounding box annotations for 'sounding' objects in videos, based on the VGG-Sound dataset.",
        "dcterms:title": "VGG-Sound Source (VGG-SS)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Localization"
        ],
        "dcat:keyword": [
            "Bounding box annotations",
            "Sounding objects",
            "Video-based dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Sound Source Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Yapeng Tian",
            "Jing Shi",
            "Bochen Li",
            "Zhiyao Duan",
            "Chenliang Xu"
        ],
        "dcterms:description": "A dataset containing 4,143 video clips spanning 28 audio-visual event categories with temporal boundary annotations.",
        "dcterms:title": "Audio-Visual Event (AVE)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Localization"
        ],
        "dcat:keyword": [
            "Event localization",
            "Video clips",
            "Temporal annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Event Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Dingzeyu Li",
            "Yapeng Tian",
            "Chenliang Xu"
        ],
        "dcterms:description": "A dataset containing 11,849 YouTube video clips spanning 25 categories, with sparse annotations for object labels and dense video and audio sound event labels.",
        "dcterms:title": "LLP",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Localization"
        ],
        "dcat:keyword": [
            "YouTube videos",
            "Sound event labels",
            "Multisensory perception"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Video Parsing"
        ]
    },
    {
        "dcterms:creator": [
            "J Gemmeke",
            "D Ellis",
            "D Freedman",
            "A Jansen",
            "W Lawrence",
            "C Moore",
            "M Plakal",
            "M Ritter"
        ],
        "dcterms:description": "An ontology and human-labeled dataset for audio events, containing a wide variety of sound events.",
        "dcterms:title": "AudioSet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Event Recognition"
        ],
        "dcat:keyword": [
            "Audio events",
            "Ontology",
            "Human-labeled dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Event Detection"
        ]
    }
]