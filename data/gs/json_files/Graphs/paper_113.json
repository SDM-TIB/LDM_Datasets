[
    {
        "dcterms:creator": [
            "Christian Szegedy",
            "Vincent Vanhoucke",
            "Sergey Ioffe",
            "Jonathon Shlens",
            "Zbigniew Wojna"
        ],
        "dcterms:description": "InceptionV3 is a convolutional neural network architecture designed for image classification tasks, known for its inception modules that allow for multi-scale feature extraction.",
        "dcterms:title": "InceptionV3",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1512.00567",
        "dcat:theme": [
            "Computer Vision",
            "Image Classification"
        ],
        "dcat:keyword": [
            "Convolutional Neural Network",
            "Image Classification",
            "Inception Architecture"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1512.00567",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Esteban Real",
            "Alok Aggarwal",
            "Yanping Huang",
            "Quoc V. Le"
        ],
        "dcterms:description": "AmoebaNet is a neural architecture search algorithm that evolves architectures for image classification tasks, optimizing for accuracy and efficiency.",
        "dcterms:title": "AmoebaNet",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1802.01548",
        "dcat:theme": [
            "Computer Vision",
            "Neural Architecture Search"
        ],
        "dcat:keyword": [
            "Neural Architecture Search",
            "Image Classification",
            "Evolutionary Algorithms"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1802.01548",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Ilya Sutskever",
            "Oriol Vinyals",
            "Quoc V. Le"
        ],
        "dcterms:description": "RNN Language Modeling is a dataset used for training recurrent neural networks on language modeling tasks, focusing on predicting the next word in a sequence.",
        "dcterms:title": "RNN Language Modeling",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "http://arxiv.org/abs/1409.3215",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Recurrent Neural Networks",
            "Language Modeling",
            "Sequence Prediction"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1409.3215",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Yonghui Wu",
            "Mike Schuster",
            "Zhifeng Chen",
            "Quoc V. Le",
            "Mohammad Norouzi",
            "Wolfgang Macherey",
            "Maxim Krikun",
            "Yuan Cao",
            "Qin Gao",
            "Klaus Macherey",
            "Jeff Klingner",
            "Apurva Shah",
            "Melvin Johnson",
            "Xiaobing Liu",
            "Lukasz Kaiser",
            "Stephan Gouws",
            "Yoshikiyo Kato",
            "Taku Kudo",
            "Hideto Kazawa",
            "Keith Stevens",
            "George Kurian",
            "Nishant Patil",
            "Wei Wang",
            "Cliff Young",
            "Jason Smith",
            "Jason Riesa",
            "Alex Rudnick",
            "Oriol Vinyals",
            "Greg Corrado",
            "Macduff Hughes",
            "Jeffrey Dean"
        ],
        "dcterms:description": "GNMT is a dataset used for training Google's Neural Machine Translation system, focusing on translating text between languages using deep learning techniques.",
        "dcterms:title": "GNMT",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "http://arxiv.org/abs/1609.08144",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Neural Machine Translation",
            "Deep Learning",
            "Language Translation"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1609.08144",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Zihang Dai",
            "Zhilin Yang",
            "Yiming Yang",
            "Jaime G. Carbonell",
            "Quoc V. Le",
            "Ruslan Salakhutdinov"
        ],
        "dcterms:description": "Transformer-XL is a dataset used for training language models that can capture long-term dependencies in text sequences beyond fixed-length contexts.",
        "dcterms:title": "Transformer-XL",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "http://arxiv.org/abs/1901.02860",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Transformer Models",
            "Language Modeling",
            "Long-term Dependencies"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1901.02860",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "AÂ¨aron van den Oord",
            "Sander Dieleman",
            "Heiga Zen",
            "Karen Simonyan",
            "Oriol Vinyals",
            "Alex Graves",
            "Nal Kalchbrenner",
            "Andrew W. Senior",
            "Koray Kavukcuoglu"
        ],
        "dcterms:description": "WaveNet is a generative model for raw audio, capable of producing high-quality audio waveforms through deep learning techniques.",
        "dcterms:title": "WaveNet",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1609.03499",
        "dcat:theme": [
            "Audio Processing",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Generative Model",
            "Audio Generation",
            "Deep Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1609.03499",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Generation"
        ]
    }
]