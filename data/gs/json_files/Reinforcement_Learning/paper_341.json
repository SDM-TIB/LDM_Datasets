[
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "Daan Wierstra",
            "Martin Riedmiller"
        ],
        "dcterms:description": "The Atari 2600 dataset is used for training deep reinforcement learning algorithms, specifically focusing on discrete action spaces and the compositional structure of actions.",
        "dcterms:title": "Atari 2600",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1312.5602",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Playing"
        ],
        "dcat:keyword": [
            "Atari games",
            "Deep reinforcement learning",
            "Discrete action space"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Action selection"
        ]
    },
    {
        "dcterms:creator": [
            "Emanuel Todorov",
            "Tom Erez",
            "Yuval Tassa"
        ],
        "dcterms:description": "MuJoCo is a physics engine for model-based control, providing a platform for simulating complex physical interactions.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "10.1109/IROS.2012.6386109",
        "dcat:theme": [
            "Robotics",
            "Physics Simulation"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Model-based control",
            "Simulation"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1109/IROS.2012.6386109",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control tasks",
            "Robotics simulation"
        ]
    },
    {
        "dcterms:creator": [
            "Bernhard Wymann",
            "Eric Espié",
            "Christophe Guionneau",
            "Christos Dimitrakakis",
            "Rémi Coulom",
            "Andrew Sumner"
        ],
        "dcterms:description": "TORCS is an open racing car simulator that provides a platform for testing and developing autonomous driving algorithms.",
        "dcterms:title": "TORCS",
        "dcterms:issued": "2000",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Simulation",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Racing simulator",
            "Autonomous driving",
            "Simulation environment"
        ],
        "dcat:landingPage": "http://torcs.sourceforge.net",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Driving simulation",
            "Autonomous vehicle control"
        ]
    },
    {
        "dcterms:creator": [
            "David Silver",
            "Aja Huang",
            "Chris J. Maddison",
            "Arthur Guez",
            "Laurent Sifre",
            "George van den Driessche",
            "Julian Schrittwieser",
            "Ioannis Antonoglou",
            "Vedavyas Panneershelvam",
            "Marc Lanctot",
            "Sander Dieleman",
            "Dominik Grewe",
            "John Nham",
            "Nal Kalchbrenner",
            "Ilya Sutskever",
            "Timothy P. Lillicrap",
            "Madeleine Leach",
            "Koray Kavukcuoglu",
            "Thore Graepel",
            "Demis Hassabis"
        ],
        "dcterms:description": "The Go dataset is used for training deep neural networks and tree search algorithms to play the game of Go at a superhuman level.",
        "dcterms:title": "Go",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "10.1038/nature16961",
        "dcat:theme": [
            "Game Playing",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "Go game",
            "Deep learning",
            "Tree search"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1038/nature16961",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Strategy optimization"
        ]
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A. Rusu",
            "Joel Veness",
            "Marc G. Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K. Fidjeland",
            "Georg Ostrovski",
            "Stig Petersen",
            "Charles Beattie",
            "Amir Sadik",
            "Ioannis Antonoglou",
            "Helen King",
            "Dharshan Kumaran",
            "Daan Wierstra",
            "Shane Legg",
            "Demis Hassabis"
        ],
        "dcterms:description": "This dataset is used to demonstrate human-level control through deep reinforcement learning, showcasing the capabilities of DRL algorithms.",
        "dcterms:title": "Human-level control through deep reinforcement learning",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Human-level performance",
            "Control tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control tasks",
            "Game playing"
        ]
    }
]