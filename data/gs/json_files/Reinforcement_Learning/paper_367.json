[
    {
        "dcterms:creator": [],
        "dcterms:description": "A benchmark for evaluating reinforcement learning algorithms, particularly in the context of Atari games.",
        "dcterms:title": "Atari benchmark",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Atari Games",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Adria Puigdomenech Badia",
            "Mehdi Mirza",
            "Alex Graves",
            "Timothy P Lillicrap",
            "Tim Harley",
            "David Silver",
            "Koray Kavukcuoglu"
        ],
        "dcterms:description": "A reinforcement learning algorithm that utilizes asynchronous updates to improve learning efficiency.",
        "dcterms:title": "A3C (Asynchronous Actor-Critic)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1602.01783",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Asynchronous",
            "Actor-Critic",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A Rusu",
            "Joel Veness",
            "Marc G Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K Fidjeland",
            "Georg Ostrovski"
        ],
        "dcterms:description": "A deep reinforcement learning algorithm that combines Q-learning with deep neural networks to achieve human-level performance in games.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "10.1038/nature14236",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Learning",
            "Neural Networks",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A class of algorithms in reinforcement learning that optimize policies directly by estimating gradients.",
        "dcterms:title": "PG (Policy Gradient)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Policy Gradient",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A reinforcement learning method that incorporates entropy regularization to improve exploration.",
        "dcterms:title": "Soft Q-learning",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Soft Q-learning",
            "Entropy Regularization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A measure of how one probability distribution diverges from a second expected probability distribution.",
        "dcterms:title": "KL (Kullback-Leibler divergence)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Kullback-Leibler Divergence",
            "Information Theory"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An actor-critic method that uses advantages to improve the learning of policies.",
        "dcterms:title": "Advantage Actor-Critic (A2C)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Advantage Actor-Critic",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]