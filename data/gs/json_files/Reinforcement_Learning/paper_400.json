[
    {
        "dcterms:creator": [
            "Yihao Feng",
            "Dilin Wang",
            "Qiang Liu"
        ],
        "dcterms:description": "A method to generate samples from the posterior variational parameter distribution by minimizing the KL divergence to match the target distribution.",
        "dcterms:title": "Stein Variational Inference",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Bayesian inference",
            "KL divergence",
            "posterior distribution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Qiang Liu",
            "Dilin Wang"
        ],
        "dcterms:description": "A general purpose Bayesian inference algorithm that utilizes Stein variational gradient descent.",
        "dcterms:title": "Stein Variational Gradient Descent",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Bayesian inference",
            "gradient descent",
            "variational inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yang Liu",
            "Prajit Ramachandran",
            "Qiang Liu",
            "Jian Peng"
        ],
        "dcterms:description": "A method that integrates Stein variational inference into policy gradient methods.",
        "dcterms:title": "Stein Variational Policy Gradient",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "policy gradient",
            "reinforcement learning",
            "variational inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Sergey Levine",
            "Philipp Moritz",
            "Michael I. Jordan",
            "Pieter Abbeel"
        ],
        "dcterms:description": "An optimization algorithm for policy gradient methods that ensures updates stay within a trust region.",
        "dcterms:title": "Trust Region Policy Optimization",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "policy optimization",
            "trust region",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Philipp Moritz",
            "Sergey Levine",
            "Michael I. Jordan",
            "Pieter Abbeel"
        ],
        "dcterms:description": "A method for estimating advantages in high-dimensional continuous control tasks.",
        "dcterms:title": "Generalized Advantage Estimation",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1506.02438",
        "dcat:theme": [],
        "dcat:keyword": [
            "advantage estimation",
            "reinforcement learning",
            "continuous control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Filip Wolski",
            "Prafulla Dhariwal",
            "Alec Radford",
            "Oleg Klimov"
        ],
        "dcterms:description": "An algorithm for optimizing policies in reinforcement learning that uses a clipped objective function.",
        "dcterms:title": "Proximal Policy Optimization Algorithms",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1707.06347",
        "dcat:theme": [],
        "dcat:keyword": [
            "policy optimization",
            "reinforcement learning",
            "proximal policy"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ronald J. Williams"
        ],
        "dcterms:description": "Algorithms for reinforcement learning that follow a statistical gradient approach.",
        "dcterms:title": "Simple Statistical Gradient-Following Algorithms",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "reinforcement learning",
            "gradient algorithms",
            "connectionist learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]