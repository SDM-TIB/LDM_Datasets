[
    {
        "dcterms:creator": [
            "Sixing Wu",
            "Ying Li",
            "Dawei Zhang",
            "Yang Zhou",
            "Zhonghai Wu"
        ],
        "dcterms:description": "A dataset containing over 1 million dialogues collected from the largest Chinese social networking site Weibo, used for knowledge-grounded dialogue generation.",
        "dcterms:title": "Weibo Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Dialogue dataset",
            "Chinese SNS",
            "Knowledge-grounded dialogue"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Robyn Speer",
            "Joshua Chin",
            "Catherine Havasi"
        ],
        "dcterms:description": "An open multilingual graph of general knowledge, consisting of various triplets that represent commonsense knowledge.",
        "dcterms:title": "ConceptNet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Knowledge",
            "Knowledge Graph"
        ],
        "dcat:keyword": [
            "Commonsense knowledge",
            "Knowledge graph",
            "Multilingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "5.5",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yiming Cui",
            "Wanxiang Che",
            "Ting Liu",
            "Bing Qin",
            "Ziqing Yang"
        ],
        "dcterms:description": "A pre-trained language model for Chinese that utilizes whole word masking to improve performance on various NLP tasks.",
        "dcterms:title": "Chinese BERT",
        "dcterms:issued": "2021",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Pre-trained Language Models"
        ],
        "dcat:keyword": [
            "BERT",
            "Chinese NLP",
            "Pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yu Sun",
            "Shuohuan Wang",
            "Shikun Feng",
            "Siyu Ding",
            "Chao Pang",
            "Junyuan Shang",
            "Jiaxiang Liu",
            "Xuyi Chen",
            "Yanbin Zhao",
            "Yuxiang Lu",
            "Weixin Liu",
            "Zhihua Wu",
            "Weibao Gong",
            "Jianzhong Liang",
            "Zhizhou Shang",
            "Peng Sun",
            "Wei Liu",
            "Xuan Ouyang",
            "Dianhai Yu",
            "Hao Tian",
            "Hua Wu",
            "Haifeng Wang"
        ],
        "dcterms:description": "A large-scale knowledge-enhanced pre-training model for language understanding and generation, which incorporates commonsense knowledge.",
        "dcterms:title": "Commonsense Knowledge Base",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "abs/2107.02137",
        "dcat:theme": [
            "Language Understanding",
            "Knowledge Enhancement"
        ],
        "dcat:keyword": [
            "Knowledge base",
            "Language generation",
            "Pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yizhe Zhang",
            "Siqi Sun"
        ],
        "dcterms:description": "A large-scale generative pre-training model designed for conversational response generation, leveraging extensive dialogue data.",
        "dcterms:title": "Reddit Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Generation",
            "Conversational AI"
        ],
        "dcat:keyword": [
            "Conversational dataset",
            "Generative pre-training",
            "Dialogue response"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]