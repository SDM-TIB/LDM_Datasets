To extract datasets from the research paper titled "Enhancing Lexicon-Based Review Classification by Merging and Revising Sentiment Dictionaries" by Heeryon Cho et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract, introduction, and experimental setup sections** to identify any datasets that are explicitly mentioned. The abstract provides a brief overview of the methodology and results, which may include references to datasets used for evaluation.

In the **introduction**, the authors discuss various sentiment resources and their relevance to the study. This section may provide context for the datasets but may not explicitly name them.

Next, I will focus on the **experimental setup section** (Section 2), where the authors describe the dataset used for their experiments. Here, they mention that they collected **90,000 Amazon book reviews** to construct a positive/negative review dataset. This is a clear indication of a dataset being utilized.

Within this section, they detail how they labeled the reviews: 5-star and 4-star reviews as positive, and 1-star and 2-star reviews as negative, while excluding 3-star reviews. They also specify that **10,000 reviews** were randomly selected for threshold setting, and the remaining **80,000 reviews** were used as test data. This provides a comprehensive understanding of the dataset's composition.

Now, I will check the **references section** to find full citations for any datasets or sentiment resources mentioned in the paper. The authors reference several sentiment dictionaries, which may not be datasets in the traditional sense but are crucial for understanding the context of the experiments.

The relevant citations for the sentiment resources mentioned in the paper are:

1. **SentiWordNet**:
   > Baccianella, S., Esuli, A., & Sebastiani, F. (2010). SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proceedings of the International Conference on Language Resources and Evaluation.

2. **SenticNet**:
   > Cambria, E., Speer, R., Havasi, C., & Hussain, A. (2010). SenticNet: A publicly available semantic resource for opinion mining. In Proceedings of the Association for the Advancement of Artificial Intelligence (AAAI) Fall Symposium.

3. **General Inquirer**:
   > Stone, P. J., & Hunt, E. B. (1963). A computer approach to content analysis: Studies using the General Inquirer system. In Proceedings of the American Federation of Information Processing Societies, Spring Joint Computer Conference.

4. **AFINN**:
   > Nielsen, F. Ã…. (2011). A new ANEW: Evaluation of a word list for sentiment analysis in microblogs. In Proceedings of the ESWC Workshop on Making Sense of Microposts.

5. **Subjectivity Lexicon**:
   > Riloff, E., & Wiebe, J. (2003). Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.

6. **WordNet-Affect**:
   > Strapparava, C., & Valitutti, A. (2004). WordNet-Affect: An affective extension of WordNet. In Proceedings of the International Conference on Language Resources and Evaluation.

After gathering this information, I will compile the dataset entries and their citations into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their relevant citations as presented in the research paper.