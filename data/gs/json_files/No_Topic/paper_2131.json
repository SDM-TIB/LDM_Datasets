[
    {
        "dcterms:creator": [
            "Stanislaw Antol",
            "Aishwarya Agrawal",
            "Jiasen Lu",
            "Margaret Mitchell",
            "Dhruv Batra",
            "C. Lawrence Zitnick",
            "Devi Parikh"
        ],
        "dcterms:description": "The VQA dataset consists of images taken from the MS COCO dataset with three questions and answers per image obtained through Mechanical Turk.",
        "dcterms:title": "VQA Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image-Question pairs",
            "Natural Language Processing",
            "Visual Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C. Lawrence Zitnick"
        ],
        "dcterms:description": "The MS COCO dataset contains images with annotations for object detection, segmentation, and captioning.",
        "dcterms:title": "MS COCO Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Recognition",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object annotations",
            "Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Yuke Zhu",
            "Oliver Groth",
            "Justin Johnson",
            "Kenji Hata",
            "Joshua Kravitz",
            "Stephanie Chen",
            "Yannis Kalantidis",
            "Li-Jia Li",
            "David A Shamma"
        ],
        "dcterms:description": "The Visual Genome dataset connects language and vision using crowdsourced dense image annotations.",
        "dcterms:title": "Visual Genome Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Annotation",
            "Visual Understanding"
        ],
        "dcat:keyword": [
            "Dense annotations",
            "Image-Text relationships",
            "Visual Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": []
    }
]