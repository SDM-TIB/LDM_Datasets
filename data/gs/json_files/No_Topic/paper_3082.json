[
    {
        "dcterms:creator": [
            "Iain McCowan",
            "Jean Carletta",
            "W Kraaij",
            "S Ashby",
            "S Bourban",
            "M Flynn",
            "M Guillemot",
            "T Hain",
            "J Kadlec",
            "V Karaiskos"
        ],
        "dcterms:description": "The AMI meeting corpus is used for analyzing the performance of ASR systems tested with naturally perturbed speech, including laughter and creaky speech.",
        "dcterms:title": "AMI meeting corpus",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Meeting corpus",
            "Speech data",
            "Perturbed speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Mark A Pitt",
            "Laura Dilley",
            "Keith Johnson",
            "Scott Kiesling",
            "William Raymond",
            "Elizabeth Hume",
            "Eric Fosler-Lussier"
        ],
        "dcterms:description": "The Buckeye corpus of conversational speech is utilized for training gender-dependent models with speech data collected from male and female speakers.",
        "dcterms:title": "Buckeye corpus of conversational speech",
        "dcterms:issued": "2007",
        "dcterms:language": "",
        "dcterms:identifier": "www.buckeyecorpus.osu.edu",
        "dcat:theme": [
            "Speech Recognition",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Conversational speech",
            "Speech data",
            "Perturbed speech"
        ],
        "dcat:landingPage": "www.buckeyecorpus.osu.edu",
        "dcterms:hasVersion": "2nd release",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]