To extract the datasets mentioned in the paper titled "Neural Latent Traversal with Semantic Constraints," I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper to identify any datasets that are explicitly mentioned. The abstract indicates that the authors demonstrate their method on two face datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4 (Experiments)**, where the authors typically describe the datasets used for their experiments. In this section, they explicitly mention two datasets: **Flickr-Faces-HQ Dataset (FFHQ)** and **CelebA-HQ**. I will take note of these names and any relevant details provided about them.

To ensure I have the correct citations, I will then refer to the **References section** of the paper. Here, I will find the full citations for both datasets:

1. **Flickr-Faces-HQ Dataset (FFHQ)**:
   > Tero Karras, Samuli Laine, and Timo Aila. *A Style-Based Generator Architecture for Generative Adversarial Networks*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4401â€“4410, 2019.

2. **CelebA-HQ**:
   > Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. *Progressive Growing of GANs for Improved Quality, Stability, and Variation*. arXiv preprint arXiv:1710.10196, 2017.

Now that I have identified the datasets and their citations, I will summarize the findings:

- The paper uses **Flickr-Faces-HQ Dataset (FFHQ)** and **CelebA-HQ** for their experiments, which are both publicly available datasets used in prior studies.

Finally, I will compile this information into a structured format that clearly presents each dataset along with its citation, ensuring that all necessary details are included for future reference or processing.