To extract datasets from the research paper titled "Does more data always yield better translations?" by Guillem Gascó et al., I will follow a systematic approach to identify and document the datasets mentioned in the text.

First, I will read through the **abstract, introduction, and experimental sections** of the paper. The abstract provides a brief overview of the study and may mention specific datasets used for training or evaluation. The introduction often elaborates on the context and significance of the datasets, while the experimental sections typically detail the datasets used in the experiments.

In the **introduction**, the authors discuss the challenges of using large bilingual corpora for statistical machine translation (SMT) and mention the need for effective bilingual sentence selection (BSS). However, they do not specify any datasets at this point.

Next, I will examine **section 5 (Experiments)**, where the authors describe the experimental setup and the datasets used. Here, they mention two specific corpora:

1. **TED Corpus**: An English-French corpus composed of subtitles for public speeches. The authors refer to the IWSLT2010 evaluation task for the dataset's structure and partitions.

2. **News Commentary Corpus (NC)**: Another English-French corpus used in the news domain. The authors provide main figures for this corpus as well.

The authors also mention three large corpora used as a pool of sentences for their experiments:

- **Europarl**: A multilingual parallel corpus extracted from the proceedings of the European Parliament.
- **United Nations (UN)**: A corpus derived from UN documents.
- **Gigaword**: A large corpus of newswire text data.

Now, I will refer to the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution and to allow others to access the datasets.

- For the **TED Corpus**, the citation is:
  > Paul, M., Federico, M., & Stüker, S. (2010). Overview of the IWSLT 2010 evaluation campaign. In Proceedings of the IWSLT 2010, Paris, France, December.

- For the **News Commentary Corpus**, the citation is:
  > Callison-Burch, C., Koehn, P., Monz, C., & Zaidan, O. (2010). Findings of the 2010 joint Workshop on Statistical Machine Translation and Metrics for Machine Translation. In Proceedings of the MATR (ACL), pages 17–53, Uppsala, Sweden, July.

- For the **Europarl Corpus**, the citation is:
  > Koehn, P. (2005). Europarl: A parallel corpus for statistical machine translation. In Proceedings of the 10th Machine Translation Summit, pages 79–86.

- For the **Gigaword Corpus**, the citation is:
  > Graff, D. (2005). The English Gigaword corpus. Linguistic Data Consortium.

- For the **United Nations Corpus**, the citation is:
  > Callison-Burch, C., Koehn, P., Monz, C., & Zaidan, O. (2010). Findings of the 2010 joint Workshop on Statistical Machine Translation and Metrics for Machine Translation. In Proceedings of the MATR (ACL), pages 17–53, Uppsala, Sweden, July.

After gathering all this information, I will compile the dataset entries, ensuring that each dataset is clearly described along with its full citation for proper documentation and future reference. This structured approach will help ensure that all relevant datasets are accurately extracted and cited.