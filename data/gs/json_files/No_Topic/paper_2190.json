[
    {
        "dcterms:creator": [
            "M. Soleymani",
            "J. Lichtenauer",
            "T. Pun",
            "M. Pantic"
        ],
        "dcterms:description": "A multimodal database for affect recognition and implicit tagging, which includes large samples of facial videos and corresponding ground truth HR signals recorded by Electrocardiography (ECG). The videos were recorded in realistic HCI scenarios that both illumination variations and subjectsâ€™ motions were involved.",
        "dcterms:title": "MAHNOB-HCI",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Affective Computing",
            "Physiological Measurement"
        ],
        "dcat:keyword": [
            "Facial videos",
            "Heart rate measurement",
            "Multimodal database",
            "Realistic scenarios"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Heart Rate Measurement",
            "Affect Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A self-collected dataset used for testing methods of heart rate measurement from face videos, recorded under controlled conditions without ambient illumination variations or body movement.",
        "dcterms:title": "VideoHR",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Self-collected dataset",
            "Heart rate measurement",
            "Controlled conditions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Heart Rate Measurement"
        ]
    }
]