[
    {
        "dcterms:creator": [
            "Mitchell P. Marcus",
            "Beatrice Santorini",
            "Mary Ann Marcinkiewicz"
        ],
        "dcterms:description": "The Penn Treebank (PTB) represents syntactic structures as graphs due to nonlocal dependencies, capturing syntactic discontinuities.",
        "dcterms:title": "Penn Treebank (PTB)",
        "dcterms:issued": "1993",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistics"
        ],
        "dcat:keyword": [
            "Syntactic structures",
            "Graphs",
            "Nonlocal dependencies"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Syntactic parsing",
            "Dependency identification"
        ]
    },
    {
        "dcterms:creator": [
            "Mitchell P. Marcus",
            "Beatrice Santorini",
            "Mary Ann Marcinkiewicz"
        ],
        "dcterms:description": "PTB graphs are syntactic representations in the PTB that capture nonlocal dependencies.",
        "dcterms:title": "PTB graphs",
        "dcterms:issued": "1993",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistics"
        ],
        "dcat:keyword": [
            "Graph structures",
            "Nonlocal dependencies"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Syntactic parsing",
            "Dependency identification"
        ]
    },
    {
        "dcterms:creator": [
            "Mitchell P. Marcus",
            "Beatrice Santorini",
            "Mary Ann Marcinkiewicz"
        ],
        "dcterms:description": "PTB augmented trees are trees that approximately represent PTB graphs, allowing for reduced complexity in parsing.",
        "dcterms:title": "PTB augmented trees",
        "dcterms:issued": "1993",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistics"
        ],
        "dcat:keyword": [
            "Tree structures",
            "Approximation",
            "Syntactic parsing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Syntactic parsing",
            "Dependency identification"
        ]
    },
    {
        "dcterms:creator": [
            "Nikita Kitaev",
            "Dan Klein"
        ],
        "dcterms:description": "The K&K parser is a state-of-the-art tree-based parser that can utilize external data such as ELMo or BERT.",
        "dcterms:title": "K&K parser",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Parsing"
        ],
        "dcat:keyword": [
            "Tree-based parsing",
            "Constituency parsing"
        ],
        "dcat:landingPage": "https://github.com/nikitakit/self-attentive-parser",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Constituency parsing"
        ]
    },
    {
        "dcterms:creator": [
            "Matthew Peters",
            "Mark Neumann",
            "Mohit Iyyer",
            "Matt Gardner",
            "Christopher Clark",
            "Kenton Lee",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "ELMo provides deep contextualized word representations that can be used in various NLP tasks.",
        "dcterms:title": "ELMo",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Representation"
        ],
        "dcat:keyword": [
            "Contextualized embeddings",
            "Word representations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word representation",
            "Language understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "BERT is a pre-trained model for deep bidirectional transformers that enhances language understanding.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1810.04805",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Transformers",
            "Pre-training",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding"
        ]
    }
]