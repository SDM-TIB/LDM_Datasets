[
    {
        "dcterms:creator": [
            "Nitin Madnani",
            "Joel Tetreault",
            "Martin Chodorow"
        ],
        "dcterms:description": "This dataset consists of over 400,000 question pairs, and each question pair is annotated with a binary value indicating whether the two questions are paraphrase of each other. We select 5,000 paraphrases and 5,000 non-paraphrases as the development set, and use another 5,000 paraphrases and 5,000 non-paraphrases as the test set.",
        "dcterms:title": "Quora Question Pairs",
        "dcterms:issued": "2012",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Paraphrase identification",
            "Binary classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "It is a natural language inference dataset containing 570,152 sentence pairs, each labeled with one of the following relationships: entailment, contradiction, neutral, and (0), where (0) indicates a lack of human annotation and is usually discarded.",
        "dcterms:title": "SNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Sentence pairs",
            "Natural language inference",
            "Entailment",
            "Contradiction",
            "Neutral"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel R Bowman"
        ],
        "dcterms:description": "It is a natural language inference dataset that contains 392,702 pairs for training, with matched and mismatched examples for evaluation.",
        "dcterms:title": "MultiNLI",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Sentence pairs",
            "Natural language inference",
            "Matched examples",
            "Mismatched examples"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "It is a reading comprehension dataset, where the answer to each question is a span of text from the corresponding passage. The dataset is split into training and development sets.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Answer Sentence Selection"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question answering",
            "Text span"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Answer Sentence Selection"
        ]
    }
]