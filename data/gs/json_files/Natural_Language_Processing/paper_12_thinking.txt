To extract datasets from the research paper titled "DSTC8-AVSD: Multimodal Semantic Transformer Network with Retrieval Style Word Generator" by Hwanhee Lee et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses the AVSD task but does not specify datasets. The introduction references previous works and challenges but does not name specific datasets either.

Next, I will focus on the **experiments section**, where the authors typically describe the datasets used for their evaluations. In this case, the authors mention the **DSTC7** and **DSTC8** datasets in the experimental results. They provide performance metrics on these datasets, indicating that they are indeed used in the study.

Now, I will look for detailed descriptions of these datasets in the paper. The authors do not provide extensive details about the datasets within the text, but they do reference them in the context of their experiments. Therefore, I will need to consult the **References section** to find the full citations for these datasets.

The citations for the datasets are as follows:

- For **DSTC7**, the citation is:
  > Alamri, H.; Cartillier, V.; Lopes, R. G.; Das, A.; Wang, J.; Essa, I.; Batra, D.; Parikh, D.; Cherian, A.; Marks, T. K.; et al. 2018. Audio visual scene-aware dialog (avsd) challenge at dstc7. arXiv preprint arXiv:1806.00525.

- For **DSTC8**, the citation is:
  > Kim, S.; Galley, M.; Gunasekara, C.; Lee, S.; Atkinson, A.; Peng, B.; Schulz, H.; Gao, J.; Li, J.; Adada, M.; et al. 2019. The eighth dialog system technology challenge. arXiv preprint arXiv:1911.06394.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing. Each dataset will be described with its name and full citation, ensuring that all necessary details are included for proper attribution.