[
    {
        "dcterms:creator": [
            "James Thorne",
            "Andreas Vlachos",
            "Christos Christodoulopoulos",
            "Arpit Mittal"
        ],
        "dcterms:description": "The FEVER dataset provides a benchmark for evidence-based claim verification, consisting of 185K generated claims labeled as 'SUPPORTED', 'REFUTED', or 'NOT ENOUGH INFO'. It includes evidence sentences extracted from a dump of 50K Wikipedia pages.",
        "dcterms:title": "FEVER",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1803.05355",
        "dcat:theme": [
            "Natural Language Processing",
            "Fact Verification"
        ],
        "dcat:keyword": [
            "Claim Verification",
            "Evidence Extraction",
            "Fact Checking"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1803.05355",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evidence Retrieval",
            "Claim Verification"
        ]
    },
    {
        "dcterms:creator": [
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "Li Deng"
        ],
        "dcterms:description": "MS MARCO is a human-generated machine reading comprehension dataset designed to facilitate research in passage re-ranking and comprehension tasks.",
        "dcterms:title": "MS MARCO",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1611.09268",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading Comprehension",
            "Passage Re-ranking"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1611.09268",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Passage Retrieval",
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "The Stanford Natural Language Inference (SNLI) dataset is a large annotated corpus for learning natural language inference, providing pairs of sentences labeled with entailment relations.",
        "dcterms:title": "Stanford Natural Language Inference (SNLI)",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1508.05326",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Entailment"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1508.05326",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel Bowman"
        ],
        "dcterms:description": "Multi-Genre NLI (MultiNLI) is a broad-coverage challenge corpus for sentence understanding through inference, providing a diverse set of sentence pairs across multiple genres.",
        "dcterms:title": "Multi-Genre NLI (MultiNLI)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Diverse Genres"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Wikipedia is used as a source for evidence extraction in the context of the FEVER dataset, providing a large corpus of textual information.",
        "dcterms:title": "Wikipedia",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]