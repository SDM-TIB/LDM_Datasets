[
    {
        "dcterms:creator": [
            "K. M. Hermann",
            "T. Kocisky",
            "E. Grefenstette",
            "L. Espeholt",
            "W. Kay",
            "M. Suleyman",
            "P. Blunsom"
        ],
        "dcterms:description": "The CNN/Dailymail dataset is used for training extractive summarization models and contains document-summary pairs.",
        "dcterms:title": "CNN/Dailymail",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Summarization"
        ],
        "dcat:keyword": [
            "Extractive summarization",
            "Document summarization",
            "Neural networks"
        ],
        "dcat:landingPage": "https://github.com/abisee/cnn-dailymail",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Document Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "G. Durrett",
            "T. Berg-Kirkpatrick",
            "D. Klein"
        ],
        "dcterms:description": "The New York Times dataset is used for summarization tasks and contains document-summary pairs, with a specific version (NYT50) created by filtering documents with summaries shorter than 50 words.",
        "dcterms:title": "New York Times",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Summarization"
        ],
        "dcat:keyword": [
            "Extractive summarization",
            "Document summarization",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "NYT50",
        "dcterms:format": "Text",
        "mls:task": [
            "Document Summarization"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The GIGA-CM dataset is created for pre-training the HIBERT model and includes a large number of documents sampled from the English Gigaword dataset and the training split of the CNN/Dailymail dataset.",
        "dcterms:title": "GIGA-CM",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Pre-training"
        ],
        "dcat:keyword": [
            "Document modeling",
            "Pre-training",
            "Large dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Pre-training"
        ]
    },
    {
        "dcterms:creator": [
            "G. Durrett",
            "T. Berg-Kirkpatrick",
            "D. Klein"
        ],
        "dcterms:description": "The NYT50 dataset is a filtered version of the New York Times dataset, created by removing documents whose summaries are shorter than 50 words.",
        "dcterms:title": "NYT50",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Summarization"
        ],
        "dcat:keyword": [
            "Extractive summarization",
            "Document summarization",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Document Summarization"
        ]
    }
]