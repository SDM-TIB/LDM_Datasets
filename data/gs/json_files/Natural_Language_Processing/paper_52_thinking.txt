To extract datasets from the research paper titled "What BERT Sees: Cross-Modal Transfer for Visual Question Generation" by Thomas Scialom et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experimental protocol sections** to identify any datasets mentioned. The abstract indicates that the authors evaluate their model on established VQG datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4 (Experimental Protocol)**, where the authors explicitly mention the datasets used for their experiments. Here, they describe two datasets:

1. **VQGCOCO**: This dataset contains 2,500 training images, 1,250 validation images, and 1,250 test images from the MS COCO dataset. Each image is associated with 5 questions and 5 ground-truth captions.

2. **VQA1.0**: This dataset is used to derive VQG data by reversing the task of Visual Question Answering (VQA). It consists of 82,783 training images, 40,504 validation images, and 81,434 testing images, with each image having 3 associated questions.

After identifying the datasets, I will check the **References section** to find the full citations for these datasets:

- For **VQGCOCO**, the citation is:
  > Mostafazadeh, N., Misra, I., Devlin, J., Mitchell, M., He, X., & Vanderwende, L. (2016). Generating natural questions about an image. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL 2016), Berlin, Germany, Volume 1: Long Papers, pages 1-10.

- For **VQA1.0**, the citation is:
  > Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C. L., & Parikh, D. (2015). VQA: Visual Question Answering. In Proceedings of the International Conference on Computer Vision (ICCV).

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the necessary details for each dataset mentioned in the paper.