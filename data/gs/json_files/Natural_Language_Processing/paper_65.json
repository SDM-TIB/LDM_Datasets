[
    {
        "dcterms:creator": [
            "Yash Goyal",
            "Tejas Khot",
            "Douglas Summers-Stay",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "A dataset for visual question answering that reduces answer bias compared to its predecessor, VQA v1.0, containing an average of 5.4 questions per image.",
        "dcterms:title": "VQA v2.0",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Visual Question Answering",
            "Image Understanding",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Drew A Hudson",
            "Christopher D Manning"
        ],
        "dcterms:description": "A dataset for compositional question answering over real-world images, requiring more reasoning skills than traditional VQA.",
        "dcterms:title": "GQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Compositional Question Answering",
            "Image Reasoning",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Alane Suhr",
            "Stephanie Zhou",
            "Iris Zhang",
            "Huajun Bai",
            "Yoav Artzi"
        ],
        "dcterms:description": "A challenging visual reasoning dataset where each datum consists of two related natural images and one natural language statement, requiring the prediction of whether the statement correctly describes the images.",
        "dcterms:title": "NLVR2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Visual Reasoning",
            "Natural Language Processing",
            "Image Comparison"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Reasoning"
        ]
    }
]