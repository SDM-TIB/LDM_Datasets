[
    {
        "dcterms:creator": [
            "Wang",
            "Hou",
            "Pang",
            "Yang",
            "Chen",
            "Zhang",
            "Liu",
            "Sun",
            "Schutte",
            "Hovy"
        ],
        "dcterms:description": "A benchmark dataset for natural language understanding tasks, including text classification, question answering, and paraphrasing.",
        "dcterms:title": "GLUE Benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification",
            "Question Answering"
        ],
        "dcat:keyword": [
            "NLP benchmark",
            "Text tasks",
            "Multi-task learning"
        ],
        "dcat:landingPage": "https://gluebenchmark.com",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification",
            "Question Answering",
            "Paraphrasing"
        ]
    },
    {
        "dcterms:creator": [
            "Rajpurkar",
            "Zhang",
            "Lopyrev",
            "Liang"
        ],
        "dcterms:description": "A dataset for question answering, containing over 100,000 questions about paragraphs from Wikipedia.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Text comprehension",
            "Wikipedia"
        ],
        "dcat:landingPage": "https://rajpurkar.github.io/SQuAD-explorer/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhang",
            "Wang",
            "Hou",
            "Pang",
            "Yang",
            "Chen",
            "Liu",
            "Sun",
            "Schutte",
            "Hovy"
        ],
        "dcterms:description": "A collection of datasets for natural language understanding tasks, including text classification, question answering, and paraphrasing.",
        "dcterms:title": "GLUE Benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification",
            "Question Answering"
        ],
        "dcat:keyword": [
            "NLP benchmark",
            "Text tasks",
            "Multi-task learning"
        ],
        "dcat:landingPage": "https://gluebenchmark.com",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification",
            "Question Answering",
            "Paraphrasing"
        ]
    },
    {
        "dcterms:creator": [
            "Maas",
            "Daly",
            "Pham",
            "Huang",
            "Ng",
            "Potts"
        ],
        "dcterms:description": "A dataset for sentiment analysis, containing movie reviews labeled as positive or negative.",
        "dcterms:title": "IMDB",
        "dcterms:issued": "2011",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment analysis",
            "Movie reviews",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Lai",
            "Xie",
            "Liu",
            "Yang",
            "Hovy"
        ],
        "dcterms:description": "A large-scale dataset for reading comprehension, containing questions and answers based on Wikipedia articles.",
        "dcterms:title": "RACE",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question answering",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    }
]