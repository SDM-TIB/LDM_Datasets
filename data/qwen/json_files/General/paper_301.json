[
    {
        "dcterms:creator": [
            "Martin da Hois",
            "Wacim Belblidia",
            "Tom Brendl",
            "Quentin Heinrich",
            "Maxime Vidal"
        ],
        "dcterms:description": "A French Reading Comprehension dataset consisting of questions and answers on Wikipedia articles, with 25,000+ samples for version 1.0 and 60,000+ samples for version 1.1.",
        "dcterms:title": "FQuAD1.0",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcterms:hasVersion": "1.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Martin da Hois",
            "Wacim Belblidia",
            "Tom Brendl",
            "Quentin Heinrich",
            "Maxime Vidal"
        ],
        "dcterms:description": "An extended version of FQuAD with 60,000+ samples, including more complex questions and answers.",
        "dcterms:title": "FQuAD1.1",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "https://illuin-tech.github.io/FQuAD-explorer/",
        "dcterms:hasVersion": "1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A large-scale dataset for machine comprehension of text, containing over 100,000 questions.",
        "dcterms:title": "SQuAD1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://rajpurkar.github.io/SQuAD-explorer/",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "https://rajpurkar.github.io/SQuAD-explorer/",
        "dcterms:hasVersion": "1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "An extension of SQuAD1.1 with unanswerable questions, containing over 150,000 questions.",
        "dcterms:title": "SQuAD2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://rajpurkar.github.io/SQuAD-explorer/",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "https://rajpurkar.github.io/SQuAD-explorer/",
        "dcterms:hasVersion": "2.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Siva Reddy",
            "Danqi Chen",
            "Christopher D. Manning"
        ],
        "dcterms:description": "A conversational question answering dataset with over 127,000 questions.",
        "dcterms:title": "CoQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/StanfordNLP/CoQA",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Conversational QA",
            "Question Answering"
        ],
        "dcat:landingPage": "https://github.com/StanfordNLP/CoQA",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Eunsol Choi",
            "He He",
            "Mohit Iyyer",
            "Mark Yatskar",
            "Wen-tau Yih",
            "Yejin Choi",
            "Percy Liang",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "A dataset for question answering in context, containing over 98,000 questions.",
        "dcterms:title": "QuAC",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/duyngu/QuAC",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "English dataset",
            "Contextual QA",
            "Question Answering"
        ],
        "dcat:landingPage": "https://github.com/duyngu/QuAC",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yiming Cui",
            "Ting Liu",
            "Wanxiang Che",
            "Li Xiao",
            "Zhipeng Chen",
            "Wentao Ma",
            "Shijin Wang",
            "Guoping Hu"
        ],
        "dcterms:description": "A Chinese dataset for machine reading comprehension with 20,000+ question-answer pairs.",
        "dcterms:title": "CMRC 2018",
        "dcterms:issued": "2019",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Chinese dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Seungyoung Lim",
            "Myungji Kim",
            "Jooyoul Lee"
        ],
        "dcterms:description": "A Korean dataset for machine reading comprehension with 70,000+ question-answer pairs.",
        "dcterms:title": "KorQuAD",
        "dcterms:issued": "2019",
        "dcterms:language": "Korean",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Korean dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pavel Eimov",
            "Leonid Boytsov",
            "Pavel Braslavski"
        ],
        "dcterms:description": "A Russian dataset for machine reading comprehension with 50,000+ question-answer pairs.",
        "dcterms:title": "SberQuAD",
        "dcterms:issued": "2019",
        "dcterms:language": "Russian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Russian dataset",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Keraron Rachel",
            "Guillaume Lancrenon",
            "Mathilde Bras",
            "FrAdAric Allary",
            "Gilles Moyse",
            "Thomas Scialom",
            "Edmundo-Pavel Soriano-Morales",
            "Jacopo Staiano"
        ],
        "dcterms:description": "A French dataset for question answering with 3,835 question-answer pairs.",
        "dcterms:title": "PIAF",
        "dcterms:issued": "2020",
        "dcterms:language": "French",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "French dataset",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mikel Artetxe",
            "Sebastian Ruder",
            "Dani Yogatama"
        ],
        "dcterms:description": "A cross-lingual dataset for question answering, containing 1,190 question-answer pairs in 10 languages.",
        "dcterms:title": "XQuAD",
        "dcterms:issued": "2019",
        "dcterms:language": "Multilingual",
        "dcterms:identifier": "https://github.com/facebookresearch/XQuAD",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Cross-lingual dataset",
            "Question Answering"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/XQuAD",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Patrick Lewis",
            "Barlas Oguz",
            "Ruty Rinott",
            "Sebastian Riedel",
            "Holger Schwenk"
        ],
        "dcterms:description": "A multilingual dataset for question answering, containing over 12,000 question-answer pairs in multiple languages.",
        "dcterms:title": "MLQA",
        "dcterms:issued": "2019",
        "dcterms:language": "Multilingual",
        "dcterms:identifier": "https://github.com/facebookresearch/MLQA",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Question Answering"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/MLQA",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]