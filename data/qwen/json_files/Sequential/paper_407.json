[
    {
        "dcterms:creator": [
            "Richard Socher",
            "Alex Perely",
            "Chris Manning"
        ],
        "dcterms:description": "A dataset for sentiment classification, distinguishing between positive and negative sentiments.",
        "dcterms:title": "SST-2",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment classification",
            "Text sentiment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Bing Liu",
            "Xiaoyan Zhu",
            "Jianyong Wang"
        ],
        "dcterms:description": "A dataset for paraphrase detection, identifying whether two sentences are paraphrases.",
        "dcterms:title": "MRPC",
        "dcterms:issued": "2011",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Paraphrase Detection"
        ],
        "dcat:keyword": [
            "Paraphrase",
            "Semantic equivalence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Quora Team"
        ],
        "dcterms:description": "A dataset for determining if two questions are semantically equivalent.",
        "dcterms:title": "QQP",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Equivalence"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Semantic equivalence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Equivalence"
        ]
    },
    {
        "dcterms:creator": [
            "Stanford Team"
        ],
        "dcterms:description": "A dataset for textual entailment, determining if a hypothesis is true given a premise.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Textual Entailment"
        ],
        "dcat:keyword": [
            "Textual entailment",
            "Hypothesis evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    },
    {
        "dcterms:creator": [
            "Stanford Team"
        ],
        "dcterms:description": "A dataset for determining if a question is entailed by a given passage.",
        "dcterms:title": "QNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Textual Entailment"
        ],
        "dcat:keyword": [
            "Question entailment",
            "Textual entailment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    },
    {
        "dcterms:creator": [
            "RTE Challenge Organizers"
        ],
        "dcterms:description": "A dataset for determining if a text entails another.",
        "dcterms:title": "RTE",
        "dcterms:issued": "2005",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Textual Entailment"
        ],
        "dcat:keyword": [
            "Textual entailment",
            "Entailment recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    }
]