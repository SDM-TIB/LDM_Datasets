<think>
Alright, I'm looking at the provided research paper to identify all the datasets mentioned. The paper is about a deep learning-based network called GCNv2 for visual odometry and SLAM. 

First, I'll go through the abstract and introduction to see if any datasets are mentioned. The abstract mentions experiments on a drone, but no specific datasets. The introduction talks about RGB-D sensors and mentions datasets like TUM and SUN-3D in later sections.

Moving to the Methods section, I see references to the TUM dataset and SUN-3D. The TUM dataset is used for training and evaluation, while SUN-3D is used for training. The authors also mention using ORB-SLAM2, which is a system, not a dataset.

In the Results section, they evaluate on TUM sequences and their own datasets collected in different environments. These include a corridor, parking lot, alcove, and kitchen. These are not standard datasets but rather custom datasets collected by the authors.

Looking at the references, I find citations for TUM and SUN-3D. TUM is cited as a benchmark for RGB-D SLAM, and SUN-3D is a large dataset of indoor scenes.

So, the datasets mentioned are:
1. TUM dataset
2. SUN-3D dataset
3. Custom datasets collected by the authors (corridor, parking lot, alcove, kitchen)

I'll extract metadata for each, focusing on creators, description, title, year, etc., as per the vocabulary.
</think>