[
    {
        "dcterms:creator": [
            "Shuankai Li",
            "Yong Yu",
            "Yongdong Zhang"
        ],
        "dcterms:description": "A dataset containing 13,320 video clips from 101 action categories, widely used for action recognition tasks.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Hao Jiang",
            "Thomas Serre",
            "Yann LeCun"
        ],
        "dcterms:description": "A dataset containing 7,042 video clips from 51 action categories, used for action recognition tasks.",
        "dcterms:title": "HMDB51",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Karol Piczak"
        ],
        "dcterms:description": "A dataset containing 2,000 audio clips from 50 environmental sound categories, used for audio event classification.",
        "dcterms:title": "ESC50",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing",
            "Sound Classification"
        ],
        "dcat:keyword": [
            "Audio dataset",
            "Environmental sounds",
            "Sound classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Joao Carreira",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A large-scale video dataset containing 240,000 video clips from 700 action categories, used for video understanding tasks.",
        "dcterms:title": "Kinetics-700",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Video Understanding"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Video understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jort Gemmeke",
            "Daniel PW Ellis",
            "Dylan Freedman",
            "Aren Jansen",
            "Wade Lawrence",
            "R Channing Moore",
            "Manoj Plakal",
            "Marvin Ritter"
        ],
        "dcterms:description": "A dataset containing audio clips from 527 audio event categories, used for audio event classification.",
        "dcterms:title": "AudioSet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing",
            "Sound Classification"
        ],
        "dcat:keyword": [
            "Audio dataset",
            "Environmental sounds",
            "Sound classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Andrew Owens",
            "Alexei A Efros"
        ],
        "dcterms:description": "A subset of Kinetics focused on audio-visual correspondence, used for self-supervised learning tasks.",
        "dcterms:title": "Kinetics-Sound",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Audio-Visual Learning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Audio-visual correspondence",
            "Self-supervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Learning"
        ]
    }
]