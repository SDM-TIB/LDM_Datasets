[
    {
        "dcterms:creator": [
            "Goyal et al."
        ],
        "dcterms:description": "A dataset for visual question answering, containing over 1 million questions about images from COCO.",
        "dcterms:title": "VQA 2.0",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Visual QA",
            "Image Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zellers et al."
        ],
        "dcterms:description": "A dataset for visual commonsense reasoning, consisting of 290k questions derived from 110k movie scenes.",
        "dcterms:title": "VCR",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Visual Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Visual Reasoning",
            "Commonsense"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Suhr et al."
        ],
        "dcterms:description": "A dataset for joint reasoning about natural language and images, focusing on semantic diversity and compositionality.",
        "dcterms:title": "NLVR2",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Language-Visual Reasoning",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Plummer et al."
        ],
        "dcterms:description": "A dataset for grounding phrases in captions to bounding regions in images, containing 30k images and nearly 250k annotations.",
        "dcterms:title": "Flickr30K",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Text-to-Image Grounding"
        ],
        "dcat:keyword": [
            "Phrase Grounding",
            "Image Annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Phrase Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Chen et al."
        ],
        "dcterms:description": "A large-scale dataset for image captioning, containing images and captions, used for pre-training.",
        "dcterms:title": "COCO",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image Captioning",
            "Visual Language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Image Captioning"
        ]
    }
]