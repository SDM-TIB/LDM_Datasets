<think>
Alright, I'm trying to figure out how to extract the datasets mentioned in the provided research paper. The paper is titled "More Efficient Topic Modelling Through a Noun Only Approach" by Fiona Martin and Mark Johnson. 

First, I'll read through the abstract and introduction to get a sense of what datasets are being used. The abstract mentions a news corpus, specifically the San Jose Mercury News (SJMN) articles from the Tipster corpus. 

Looking into the methods section, the paper details that they used a 1991 set of SJMN articles from the Tipster corpus. The corpus was processed in three versions: original, lemmatised, and lemmatised nouns only. 

I need to identify the datasets mentioned. The primary dataset is the SJMN articles from the Tipster corpus. The authors reference Harman & Liberman (1993) for the Tipster corpus. 

Now, I'll extract the metadata for this dataset. The creators are the authors of the Tipster corpus, which are Harman and Liberman. The description is based on how the paper describes the dataset: a collection of news articles from 1991, processed into different versions for topic modeling. The title is "San Jose Mercury News (SJMN) articles from the Tipster corpus." The issued year is 1993. The language is English. There's no specific identifier provided, so that's empty. The themes are "News Corpus" and "Topic Modeling." Keywords include "news articles," "topic modeling," "noun only," "lemmatised," and "part-of-speech tagging." The landing page is empty as no URL is provided. The format is text. The task is "Topic Modeling."

I don't see any other datasets mentioned in the paper, so this is the only one to include.
</think>