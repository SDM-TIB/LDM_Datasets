[
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset containing 4000 source segments, their reference translations, machine translation outputs from four SMT systems, and human estimations of post-editing effort on a scale from 1 to 4.",
        "dcterms:title": "Specia et al. 2010 Dataset",
        "dcterms:issued": "2010",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Post-editing"
        ],
        "dcat:keyword": [
            "Post-editing effort",
            "Human evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset of Irish SMT translations rated for overall quality on a scale from 1 (bad) to 4 (good).",
        "dcterms:title": "Irish SMT Dataset",
        "dcterms:issued": "",
        "dcterms:language": "Irish",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Quality Assessment"
        ],
        "dcat:keyword": [
            "Translation quality",
            "Human ratings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset of Serbian SMT translations rated for adequacy and fluency on a scale from 1 (bad) to 5 (good), with the mean value used as the direct human score.",
        "dcterms:title": "Serbian SMT Dataset",
        "dcterms:issued": "",
        "dcterms:language": "Serbian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Quality Assessment"
        ],
        "dcat:keyword": [
            "Translation adequacy",
            "Translation fluency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Datasets from the 2014 and 2015 Workshops on Machine Translation, containing translation outputs and human rankings for multiple languages.",
        "dcterms:title": "WMT14 and WMT15 Datasets",
        "dcterms:issued": "2014, 2015",
        "dcterms:language": "Multiple languages (English, French, German, Czech, Russian, Hindi, Finnish)",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Evaluation Metrics"
        ],
        "dcat:keyword": [
            "Translation evaluation",
            "Human rankings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    }
]