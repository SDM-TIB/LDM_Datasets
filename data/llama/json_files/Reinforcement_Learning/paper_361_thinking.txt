>

<think>
To extract datasets from the research paper titled "9102nuJ8]GL.sc[3v53050.5071:viXraDISCRETE SEQUENTIAL PREDICTION OF CONTINU-OUS ACTIONS FOR DEEP RLLuke MetzGoogle Brainlmetz@google.comJulian IbarzGoogle Brainjulianibarz@google.comNavdeep JaitlyGoogle Brainnjaitly@google.comJames DavidsonGoogle Brainjcdavidson@google.comABSTRACTIt has long been assumed that high dimensional continuous control problemscannot be solved effectively by discretizing individual dimensions of the actionspace due to the exponentially large number of bins over which policies wouldhave to be learned. In this paper, we draw inspiration from the recent successof sequence-to-sequence models for structured prediction problems to developpolicies over discretized spaces. Central to this method is the realization that com-plex functions over high dimensional spaces can be modeled by neural networksthat predict one dimension at a time. Speciically, we show how Q-values andpolicies over continuous spaces can be modeled using a next step prediction modelover discretized dimensions. With this parameterization, it is possible to bothleverage the compositional structure of action spaces during learning, as well ascompute maxima over action spaces (approximately). On a simple example taskwe demonstrate empirically that our method can perform global search, whicheffectively gets around the local optimization issues that plague DDPG. We applythe technique to off-policy (Q-learning) methods and show that our method canachieve the state-of-the-art for off-policy methods on several continuous controltasks.
</think>