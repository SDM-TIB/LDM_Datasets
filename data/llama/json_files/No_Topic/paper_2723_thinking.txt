>

<think>
To extract datasets from the research paper titled "Domain adaptation model for retinopathy detection from cross-domain OCT images" by Jing Wang et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the use of OCT images and digit images, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the limitations of traditional deep neural networks for retinopathy detection and the need for domain adaptation. They hint at the use of public datasets for evaluation.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention two named datasets:

1. **MNIST-USPS dataset pair**: This dataset is used for digits recognition tasks.
2. **Custom retina OCT images dataset**: This dataset is used for retinopathy detection tasks.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models, which reinforces their relevance.

Now, I will check the **references section** to find the full citations for these datasets:

- For **MNIST-USPS dataset pair**, the citation is:
  > MNIST dataset (LeCun et al., 1998)
  > USPS dataset (Geshi et al., 1999)

- For **Custom retina OCT images dataset**, the citation is:
  > Not explicitly mentioned, but the dataset is described as a custom dataset containing OCT images from two different devices.

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>