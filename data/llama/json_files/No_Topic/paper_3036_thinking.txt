>

<think>
To extract datasets from the research paper titled "Empirical Analysis of Noising Scheme based Synthetic Data Generation for Automatic Post-editing" by Hyeonseok Moon et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the use of parallel corpus for data generation, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the limitations of APE data acquisition and the need for data generation methods. They hint at the use of parallel corpus for data generation.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **Ko-En parallel corpus**: This dataset is used for data generation and evaluation.
2. **WMT**: This dataset is used for evaluation, but not explicitly mentioned as a parallel corpus.

In the **results section**, the authors confirm that these datasets were used for evaluation.

Now, I will check the **references section** to find the full citations for these datasets:

- For **Ko-En parallel corpus**, the citation is not explicitly mentioned in the paper.
- For **WMT**, the citation is:
  > Chatterjee et al. (2018). Findings of the wmt 2018 shared task on automatic post-editing. In Third Conference on Machine Translation (WMT), pages 723a738. Association for Computational Linguistics (ACL).

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>