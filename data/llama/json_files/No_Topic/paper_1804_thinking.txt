>

<think>
To extract datasets from the research paper titled "Implicit/Explicit Messages in Offensive and Abusive Language" by Tommaso Casella, Valerio Basile, Jelena Mitrovica, Inga Kartoziya, and Michael Granitzer, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the creation of a new dataset called AbuseEval v1.0.

In the **introduction**, the authors discuss the lack of datasets that take into account the degree of explicitness of abusive language.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **OLID/OffensEval**: A dataset of English tweets annotated with the target of abusive messages.
2. **AbuseEval v1.0**: A newly created dataset that annotates the explicit-implicit dimension of offensive data.
3. **HatEval**: A dataset for hate speech detection.
4. **Waseem and Hovy (2016b)**: A dataset for hate speech detection.
5. **Founta et al. (2018)**: A dataset for abusive language detection.
6. **HatEval**: A dataset for hate speech detection.
7. **CHEMDNER**: A dataset for chemical names extraction.
8. **JNLPBA**: A dataset for bio-entity recognition.
9. **BC2GM**: A dataset for gene mention recognition.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models, which reinforces their relevance.

Now, I will check the **references section** to find the full citations for these datasets:

- For **OLID/OffensEval**, the citation is:
  > Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., and Kumar, R. (2019). Predicting the Type and Target of Offensive Posts in Social Media. In Proceedings of NAACL.

- For **AbuseEval v1.0**, the citation is:
  > Casella, T., Basile, V., Mitrovica, J., Kartoziya, I., and Granitzer, M. (2020). Implicit/Explicit Messages in Offensive and Abusive Language. In Proceedings of LREC 2020.

- For **HatEval**, the citation is:
  > Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Rangel Pardo, F. M., Rosso, P., and Sanguinetti, M. (2019). SemEval-2019 task 5: Multilingual detection of hate speech against immigrants and women in Twitter.

- For **Waseem and Hovy (2016b)**, the citation is:
  > Waseem, Z. and Hovy, D. (2016b). Hateful symbols or hateful people? predictive features for hate speech detection on twitter. In Proceedings of NAACL.

- For **Founta et al. (2018)**, the citation is:
  > Founta, A. M., Djouvas, C., Chatzakou, D., Leontiadis, I., Blackburn, J., Stringhini, G., Vakali, A., Sirivianos, M., and Kourtellis, N. (2018). Large scale crowdsourcing and characterization of twitter abusive behavior. In Twelfth International AAAI Conference on Web and Social Media.

- For **CHEMDNER**, the citation is:
  > Krallinger, M., Leitner, F., Rabal, O., Vazquez, M., Oyarzabal, J., and Valencia, A. (2015). CHEMDNER: The drugs and chemical names extraction challenge. Journal of Cheminformatics, 7(Suppl 1): S1, 2015.

- For **JNLPBA**, the citation is:
  > Kim, J.-D., Ohta, T., Tsuruoka, Y., Tateisi, Y., and Collier, N. (2004). Introduction to the bio-entity recognition task at JNLPBA. In Proceedings of the 2004 Conference on Computational Natural Language Learning (CoNLL), pages 70–75, 2004.

- For **BC2GM**, the citation is:
  > Smith, L., Tanabe, L. K., Ando, R. J., Kuo, C. J., Chung, I. F., Hsu, C. N., Lin, Y. S., Klinger, R., Friedrich, C. M., Ganchev, K., et al. (2008). Overview of biocreative ii gene mention recognition. Genome biology, 9(Suppl 2):1–19, 2008.

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>