>

<think>
To extract datasets from the research paper titled "Using CollGram to Compare Formulaic Language in Human and Machine Translation" by Yves Bestgen, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the comparison of formulaic sequences in human and neural machine translation of quality newspaper articles, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the importance of comparing formulaic language in human and machine translation, but no specific datasets are mentioned.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **PLECI corpus**: A sentence-aligned translation corpus of quality newspaper articles written in French and published in Le Monde diplomatique and in English in one of the international editions of this same newspaper.
2. **British National Corpus (BNC)**: A large corpus of British English texts.
3. **COCA (Corpus of Contemporary American English)**: A large corpus of American English texts.
4. **WaCKy**: A large corpus of web texts.

In the **results section**, the authors confirm that these datasets were used for evaluation of their model.

Now, I will check the **references section** to find the full citations for these datasets:

- For **PLECI corpus**, the citation is:
  > http://collgram.pja.edu.pl

- For **British National Corpus (BNC)**, the citation is:
  > www.natcorp.ox.ac.uk

- For **COCA**, the citation is:
  > corpus.byu.edu/coca

- For **WaCKy**, the citation is:
  > http://www.bar-i-lab.org/wacky/

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>