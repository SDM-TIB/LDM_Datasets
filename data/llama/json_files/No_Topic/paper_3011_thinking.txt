>

<think>
To extract datasets from the research paper titled "Facial Expression Recognition by De-expression Residue Learning" by Huiyuan Yang, Umur Ciftci and Lijun Yin, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the use of seven public facial expression databases.

In the **introduction**, the authors discuss the limitations of previous facial expression recognition methods and the importance of using neutral face images.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention seven public facial expression databases:

1. **CK+**: A widely used dataset for facial expression recognition.
2. **Oulu-CASIA**: A dataset containing images of faces with different ethnic backgrounds.
3. **MMI**: A dataset containing images of faces with different expressions.
4. **BU-3DFE**: A 3D facial expression recognition dataset.
5. **BP4D+**: A multimodal spontaneous emotion corpus.
6. **BU-4DFE**: A 3D facial expression recognition dataset.
7. **BP4D**: A spontaneous expression database.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models.

Now, I will check the **references section** to find the full citations for these datasets:

- For **CK+**, the citation is:
  > P. Lucey, J. F. Cohn, T. Kanade, J. Saragih, Z. Ambadar, and I. Matthews. *The extended cohn-kanade dataset (ck+): A complete dataset for action unit and emotion-specified expression*. In Proceedings of the 2004 Conference on Computational Natural Language Learning (CoNLL), pages 94–101, 2004. http://www.aclweb.org/anthology/W04-1213

- For **Oulu-CASIA**, the citation is:
  > G. Zhao, X. Huang, M. Taini, S. Z. Li, and M. PietikAinen. *Facial expression recognition from near-infrared videos*. Image and Vision Computing, 29(9):607–619, 2011. http://dx.doi.org/10.1016/j.iva.2011.04.004

- For **MMI**, the citation is:
  > M. Pantic, M. Valstar, R. Rademaker, and L. Maat. *Web-based database for facial expression analysis*. In Multimedia and Expo, 2005. ICME 2005. IEEE International Conference on, pages 5–8, 2005. http://dx.doi.org/10.1109/ICME.2005.1528294

- For **BU-3DFE**, the citation is:
  > L. Yin, X. Chen, Y. Sun, T. Worm, and M. J. Rosato. *A 3D facial expression database for facial behavior research*. In Automatic face and gesture recognition, 2006. FGR 2006. 7th international conference on, pages 211–216, 2006. http://dx.doi.org/10.1109/FGR.2006.1615334

- For **BP4D+**, the citation is:
  > Z. Zhang, J. M. Girard, Y. Wu, X. Zhang, P. Liu, U. Ciftci, S. Canavan, M. Reale, A. Horowitz, H. Yang, et al. *Multimodal spontaneous emotion corpus for human behavior analysis*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3438–3446, 2016. http://dx.doi.org/10.1109/CVPR.2016.0244

- For **BU-4DFE**, the citation is:
  > L. Yin, X. Chen, Y. Sun, T. Worm, and M. J. Rosato. *A high-resolution 3D dynamic facial expression database*. In Automatic face and gesture recognition, 2008. FGR 2008. 8th international conference on, pages 1–6, 2008. http://dx.doi.org/10.1109/FGR.2008.4434453

- For **BP4D**, the citation is:
  > X. Zhang, L. Yin, J. F. Cohn, S. Canavan, M. Reale, A. Horowitz, P. Liu, and J. M. Girard. *BP4D-spontaneous: A high-resolution spontaneous 3D dynamic facial expression database*. Image and Vision Computing, 32(10):692–706, 2014. http://dx.doi.org/10.1016/j.iva.2014.04.004
</think>