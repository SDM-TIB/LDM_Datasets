>
<think>
To extract datasets from the research paper titled "Proceedings of the Workshop on Reordering for Statistical Machine Translation, pages 17a26,COLING 2012, Mumbai, December 2012.17A Tagging-style Reordering Model for Phrase-based SMTM inwei F EN G H er mann N EYHuman Language Technology and Pattern Recognition Group,Computer Science Department,RWTH Aachen University,Aachen, Germanyfeng@cs.rwth-aachen.de, ney@cs.rwth-aachen.deABSTRACTFor current statistical machine translation system, reordering is still a major problem forlanguage pairs like Chinese-English, where the source and target language have signiicantword order differences. In this paper we propose a novel tagging-style reordering model. Ourmodel converts the reordering problem into a sequence labeling problem, i.e. a tagging task. Forthe given source sentence, we assign each source token a label which contains the reorderinginformation for that token. We also design an unaligned word tag so that the unalignedword phenomenon is automatically covered in the proposed model. Our reordering model isconditioned on the whole source sentence. Hence it is able to catch long dependencies in thesource sentence. The decoder makes use of the tagging information as soft constraints so that inthe test phase (during translation) our model is very eficient. The model training on large scaletasks requests notably amounts of computational resources. We carried out experiments on iveChinese-English NIST tasks trained with BOLT data. Results show that our model improves thebaseline system by 0.98 BLEU 1.21 TER on average.KEYWORDS: statistical machine translation, reordering, conditional random ields.181 IntroductionThe systematic word order difference between two languages pose a challenge for currentstatistical machine translation (SMT) systems. The system has to decide in which order totranslate the given source words. This problem is known as the reordering problem. As shownin (Knight, 1999), if arbitrary reordering is allowed, the search problem is NP-hard.In this paper, we propose a novel tagging style reordering model. Our model converts thereordering problem into a sequence labeling problem, i.e. a tagging task. For a given sourcesentence, we assign each source token a label which contains the reordering information forthat token. We also design an unaligned word tag so that the unaligned word phenomenon isautomatically covered in the proposed model. Our model is conditioned on the whole sourcesentence. Hence it is able to capture the long dependencies in the source sentence. We choosethe conditional random ields (CRFs) approach for the tagging model. Although utilizing CRFson large scale task requests a notable amount of computational resources, the decoder makesuse of the tagging information as soft constraints. Therefore, the training procedure of ourmodel is computationally expensive while in the test phase (during translation) our model isvery eficient.The remainder of this paper is organized as follows: Section 2 reviews the related work forsolving the reordering problem. Section 3 introduces the basement of this research: the principleof statistical machine translation. Section 4 describes the proposed model. Section 5 providesthe experimental coniguration and results. Conclusion will be given in Section 6.2 Related WorkMany ideas have been proposed to address the reordering problem. Within the phrase-basedSMT framework there are mainly three stages where improved reordering could be integrated:1. Reorder the source sentence. So that the word order of source and target sentences issimilar. Usually it is done as the preprocessing step for both training data and test data.2. In the decoder, add models in the log-linear framework or constraints in the decoder toreward good reordering options or penalize bad ones.3. In the reranking framework.For the irst point, (Wang et al., 2007) used manually designed rules to reorder parse trees ofthe source sentences as a preprocessing step. Based on shallow syntax, (Zhang et al., 2007)used rules to reorder the source sentences on the chunk level and provide a source-reorderinglattice instead of a single reordered source sentence as input to the SMT system. Designingrules to reorder the source sentence is conceptually clear and usually easy to implement. In thisway, syntax information can be incorporated into phrase-based SMT systems. However, onedisadvantage is that the reliability of the rules is often language pair dependent.In the second category, researchers try to inform the decoder on what a good reordering is orwhat a suitable decoding sequence is. (Zens and Ney, 2006) used a discriminative reorderingmodel to predict the orientation of the next phrase given the previous phrase. (MariAo et al.,2006) presents a translation model that constitutes a language model of a sort of abilanguageacomposed of bilingual units. From the reordering point of view, the idea is that the correctreordering is to ind the suitable order of translation units. (Cherry, 2008) puts the syntacticcohesion as a soft constraint in the decoder to guide the decoding process to choose thosetranslations that do not violate the syntactic structure of the source sentence. Adding new19features in the log-linear framework has the advantage that the new feature has access to thewhole search space. Another advantage of methods in this category is that we let the decoderdecide the weights of features, so that even if one model gives wrong estimation sometimes, itcan still be corrected by other models. Our work in this paper belongs to this category.In the reranking step, the system has the last opportunity to choose a good translation. (Ochet al., 2004) describe the use of syntactic features in the rescoring step. They report the mostuseful feature is IBM Model 1 score. The syntactic features contribute very small gains. Anotherdisadvantage of carrying out reordering in reranking is the representativeness of the N-best listis often a question mark.3 Translation System OverviewIn this section, we are going to describe the phrase-based SMT system we used for theexperiments.In statistical machine translation, we are given a source language sentencef J1 = f1... f j... fJ. The objective is to translate the source into a target language sentenceeI1 = e1... ei... eI. The strategy is among all possible target language sentences, we will choosethe one with the highest probability:EeEIi = arg maxI,eI1 {P r(eI1f J1 )}|(1)We model P r(eI2002):1|f J1 ) directly using a log-linear combination of several models (Och and Ney,MexpImhm(eI1, f J1 )P r(eI1|f J1 ) =expm=1PMI0I 0,e0P1m=1PImhm(e0I 01, f J1 )(2)The denominator is to make the P r(eIon the source sentence f J1|1. For search, the decision rule is simply:f J1 ) to be a probability distribution and it depends onlyEeEIi = arg maxI,eI1Mm=1XnImhm(eI1, f J1 )o(3)The model scaling factors IM1 are trained with Minimum Error Rate Training (MERT).In this paper, the phrase-based machine translation system is utilized (Och et al., 1999; Zenset al., 2002; Koehn et al., 2003). The translation process consists in segmenting of the sourcesentence according to the phrase table which is built from the word alignment. The translationof each of these segments consists just in extracting the target side from the phrase pair. With thecorresponding target side, the inal translation is the composition of these translated segments.In this last step, reordering is allowed.4 Tagging-style Reordering ModelIn this section, we describe the proposed model. First we will describe the training process.Then we explain how to use the model in the decoder.20e1e2e3e4e5e6e7e1e2e3e4e5e6e7f1f3f1f a2f3f2f3f4(a)f4f4(c)f5f6f6f7f1f a2f3f6f7f5+21a1af5f6f7f4(b)0f4(d)BEGIN-Rmono Unalign Lreorder-Rmono Lmono-Rmono Lmono-Rreorder Lreorder-Rmono END-Lmonof1f a2f3f4(e)f5f6f7Figure 1: Modeling process illustration.4.1 Modeling{1, the system translates it into the target sentence e7a1 = 3, a3 = 2, a4 = 4, a4 = 5, a5 = 7, a6 = 6, a7 = 6}Figure 1 demonstrates the modeling steps. The irst step is word alignment training. Figure1(a) is an example after GIZA++ training. If we regard this alignment as a translation result,i.e. given the source sentence f 71. Thealignment link setreveals the decodingprocess, i.e. the alignment implies the order in which the source words should be translated,e.g. the irst generated target word e1 has no alignment, we can regard it as a translationfrom a NULL source word; then the second generated target word e2 is translated from f3. Wereorder the source side of the alignment to get Figure 1(b). Figure 1(b) implies the sourcesentence decoding sequence information, which is depicted in Figure 1(c). Using this examplewe describe the strategies we used for special cases in the transformation from Figure 1(b) toFigure 1(c):aaaaignore the unaligned target word, e.g. e1the unaligned source word should follow its preceding word, the unaligned feature iskept with asymbol, e.g. f a2 is after f1when one source word is aligned to multiple target words, only keep the alignment thatlinks the source word to the irst target word, e.g. f4 is linked to e5 and e6, only f4e5is kept. In other words, every source word appears only once in the source decodingsequence.aawhen multiple source words are aligned to one target word, put together the sourcewords according to their original relative positions, e.g. e6 is linked to f6 and f7. So inthe decoding sequence, f6 is before f7.Now Figure 1(c) shows the original source sentence and its decoding sequence. By using thestrategies above, it is guaranteed that the source sentence and its decoding sequence has theexactly same length. Hence the relation can be modeled by a function F ( f ) which assigns avalue for each of the source word f. Figure 1(d) manifests this function. The positive function21values mean that compared to the original position in the source sentence, its position in thedecoding sequence should move right, and vice versa. If the function value is 0, the wordasposition in original source sentence and its decoding sequence is same. For example, f1 is theirst word in the source sentence but it is the second word in the decoding sequence. So itsfunction value is +1 (move right one position).Now Figure 1(d) converts the reordering problem into a sequence labeling or tagging problem.To move the computational cost to a reasonable level, we do a inal simpliication step in Figure1(e). Suppose the longest sentence length is 100, then according to Figure 1(d), there are 200tags (from -99 to +99 plus the unalign tag). As we will see later, this number is too large forour task. We instead design nine tags. For a source word f j in one source sentence f J1, the tagof f j will be one of the following:1 translated before f j (Lmono for left monotonic)BEGIN-Rmono j = 1 and f j+1 is translated after f j (Rmono for right monotonic)BEGIN-Rreorder j = 1 and f j+1 is translated before f j (Rreorder for right reordered)END-Lmono j = J and f jaEND-Lreorder j = J and f jLmono-Rmono 1 < j < J and f j1 translated before f j and f j translated before f j+1aLmono-Rreorder 1 < j < J and f j1 translated before f j and f j translated after f j+1a1 translated after f j and f j translated before f j+1Lreorder-Rmono 1 < j < J and f ja1 translated after f j and f j translated after f j+1Lreorder-Rreorder 1 < j < J and f jUnaligned f j is an unaligned source word1 translated after f j (Lreorder for left reordered)aaUp to this point, we have converted the reordering problem into a tagging problem with ninetags. The transformation in Figure 1 is conducted for all the sentence pairs in the bilingualtraining corpus. After that, we have built an aannotateda corpus for the training. For thissupervised structure learning task, we choose the approach conditional random ields (CRFs)(Lafferty et al., 2001; Sutton and Mccallum, 2006; Lavergne et al., 2010). More speciically, weadopt the linear-chain CRFs. However, even for the simple linear-chain CRFs, the complexity oflearning and inference grows quadratically with respect to the number of output labels and theamount of structural features which are with regard to adjacent pairs of labels. Hence, to makethe computational cost as low as possible, two measures have been taken. Firstly, as describedabove we reduce the number of tags to nine. Secondly, we add source sentence part-of-speech(POS) tags to the input. For features with window size one to three, both source words and itsPOS tags are used. For features with window size four and ive, only POS tags are used.4.2 DecodingOnce the CRFs training is inished, we make inference on develop and test corpora. After thatwe get the labels of the source sentences that need to be translated. In the decoder, we add anew model which checks the labeling consistence when scoring an extended state. During thesearch, a sentence pair ( f J1 which consistsof K phrase pairs. Each sk = (ik; bk, jk) is a triple consisting of the last position ik of the kthtarget phrase Eek. The start and end position of the kth source phrase Efk are bk and jk. Supposethe search state is now extended with a new phrase pair (1) will be formally splitted into a segmentation SKEfk, Eek):1, eIEfk := f bk... f jk(4)22Eek := eik1+1... eik(5)aaWe have access to the old coverage vector, from which we know if the left neighboring sourceword f bk1 and the right neighboring source word f jk+1 of the new phrase have been translated.We also have the word alignment within the new phrase pair, which is stored during thephrase extraction process. Based on the old coverage vector and alignment, we can repeat thetransformation in Figure 1 to calculate the labels for the new phrase. The added model willthen check the consistence between the calculated labels and the labels predicted by the CRFs.The number of source words that have inconsistent labels is regarded as penalty and then thepenalty is added as a new feature into the log-linear framework.5 ExperimentsIn this section, we describe the baseline setup, the CRFs training results and translationexperimental results.5.1 Experimental SetupOur baseline is a phrase-based decoder, which includes the following models: an n-gram target-side language model (LM), a phrase translation model and a word-based lexicon model. Thelatter two models are used for both directions: p( ff ). Additionally we use phrasecount features, word and phrase penalty. The reordering model for the baseline system is thedistance-based jump model which uses linear distance. This model does not have hard limit.We list the important information regarding the experimental setup below. All those conditionshave been kept same in this work.e) and p(e||aaaaalowercased training data (Table 1) from the BOLT taskalignment trained with GIZA++development corpus: NIST06 test corpora: NIST02 03 04 05 and 085-gram LM (1 694 412 027 running words) trained by SRILM toolkit (Stolcke, 2002) withmodiied Kneser-Ney smoothingtraining data: target side of bilingual data.BLEU (Papineni et al., 2001) and TER (Snover et al., 2005) reportedall scores calculated in lowercase way.Wapiti toolkit (Lavergne et al., 2010) used for CRFsSentencesRunning WordsVocabularyChineseEnglish5 384 856115 172 7481 125 437129 820 318739 251Table 1: training data statistics5.2 CRFs Training ResultsTable 1 contains the data statistics used for translation model and LM. For the reordering model,we take two further iltering steps. Firstly, we delete the sentence pairs if the source sentencelength is one. When the source sentence has only one word, the translation will be alwaysmonotonic and the reordering model does not need to learn this. Secondly, we delete thesentence pairs if the source sentence contains more than three contiguous unaligned words.23When this happens, the sentence pair is usually low quality hence not suitable for learning.The main purpose of the two iltering steps is to further lay down the computational burden.We then divide the corpus into three parts: train, validation and test. The source side datastatistics for CRFs training is given in Table 2 (target side has only 9 labels). The toolkit WapitiSentencesRunning WordsVocabularytrain2 973 51962 263 295454 951validation400 0008 370 361149686test400 0008 382 086150 007Table 2: reordering model training data statistics(Lavergne et al., 2010) is used in this paper. We choose the classical optimization algorithmlimited memory BFGS (L-BFGS) (Liu and Nocedal, 1989). For regularization, Wapiti uses boththe a1 and a2 penalty terms, yielding the elastic-net penalty of the formI1I A kk1 +I22 A kI 22k(6)kkI In this work, we use as many features as possible because a1 penalty I11 is able to yieldsparse parameter vectors, i.e. using a a1 penalty term implicitly performs the feature selection.On a cluster with two AMD Opteron(tm) Processor 6176 (total 24 cores), the training time isabout 16 hours, peak memory is around 120G. Several experiments have been done to indthe suitable hyperparameters I1 and I2. We choose the model with lowest error rate on thevalidation corpus for the translation experiments. The error rate of the chosen model on testcorpus is 25.75% for token error rate and 69.39% for sequence error rate. The error ratevalues are much higher than what we usually see in part-of-speech tagging task. The mainreason is that the aannotateda corpus is converted from word alignment which contains a lot oferrors. However, as we will show later, the learned CRFs model helps to improve the translationquality. The feature template we set initially will generate 722 999 637 features. After training36 902 363 features are kept.5.3 Translation ResultsResults are summarized in Table 3. Automatic measure BLEU and TER scores are provided. Alsowe report signiicance testing results on both BLEU and TER. We perform bootstrap resamplingwith bounds estimation as described in (Koehn, 2004). We use the 95% conidence threshold(denoted by a in the table) to draw signiicance conclusions. Besides the ive test corpora, weadd a column avg. to show the average improvements. We also add a column Index for scorereference convenience.From Table 3 we see that our proposed reordering model is able to improve the baseline by0.98 BLEU and 1.21 TER on average. The largest BLEU improvement 1.11 is from NIST04 andthe largest TER improvement 1.57 is from NIST03. For line 2 and 6, the signiicance test wasdone and most scores are better than their corresponding baseline values with more than 95%conidence (scores marked with a).We also compare our model with the widely used Moses Lexicalized Reordering Model (Koehnet al., 2007). Line 3 and 7 are the results. Results show that for BLEU both model achieve almostsame results (average improvement 0.98 BLEU versus 0.99 BLEU). For TER, our tagging-stylereordering model is 0.25 points better (average improvement 1.21 TER versus 0.96 TER). When24SystemsNIST02 NIST03 NIST04 NIST05 NIST08avg.Indexbaselinebaseline+CRFsbaseline+Mosesbaseline+CRFs+Mosesbaselinebaseline+CRFsbaseline+Mosesbaseline+CRFs+Moses33.6034.5334.8735.4161.3660.14a60.0759.33BLEU scores35.7336.56a36.4037.24TER scores59.1257.91a58.4257.4434.2935.1934.9035.6360.4858.91a59.0858.4832.1533.30a33.4333.9860.9459.77a59.7459.1226.3427.41a27.4527.4765.1764.30a64.5064.43-0.980.991.52-1.210.961.6512345678Table 3: Experimental results
</think>