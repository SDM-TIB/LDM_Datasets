>

<think>
To extract datasets from the research paper titled "PanoRecon: Real-Time Panoptic 3D Reconstruction from Monocular Video" by Dong Wu, Zike Yan, and Hongbin Zha, I will follow a systematic approach.

First, I will read through the **abstract, introduction, methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the online reconstruction of 3D geometry and semantic labeling from monocular video, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the limitations of existing methods for 3D scene understanding and the need for a unified task of panoptic 3D reconstruction. They hint at the evaluation of their method on various datasets.

Next, I will focus on the **methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the ScanNet dataset:

1. **ScanNet**: This dataset consists of 1613 scans across 807 distinct scenes with RGB images, groundtruth depths, camera poses, surface reconstructions, and instance-level semantic segmentations.

In the **results section**, the authors confirm that the ScanNet dataset was used for evaluation of their method.

Now, I will check the **references section** to find the full citation for the ScanNet dataset:

> Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias NieAner. *ScanNet: Richly-annotated 3d reconstructions of indoor scenes*. Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5828a5839, 2017. https://doi.org/10.1109/CVPR.2017.1707

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>