>

<think>
To extract datasets from the research paper titled "QUASE: Question-Answer Driven Sentence Encoding" by Hangfeng He, Qiang Ning, and Dan Roth, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the use of various datasets for evaluation, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the limitations of using QA data for other tasks and propose the QUASE framework. They mention several datasets, including:

1. **TriviaQA**: A large-scale QA dataset.
2. **NewsQA**: A QA dataset.
3. **SQuAD**: A QA dataset.
4. **QA-RE**: A relation extraction dataset in QA format.
5. **Large QA-SRL**: A large-scale QA-SRL dataset.
6. **QAMR**: A QA dataset.

In the **materials and methods section**, the authors mention that they use these datasets for further pre-training and evaluation of the QUASE model.

In the **results section**, the authors confirm that these datasets were used for evaluation of the QUASE model.

Now, I will check the **references section** to find the full citations for these datasets:

- For **TriviaQA**, the citation is:
  > Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. *TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension*. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1601-1611, 2017.

- For **NewsQA**, the citation is:
  > Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Ka-heer Suleman. *NewsQA: A machine comprehension dataset*. In Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 191-200, 2017.

- For **SQuAD**, the citation is:
  > Pradeep Dasigi, Nelson F. Liu, Matthew Peters, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. *SQuAD: 100,000+ questions from machine comprehension of text*. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 188-197, 2016.

- For **QA-RE**, the citation is:
  > Omer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. *Zero-shot relation extraction via reading comprehension*. In CoNLL, pages 333-342, 2017.

- For **Large QA-SRL**, the citation is:
  > Nicholas FitzGerald, Julian Michael, Luheng He, and Luke Zettlemoyer. *Large-scale QA-SRL parsing*. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 2051-2060, 2018.

- For **QAMR**, the citation is:
  > Julian Michael, Gabriel Stanovsky, Luheng He, Ido Dagan, and Luke Zettlemoyer. *Crowdsourcing question-answer meaning representations*. NAACL.
</think>