>

<think>
To extract datasets from the research paper titled "Transformer-based Model for Single Documents Neural Summarization" by Elozino Egonmwan and Yllias Chali, I will follow a systematic approach.

First, I will read through the **abstract, introduction, methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the CNN/DailyMail and Newsroom datasets.

In the **introduction**, the authors discuss the CNN/DailyMail and Newsroom datasets.

Next, I will focus on the **methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **CNN/DailyMail dataset**: This dataset is used for extractive summarization.
2. **Newsroom dataset**: This dataset is used for abstractive summarization.

In the **results section**, the authors confirm that these datasets were used for evaluation.

Now, I will check the **references section** to find the full citations for these datasets:

- For **CNN/DailyMail dataset**, the citation is:
  > Not found

- For **Newsroom dataset**, the citation is:
  > Grusky et al. (2018) Newsroom: A dataset of 1.3 million summaries with diverse extractive strategies.

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>