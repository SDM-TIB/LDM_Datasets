

<think>
To analyze the generalizability, we follow the experimental setting of Guo et al. (2019), where all baselines and the proposed model are pretrained and evaluated directly on the large WiC training set without fine-tuning. 
</think>