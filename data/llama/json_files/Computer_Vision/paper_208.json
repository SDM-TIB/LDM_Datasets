[
    {
        "dcterms:creator": [
            "Shikhar Vashishth",
            "Manik Bhandari",
            "Piyush Rai",
            "Chiranjib Bhattacharyya",
            "Partha Talukdar"
        ],
        "dcterms:description": "Wikipedia2 corpus is a large dataset used for training and evaluation of the proposed SynGCN and SemGCN models.",
        "dcterms:title": "Wikipedia2 corpus",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://dumps.wikimedia.org/enwiki/20180301/",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Wikipedia",
            "Corpus",
            "Word Embeddings",
            "SynGCN",
            "SemGCN"
        ],
        "dcat:landingPage": "https://dumps.wikimedia.org/enwiki/20180301/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Embeddings",
            "Named Entity Recognition",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher D. Manning",
            "Hittin Jain",
            "Jamal E. Lavasani",
            "Shiyu Chang"
        ],
        "dcterms:description": "Stanford CoreNLP parser is a dataset used for dependency parse graph construction.",
        "dcterms:title": "Stanford CoreNLP parser",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "Manning et al. (2014)",
        "dcat:theme": [
            "Natural Language Processing",
            "Dependency Parsing"
        ],
        "dcat:keyword": [
            "Stanford CoreNLP",
            "Parser",
            "Dependency Parsing"
        ],
        "dcat:landingPage": "https://nlp.stanford.edu/software/corenlp.shtml",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Dependency Parsing"
        ]
    }
]