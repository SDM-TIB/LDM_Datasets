>

<think>
To extract datasets from the research paper titled "FastSpeech: Fast, Robust and Controllable Text to Speech" by Yi Ren, Xu Tan, Tao Qin, Sheng Zhao, Zhou Zhao, and Tie-Yan Liu, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the optimization and comparison of representations for the text-to-speech task, which suggests that datasets are likely involved.

In the **introduction**, the authors discuss the limitations of traditional text-to-speech systems and the importance of generating high-quality speech in parallel.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **LJSpeech dataset**: This dataset is used for evaluation of the proposed FastSpeech model.
2. **VCTK dataset**: This dataset is used for evaluation of the proposed FastSpeech model.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models, which reinforces their relevance.

Now, I will check the **references section** to find the full citations for these datasets:

- For **LJSpeech dataset**, the citation is:
  > Keith Ito. The LJ Speech Dataset. https://keithito.com/LJ-Speech-Dataset/, 2017.

- For **VCTK dataset**, the citation is:
  > David V. Prokhorov, et al. The VCTK corpus: A large-scale corpus for the speech synthesis task. In Proceedings of the 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 5059â€“5063, 2017. https://doi.org/10.1109/ICASSP.2017.8002241

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>