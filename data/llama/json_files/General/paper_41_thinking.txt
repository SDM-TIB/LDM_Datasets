>

<think>
To extract datasets from the research paper titled "Transformer-based Automatic Post-Editing Model with Joint Encoder and Multi-source Attention of Decoder" by WonKee Lee, Jaehun Shin, and Jong-hyeok Lee, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the WMT19 English-German APE dataset and the eSCAPE-NMT dataset.

In the **introduction**, the authors discuss the WMT19 English-German APE dataset and the eSCAPE-NMT dataset.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **WMT19 English-German APE dataset**: This dataset is used for automatic post-editing tasks.
2. **eSCAPE-NMT dataset**: This dataset is used as additional training data for the model.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models.

Now, I will check the **references section** to find the full citations for these datasets:

- For **WMT19 English-German APE dataset**, the citation is:
  > Rajen Chatterjee, Matteo Negri, Raphael Rubino, and Marco Turchi. 2018. Findings of the WMT 2018 Shared Task on Automatic Post-Editing. In Proceedings of the Third Conference on Machine Translation: Shared Task Papers, page 710-725.

- For **eSCAPE-NMT dataset**, the citation is:
  > Matteo Negri, Marco Turchi, Rajen Chatterjee, and Nicola Bertoldi. 2018. ESCAPE: a Large-scale Synthetic Corpus for Automatic Post-Editing. In International Proceedings of Conference and on Evaluation (LREC-2018).

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>