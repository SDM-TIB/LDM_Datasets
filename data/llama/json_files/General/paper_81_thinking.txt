>

<think>
To extract datasets from the research paper titled "HIBERT: Document Level Pre-training of Hierarchical BidirectionalTransformers for Document Summarization" by Xingxing Zhang, Furu Wei and Ming Zhou, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the CNN/Dailymail and New York Times datasets.

In the **introduction**, the authors discuss the CNN/Dailymail and New York Times datasets.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for evaluation. Here, the authors mention the following datasets:

1. **CNN/Dailymail dataset**: This dataset is used for document summarization.
2. **New York Times dataset**: This dataset is used for document summarization.

In the **results section**, the authors confirm that these datasets were used for extrinsic evaluation of their models, which reinforces their relevance.

Now, I will check the **references section** to find the full citations for these datasets:

- For **CNN/Dailymail dataset**, the citation is:
  > Hermann, Karl Moritz, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. *Teaching machines to read and comprehend*. In Advances in Neural Information Processing Systems, pages 1680–1690, 2015.

- For **New York Times dataset**, the citation is:
  > Durrett, Greg, Taylor Berg-Kirkpatrick, and Dan Klein. *Learning-based single-document summarization with compression and anaphoricity constraints*. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1998–2008, 2016.

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>