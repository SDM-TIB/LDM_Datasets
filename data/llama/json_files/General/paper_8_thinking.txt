>

<think>
To extract datasets from the research paper titled "XQA: A Cross-lingual Open-domain Question Answering Dataset" by Jiahua Liu, Yankai Lin, Zhiyuan Liu, and Maosong Sun, I will follow a systematic approach.

First, I will read through the **abstract, introduction, materials and methods, and results sections** to identify any datasets that are mentioned or referenced. The abstract mentions the construction of a novel dataset XQA for cross-lingual OpenQA research.

In the **introduction**, the authors discuss the importance of cross-lingual OpenQA and the lack of existing datasets for this task.

Next, I will focus on the **materials and methods section**, particularly the subsections that detail the datasets used for the XQA task. Here, the authors mention the following datasets:

1. **XQA dataset**: This dataset consists of a training set in English, and development and test sets in eight other languages.
2. **Wikipedia**: The authors use Wikipedia as a source for collecting questions and answers.
3. **WikiData**: The authors use WikiData as a knowledge base to match answers with entity types.

In the **results section**, the authors confirm that these datasets were used for the XQA task.

Now, I will check the **references section** to find the full citations for these datasets:

- For **XQA dataset**, the citation is:
  > Jiahua Liu, Yankai Lin, Zhiyuan Liu, and Maosong Sun. *XQA: A Cross-lingual Open-domain Question Answering Dataset*. arXiv preprint arXiv:1901.07291.

- For **Wikipedia**, the citation is:
  > Wikipedia. *Wikipedia*. https://en.wikipedia.org/

- For **WikiData**, the citation is:
  > Wikidata. *Wikidata*. https://www.wikidata.org/

After gathering this information, I will compile the dataset entries into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their citations from the paper.
</think>