>

<think>
To extract datasets from the research paper titled "French Question Answering Dataset" by Martin daHoischmidt Wacim BelblidiaTom BrendlA Quentin HeinrichIlluin TechnologyParis, France{martin, wacim, tom, quentin}@illuin.techMaxime VidalETH Zurichmvidal@student.ethz.chAbstractRecent advances in the ield of languagemodeling have improved state-of-the-art re-sults on many Natural Language Process-ing tasks. Among them, Reading Compre-hension has made signiicant progress overthe past few years. However, most resultsare reported in English since labeled re-sources available in other languages, suchas French, remain scarce. In the presentwork, we introduce the French QuestionAnswering Dataset (FQuAD). FQuAD isa French Native Reading Comprehensiondataset of questions and answers on aset of Wikipedia articles that consists of25,000+ samples for the 1.0 version and60,000+ samples for the 1.1 version. Wetrain a baseline model which achieves anF1 score of 92.2 and an exact match ratioof 82.1 on the test set. In order to trackthe progress of French Question Answeringmodels we propose a leader-board and wehave made the 1.0 version of our datasetfreely available at https://illuin-tech.github.io/FQuAD-explorer/.1IntroductionCurrent progress in language modeling has led toincreasingly successful results on various NaturalLanguage Processing (NLP) tasks such as Partof Speech Tagging (PoS), Named Entity Recogni-tion (NER) and Natural Language Inference (NLI).Large amounts of unstructured text data availablefor most languages have facilitated the develop-ment of language models. Therefore, the releasesof language speciic models in Japanese, Chinese,German and Dutch [de Vries et al., 2019], amongstother languages, are now thriving as well as mul-tilingual models [Pires et al., 2019] and [Conneauet al., 2019]. Recently, two French language models,CamemBERT [Martin et al., 2019] and FlauBERT[Le et al., 2019], were released.However, language speciic datasets are costlyand diicult to collect. This is especially the casewith the Reading Comprehension task [Richard-son et al., 2013]. On one hand, numerous Englishdatasets have been released such as SQuAD1.1 [Ra-jpurkar et al., 2016], SQuAD2.0 [Rajpurkar et al.,2018] or CoQA [Reddy et al., 2018] that fosteredimportant and impressive progress for English Ques-tion Answering models over the past few years. Onthe other hand, the lack of native language anno-tated datasets apart from English is one of themain reasons why the development of language spe-ciic Question Answering models is slower. This isnamely the case for French.To tackle this problem, substantial eiorts havebeen carried out recently to come up with nativeReading Comprehension datasets in for instanceKorean [Lim et al., 2019], Russian [Eimov et al.,2019] and Chinese [Cui et al., 2019]. A more ap-pealing solution in terms of cost and time eiciencyrelies on leveraging the advances in Neural Ma-chine Translation (NMT) to translate the Englishdatasets in target languages to ine-tune the lan-guage model on the translated dataset. This is forinstance the case of Carrino et al. where SQuAD1.1is translated in Spanish in order to train a mul-tilingual model to answer Spanish questions. Analternative is proposed by [Artetxe et al., 2019]and [Lewis et al., 2019] where the authors providea cross-lingual evaluation benchmark to enhancethe development of cross-lingual Question Answer-ing models that can transfer to a target languagewithout requiring training data in that language.However, in both cases, the reported performancesfail to reach English comparable results on otherlanguages.In order to ill the gap for the French language,we release a French Reading Comprehension datasetsimilar to SQuAD1.1. The dataset consists ofFrench native questions and answers samples anno-tated by a team of university students. The datasetcomes in two versions. First FQuAD1.0, containingover 25,000+ samples. Second, FQuAD1.1 contain-ing over 60,000+ samples. The 35k+ additionalsamples have been annotated with more demand-1 ing guidelines to strengthen complexity of the dataand model to make the task harder. More specif-ically, the training, development and test sets ofFQuAD1.0 contain respectively 20703, 3188 and2189 samples. And the training, development andtest sets of FQuAD1.1 contain respectively 50741,5668 and 5594 samples.In order to evaluate the FQuAD dataset, weperform various experiments by ine-tuning BERTbased Question Answering models on both versionsof the FQuAD dataset. Our experiments cover notonly the recently released French pre-trained lan-guage models CamemBERT [Martin et al., 2019]and FlauBERT [Le et al., 2019] but also multilin-gual models such as mBERT [Pires et al., 2019],XLM-RoBERTa [Conneau et al., 2019] in order tobetter understand how multilingual models performon native datasets other than English.Finally, we perform two types of cross-lingualReading Comprehension experiences. First, we eval-uate the performance of the zero-shot cross-lingualtransfer learning approach as stated in [Artetxeet al., 2019] and [Lewis et al., 2019] on our newlyobtained native French dataset. Second, we evalu-ate the performance of the translation approach byine-tuning models on the French translated versionof SQuAD1.1. The results of these two experimentshelp to better understand how the two cross-lingualapproaches actually perform on a native dataset.
</think>