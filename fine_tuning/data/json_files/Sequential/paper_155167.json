[
    {
        "dcterms:creator": [
            "S. Merity",
            "C. Xiong",
            "J. Bradbury",
            "R. Socher"
        ],
        "dcterms:description": "A collection of high-quality Wikipedia articles tokenized at the word level, containing 103 million words.",
        "dcterms:title": "Wikitext-103",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Generation"
        ],
        "dcat:keyword": [
            "Wikipedia",
            "Language Modeling",
            "Text Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling",
            "Text Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. Wu",
            "R. Child",
            "D. Luan",
            "D. Amodei",
            "I. Sutskever"
        ],
        "dcterms:description": "A dataset constructed from webpages linked to on Reddit, containing 7.7 billion words.",
        "dcterms:title": "WebText",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Generation"
        ],
        "dcat:keyword": [
            "Web Pages",
            "Language Modeling",
            "Text Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling",
            "Text Generation"
        ]
    }
]