[
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.-C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J. N. Chang",
            "S. Lee",
            "S. S. Narayanan"
        ],
        "dcterms:description": "The IEMOCAP dataset is an interactive emotional dyadic motion capture database that includes recordings of actors performing scripted and improvised dialogues, annotated with emotional labels.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Analysis"
        ],
        "dcat:keyword": [
            "Emotion recognition",
            "Speech dataset",
            "Dyadic interactions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Busso",
            "S. Parthasarathy",
            "A. Burmania",
            "M. AbdelWahab",
            "N. Sadoughi",
            "E. M. Provost"
        ],
        "dcterms:description": "MSP-IMPROV is an acted corpus of dyadic interactions designed to study emotion perception, featuring various emotional expressions performed by actors.",
        "dcterms:title": "MSP-IMPROV",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Perception"
        ],
        "dcat:keyword": [
            "Dyadic interactions",
            "Emotion perception",
            "Acted corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Perception Study"
        ]
    },
    {
        "dcterms:creator": [
            "R. Lotfian",
            "C. Busso"
        ],
        "dcterms:description": "The MSP-Podcast dataset is built by retrieving emotional speech from existing podcast recordings, aiming to create a naturalistic and emotionally balanced speech corpus.",
        "dcterms:title": "MSP-Podcast",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Naturalistic Speech"
        ],
        "dcat:keyword": [
            "Podcast recordings",
            "Emotionally balanced",
            "Speech corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    }
]