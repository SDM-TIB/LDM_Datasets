[
    {
        "dcterms:creator": [
            "Yuke Zhu",
            "Oliver Groth",
            "Michael Bernstein",
            "Li Fei-Fei"
        ],
        "dcterms:description": "A dataset containing 327,939 multiple-choice QA pairs on 47,300 COCO images, with object-level grounding annotations linking object mentions in questions to their bounding boxes in the images.",
        "dcterms:title": "Visual7W",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Image Understanding"
        ],
        "dcat:keyword": [
            "QA pairs",
            "object grounding",
            "multiple-choice",
            "COCO images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Antol",
            "A. Agrawal",
            "J. Lu",
            "M. Mitchell",
            "D. Batra",
            "C. L. Zitnick",
            "D. Parikh"
        ],
        "dcterms:description": "A dataset for visual question answering that includes a variety of questions and answers based on images.",
        "dcterms:title": "VQA",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "QA dataset",
            "visual questions",
            "image understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Malinowski",
            "M. Fritz"
        ],
        "dcterms:description": "A multi-world approach to question answering about real-world scenes based on uncertain input, focusing on indoor scene RGB-D images.",
        "dcterms:title": "DAQUAR",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "QA dataset",
            "indoor scenes",
            "RGB-D images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "L. Yu",
            "E. Park",
            "A. C. Berg",
            "T. L. Berg"
        ],
        "dcterms:description": "A dataset for fill-in-the-blank image generation and question answering, providing a unique approach to visual QA.",
        "dcterms:title": "Visual Madlibs",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "fill-in-the-blank",
            "image generation",
            "QA dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Ren",
            "R. Kiros",
            "R. Zemel"
        ],
        "dcterms:description": "A dataset exploring models and data for image question answering, focusing on the relationship between images and questions.",
        "dcterms:title": "COCO-QA",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "QA dataset",
            "image question answering",
            "COCO images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "H. Gao",
            "J. Mao",
            "J. Zhou",
            "Z. Huang",
            "L. Wang",
            "W. Xu"
        ],
        "dcterms:description": "A dataset and methods for multilingual image question answering, focusing on the interaction between language and images.",
        "dcterms:title": "Baidu",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "multilingual",
            "image question answering",
            "QA dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "B. Plummer",
            "L. Wang",
            "C. Cervantes",
            "J. Caicedo",
            "J. Hockenmaier",
            "S. Lazebnik"
        ],
        "dcterms:description": "A dataset that collects region-to-phrase correspondences for richer image-to-sentence models, enhancing visual understanding.",
        "dcterms:title": "Flickr30K",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "region-to-phrase",
            "image-to-sentence",
            "QA dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L.-J. Li",
            "D. A. Shamma",
            "M. Bernstein",
            "L. Fei-Fei"
        ],
        "dcterms:description": "A dataset that connects language and vision using crowdsourced dense image annotations, providing a comprehensive resource for visual understanding.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arxiv:1602.07332",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "dense annotations",
            "language and vision",
            "QA dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]