[
    {
        "dcterms:creator": [
            "K. Fang",
            "T.-L. Wu",
            "D. Yang",
            "S. Savarese",
            "J. J. Lim"
        ],
        "dcterms:description": "The OPRA dataset aims to use demonstration videos for object affordance inference. Each sample contains a video, an object image, affordance class, and annotations of the interacting regions on the object image.",
        "dcterms:title": "OPRA (Online Product Review dataset for Affordance)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Affordance"
        ],
        "dcat:keyword": [
            "Demonstration videos",
            "Object affordance",
            "Interaction regions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Affordance Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "D. Damen",
            "H. Doughty",
            "G. M. Farinella",
            "S. Fidler",
            "A. Furnari",
            "E. Kazakos",
            "D. Moltisanti",
            "J. Munro",
            "T. Perrett",
            "W. Price",
            "M. Wray"
        ],
        "dcterms:description": "The EPIC-KITCHENS dataset contains a large number of egocentric videos of activities in kitchens. Each clip contains an action label and an object, with each frame having a bounding box of the object that interacts with the person.",
        "dcterms:title": "EPIC (EPIC-KITCHENS)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Egocentric Vision"
        ],
        "dcat:keyword": [
            "Egocentric videos",
            "Action recognition",
            "Object interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Affordance Grounding"
        ]
    }
]