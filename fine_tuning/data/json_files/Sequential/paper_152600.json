[
    {
        "dcterms:creator": [
            "M.S. Aliakbarian",
            "F.S. Saleh",
            "M. Salzmann",
            "B. Fernando",
            "L. Petersson",
            "L. Andersson"
        ],
        "dcterms:description": "VIENA2 is a large-scale dataset for action anticipation in driving scenarios, covering 5 generic driving scenarios with a total of 25 distinct action classes. It contains over 15K full HD videos, each annotated with an action label, and includes synchronized vehicle dynamics measurements.",
        "dcterms:title": "VIENA2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automated Driving",
            "Action Anticipation"
        ],
        "dcat:keyword": [
            "Driving scenarios",
            "Action anticipation",
            "Video dataset",
            "Vehicle dynamics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action anticipation",
            "Action recognition",
            "Temporal action localization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Jain",
            "H.S. Koppula",
            "S. Soh",
            "B. Raghavan",
            "A. Singh",
            "A. Saxena"
        ],
        "dcterms:description": "Brain4Cars is a dataset that focuses on anticipating driver maneuvers using sensory-fusion deep learning architecture.",
        "dcterms:title": "Brain4Cars",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1601.00740",
        "dcat:theme": [
            "Automated Driving",
            "Action Anticipation"
        ],
        "dcat:keyword": [
            "Driver maneuvers",
            "Sensory fusion",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Jain",
            "H.S. Koppula",
            "S. Soh",
            "B. Raghavan",
            "A. Singh",
            "A. Saxena"
        ],
        "dcterms:description": "The Toyota Action Dataset is designed for anticipating maneuvers via learning temporal driving models.",
        "dcterms:title": "Toyota Action Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automated Driving",
            "Action Anticipation"
        ],
        "dcat:keyword": [
            "Maneuver anticipation",
            "Temporal driving models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Rasouli",
            "I. Kotseruba",
            "J.K. Tsotsos"
        ],
        "dcterms:description": "JAAD is a dataset that studies the interactions between drivers and pedestrians, focusing on how they communicate intentions.",
        "dcterms:title": "JAAD",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1702.03555",
        "dcat:theme": [
            "Automated Driving",
            "Human-Computer Interaction"
        ],
        "dcat:keyword": [
            "Driver-pedestrian interaction",
            "Intent communication"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Intent recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F.H. Chan",
            "Y.T. Chen",
            "Y. Xiang",
            "M. Sun"
        ],
        "dcterms:description": "DashCam is a dataset focused on anticipating accidents in dashcam videos.",
        "dcterms:title": "DashCam",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automated Driving",
            "Accident Prediction"
        ],
        "dcat:keyword": [
            "Accident anticipation",
            "Dashcam videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Accident prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Rockstar-Games"
        ],
        "dcterms:description": "CityScapes is a dataset that provides a standard benchmark set for semantic segmentation in urban scenes.",
        "dcterms:title": "CityScapes",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "http://tinyurl.com/yc8kq7vn",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Urban scenes",
            "Semantic segmentation"
        ],
        "dcat:landingPage": "http://tinyurl.com/yc8kq7vn",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S.R. Richter",
            "V. Vineet",
            "S. Roth",
            "V. Koltun"
        ],
        "dcterms:description": "GTA5 is a dataset that provides ground truth data for various tasks by using the Grand Theft Auto V video game.",
        "dcterms:title": "GTA5",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Data Generation"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Ground truth"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Sadat Saleh",
            "M.S. Aliakbarian",
            "M. Salzmann",
            "L. Petersson",
            "J.M. Alvarez"
        ],
        "dcterms:description": "VIPER is a dataset that focuses on the effective use of synthetic data for urban scene semantic segmentation.",
        "dcterms:title": "VIPER",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Urban scene segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Ros",
            "L. Sellart",
            "G. Villalonga",
            "E. Maidanik",
            "F. Molero",
            "M. Garcia",
            "A. Cedeño",
            "F. Perez",
            "D. Ramirez",
            "E. Escobar"
        ],
        "dcterms:description": "SYNTHIA is a dataset for semantic segmentation of urban scenes via domain adaptation.",
        "dcterms:title": "SYNTHIA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Urban scenes",
            "Domain adaptation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A.R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "UCF-101 is a dataset of 101 human action classes from videos in the wild.",
        "dcterms:title": "UCF-101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1212.0402",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. Zufﬁ",
            "C. Schmid",
            "M.J. Black"
        ],
        "dcterms:description": "HMDB/JHMDB is a dataset aimed at understanding action recognition.",
        "dcterms:title": "HMDB/JHMDB",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Action recognition",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action recognition"
        ]
    }
]