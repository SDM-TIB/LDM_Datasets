To extract the datasets mentioned in the research paper titled "Mask-adaptive Gated Convolution and Bi-directional Progressive Fusion Network for Depth Completion" by Tingxuan Huang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors conducted extensive experiments on popular benchmarks, which suggests that datasets are involved. I will look for specific names of datasets in these sections.

In the **introduction**, the authors discuss the importance of depth completion and reference various datasets. I will pay close attention to any datasets that are explicitly named or described.

Next, I will focus on **section 4 (Experiments)**, where the authors typically provide detailed information about the datasets used for their experiments. Here, they mention three datasets:

1. **NYU-Depth V2**: This dataset is described as containing 408,473 images collected from 464 different indoor scenes, with 1,449 officially labeled images for evaluation.

2. **DIML**: This dataset consists of 2 million images captured in diverse indoor and outdoor settings, including images with edge shadows and irregular holes. The authors utilize 2,000 pairs of labeled samples from the indoor part of this dataset.

3. **SUN RGB-D**: This extensive dataset comprises 10,335 RGB-D images obtained from four different sensors, covering 19 primary scene categories. The authors partition this dataset into 4,845 images for training and 4,659 for testing.

To ensure I have the correct citations for these datasets, I will refer to the **References section** of the paper. Here are the full citations for each dataset:

- For **NYU-Depth V2**, the citation is:
  > Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. *Indoor segmentation and support inference from RGBD images*. In Computer Vision – ECCV 2012, pages 746–760, 2012.

- For **DIML**, the citation is:
  > Jaehoon Cho, Dongbo Min, Youngjung Kim, and Kwanghoon Sohn. *A large RGB-D dataset for semi-supervised monocular depth estimation*. CoRR, 2019.

- For **SUN RGB-D**, the citation is:
  > Shuran Song, Samuel P. Lichtenberg, and Jianxiong Xiao. *SUN RGB-D: A RGB-D scene understanding benchmark suite*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.