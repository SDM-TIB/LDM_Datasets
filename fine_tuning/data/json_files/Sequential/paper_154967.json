[
    {
        "dcterms:creator": [
            "Will Kay",
            "Joao Carreira",
            "Karen Simonyan",
            "Brian Zhang",
            "Chloe Hillier",
            "Sudheendra Vijayanarasimhan",
            "Fabio Viola",
            "Tim Green",
            "Trevor Back",
            "Paul Natsev"
        ],
        "dcterms:description": "The Kinetics-400 dataset is a large-scale dataset for human action recognition, containing a diverse set of video clips categorized into 400 action classes.",
        "dcterms:title": "Kinetics-400",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1705.06950",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Joao Carreira",
            "Eric Noland",
            "Andras Banki-Horvath",
            "Chloe Hillier",
            "Andrew Zisserman"
        ],
        "dcterms:description": "Kinetics-600 is an extension of the Kinetics dataset, containing 600 action classes and a larger number of video clips for action recognition tasks.",
        "dcterms:title": "Kinetics-600",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1808.01340",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Khurram Soomro",
            "Amir Roshan Zamir",
            "Mubarak Shah"
        ],
        "dcterms:description": "UCF101 is a dataset of 101 human action classes collected from videos in the wild, widely used for action recognition research.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1212.0402",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Hildegard Kuehne",
            "Hueihan Jhuang",
            "Est√≠baliz Garrote",
            "Tomaso Poggio",
            "Thomas Serre"
        ],
        "dcterms:description": "HMDB51 is a large video database for human motion recognition, containing 51 action categories with a variety of real-world actions.",
        "dcterms:title": "HMDB51",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Mathew Monfort",
            "Alex Andonian",
            "Bolei Zhou",
            "Kandan Ramakrishnan",
            "Sarah Adel Bargal",
            "Tom Yan",
            "Lisa Brown",
            "Quanfu Fan",
            "Dan Gutfreund",
            "Carl Vondrick"
        ],
        "dcterms:description": "The Moments in Time dataset consists of one million videos designed for event understanding, covering a wide range of actions and events.",
        "dcterms:title": "Moment-in-Time",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Event Understanding",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Event recognition",
            "Video dataset",
            "Temporal understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Event Recognition"
        ]
    }
]