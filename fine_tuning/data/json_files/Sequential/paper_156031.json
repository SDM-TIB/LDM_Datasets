[
    {
        "dcterms:creator": [
            "Matthew E. Peters",
            "Mark Neumann",
            "Mohit Iyyer",
            "Matt Gardner",
            "Christopher Clark",
            "Kenton Lee",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "A language model that utilizes bidirectional LSTM networks to provide deep contextualized word representations.",
        "dcterms:title": "ELMo",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Contextualized embeddings",
            "Bidirectional LSTM",
            "Language model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Processing tasks",
            "Sequence tagging",
            "Question answering",
            "Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Graves",
            "Jürgen Schmidhuber"
        ],
        "dcterms:description": "A recurrent neural network architecture that processes sequences in both directions, improving performance on various tasks.",
        "dcterms:title": "Bidirectional LSTM",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sequence Modeling"
        ],
        "dcat:keyword": [
            "Bidirectional processing",
            "Sequence classification",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sequence tagging",
            "Speech recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Graves",
            "Santiago Fernández",
            "Jürgen Schmidhuber"
        ],
        "dcterms:description": "A model that combines bidirectional LSTM networks with Conditional Random Fields for improved sequence tagging.",
        "dcterms:title": "Hybrid of Bidirectional LSTM and CRF",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sequence Tagging"
        ],
        "dcat:keyword": [
            "Bidirectional LSTM",
            "CRF",
            "Sequence tagging"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sequence tagging"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Graves",
            "Jürgen Schmidhuber"
        ],
        "dcterms:description": "A neural network architecture designed for phoneme classification using bidirectional LSTM networks.",
        "dcterms:title": "Bidirectional LSTM",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Phoneme Classification"
        ],
        "dcat:keyword": [
            "Phoneme classification",
            "Bidirectional LSTM",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Phoneme classification"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Graves",
            "Jürgen Schmidhuber"
        ],
        "dcterms:description": "A recurrent neural network architecture that utilizes LSTM cells to handle long-term dependencies in sequence data.",
        "dcterms:title": "Long Short-Term Memory (LSTM)",
        "dcterms:issued": "1997",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sequence Modeling"
        ],
        "dcat:keyword": [
            "LSTM",
            "Long-term dependencies",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sequence modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Kyunghyun Cho",
            "Bart Van Merriënboer",
            "Dzmitry Bahdanau",
            "Yoshua Bengio"
        ],
        "dcterms:description": "A simplified version of LSTM that reduces complexity while maintaining performance for sequence learning tasks.",
        "dcterms:title": "Gated Recurrent Units (GRU)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sequence Learning"
        ],
        "dcat:keyword": [
            "GRU",
            "Simplified LSTM",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sequence learning"
        ]
    }
]