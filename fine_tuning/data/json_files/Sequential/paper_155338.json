[
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing over 100,000 questions for machine comprehension of text, designed to evaluate reading comprehension systems.",
        "dcterms:title": "SQuAD1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Generation"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "Reading comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Generation",
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "An extension of SQuAD1.1 that includes unanswerable questions, allowing for the evaluation of models' ability to identify when no answer is present.",
        "dcterms:title": "SQuAD2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Generation"
        ],
        "dcat:keyword": [
            "Unanswerable questions",
            "Machine comprehension",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Generation",
            "Reading Comprehension"
        ]
    }
]