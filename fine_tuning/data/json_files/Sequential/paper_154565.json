[
    {
        "dcterms:creator": [
            "Marcus Hutter"
        ],
        "dcterms:description": "A character-level language modeling dataset consisting of 100M tokens taken from Wikipedia, used for evaluating language models.",
        "dcterms:title": "ENWIK8",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "http://prize.hutter1.net/",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Character-level",
            "Language modeling",
            "Wikipedia"
        ],
        "dcat:landingPage": "http://prize.hutter1.net/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Baevski",
            "Michael Auli"
        ],
        "dcterms:description": "A word-level language modeling dataset containing 100M tokens extracted from Wikipedia articles, used for evaluating language models.",
        "dcterms:title": "WIKI-103",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Word-level",
            "Language modeling",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Ciprian Chelba",
            "Tomas Mikolov",
            "Mike Schuster",
            "Qi Ge",
            "Thorsten Brants",
            "Phillipp Koehn",
            "Tony Robinson"
        ],
        "dcterms:description": "One of the largest language modeling datasets containing 768M tokens for training, used for evaluating language models.",
        "dcterms:title": "BILLION WORD",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Large dataset",
            "Language modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Alexander Lin",
            "Jeremy Wohlwend",
            "Howard Chen",
            "Tao Lei"
        ],
        "dcterms:description": "A low-resource machine translation dataset consisting of 170K translation pairs, used for evaluating translation models.",
        "dcterms:title": "IWSLT’14 De→En",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Translation",
            "Low-resource"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    }
]