[
    {
        "dcterms:creator": [
            "Praveen Kumar Bodigutla",
            "Lazaros Polymenakos",
            "Spyros Matsoukas"
        ],
        "dcterms:description": "A dataset containing multi-domain dialogues sampled from 28 Alexa domains, used for evaluating conversation quality via user satisfaction estimation.",
        "dcterms:title": "Multi-domain dialogues from Alexa",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "User Satisfaction"
        ],
        "dcat:keyword": [
            "Multi-domain dialogues",
            "User satisfaction",
            "Alexa"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Quality Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Praveen Kumar Bodigutla",
            "Longshaokan Wang",
            "Kate Ridgeway",
            "Joshua Levy",
            "Swanand Joshi",
            "Alborz Geramifard",
            "Spyros Matsoukas"
        ],
        "dcterms:description": "A dataset for dialogue quality evaluation that provides turn-level ratings based on user satisfaction, applicable across various domains.",
        "dcterms:title": "Dialogue Quality Data",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "User Satisfaction"
        ],
        "dcat:keyword": [
            "Dialogue quality",
            "User satisfaction",
            "Turn-level ratings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Quality Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Cer",
            "Yinfei Yang",
            "Sheng-yi Kong",
            "Nan Hua",
            "Nicole Limtiaco",
            "Rhomni St. John",
            "Noah Constant",
            "Mario Guajardo-Cespedes",
            "Steve Yuan",
            "Chris Tar",
            "Yun-Hsuan Sung",
            "Brian Strope",
            "Ray Kurzweil"
        ],
        "dcterms:description": "Pre-trained embeddings for sentences that can be used to improve the performance of various natural language processing tasks.",
        "dcterms:title": "Universal Sentence Encoder (USE) embeddings",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1803.11175",
        "dcat:theme": [
            "Natural Language Processing",
            "Embeddings"
        ],
        "dcat:keyword": [
            "Sentence embeddings",
            "Natural language processing",
            "Semantic similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Representation",
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Alexander Schmitt",
            "Benjamin Schatz",
            "Wolfgang Minker"
        ],
        "dcterms:description": "A dataset used for modeling and predicting quality in spoken human-computer interaction.",
        "dcterms:title": "Interaction Quality (IQ) dataset",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "User Interaction"
        ],
        "dcat:keyword": [
            "Interaction quality",
            "Human-computer interaction",
            "Quality prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Quality Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Jost Schatzmann",
            "Blaise Thomson",
            "Karl Weilhammer",
            "Hui Ye",
            "Steve Young"
        ],
        "dcterms:description": "A dataset focused on measuring task success in dialogue systems, providing insights into user interactions.",
        "dcterms:title": "Task Success (TS) dataset",
        "dcterms:issued": "2007",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "User Interaction"
        ],
        "dcat:keyword": [
            "Task success",
            "Dialogue systems",
            "User interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Task Success Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Praveen Kumar Bodigutla",
            "Longshaokan Wang",
            "Kate Ridgeway",
            "Joshua Levy",
            "Swanand Joshi",
            "Alborz Geramifard",
            "Spyros Matsoukas"
        ],
        "dcterms:description": "A dataset providing ratings for response quality in dialogues, used for evaluating user satisfaction.",
        "dcterms:title": "RQ ratings dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "User Satisfaction"
        ],
        "dcat:keyword": [
            "Response quality",
            "User satisfaction",
            "Turn-level ratings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Quality Evaluation"
        ]
    }
]