[
    {
        "dcterms:creator": [
            "Carlos Busso",
            "Murtaza Bulut",
            "Chi-Chun Lee",
            "Abe Kazemzadeh",
            "Emily Mower",
            "Samuel Kim",
            "Jeannette N Chang",
            "Sungbok Lee",
            "Shrikanth S Narayanan"
        ],
        "dcterms:description": "The IEMOCAP dataset is an interactive emotional dyadic motion capture database that includes various emotional expressions in speech.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Analysis"
        ],
        "dcat:keyword": [
            "Emotion recognition",
            "Speech dataset",
            "Dyadic interactions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C Busso",
            "S Parthasarathy",
            "A Burmania",
            "M AbdelWahab",
            "N Sadoughi",
            "E M Provost"
        ],
        "dcterms:description": "MSP-IMPROV is an acted corpus of dyadic interactions designed to study emotion perception.",
        "dcterms:title": "MSP-IMPROV",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Analysis"
        ],
        "dcat:keyword": [
            "Emotion perception",
            "Dyadic interactions",
            "Acted corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    }
]