To extract datasets from the research paper titled "Memory Time Span in LSTMs for Multi-Speaker Source Separation" by Jeroen Zegers and Hugo Van Hamme, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses the task of separating speakers from overlapping speech, which suggests that there may be datasets involved.

Next, I will focus on the **experiments section (Section 4)**, as it is likely to contain detailed information about the datasets used. In **Section 4.1 (Experimental setup)**, the authors mention using a corpus created by mixing single speaker utterances from the **Wall Street Journal 0 (WSJ0)** corpus. This indicates that WSJ0 is a dataset used in their experiments.

I will also look for any additional datasets mentioned in the paper. The authors refer to the **Wall Street Journal 1 (WSJ1)** corpus when discussing the training of i-vectors, which suggests that this dataset is also relevant to their work.

Now, I will check the **References section** to find the full citations for these datasets:

1. For the **Wall Street Journal 0 (WSJ0)** corpus, the citation is:
   > P. Godfrey, D. Holliman, and J. McDaniel. *SWITCHBOARD: Telephone Speech Corpus for Research and Development*. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), 1992.

2. For the **Wall Street Journal 1 (WSJ1)** corpus, the citation is:
   > P. C. Woodland and D. J. Povey. *Large Scale Discriminative Training of Hidden Markov Models for Speech Recognition*. Computer Speech and Language, 2002.

After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets used in the research paper.