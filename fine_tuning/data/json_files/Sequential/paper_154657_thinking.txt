To extract datasets from the research paper titled "UPB at SemEval-2021 Task 7: Adversarial Multi-Task Learning for Detecting and Rating Humor and Offense" by Răzvan-Alexandru Smădu et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and method sections** to identify any datasets mentioned. The abstract indicates that the authors describe their adversarial multi-task network used for detecting and rating humor and offensive texts from Task 7 at SemEval-2021, which suggests that a dataset is involved.

Next, I will focus on the **introduction section**, where the authors mention SemEval-2021 Task 7 and describe the four subtasks associated with it. They state that the dataset consists of 10,000 texts, which is a clear indication of a dataset being used.

In **section 3.1 (Corpus)**, the authors provide detailed information about the dataset used for SemEval-2021 Task 7. They specify that the dataset contains 10,000 texts, with 6,179 labeled as humorous and the rest not. They also mention the subjective nature of the labeling and provide statistics about the humor and offensiveness scores.

Now, I will look into the **References section** to find the full citation for the dataset. The dataset is attributed to the SemEval-2021 Task 7 paper by Meaney et al. (2021). The citation for this dataset is:

- Meaney, J.A., Wilson, S.R., Chiruzzo, L., Lopez, A., & Magdy, W. (2021). *SemEval 2021 Task 7, HaHackathon: Detecting and Rating Humor and Offense*. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing.

With this information, I will compile the dataset entry, ensuring to include the full citation as required. The dataset entry will reflect the details provided in the paper, including the number of texts, the classification of humor, and the subjective nature of the labeling.