[
    {
        "dcterms:creator": [
            "A. Radford",
            "L. Metz",
            "S. Chintala"
        ],
        "dcterms:description": "A toy dataset consisting of two MNIST digits bouncing around a 64x64 image. Each video sequence consists of a different pair of digits with independent trajectories.",
        "dcterms:title": "MNIST",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Digit recognition",
            "Video generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Video Prediction",
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Y. LeCun",
            "F. Huang",
            "L. Bottou"
        ],
        "dcterms:description": "The NORB dataset is used by converting it into videos by taking sequences of different azimuths, while holding object identity, lighting and elevation constant.",
        "dcterms:title": "NORB",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Recognition"
        ],
        "dcat:keyword": [
            "3D object recognition",
            "Video generation",
            "Pose variation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Video Prediction",
            "Object Classification"
        ]
    },
    {
        "dcterms:creator": [
            "S. Song",
            "F. Yu",
            "A. Zeng",
            "A. X. Chang",
            "M. Savva",
            "T. Funkhouser"
        ],
        "dcterms:description": "The SUNCG dataset is used to generate sequences where the camera rotates around a range of 3D chair models.",
        "dcterms:title": "SUNCG",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "3D Scene Understanding"
        ],
        "dcat:keyword": [
            "3D modeling",
            "Scene generation",
            "Camera rotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Video Prediction",
            "Scene Completion"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schuldt",
            "I. Laptev",
            "B. Caputo"
        ],
        "dcterms:description": "The KTH dataset consists of real-world videos of people performing one of six actions against fairly uniform backgrounds.",
        "dcterms:title": "KTH Actions",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video classification",
            "Action prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Video Prediction"
        ]
    }
]