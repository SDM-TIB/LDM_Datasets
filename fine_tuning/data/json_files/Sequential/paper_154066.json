[
    {
        "dcterms:creator": [
            "J. Xu",
            "T. Mei",
            "T. Yao",
            "Y. Rui"
        ],
        "dcterms:description": "A large-scale benchmark for video description generation, containing 10K web video clips with 41.2 hours of video and 200K clip-description pairs, annotated with 20 natural language sentences per video.",
        "dcterms:title": "MSR-VTT",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Description",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Video captioning",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Rohrbach",
            "A. Torabi",
            "M. Rohrbach",
            "N. Tandon",
            "C. Pal",
            "H. Larochelle",
            "A. Courville",
            "B. Schiele"
        ],
        "dcterms:description": "Combines two common benchmark datasets, M-VAD and MPII-MD, consisting of video descriptions extracted from professionally generated Descriptive Video Services tracks on popular movies, containing 118,081 clips from 202 unique films.",
        "dcterms:title": "LSMDC",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Description",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Movie dataset",
            "Video captioning",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Captioning"
        ]
    }
]