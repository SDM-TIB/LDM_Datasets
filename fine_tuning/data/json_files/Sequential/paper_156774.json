[
    {
        "dcterms:creator": [
            "Mor Geva",
            "Daniel Khashabi",
            "Elad Segal",
            "Tushar Khot",
            "Dan Roth",
            "Jonathan Berant"
        ],
        "dcterms:description": "A binary true/false QA benchmark that emphasizes implicit multi-hop reasoning for strategy-based questions, requiring models to infer unspoken premises and perform multiple reasoning steps.",
        "dcterms:title": "StrategyQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Implicit Reasoning"
        ],
        "dcat:keyword": [
            "QA benchmark",
            "multi-hop reasoning",
            "implicit reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano"
        ],
        "dcterms:description": "A collection of high-quality, linguistically diverse grade school math word problems requiring multi-step reasoning and mathematical computations.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.14168",
        "dcat:theme": [
            "Mathematics",
            "Education"
        ],
        "dcat:keyword": [
            "math word problems",
            "multi-step reasoning",
            "grade school"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical Problem Solving"
        ]
    },
    {
        "dcterms:creator": [
            "Stephanie Lin",
            "Jacob Hilton",
            "Owain Evans"
        ],
        "dcterms:description": "A dataset to assess a modelâ€™s ability to produce truthful, factual, and accurate answers, targeting the issue of AI models generating plausible yet incorrect responses.",
        "dcterms:title": "TruthfulQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Truthfulness",
            "Question Answering"
        ],
        "dcat:keyword": [
            "truthfulness",
            "factual accuracy",
            "AI responses"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pan Lu",
            "Swaroop Mishra",
            "Tanglin Xia",
            "Liang Qiu",
            "Kai-Wei Chang",
            "Song-Chun Zhu",
            "Oyvind Tafjord",
            "Peter Clark",
            "Ashwin Kalyan"
        ],
        "dcterms:description": "A multi-modal question-answering dataset centered on science topics, consisting of annotated answers, lectures, and explanations.",
        "dcterms:title": "ScienceQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Science",
            "Question Answering"
        ],
        "dcat:keyword": [
            "multi-modal",
            "science questions",
            "question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]