[
    {
        "dcterms:creator": [
            "A. van den Oord",
            "S. Dieleman",
            "H. Zen",
            "K. Simonyan",
            "O. Vinyals",
            "A. Graves",
            "N. Kalchbrenner",
            "A. W. Senior",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "WaveNet is a generative model for raw audio, particularly effective in generating high-fidelity speech audio.",
        "dcterms:title": "WaveNet Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1609.03499",
        "dcat:theme": [
            "Audio Generation",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Generative Model",
            "Raw Audio",
            "Speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "S. Mehri",
            "K. Kumar",
            "I. Gulrajani",
            "R. Kumar",
            "S. Jain",
            "J. Sotelo",
            "A. Courville",
            "Y. Bengio"
        ],
        "dcterms:description": "SampleRNN is an unconditional end-to-end neural audio generation model that generates audio samples directly.",
        "dcterms:title": "SampleRNN Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Generation"
        ],
        "dcat:keyword": [
            "Neural Audio Generation",
            "Unconditional Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Generation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Kalchbrenner",
            "E. Elsen",
            "K. Simonyan",
            "S. Noury",
            "N. Casagrande",
            "E. Lockhart",
            "F. Stimberg",
            "A. van den Oord",
            "S. Dieleman",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "WaveRNN is an efficient neural audio synthesis model that generates high-quality audio waveforms.",
        "dcterms:title": "WaveRNN Dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Generation"
        ],
        "dcat:keyword": [
            "Neural Audio Synthesis",
            "Efficient Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Gibiansky",
            "S. Arik",
            "G. Diamos",
            "J. Miller",
            "K. Peng",
            "W. Ping",
            "J. Raiman",
            "Y. Zhou"
        ],
        "dcterms:description": "Deep Voice 2 is a multi-speaker neural text-to-speech model that generates speech audio from text input.",
        "dcterms:title": "Deep Voice 2 Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Multi-Speaker",
            "Speech Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wang",
            "R. J. Skerry-Ryan",
            "D. Stanton",
            "Y. Wu",
            "R. J. Weiss",
            "N. Jaitly",
            "Z. Yang",
            "Y. Xiao",
            "Z. Chen",
            "S. Bengio"
        ],
        "dcterms:description": "Tacotron is an end-to-end speech synthesis model that generates mel spectrograms from text input.",
        "dcterms:title": "Tacotron Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "End-to-End",
            "Speech Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "J. Engel",
            "C. Resnick",
            "A. Roberts",
            "S. Dieleman",
            "M. Norouzi",
            "D. Eck",
            "K. Simonyan"
        ],
        "dcterms:description": "NSynth is a dataset for neural audio synthesis of musical notes using WaveNet autoencoders.",
        "dcterms:title": "NSynth Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Generation",
            "Music Synthesis"
        ],
        "dcat:keyword": [
            "Musical Notes",
            "Neural Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Generation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Amodei",
            "R. Anubhai",
            "E. Battenberg",
            "C. Case",
            "J. Casper",
            "B. Catanzaro",
            "J. Chen",
            "M. Chrzanowski",
            "A. Coates",
            "G. Diamos",
            "E. Elsen",
            "J. Engel",
            "L. Fan",
            "C. Fougner",
            "T. Han",
            "A. Hannun",
            "B. Jun",
            "P. LeGresley",
            "L. Lin",
            "S. Narang",
            "A. Ng",
            "S. Ozair",
            "R. Prenger",
            "J. Raiman",
            "S. Satheesh",
            "D. Seetapun",
            "S. Sengupta",
            "Y. Wang",
            "Z. Wang",
            "C. Wang",
            "B. Xiao",
            "D. Yogatama",
            "J. Zhan",
            "Z. Zhu"
        ],
        "dcterms:description": "DeepSpeech2 is an end-to-end speech recognition model for English and Mandarin.",
        "dcterms:title": "DeepSpeech2 Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "End-to-End",
            "Speech Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]