[
    {
        "dcterms:creator": [
            "A. Shahroudy",
            "J. Liu",
            "T.-T. Ng",
            "G. Wang"
        ],
        "dcterms:description": "NTU RGB+D 60 is a 3D large-scale human action dataset which provides skeleton data sequences consisting of 56,880 instances for 60 types of human actions recorded from 40 different subjects with 17 different scene conditions.",
        "dcterms:title": "NTU RGB+D 60",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "3D Human Activity Analysis"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "Human actions",
            "3D dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Skeleton",
        "mls:task": [
            "Medical Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Liu",
            "A. Shahroudy",
            "M. Perez",
            "G. Wang",
            "L.-Y. Duan",
            "A. C. Kot"
        ],
        "dcterms:description": "NTU RGB+D 120 is an extended version of NTU RGB+D 60 dataset containing 120 types of human actions recorded from 106 subjects in 155 different scene conditions, with over 114,000 skeleton sequences including daily, interaction, and medical-related actions.",
        "dcterms:title": "NTU RGB+D 120",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "3D Human Activity Understanding"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "Human actions",
            "3D dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Skeleton",
        "mls:task": [
            "Medical Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Liu",
            "Y. Hu",
            "Y. Li",
            "S. Song",
            "J. Liu"
        ],
        "dcterms:description": "PKU-MMD is a large-scale benchmark dataset for continuous multi-modal human action understanding, containing 1076 long skeleton sequences in 51 action classes recorded from 66 subjects in 3 different camera views.",
        "dcterms:title": "PKU-MMD",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Multi-modal Action Understanding"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "Multi-modal data",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Skeleton",
        "mls:task": [
            "Medical Action Recognition"
        ]
    }
]