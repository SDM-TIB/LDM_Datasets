[
    {
        "dcterms:creator": [
            "C.I. Nwoye",
            "D. Alapatt",
            "T. Yu",
            "A. Vardazaryan",
            "F. Xia",
            "Z. Zhao",
            "T. Xia",
            "F. Jia",
            "Y. Yang",
            "H. Wang",
            "D. Yu",
            "G. Zheng",
            "X. Duan",
            "N. Getty",
            "R. Sanchez-Matilla",
            "M. Robu",
            "L. Zhang",
            "H. Chen",
            "J. Wang",
            "L. Wang",
            "B. Zhang",
            "B. Gerats",
            "S. Raviteja",
            "R. Sathish",
            "R. Tao",
            "S. Kondo",
            "W. Pang",
            "H. Ren",
            "J.R. Abbing",
            "M.H. Sarhan",
            "S. Bodenstedt",
            "N. Bhasker",
            "B. Oliveira",
            "H.R. Torres",
            "L. Ling",
            "F. Gaida",
            "T. Czempiel",
            "J.L. Vilac¸a",
            "P. Morais",
            "J. Fonseca",
            "R.M. Egging",
            "I.N. Wijma",
            "C. Qian",
            "G. Bian",
            "Z. Li",
            "V. Balasubramanian",
            "D. Sheet",
            "I. Luengo",
            "Y. Zhu",
            "S. Ding",
            "J.A. Aschenbrenner",
            "N.E. van der Kar",
            "M. Xu",
            "M. Islam",
            "L. Seenivasan",
            "A. Jenke",
            "D. Stoyanov",
            "D. Mutter",
            "P. Mascagni",
            "B. Seeliger",
            "C. Gonzalez",
            "N. Padoy"
        ],
        "dcterms:description": "The CholecT50 dataset is the largest endoscopic video dataset for surgical action triplet recognition, consisting of 50 video footages of laparoscopic cholecystectomy annotated with 100 distinct categories of surgical action triplets.",
        "dcterms:title": "CholecT50",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Surgical Action Recognition",
            "Endoscopic Video Analysis"
        ],
        "dcat:keyword": [
            "Surgical action triplet",
            "Laparoscopic videos",
            "Video dataset",
            "Action detection",
            "Weak supervision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Instrument Localization",
            "Triplet Detection"
        ]
    },
    {
        "dcterms:creator": [
            "C.I. Nwoye",
            "T. Yu",
            "C. Gonzalez",
            "B. Seeliger",
            "P. Mascagni",
            "D. Mutter",
            "J. Marescaux",
            "N. Padoy"
        ],
        "dcterms:description": "The CholecT40 dataset expands upon previous efforts by providing direct labeling of surgical activities in the form of ⟨instrument, verb, target⟩ triplets for surgical action triplet recognition.",
        "dcterms:title": "CholecT40",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Surgical Action Recognition",
            "Endoscopic Video Analysis"
        ],
        "dcat:keyword": [
            "Surgical action triplet",
            "Laparoscopic videos",
            "Video dataset",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A.P. Twinanda",
            "S. Shehata",
            "D. Mutter",
            "J. Marescaux",
            "M. De Mathelin",
            "N. Padoy"
        ],
        "dcterms:description": "The Cholec80 dataset divides cholecystectomy into 7 phases and is used for surgical phase classification.",
        "dcterms:title": "Cholec80",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Surgical Phase Recognition",
            "Endoscopic Video Analysis"
        ],
        "dcat:keyword": [
            "Surgical phase classification",
            "Laparoscopic videos",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Phase Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Al Hajj",
            "M. Lamard",
            "P.H. Conze",
            "B. Cochener",
            "G. Quellec"
        ],
        "dcterms:description": "The CATARACTS dataset focuses on automatic tool annotation for cataract surgery.",
        "dcterms:title": "CATARACTS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cataract Surgery",
            "Tool Annotation"
        ],
        "dcat:keyword": [
            "Cataract surgery",
            "Tool annotation",
            "Surgical dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Tool Annotation"
        ]
    },
    {
        "dcterms:creator": [
            "V.S. Bawa",
            "G. Singh",
            "F. Kaping’a",
            "I. Skarga-Bandurova",
            "E. Oleari",
            "A. Leporini",
            "C. Landolfo",
            "P. Zhao",
            "X. Xiang",
            "G. Luo",
            "K. Wang",
            "L. Li",
            "B. Wang",
            "S. Zhao",
            "L. Li",
            "A. Stabile",
            "F. Setti",
            "R. Muradore",
            "F. Cuzzolin"
        ],
        "dcterms:description": "The SARAS-ESAD dataset provides bounding boxes pointing to action verbs being performed in endoscopic videos.",
        "dcterms:title": "SARAS-ESAD",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Surgical Action Detection",
            "Endoscopic Video Analysis"
        ],
        "dcat:keyword": [
            "Action detection",
            "Endoscopic videos",
            "Surgical dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Gao",
            "S.S. Vedula",
            "C.E. Reiley",
            "N. Ahmidi",
            "B. Varadarajan",
            "H.C. Lin",
            "L. Tao",
            "L. Zappella",
            "B. Bejar",
            "D.D. Yuh"
        ],
        "dcterms:description": "The JIGSAWS dataset is a surgical activity dataset for human motion modeling, providing data labels of different granularity levels for surgical skill assessment.",
        "dcterms:title": "JIGSAWS",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Surgical Skill Assessment",
            "Human Motion Modeling"
        ],
        "dcat:keyword": [
            "Surgical activity dataset",
            "Skill assessment",
            "Motion analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Skill Assessment",
            "Motion Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "S. Gupta",
            "J. Malik"
        ],
        "dcterms:description": "The V-COCO dataset extends the original COCO dataset with bounding boxes around interacting elements for visual semantic role labeling.",
        "dcterms:title": "V-COCO",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human-Object Interaction",
            "Visual Semantic Role Labeling"
        ],
        "dcat:keyword": [
            "Human-object interaction",
            "Visual dataset",
            "Bounding boxes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Interaction Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Y.W. Chao",
            "Z. Wang",
            "Y. He",
            "J. Wang",
            "J. Deng"
        ],
        "dcterms:description": "The HICO-DET dataset is a benchmark for recognizing human-object interactions in images, providing a comprehensive set of annotations.",
        "dcterms:title": "HICO-DET",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human-Object Interaction Recognition",
            "Image Analysis"
        ],
        "dcat:keyword": [
            "Human-object interactions",
            "Image dataset",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Interaction Recognition"
        ]
    }
]