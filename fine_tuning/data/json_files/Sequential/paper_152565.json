[
    {
        "dcterms:creator": [
            "Yuanlong Shao",
            "Stephan Gouws",
            "Denny Britz",
            "Anna Goldie",
            "Brian Strope",
            "Ray Kurzweil"
        ],
        "dcterms:description": "A large dataset containing about 1.7 billion messages (221 million conversations) from Reddit, used to study conversational models and generate diverse responses.",
        "dcterms:title": "Reddit Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Conversational Modeling"
        ],
        "dcat:keyword": [
            "Reddit",
            "conversational dataset",
            "dialogue",
            "machine learning"
        ],
        "dcat:landingPage": "https://goo.gl/9gKEbc",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Generation",
            "Conversational AI"
        ]
    }
]