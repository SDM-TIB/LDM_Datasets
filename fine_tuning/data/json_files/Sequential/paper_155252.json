[
    {
        "dcterms:creator": [
            "Ephrem Afele Retta",
            "Eiad AlmekhlaÔ¨Å",
            "Richard Sutcliffe",
            "Mustafa Mhamed",
            "Haider Ali",
            "Jun Feng"
        ],
        "dcterms:description": "The Amharic Speech Emotion Dataset (ASED) is the first dataset for Speech Emotion Recognition (SER) in the Amharic language, covering four dialects (Gojjam, Wollo, Shewa, and Gonder) and five emotions (neutral, fearful, happy, sad, and angry). It consists of 2,474 sound samples recorded by 65 native speakers of Amharic, with high agreement among judges on emotion assignment.",
        "dcterms:title": "Amharic Speech Emotion Dataset (ASED)",
        "dcterms:issued": "",
        "dcterms:language": "Amharic",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Dataset"
        ],
        "dcat:keyword": [
            "Amharic",
            "Speech Emotion Recognition",
            "Emotion dataset",
            "Dialect",
            "MFCC",
            "VGGb"
        ],
        "dcat:landingPage": "https://github.com/Ethio2021/ASED_V1",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S. R. Livingstone",
            "F. A. Russo"
        ],
        "dcterms:description": "The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) contains audio and video recordings of English sentences spoken by twelve males and twelve females in eight emotions: neutral, calm, happy, sad, angry, fearful, surprise, and disgust.",
        "dcterms:title": "RAVDESS",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "10.1371/journal.pone.0196391",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Multimodal Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "Audio-visual dataset",
            "Emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. Burkhardt",
            "A. Paeschke",
            "M. Rolfes",
            "W. F. Sendlmeier",
            "B. Weiss"
        ],
        "dcterms:description": "The Berlin Emo-DB dataset contains audio recordings of German sentences made by five males and five females in seven different emotions: neutral, fear, anger, happiness, sadness, disgust, and boredom.",
        "dcterms:title": "EMO-DB",
        "dcterms:issued": "2005",
        "dcterms:language": "German",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "German language",
            "Emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    }
]