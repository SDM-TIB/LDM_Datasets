To extract the datasets from the research paper titled "SPARTA: Speaker Profiling for Arabic Talk" by Wael Farhan et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and datasets section** of the paper. The abstract mentions a novel approach for estimating speaker traits from Arabic speech and indicates that the dataset was assembled from six publicly available datasets. This suggests that multiple datasets will be discussed in detail.

Next, I will focus on **section 3 (Datasets)**, where the authors provide descriptions of the datasets used for their experiments. Here, I will look for specific names, characteristics, and any relevant details about each dataset.

The paper describes the following datasets:

1. **Qatar Computing Research Institute (QCRI) Arabic Dialect Detection Data**: This dataset consists of 15,000 utterances collected from the Broadcast News domain in four Arabic dialects (Egyptian, North African, Gulf, Levantine, and Modern Standard Arabic). It includes a development set of 1,500 utterances.

2. **King Saud University Emotions (KSUEmotion) Corpus**: This corpus contains 3,280 utterances spoken with six distinct emotions (Neutral, happy, sad, angry, surprised, and questioning) by 23 different speakers. It is suitable for both emotion and gender detection tasks.

3. **Arabic Natural Audio Dataset (ANAD)**: This dataset was developed to recognize three types of emotions (Happy, angry, and surprised) from Arabic speech. It consists of recordings from online Arabic talk shows, totaling 475 recordings after segmentation.

4. **Spoken Arabic Regional Archive (SARA)**: This dataset includes 3,480 voice recordings from episodes and films published on YouTube, featuring three different Arabic dialects.

5. **Multi Dialect Arabic Speech (MDAS)**: This corpus was designed to recognize three dialects along with Modern Standard Arabic (MSA), totaling around 32 hours of recordings from 52 participants.

6. **King Saud University (KSU) Arabic Speech Database**: This extensive database consists of 590 hours of recorded Arabic speech from 269 speakers, with 49 hours used for gender detection in this research.

After identifying these datasets, I will check the **References section** for full citations. The citations for the datasets are as follows:

- For **Qatar Computing Research Institute (QCRI) Arabic Dialect Detection Data**:
  > Ziedan, R., Micheal, M., Alsammak, A., Mursi, M., & Elmaghraby, A. (2016). A unified approach for Arabic language dialect detection. In 29th International Conference on Computers Applications in Industry and Engineering (CAINE 2016), Denver, USA.

- For **King Saud University Emotions (KSUEmotion) Corpus**:
  > Meftah, A. H., Alotaibi, Y. A., & Selouani, S. A. (2018). Evaluation of an Arabic speech corpus of emotions: A perceptual and statistical analysis. IEEE Access, 6, 72845–72861.

- For **Arabic Natural Audio Dataset (ANAD)**:
  > Klaylat, S., Hamandi, L., Zantout, R., & Osman, Z. (2018). Arabic natural audio dataset. Mendeley Data, v1.

- For **Spoken Arabic Regional Archive (SARA)**:
  > Ziedan, R., Micheal, M., Alsammak, A., Mursi, M., & Elmaghraby, A. (2016). A unified approach for Arabic language dialect detection. In 29th International Conference on Computers Applications in Industry and Engineering (CAINE 2016), Denver, USA.

- For **Multi Dialect Arabic Speech (MDAS)**:
  > Almeman, K., Lee, M., & Almiman, A. A. (2013). Multi dialect Arabic speech parallel corpora. In 2013 1st International Conference on Communications, Signal Processing, and their Applications (ICCSPA), pages 1–6. IEEE.

- For **King Saud University (KSU) Arabic Speech Database**:
  > Alsulaiman, M., Muhammad, G., Bencherif, M. A., Mahmood, A., & Ali, Z. (2013). KSU rich Arabic speech database. Information (Japan), 16(6 B), 4231–4253.

Now that I have gathered all the necessary information and citations, I will compile the dataset entries into a structured format for further processing or review.