[
    {
        "dcterms:creator": [
            "L.-J. Liu",
            "Z.-H. Ling",
            "Y. Jiang",
            "M. Zhou",
            "L.-R. Dai"
        ],
        "dcterms:description": "Dataset from the mono-lingual task of Voice Conversion Challenge 2020, containing 4 source English speakers and 4 target English speakers, with each speaker having 70 utterances for training.",
        "dcterms:title": "Voice Conversion Challenge 2020",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Voice conversion",
            "Mono-lingual task",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "D. G. Childers",
            "K. Wu",
            "D. M. Hicks",
            "B. Yegnanarayana"
        ],
        "dcterms:description": "LibriTTS corpus was adopted for pretraining the model, containing approximately 460 hours of training data from 1150 speakers.",
        "dcterms:title": "LibriTTS corpus",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "http://www.openslr.org/60/",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Speech corpus",
            "Text-to-speech synthesis",
            "Pretraining data"
        ],
        "dcat:landingPage": "http://www.openslr.org/60/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wang",
            "D. Stanton",
            "Y. Zhang",
            "R. Skerry-Ryan",
            "E. Battenberg",
            "J. Shor",
            "Y. Xiao",
            "F. Ren",
            "Y. Jia",
            "R. A. Saurous"
        ],
        "dcterms:description": "A multi-speaker dataset used for pretraining the Transformer TTS model, which helps improve the generalization capacity of the model.",
        "dcterms:title": "Multi-speaker dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Multi-speaker TTS"
        ],
        "dcat:keyword": [
            "Multi-speaker",
            "Text-to-speech synthesis",
            "Pretraining"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "S. Watanabe",
            "T. Hori",
            "S. Karita",
            "T. Hayashi",
            "J. Nishitoba",
            "Y. Unno",
            "N. Enrique",
            "Y. Soplin",
            "J. Heymann",
            "M. Wiesner",
            "N. Chen",
            "A. Renduchintala",
            "T. Ochiai"
        ],
        "dcterms:description": "An open-source ASR model based on ESPnet, used for comparison in the experiments.",
        "dcterms:title": "ESPnet based ASR model",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "ASR",
            "Speech recognition",
            "Open-source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Liu",
            "X. Chen",
            "X. Wen"
        ],
        "dcterms:description": "An improved version of the N10 system in Voice Conversion Challenge 2018, used as a baseline for comparison in the experiments.",
        "dcterms:title": "VCC2018+",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Voice conversion",
            "Baseline",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Conversion"
        ]
    }
]