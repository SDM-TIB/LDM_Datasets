[
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.-C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J. N. Chang",
            "S. Lee",
            "S. S. Narayanan"
        ],
        "dcterms:description": "The IEMOCAP database consists of scripted acts and improvisations involving 10 speakers. Each video involves a conversation between 2 subjects divided into several utterances, each associated with one of the following 6 emotion labels: happy, sad, neutral, angry, excited, and frustrated.",
        "dcterms:title": "IEMOCAP (Interactive Emotional Dyadic Motion Capture)",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Emotion labels",
            "Video data",
            "Speech data",
            "Text data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Qing",
            "R. Qiao",
            "X. Xu",
            "Y. Cheng"
        ],
        "dcterms:description": "The DEAP dataset is used for emotion analysis using physiological signals, particularly EEG signals, to interpret emotions.",
        "dcterms:title": "DEAP (Dataset for Emotion Analysis using Physiological Signals)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Physiological Signals"
        ],
        "dcat:keyword": [
            "EEG signals",
            "Emotion analysis",
            "Physiological data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Physiological Data",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Qing",
            "R. Qiao",
            "X. Xu",
            "Y. Cheng"
        ],
        "dcterms:description": "The SEED dataset is used for emotion recognition based on EEG signals, providing a basis for interpretable emotion recognition.",
        "dcterms:title": "SEED (SJTU Emotion EEG Dataset)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Physiological Signals"
        ],
        "dcat:keyword": [
            "EEG signals",
            "Emotion recognition",
            "Physiological data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Physiological Data",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]