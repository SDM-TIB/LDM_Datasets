To extract datasets from the research paper titled "AuthNet: A Deep Learning based Authentication Mechanism using Temporal Facial Feature Movements" by Mohit Raghavendra et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract states that the proposed model was evaluated on the **MIRACL-VC1 dataset**, which indicates that this is a key dataset used in the research.

Next, I will look for specific details about the datasets in the **experiments and results sections**. In the introduction, the authors mention the effectiveness of their model when evaluated on the **MIRACL-VC1 dataset**, achieving an accuracy of 98.1%. This confirms the importance of this dataset in their research.

In the **Proposed Approach section**, the authors provide a detailed description of the **MIRACL-VC1 dataset**, noting that it consists of 10 speakers speaking 10 different words, 10 times each, totaling 1000 utterances. This section also mentions that the dataset has been split for testing and validation purposes.

Additionally, the authors describe a **collated dataset** that consists of videos captured from smartphone cameras under varying conditions. This dataset is also crucial for evaluating the model's performance in real-world scenarios.

Now, I will check the **References section** to find the full citations for these datasets:

1. For the **MIRACL-VC1 dataset**, the citation is:
   > Rekik, A., Ben-Hamadou, A., & Mahdi, W. (2014). A New Visual Speech Recognition Approach for RGB-D Cameras. In *Advances in Visual Computing* (pp. 3-12). Springer. doi:10.1007/978-3-319-11755-3_3.

2. The **collated dataset** does not have a specific citation provided in the paper, as it is a custom dataset compiled by the authors. Therefore, I will note it as a proprietary dataset created for the study.

After gathering all this information, I will summarize the datasets as follows:

- **MIRACL-VC1 Dataset**: A dataset consisting of 10 speakers uttering 10 different words, 10 times each, used for evaluating the proposed authentication mechanism.
- **Collated Dataset**: A custom dataset compiled from smartphone videos taken under varying conditions, used to test the model's performance in real-world scenarios.

Finally, I will compile the dataset entries into a structured format for further processing or review.