[
    {
        "dcterms:creator": [
            "D. Karatzas",
            "F. Shafait",
            "S. Uchida",
            "M. Iwamura",
            "S. R. Mestre",
            "L. G. i Bigorda",
            "J. Mas",
            "D. F. Mota",
            "J. Almazan",
            "L. P. de las Heras"
        ],
        "dcterms:description": "The ICDAR 2013 dataset is used for evaluating the performance of text recognition systems on natural scene text. It consists of a test set with 1439 images focused on reading text in real scenes.",
        "dcterms:title": "ICDAR 2013",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Natural Scene Text",
            "Text Recognition",
            "Benchmark Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Text Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Max Jaderberg",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "The synthetic dataset consists of 9 million images covering 90,000 English words, designed to train and evaluate text recognition systems in various conditions.",
        "dcterms:title": "Synthetic Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Synthetic Data",
            "Text Recognition",
            "Deep Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Text Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The NUvideo dataset consists of three videos (NUvideoI, NUvideoII, NUvideoIII) representing vehicles in very crowded scenes, recorded under different conditions.",
        "dcterms:title": "NUvideoI, NUvideoII, NUvideoIII",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "http://www.cis.nileu.edu.eg/cv/papers/dataset-1/",
        "dcat:theme": [
            "Traffic Monitoring",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Vehicle Detection",
            "Traffic Monitoring",
            "Crowded Scenes"
        ],
        "dcat:landingPage": "http://www.cis.nileu.edu.eg/cv/papers/dataset-1/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Vehicle Counting",
            "Tracking"
        ]
    }
]