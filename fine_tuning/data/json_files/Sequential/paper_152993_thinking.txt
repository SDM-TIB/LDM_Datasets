To extract datasets from the research paper titled "AutoDispNet: Improving Disparity Estimation With AutoML" by Tonmoy Saikia et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors show results on disparity estimation, which suggests that datasets are likely involved. 

Next, I will focus on the **experiments section** (section 7), where the authors typically describe the datasets used for training and evaluation. In this section, they mention using the **FlyingThings3D dataset** for training their search network. The dataset is described as providing ground truth disparity maps generated using rendered scenes, with specific details about the number of samples and their resolution.

I will also check the **references section** to find the full citation for the FlyingThings3D dataset. The citation is as follows:
> Daniel J. Butler, Jonas Wulff, Garrett B. Stanley, and Michael J. Black. *A naturalistic open source movie for optical flow evaluation*. In Computer Vision – ECCV 2012, pages 4040–4048, 2016.

Since the paper does not mention any other datasets explicitly, I will conclude that the FlyingThings3D dataset is the primary dataset used in this research.

Now, I will compile the information into a structured format, ensuring that I include the dataset name, description, and full citation. This will allow for easy reference and further analysis.

In summary, the steps I took were:
1. Read the abstract and introduction for initial context.
2. Focused on the experiments section to identify datasets.
3. Retrieved the full citation from the references section.
4. Compiled the dataset information for clarity and future use.