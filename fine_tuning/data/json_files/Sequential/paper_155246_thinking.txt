To extract datasets from the research paper titled "TFCN: Temporal-Frequential Convolutional Network for Single-Channel Speech Enhancement" by Xupeng Jia and Dongmei Li, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the research, but the experiments section is likely to contain detailed information about the datasets used.

In the **experiments section**, specifically section III, the authors mention two datasets:

1. **VCTK Dataset**: This dataset is described as containing clean and noisy speech signals sampled at 48 KHz, which are resampled to 16 KHz for the experiments. The authors provide a link to the dataset, indicating its public availability.

2. **Voice Bank Corpus**: This dataset is used for training and consists of clean speech signals from 28 speakers, with a total of about 400 utterances per speaker. The authors also mention the types of noise used to generate the training data and the SNR levels applied.

Next, I will check the **References section** to find the full citations for these datasets:

- For the **VCTK Dataset**, the citation is:
  > C. Valentini-Botinhao, “Noisy speech database for training speech enhancement algorithms and TTS models,” 2016. Available at: https://datashare.ed.ac.uk/handle/10283/2791.

- For the **Voice Bank Corpus**, the citation is:
  > C. Veaux, J. Yamagishi, and S. King, “The voice bank corpus: Design, collection and data analysis of a large regional accent speech database,” in 2013 International Conference Oriental COCOSDA held jointly with 2013 Conference on Asian Spoken Language Research and Evaluation (O-COCOSDA/CASLRE), 2013, pp. 1–4.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This includes ensuring that each dataset is clearly described along with its full citation.