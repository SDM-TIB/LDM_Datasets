[
    {
        "dcterms:creator": [
            "Charles Beattie",
            "Joel Z Leibo",
            "Denis Teplyashin",
            "Tom Ward",
            "Marcus Wainwright",
            "Heinrich Küttler",
            "Andrew Lefrancq",
            "Simon Green",
            "Víctor Valdés",
            "Amir Sadik"
        ],
        "dcterms:description": "DMLab-30 is a collection of 30 first-person 3D game environments, with a mix of both memory and reactive tasks. The authors focused on two well-known environments, rooms select nonmatching object and rooms watermaze, which are categorized as memory tasks.",
        "dcterms:title": "DMLab-30",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1612.03801",
        "dcat:theme": [
            "Reinforcement Learning",
            "Memory Tasks"
        ],
        "dcat:keyword": [
            "3D environments",
            "memory tasks",
            "reactive tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Christopher Hesse",
            "Jacob Hilton",
            "John Schulman"
        ],
        "dcterms:description": "ProcGen is a benchmark for reinforcement learning that leverages procedural generation to create diverse environments. The authors focused on the Chaser environment, which requires counting capabilities to exploit power pellets.",
        "dcterms:title": "ProcGen",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Procedural Generation"
        ],
        "dcat:keyword": [
            "benchmark",
            "reinforcement learning",
            "procedural generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Marc G Bellemare",
            "Yavar Naddaf",
            "Joel Veness",
            "Michael Bowling"
        ],
        "dcterms:description": "Atari-2600 is a collection of classic arcade games used as a benchmark for evaluating reinforcement learning agents. The authors tested their methods on several Atari environments including Breakout, Gravitar, MsPacman, Q*bert, and Seaquest.",
        "dcterms:title": "Atari-2600",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Environments"
        ],
        "dcat:keyword": [
            "arcade games",
            "benchmark",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]