To extract datasets from the research paper titled "Phonetic Posteriorgrams based Many-to-Many Singing Voice Conversion via Adversarial Training" by Haohan Guo et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the proposed method but does not explicitly mention any datasets. Therefore, I will focus on the introduction and experiments sections for more detailed information.

In the **introduction**, the authors discuss the importance of various features like phonetic posteriorgrams (PPG), pitch (F0), and speaker embeddings in the context of singing voice conversion. However, they do not specify any datasets at this point.

Next, I will examine the **experiments section** closely. The authors mention using a "Mandarin multi-singer singing corpus" that contains around 3,800 clean singing segments totaling 25 hours of Chinese popular songs. This is a significant dataset for their experiments, and I will need to note its details.

Additionally, they compare their results with the **NUS-48E dataset**, which is an established dataset in the field of singing voice conversion. This dataset is crucial for contextualizing their results and comparisons.

Now, I will look for the **References section** to gather full citations for these datasets:

1. For the **Mandarin multi-singer singing corpus**, the authors do not provide a specific citation in the references, but I will note it as an internal dataset used in their experiments.

2. For the **NUS-48E dataset**, the citation is:
   > Duan, Z.; Fang, H.; Li, B.; Sim, K. C.; and Wang, Y. (2013). The NUS sung and spoken lyrics corpus: A quantitative comparison of singing and speech. In 2013 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference, 1â€“9. IEEE.

With this information, I will summarize the datasets as follows:

- **Mandarin multi-singer singing corpus**: An internal dataset used for training and evaluation, containing 3,800 clean singing segments (totaling 25 hours) of Chinese popular songs.

- **NUS-48E dataset**: A well-known dataset for singing voice conversion, providing a quantitative comparison of singing and speech.

Finally, I will compile this information into a structured format for further processing or review.