[
    {
        "dcterms:creator": [
            "M. Cooke",
            "J. Barker",
            "S. Cunningham",
            "X. Shao"
        ],
        "dcterms:description": "The GRID corpus consists of video and audio recordings of 34 speakers saying 1000 sentences each, designed for speech perception and automatic speech recognition tasks.",
        "dcterms:title": "GRID corpus",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Lipreading",
            "Speech Perception",
            "Automatic Speech Recognition",
            "Video Data",
            "Audio Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Audio",
        "mls:task": [
            "Speech Recognition",
            "Lipreading"
        ]
    }
]