To extract datasets from the research paper titled "Is it Time to Swish? Comparing Deep Learning Activation Functions Across NLP tasks" by Steffen Eger, Paul Youssef, and Iryna Gurevych, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the study's focus on comparing activation functions across various NLP tasks, which suggests that datasets will be discussed in the context of these tasks.

Next, I will examine **section 3 (Experiments)**, which details the methodologies used for the experiments. This section is likely to contain specific references to the datasets utilized for each NLP task. The authors mention conducting experiments on three types of NLP tasks: sentence classification, document classification, and sequence tagging.

In **subsection 3.1 (MLP & Sentence Classification)**, the authors list four datasets used for sentence classification:
1. **Movie Review (MR) Dataset**: A standard dataset for sentiment analysis.
2. **Subjectivity (SUBJ) Dataset**: A dataset for subjectivity classification.
3. **TREC Dataset**: A dataset for question type classification.
4. **Argumentation Mining (AM) Dataset**: A dataset derived from token-level annotations for argumentation structure classification.

In **subsection 3.2 (CNN & Document Classification)**, the authors mention two datasets:
1. **20 Newsgroup (NG) Dataset**: A dataset for classifying documents into newsgroup categories.
2. **Reuters-21578 (R8) Dataset**: A dataset for classifying Reuters news articles into categories.

In **subsection 3.3 (RNN & Sequence Tagging)**, the authors refer to two datasets:
1. **POS Dataset**: A dataset for English part-of-speech tagging.
2. **Token-Level Argumentation Mining (TL-AM) Dataset**: A dataset for tagging tokens in student essays.

Now, I will check the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution and to allow others to access the datasets.

- For the **Movie Review (MR) Dataset**, the citation is:
  > Pang, B., & Lee, L. (2005). *Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales*. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 115–124.

- For the **Subjectivity (SUBJ) Dataset**, the citation is:
  > Pang, B., & Lee, L. (2004). *A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts*. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), pages 271–278.

- For the **TREC Dataset**, the citation is:
  > Voorhees, E. M. (2003). *The TREC-2003 Question Answering Track Evaluation*. In Proceedings of the Twelfth Text REtrieval Conference (TREC), pages 1–8.

- For the **Argumentation Mining (AM) Dataset**, the citation is:
  > Stab, C., & Gurevych, I. (2017). *Parsing argumentation structures in persuasive essays*. Computational Linguistics, 43(3), 619–659.

- For the **20 Newsgroup (NG) Dataset**, the citation is:
  > Lang, K. (1995). *Newsweeder: Learning to filter netnews*. In Proceedings of the 1995 International Conference on Machine Learning (ICML), pages 331–339.

- For the **Reuters-21578 (R8) Dataset**, the citation is:
  > Lewis, D. D., Yang, Y., Rose, T., & Li, F. (2004). *RCV1: A new benchmark collection for text categorization research*. Journal of Machine Learning Research, 5, 361–397.

- For the **POS Dataset**, the citation is:
  > Toutanova, K., Klein, D., Manning, C. D., & Singer, Y. (2003). *Feature-rich part-of-speech tagging with a cyclic dependency network*. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 252–259.

- For the **Token-Level Argumentation Mining (TL-AM) Dataset**, the citation is:
  > Eger, S., Daxenberger, J., & Gurevych, I. (2017). *Neural end-to-end learning for computational argumentation mining*. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL), pages 11–22.

After gathering all this information, I will compile the dataset entries into a structured format for further processing or review.