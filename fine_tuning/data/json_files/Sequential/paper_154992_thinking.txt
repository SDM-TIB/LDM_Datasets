To extract datasets from the research paper titled "TrouSPI-Net: Spatio-temporal attention on parallel atrous convolutions and U-GRUs for skeletal pedestrian crossing prediction" by Joseph Gesnouin et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors evaluate their method on **two large public naturalistic datasets for studying pedestrian behavior in traffic: JAAD and PIE**. This is a clear indication that these datasets are crucial to the research.

Next, I will look for more detailed descriptions of these datasets in the **experiments section**. The authors mention that JAAD contains **346 clips focusing on pedestrians intending to cross**, while PIE consists of **6 hours of continuous footage with annotations for all pedestrians close to the road**, regardless of their intent to cross. This provides a good overview of the datasets' contents and purposes.

I will also check the **references section** to find the full citations for these datasets. The citations are essential for proper attribution and to allow others to access the datasets.

For the **JAAD dataset**, the citation is:
> I. Kotseruba, A. Rasouli, and J. K. Tsotsos. *Are they going to cross? A benchmark dataset and baseline for pedestrian crosswalk behavior*. In Proceedings of the IEEE International Conference on Computer Vision Workshops, pages 206â€“213, 2017.

For the **PIE dataset**, the citation is:
> A. Rasouli, I. Kotseruba, T. Kunic, and J. K. Tsotsos. *PIE: A large-scale dataset and models for pedestrian intention estimation and trajectory prediction*. In ICCV, 2019.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This will ensure that the datasets are accurately represented and properly cited in any subsequent work.