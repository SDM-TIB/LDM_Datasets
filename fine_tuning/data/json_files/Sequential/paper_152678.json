[
    {
        "dcterms:creator": [
            "J. Lorenzo-Trueba",
            "J. Yamagishi",
            "T. Toda",
            "D. Saito",
            "F. Villavicencio",
            "T. Kinnunen",
            "Z. Ling"
        ],
        "dcterms:description": "The Voice Conversion Challenge 2018 (VCC2018) corpus includes recordings of 12 professional US English speakers, providing a dataset for voice conversion research.",
        "dcterms:title": "Voice Conversion Challenge 2018 (VCC2018)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Voice conversion",
            "Speech synthesis",
            "English speakers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "M. Morise",
            "F. Yokomori",
            "K. Ozawa"
        ],
        "dcterms:description": "The WORLD vocoder is a high-quality speech synthesis system that extracts acoustic features for voice conversion applications.",
        "dcterms:title": "WORLD vocoder",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Signal Processing"
        ],
        "dcat:keyword": [
            "Vocoding",
            "Speech synthesis",
            "Acoustic features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Feature extraction"
        ]
    },
    {
        "dcterms:creator": [
            "W.-C. Huang",
            "H.-T. Hwang",
            "Y.-H. Peng",
            "Y. Tsao",
            "H.-M. Wang"
        ],
        "dcterms:description": "The CDVAE variant is a voice conversion model based on cross-domain features using variational autoencoders, capable of modeling mel-cepstral coefficients.",
        "dcterms:title": "CDVAE variant",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Variational autoencoder",
            "Voice conversion",
            "Cross-domain features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Voice Conversion"
        ]
    }
]