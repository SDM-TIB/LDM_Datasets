[
    {
        "dcterms:creator": [
            "Brian Dolhansky",
            "M. Zami Al Zunaed Farabe",
            "Gazi Hasin Ishrak",
            "Zalish Mahmud",
            "Tahera Khanom Tinni",
            "Tanzim Reza",
            "Mohammad Zavid Parvez"
        ],
        "dcterms:description": "The DFDC dataset is considered the largest Deepfake detection dataset, which consists of more than 100,000 clips gathered from 3,426 paid actors. Each one of the 100,000 fake videos in the dataset is a unique target or source swap. The dataset provides publicly available face swap videos and is assembled using several Deepfake, GAN-based, and non-learned methods.",
        "dcterms:title": "DFDC (Deepfake Detection Challenge)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2006.07397",
        "dcat:theme": [
            "Deepfake Detection",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Deepfake",
            "Video dataset",
            "Face swap",
            "Machine learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "Full dataset",
        "dcterms:format": "Video",
        "mls:task": [
            "Deepfake Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Ohad Fried"
        ],
        "dcterms:description": "The T2V-L dataset is used for text-based editing of talking-head video, allowing for the synthesis of videos based on textual descriptions.",
        "dcterms:title": "T2V-L (Text-to-Video - Long)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Synthesis",
            "Text-to-Video"
        ],
        "dcat:keyword": [
            "Text-based editing",
            "Talking-head video"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Ohad Fried"
        ],
        "dcterms:description": "The T2V-S dataset is used for text-based editing of talking-head video, allowing for the synthesis of videos based on textual descriptions.",
        "dcterms:title": "T2V-S (Text-to-Video - Short)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Synthesis",
            "Text-to-Video"
        ],
        "dcat:keyword": [
            "Text-based editing",
            "Talking-head video"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Rossler"
        ],
        "dcterms:description": "The FF++ dataset is designed for learning to detect manipulated facial images, providing a benchmark for deepfake detection methods.",
        "dcterms:title": "FF++ (FaceForensics++)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deepfake Detection",
            "Image Manipulation"
        ],
        "dcat:keyword": [
            "Facial manipulation",
            "Deepfake detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Manipulation Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Yuezun Li",
            "Siwei Lyu"
        ],
        "dcterms:description": "The UADFV dataset is used for exposing deepfake videos by detecting face warping artifacts, providing a resource for training detection algorithms.",
        "dcterms:title": "UADFV",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1811.00656",
        "dcat:theme": [
            "Deepfake Detection",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Face warping",
            "Deepfake detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Deepfake Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Edmar RS De Rezende",
            "Guilherme CS Ruppert",
            "Tiago Carvalho"
        ],
        "dcterms:description": "The DeepFakeTIMIT dataset is used for detecting computer-generated images with deep convolutional neural networks, providing a resource for training and testing detection models.",
        "dcterms:title": "DeepFakeTIMIT",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deepfake Detection",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Computer-generated images",
            "Deepfake detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Supasorn Suwajanakorn",
            "Steven M Seitz",
            "Ira Kemelmacher-Shlizerman"
        ],
        "dcterms:description": "The A2V dataset is used for synthesizing videos from audio, allowing for the generation of lip-synced videos based on audio input.",
        "dcterms:title": "A2V (Audio-to-Video)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Synthesis",
            "Video Generation"
        ],
        "dcat:keyword": [
            "Lip sync",
            "Audio-to-video synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Synthesis"
        ]
    }
]