To extract datasets from the research paper titled "Automatic Generation of Semantic Parts for Face Image Synthesis" by Tomaso Fontanini et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract indicates that the authors report results on the **CelebMask-HQ dataset**, which is a key dataset for their experiments.

Next, I will examine the **experimental results section (Section 4)**, where the authors provide details about the dataset used for training and testing their model. In this section, they specify that the **CelebAMask-HQ** dataset consists of 30,000 high-resolution face images along with corresponding segmentation masks, with 28,000 samples used for training and 2,000 for testing. This confirms the dataset's relevance and usage in their experiments.

I will also check the **References section** to find the full citation for the **CelebAMask-HQ dataset**. The citation provided in the paper is:
> Lee, C.H., Liu, Z., Wu, L., Luo, P. *Maskgan: Towards diverse and interactive facial image manipulation*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 5549â€“5558, 2020.

Now that I have identified the dataset and its citation, I will summarize the findings:

1. **CelebAMask-HQ Dataset**: This dataset is composed of 30,000 high-resolution face images (1024x1024) along with the corresponding segmentation masks. It is used for training and testing the proposed model.

Finally, I will compile the dataset entry with the full citation into a structured format for further processing or review.