[
    {
        "dcterms:creator": [
            "S. Abu-El-Haija",
            "N. Kothari",
            "J. Lee",
            "P. Natsev",
            "G. Toderici",
            "B. Varadarajan",
            "S. Vijayanarasimhan"
        ],
        "dcterms:description": "The YouTube-8M dataset adopted in the 2nd YouTube-8M Video Understanding Challenge is the 2018 version with higher-quality, more topical annotations, and a cleaner annotation vocabulary. It contains about 6.1 million videos, 3862 class labels and 3 labels per video on average. Because of the large scale of the dataset, the video information is provided as pre-extracted visual and audio features at 1 FPS.",
        "dcterms:title": "YouTube-8M",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1609.08675",
        "dcat:theme": [
            "Video Classification",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Large-scale",
            "Multi-label classification",
            "Pre-extracted features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "2018",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Classification"
        ]
    },
    {
        "dcterms:creator": [
            "W. Kay",
            "J. Carreira",
            "K. Simonyan",
            "B. Zhang",
            "C. Hillier",
            "S. Vijayanarasimhan",
            "F. Viola",
            "T. Green",
            "T. Back",
            "P. Natsev"
        ],
        "dcterms:description": "Kinetics is a large-scale dataset for human action recognition, containing a diverse set of video clips from YouTube, covering a wide range of human actions.",
        "dcterms:title": "Kinetics",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1705.06950",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Monfort",
            "B. Zhou",
            "S. A. Bargal",
            "A. Andonian",
            "T. Yan",
            "K. Ramakrishnan",
            "L. Brown",
            "Q. Fan",
            "D. Gutfruend",
            "C. Vondrick"
        ],
        "dcterms:description": "The Moments in Time dataset consists of one million videos designed for event understanding, covering a wide range of activities and events.",
        "dcterms:title": "Moments in Time",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1801.03150",
        "dcat:theme": [
            "Event Understanding",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Event recognition",
            "Video dataset",
            "Temporal understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Event Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A. R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "UCF-101 is a dataset of 101 human action classes from videos in the wild, widely used for action recognition tasks.",
        "dcterms:title": "UCF-101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1212.0402",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "H. Garrote",
            "E. Poggio",
            "T. Serre"
        ],
        "dcterms:description": "HMDB-51 is a large video database for human motion recognition, containing a diverse set of actions and activities.",
        "dcterms:title": "HMDB-51",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Motion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Motion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. Caba Heilbron",
            "V. Escorcia",
            "B. Ghanem",
            "J. Carlos Niebles"
        ],
        "dcterms:description": "ActivityNet is a large-scale video benchmark for human activity understanding, providing a diverse set of activities and annotations.",
        "dcterms:title": "ActivityNet",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Activity Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human activities",
            "Video dataset",
            "Activity recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    }
]