[
    {
        "dcterms:creator": [
            "G. A. Sigurdsson",
            "G. Varol",
            "X. Wang",
            "A. Farhadi",
            "I. Laptev",
            "A. Gupta"
        ],
        "dcterms:description": "The Charades video dataset is composed of daily indoor activities collected through Amazon Mechanical Turk. There are 157 action classes and on average 6.8 actions in each video, which occur in various orders and contexts.",
        "dcterms:title": "Charades",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Analysis",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action detection",
            "Weakly-supervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Detection",
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Everingham",
            "L. Van Gool",
            "C. K. Williams",
            "J. Winn",
            "A. Zisserman"
        ],
        "dcterms:description": "The PASCAL Visual Object Classes (VOC) challenge is a benchmark in visual object category recognition and detection, providing a standard dataset for evaluating object detection algorithms.",
        "dcterms:title": "PASCAL VOC",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Visual recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "T. Lin",
            "M. Maire",
            "S. J. Belongie",
            "L. D. Bourdev",
            "R. B. Girshick",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C. L. Zitnick"
        ],
        "dcterms:description": "Microsoft COCO is a large-scale object detection, segmentation, and captioning dataset that contains images of complex everyday scenes.",
        "dcterms:title": "MS COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Image Segmentation"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A. R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "UCF101 is a dataset of 101 human action classes from videos in the wild, designed for action recognition tasks.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human action",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]