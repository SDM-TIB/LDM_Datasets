[
    {
        "dcterms:creator": [
            "G. Orchard",
            "A. Jayawant",
            "G. Cohen",
            "N. Thakor"
        ],
        "dcterms:description": "The N-MNIST dataset consists of recordings from an event-based vision sensor that captures local temporal contrast changes. Events are generated when the contrast change exceeds a threshold, and each event is encoded with position, polarity, and timestamp. The dataset is used for neuromorphic vision tasks, particularly in recognizing digits through spatio-temporal event streams.",
        "dcterms:title": "N-MNIST",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1507.07629",
        "dcat:theme": [
            "Neuromorphic Vision",
            "Event-based Data"
        ],
        "dcat:keyword": [
            "Event-based vision",
            "Neuromorphic dataset",
            "Digit recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Visual recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Cooke",
            "J. Barker",
            "S. Cunningham",
            "X. Shao"
        ],
        "dcterms:description": "The GRID dataset is an audio-visual corpus designed for speech perception and automatic speech recognition. It includes video and audio recordings of speakers uttering sentences composed of a fixed grammar and vocabulary, facilitating research in multimodal learning and sensor fusion.",
        "dcterms:title": "GRID",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Audio-visual corpus",
            "Speech perception",
            "Automatic speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio and Video",
        "mls:task": [
            "Speech recognition",
            "Lip reading"
        ]
    },
    {
        "dcterms:creator": [
            "C. Posch",
            "T. Serrano-Gotarredona",
            "B. Linares-Barranco",
            "T. Delbruck"
        ],
        "dcterms:description": "The MNIST dataset is a well-known collection of handwritten digits used for training various image processing systems. In this context, it is referenced in relation to retinomorphic event-based vision sensors that produce spiking outputs, allowing for the study of neuromorphic computing.",
        "dcterms:title": "MNIST",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Handwritten digits",
            "Image dataset",
            "Spiking outputs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Digit recognition"
        ]
    }
]