To extract datasets from the research paper titled "Knowledge-Guided Recurrent Neural Network Learning for Task-Oriented Action Prediction" by Liang Lin et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract, introduction, and experiments sections** to gather initial insights about any datasets that may be referenced. The abstract mentions the creation of a new dataset containing diverse daily tasks, which indicates that there is a dataset of interest.

Next, I will focus on **section 6 (Experiments)**, where the authors provide detailed information about the dataset they created. Here, they describe the dataset as containing 13 daily tasks and 861 RGB-D images captured from 16 scenarios. This section is crucial as it outlines the specifics of the dataset, including the types of tasks and the number of images.

The authors specify that the dataset includes:
- **General daily tasks**: Such as "make tea," "make ramen," "pour water," and "wash apple."
- **Derived tasks**: Like "pour water with cup" and "make tea using water from water-dispenser."
- **Annotated objects**: The dataset includes annotations for objects in the images, such as "bowl," "cup," "pot," and "water-dispenser."

I will also check the **References section** to find any citations related to the dataset. However, it appears that the dataset is newly created by the authors, and thus, it may not have a separate citation in the references.

Now, I will compile the information into a structured format, ensuring to include the full citation for the paper itself, as it is essential to attribute the dataset correctly.

The full citation for the paper is:
> Liang Lin, Lili Huang, Tianshui Chen, Yukang Gan, and Hui Cheng. "Knowledge-Guided Recurrent Neural Network Learning for Task-Oriented Action Prediction." In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2017.

Finally, I will summarize the dataset details, including the number of tasks, images, and the types of annotations provided, ensuring that the information is clear and comprehensive for future reference.