To extract the datasets mentioned in the research paper titled "Pushing Paraphrase Away from Original Sentence: A Multi-Round Paraphrase Generation Approach" by Zhe Lin and Xiaojun Wan, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** of the paper to identify any datasets that are explicitly mentioned. The abstract states that the authors evaluate their method on **two benchmark datasets**, which indicates that datasets are involved.

Next, I will focus on **section 4.1 (Datasets)**, where the authors provide detailed descriptions of the datasets used for evaluation. Here, they mention:

1. **MSCOCO Dataset**: This dataset contains human-annotated captions for over 120,000 images, with each image having five captions from different annotators. The authors note that this dataset has been widely used in previous works.

2. **Quora Dataset**: This dataset consists of over 400,000 question pairs, where each pair is marked with a binary value indicating whether the questions are duplicates. The authors specify that they selected all pairs with a binary value of 1, resulting in about 150,000 question pairs.

After identifying the datasets, I will check the **References section** to find the full citations for these datasets:

- For the **MSCOCO Dataset**, the citation is:
  > Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollar, and C Lawrence Zitnick. *Microsoft COCO: Common Objects in Context*. In European Conference on Computer Vision, pages 740â€“755, 2014.

- For the **Quora Dataset**, the citation is:
  > Quora. *Quora Question Pairs Dataset*. Available at: https://www.kaggle.com/c/quora-question-pairs/data?select=train.csv.zip.

Now that I have the dataset names and their full citations, I will compile this information into a structured format for further use or processing. This ensures that I have accurately captured the datasets and their sources as described in the paper.