[
    {
        "dcterms:creator": [
            "Jieyu Zhao",
            "Tianlu Wang",
            "Mark Yatskar",
            "Ryan Cotterell",
            "Vicente Ordonez",
            "Kai-Wei Chang"
        ],
        "dcterms:description": "A benchmark dataset for measuring bias in coreference pronoun resolution, consisting of two test sets with sentences that have ambiguous pronouns resolved in both pro- and anti-stereotypical contexts.",
        "dcterms:title": "WinoBias",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Bias Measurement"
        ],
        "dcat:keyword": [
            "Coreference resolution",
            "Gender bias",
            "Pronoun resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Coreference resolution",
            "Bias quantification"
        ]
    },
    {
        "dcterms:creator": [
            "Ralph Weischedel",
            "Eduard Hovy",
            "Mitchell Marcus",
            "Martha Palmer",
            "Robert Belvin",
            "Sameer Pradhan",
            "Lance Ramshaw",
            "Nianwen Xue"
        ],
        "dcterms:description": "A large training corpus designed for enhanced processing in natural language understanding tasks.",
        "dcterms:title": "OntoNotes 5.0",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Corpus"
        ],
        "dcat:keyword": [
            "Training corpus",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ciprian Chelba",
            "Tomas Mikolov",
            "Mike Schuster",
            "Qi Ge",
            "Thorsten Brants",
            "Phillipp Koehn"
        ],
        "dcterms:description": "A benchmark dataset consisting of one billion words, used for measuring progress in statistical language modeling.",
        "dcterms:title": "Billion Word corpus",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Yukun Zhu",
            "Ryan Kiros",
            "Richard S. Zemel",
            "Ruslan Salakhutdinov",
            "Raquel Urtasun",
            "Antonio Torralba",
            "Sanja Fidler"
        ],
        "dcterms:description": "A dataset consisting of books and their corresponding movie adaptations, used for aligning visual and textual information.",
        "dcterms:title": "BookCorpus",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Books",
            "Movies",
            "Visual explanations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Rachel Rudinger",
            "Jason Naradowsky",
            "Brian Leonard",
            "Benjamin Van Durme"
        ],
        "dcterms:description": "A dataset designed to evaluate gender bias in coreference resolution, focusing on the resolution of gendered pronouns.",
        "dcterms:title": "Winogender",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Bias Measurement"
        ],
        "dcat:keyword": [
            "Coreference resolution",
            "Gender bias",
            "Pronoun resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Coreference resolution",
            "Bias quantification"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A benchmark for evaluating the performance of models on a variety of NLP tasks, including those related to bias.",
        "dcterms:title": "SuperGLUE",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmark"
        ],
        "dcat:keyword": [
            "NLP tasks",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]