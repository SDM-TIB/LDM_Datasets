To extract datasets from the research paper titled "Machine and Deep Learning Methods with Manual and Automatic Labelling for News Classification in Bangla Language" by Istiak Ahmad et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and results sections** to identify any datasets mentioned. The abstract indicates that the authors developed a dataset called **Potrika**, which is a significant clue that a dataset is present.

Next, I will focus on the **introduction** and **methodology sections**. In the introduction, the authors mention that they developed Potrika, the largest dataset for news classification in the Bangla language, which comprises 185.51 million words and 12.57 million sentences from 664,880 news articles. This section provides essential details about the dataset, including its size and the number of articles.

In the **methodology section**, specifically section 3.2, the authors provide a detailed description of the Potrika dataset, including its attributes and the sources from which it was curated. They mention that the dataset is divided into eight categories: National, Sports, International, Entertainment, Economy, Education, Politics, and Science & Technology. This confirms the dataset's structure and purpose.

I will also check the **references section** to find the full citation for the Potrika dataset. The authors cite their own work for this dataset, which is crucial for proper attribution.

The citation for the Potrika dataset is:
> Istiak Ahmad, Fahad AlQurashi, and Rashid Mehmood. *Potrika: Raw and balanced newspaper datasets in the Bangla language with eight topics and five attributes*. 2022. DOI: https://doi.org/10.17632/v362rp78dc.2.

Now, I will compile the information into a structured format, ensuring that I include the dataset name, description, and full citation.

After completing this process, I will have a clear and concise entry for the Potrika dataset, ready for further use or analysis.