To extract datasets from the research paper titled "Interaction Relational Network for Mutual Action Recognition" by Mauricio Perez et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors validate their approach on several datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on the **experiments section** where the authors explicitly mention the datasets used for their evaluations. In this section, they refer to four datasets:

1. **SBU Dataset**: This dataset is used for two-person interaction recognition and consists of 282 short videos with various interactions. The authors mention that it provides RGBD data captured using Kinect.

2. **UT-Interaction Dataset**: This dataset focuses on inter-person interactions and contains 120 videos across six action classes. The authors note that they used OpenPose to extract pose information from the RGB videos.

3. **NTU RGB+D Dataset**: Although primarily for general action recognition, this dataset includes 11 classes of mutual actions. It consists of 10,347 videos collected with Kinect under challenging conditions.

4. **NTU RGB+D 120 Dataset**: This is an extension of the NTU RGB+D dataset, containing 24,794 videos and 15 mutual-action classes. The authors highlight its complexity and the large number of classes.

After identifying these datasets, I will check the **References section** for the full citations of each dataset:

- For the **SBU Dataset**, the citation is:
  > Yun, K., Honorio, J., Chattopadhyay, D., Berg, T. L., & Samaras, D. (2012). Two-person interaction detection using body-pose features and multiple instance learning. In IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), 2012, pp. 28–35.

- For the **UT-Interaction Dataset**, the citation is:
  > Ryoo, M. S., & Aggarwal, J. K. (2009). Spatio-Temporal Relationship Match: Video Structure Comparison for Recognition of Complex Human Activities. In IEEE International Conference on Computer Vision (ICCV), 2009, pp. 1593–1600.

- For the **NTU RGB+D Dataset**, the citation is:
  > Shahroudy, A., Liu, J., Ng, T.-T., & Wang, G. (2016). NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp. 1010–1019.

- For the **NTU RGB+D 120 Dataset**, the citation is:
  > Liu, J., Shahroudy, A., Perez, M., Wang, G., Duan, L.-Y., & Kot, A. C. (2019). NTU RGB+D 120: A Large-Scale Benchmark for 3D Human Activity Understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 42(10), 2684–2701.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.