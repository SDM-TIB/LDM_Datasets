[
    {
        "dcterms:creator": [
            "L. Martínez-Villasen˜or",
            "H. Ponce",
            "J. Brieva",
            "E. Moya-Albor",
            "J. Nu´n˜ez-Mart´ınez",
            "C. Pen˜afort-Asturiano"
        ],
        "dcterms:description": "The UP-Fall Detection dataset was recorded with the help of 17 adult subjects who performed 11 daily activities along with falls, with three attempts each. The daily activities involve six simple activities such as walking, standing, picking up an object, sitting, jumping, and laying. They recorded five types of falls.",
        "dcterms:title": "UP-Fall Detection",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Fall Detection"
        ],
        "dcat:keyword": [
            "Multimodal",
            "Activity Recognition",
            "Fall Detection",
            "Wearable Sensors",
            "Video Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition",
            "Fall Detection"
        ]
    },
    {
        "dcterms:creator": [
            "C. Chen",
            "R. Jafari",
            "N. Kehtarnavaz"
        ],
        "dcterms:description": "The UTD-MHAD dataset consists of four temporally synchronized data modalities, which include RGB videos, depth videos, skeleton positions, and wearable inertial signals. It contains 27 actions performed by 8 subjects, where each action is repeated 4 times by all the subjects.",
        "dcterms:title": "UTD-MHAD",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Multimodal",
            "Activity Recognition",
            "Depth Camera",
            "Wearable Sensors",
            "RGB Videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. Ofli",
            "R. Chaudhry",
            "G. Kurillo",
            "R. Vidal",
            "R. Bajcsy"
        ],
        "dcterms:description": "The Berkeley-MHAD dataset consists of temporally synchronized data from an optical motion capture system, multi-baseline stereo cameras from multiple views, depth sensors, accelerometers, and microphones. The dataset contains 11 actions performed by 12 subjects.",
        "dcterms:title": "Berkeley-MHAD",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Multimodal",
            "Activity Recognition",
            "Optical Motion Capture",
            "Depth Sensors",
            "Accelerometers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Wei",
            "P. Chopada",
            "N. Kehtarnavaz"
        ],
        "dcterms:description": "The Continuous Multimodal Human Action Dataset (C-MHAD) is a first of its kind multimodal activity recognition dataset in which video and inertial data stream were captured simultaneously in a continuous way. The dataset contains actions performed by subjects captured with wearable inertial sensors and video.",
        "dcterms:title": "C-MHAD",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Continuous Data"
        ],
        "dcat:keyword": [
            "Continuous Data",
            "Multimodal",
            "Activity Recognition",
            "Wearable Sensors",
            "Video Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    }
]