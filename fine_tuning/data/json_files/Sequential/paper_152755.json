[
    {
        "dcterms:creator": [
            "S. Zhang",
            "E. Dinan",
            "J. Urbanek",
            "A. Szlam",
            "D. Kiela",
            "J. Weston"
        ],
        "dcterms:description": "A crowd-sourced dialogue dataset where each speaker conditions their utterances on a predefined profile comprising a few sentences defining a personality.",
        "dcterms:title": "PERSONA-CHAT",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1801.07243",
        "dcat:theme": [
            "Natural Language Processing",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "Dialogue dataset",
            "Conversational agents",
            "Personality-based dialogue"
        ],
        "dcat:landingPage": "https://github.com/huggingface/pytorch-openai-transformer-lm",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue generation",
            "Next utterance prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhu",
            "R. Kiros",
            "R. Zemel",
            "R. Salakhutdinov",
            "R. Urtasun",
            "A. Torralba",
            "S. Fidler"
        ],
        "dcterms:description": "A dataset containing over 7,000 unpublished books from various genres, used for pre-training language models.",
        "dcterms:title": "BooksCorpus",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1506.06724",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Language model pre-training",
            "Unpublished books"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling"
        ]
    },
    {
        "dcterms:creator": [
            "C. Chelba",
            "T. Mikolov",
            "M. Schuster",
            "Q. Ge",
            "T. Brants",
            "P. Koehn",
            "T. Robinson"
        ],
        "dcterms:description": "A benchmark dataset for measuring progress in statistical language modeling, consisting of one billion words.",
        "dcterms:title": "Billion Word Benchmark",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1312.3005",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling benchmark",
            "Statistical language modeling",
            "Large text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling"
        ]
    }
]