[
    {
        "dcterms:creator": [
            "C. Hori",
            "H. Alamri",
            "J. Wang",
            "G. Winchern",
            "T. Hori",
            "A. Cherian",
            "T. K. Marks",
            "V. Cartillier",
            "R. G. Lopes",
            "A. Das"
        ],
        "dcterms:description": "The AVSD dataset is designed for the Audio Visual Scene-aware Dialog task, which includes multiple modalities such as video, dialogue history, summary, and caption to facilitate scene-aware dialogue generation.",
        "dcterms:title": "Audio Visual Scene-aware Dialog (AVSD)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1806.08409",
        "dcat:theme": [
            "Multimodal Dialogue",
            "Video Understanding"
        ],
        "dcat:keyword": [
            "Dialogue generation",
            "Video",
            "Multimodal",
            "Scene-aware"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Video",
        "mls:task": [
            "Dialogue Generation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Antol",
            "A. Agrawal",
            "J. Lu",
            "M. Mitchell",
            "D. Batra",
            "C. Lawrence Zitnick",
            "D. Parikh"
        ],
        "dcterms:description": "The VQA dataset consists of images paired with questions and answers, enabling models to learn visual question answering.",
        "dcterms:title": "VQA (Visual Question Answering)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Image",
            "Question Answering",
            "Visual Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Carreira",
            "A. Zisserman"
        ],
        "dcterms:description": "The Kinetics dataset is a large-scale dataset for action recognition in videos, containing a diverse set of human actions.",
        "dcterms:title": "Kinetics Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "The Penn Action Dataset contains video clips with detailed annotations for various actions, enabling detailed action understanding.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "D. Tran",
            "L. Bourdev",
            "R. Fergus",
            "L. Torresani",
            "M. Paluri"
        ],
        "dcterms:description": "C3D is a dataset that focuses on learning spatiotemporal features using 3D convolutional networks for video analysis.",
        "dcterms:title": "C3D",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Analysis"
        ],
        "dcat:keyword": [
            "3D Convolutional Networks",
            "Video features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Pennington",
            "R. Socher",
            "C. Manning"
        ],
        "dcterms:description": "GloVe is a dataset for generating global vectors for word representation, useful in various natural language processing tasks.",
        "dcterms:title": "Glove",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word Embedding",
            "Text Representation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Representation"
        ]
    }
]