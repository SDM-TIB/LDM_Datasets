[
    {
        "dcterms:creator": [
            "J. Shen",
            "R. Pang",
            "R. J. Weiss",
            "M. Schuster",
            "N. Jaitly",
            "Z. Yang",
            "Z. Chen",
            "Y. Zhang",
            "Y. Wang",
            "R. Skerrv-Ryan"
        ],
        "dcterms:description": "A text-to-speech model that generates speech conditioned on mel spectrogram predictions.",
        "dcterms:title": "Tacotron 2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "TTS",
            "mel spectrogram",
            "speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "D. Povey",
            "A. Ghoshal",
            "G. Boulianne",
            "L. Burget",
            "O. Glembek",
            "N. Goel",
            "M. Hannemann",
            "P. Motlicek",
            "Y. Qian",
            "P. Schwarz",
            "J. Silovsky",
            "G. Stemmer",
            "K. Vesely"
        ],
        "dcterms:description": "A toolkit for speech recognition that provides various tools and libraries for building speech recognition systems.",
        "dcterms:title": "Kaldi Toolkit",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "speech recognition",
            "toolkit",
            "ASR"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "B. McFee",
            "V. Lostanlen",
            "M. McVicar",
            "A. Metsai",
            "S. Balke",
            "C. Thomé",
            "C. Raffel",
            "A. Malek",
            "D. Lee",
            "F. Zalkow",
            "K. Lee",
            "O. Nieto",
            "J. Mason",
            "D. Ellis",
            "R. Yamamoto",
            "S. Seyfarth",
            "E. Battenberg",
            "V. Moroz",
            "R. Bittner",
            "K. Choi",
            "J. Moore",
            "Z. Wei",
            "S. Hidaka",
            "nullmightybofo",
            "P. Friesch",
            "F.-R. Stöter",
            "D. Hereñu",
            "T. Kim",
            "M. Vollrath",
            "A. Weiss"
        ],
        "dcterms:description": "A Python library for audio and music analysis, providing tools for audio processing.",
        "dcterms:title": "Librosa",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing",
            "Music Analysis"
        ],
        "dcat:keyword": [
            "audio analysis",
            "music processing",
            "Python library"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "0.7.2",
        "dcterms:format": "",
        "mls:task": [
            "Audio Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "N. Kalchbrenner",
            "E. Elsen",
            "K. Simonyan",
            "S. Noury",
            "N. Casagrande",
            "E. Lockhart",
            "F. Stimberg",
            "A. van den Oord",
            "S. Dieleman",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "A neural audio synthesis model that efficiently generates audio waveforms.",
        "dcterms:title": "WaveRNN",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Synthesis",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "audio synthesis",
            "neural networks",
            "WaveRNN"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ren",
            "C. Hu",
            "X. Tan",
            "T. Qin",
            "S. Zhao",
            "Z. Zhao",
            "T.-Y. Liu"
        ],
        "dcterms:description": "An end-to-end text-to-speech model that is fast and produces high-quality speech.",
        "dcterms:title": "FastSpeech 2",
        "dcterms:issued": "In Press",
        "dcterms:language": "",
        "dcterms:identifier": "https://openreview.net/forum?id=piLPYqxtWuA",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "TTS",
            "fast synthesis",
            "high quality"
        ],
        "dcat:landingPage": "https://openreview.net/forum?id=piLPYqxtWuA",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Lee",
            "T. Kim"
        ],
        "dcterms:description": "A model for robust and fine-grained prosody control in end-to-end speech synthesis.",
        "dcterms:title": "T-VAE",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Prosody Control"
        ],
        "dcat:keyword": [
            "prosody control",
            "T-VAE",
            "speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A proprietary dataset used for evaluating speech synthesis models, consisting of approximately 38 hours of Mexican-Spanish speech.",
        "dcterms:title": "Mexican-Spanish corpus",
        "dcterms:issued": "",
        "dcterms:language": "Spanish",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Speech Data"
        ],
        "dcat:keyword": [
            "Mexican-Spanish",
            "speech corpus",
            "proprietary dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A method for subjective assessment of intermediate sound quality.",
        "dcterms:title": "MUSHRA",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sound Quality Assessment"
        ],
        "dcat:keyword": [
            "MUSHRA",
            "sound quality",
            "subjective assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]