To extract datasets from the research paper titled "Implicit Premise Generation with Discourse-aware Commonsense Knowledge Models" by Tuhin Chakrabarty et al., I will follow a systematic approach to identify and document each dataset mentioned in the paper, ensuring to include full citations for each.

First, I will read through the **abstract, introduction, and datasets sections** of the paper. The abstract mentions the largest available dataset for enthymemes, which is a good starting point for identifying datasets.

In the **introduction**, the authors discuss the challenges of generating implicit premises and reference the **Habernal et al. (2018)** dataset, which consists of 1.7k samples. This indicates that this dataset is relevant to their work.

Next, I will focus on the **Datasets section (Section 3)**, where the authors provide detailed information about the datasets used in their research. They mention:

1. **Abductive Reasoning in Narrative Text (ART)**: This dataset is used for training their models and consists of 50,481 instances. It is developed for the abductive NLG task and is based on observations drawn from the ROCStories dataset.

2. **Argument Reasoning Comprehension Task (D1)**: This dataset contains 1,654 triples of claims, premises, and implicit premises, as released by Habernal et al. (2018).

3. **Dataset by Boltužić and Šnajder (D2)**: This dataset includes 494 enthymemes from an online debate forum, annotated with implicit premises.

4. **Dataset by Becker et al. (2020) (D3)**: This dataset contains 112 enthymemes with implicit premises annotated for arguments from the MicroText Corpus.

Now, I will look into the **References section** to find the full citations for each of these datasets:

- For the **Habernal et al. (2018)** dataset, the citation is:
  > Ivan Habernal, Henning Wachsmuth, Iryna Gurevych, and Benno Stein. *The argument reasoning comprehension task: Identification and reconstruction of implicit warrants*. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1930–1940, New Orleans, Louisiana. Association for Computational Linguistics.

- For the **ART dataset** (Bhagavatula et al., 2020), the citation is:
  > Chandra Bhagavatula, Ronan Le Bras, Chaitanya Malaviya, Keisuke Sakaguchi, Ari Holtzman, Hannah Rashkin, Doug Downey, Wen tau Yih, and Yejin Choi. *Abductive commonsense reasoning*. In International Conference on Learning Representations.

- For the **Boltužić and Šnajder (2016)** dataset, the citation is:
  > Filip Boltužić and Jan Šnajder. *Fill the gap! analyzing implicit premises between claims from online debates*. In Proceedings of the Third Workshop on Argument Mining (ArgMining2016), Berlin, Germany. Association for Computational Linguistics.

- For the **Becker et al. (2020)** dataset, the citation is:
  > Maria Becker, Katharina Korfhage, and Anette Frank. *Implicit knowledge in argumentative texts: An annotated corpus*. In Proceedings of the 12th Language Resources and Evaluation Conference, pages 2316–2324, Marseille, France. European Language Resources Association.

After gathering all this information, I will compile the dataset entries, ensuring that each dataset is clearly described and properly cited. This will provide a comprehensive overview of the datasets utilized in the research paper.