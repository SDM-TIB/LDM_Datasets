[
    {
        "dcterms:creator": [
            "P. Liang",
            "R. Salakhutdinov",
            "L.-P. Morency"
        ],
        "dcterms:description": "The CMU-MOSEI dataset consists of 23,453 single-speaker video segments from YouTube, manually transcribed and annotated for sentiment and emotion, covering six emotions: happy, sad, angry, disgust, surprise, and fear.",
        "dcterms:title": "CMU-MOSEI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Video segments",
            "Sentiment analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. S. Chung",
            "A. Nagrani",
            "A. Zisserman"
        ],
        "dcterms:description": "The VoxCeleb2 dataset contains audio data from 1.1 million examples of speakers, used for speaker recognition tasks. It includes data from multiple languages, filtered to focus on English for training.",
        "dcterms:title": "VoxCeleb2",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speaker recognition",
            "Audio dataset",
            "Multilingual data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "V. Peddinti",
            "D. Povey",
            "S. Khudanpur"
        ],
        "dcterms:description": "The Librispeech dataset is used for automatic speech recognition, providing transcriptions and audio data for training ASR models.",
        "dcterms:title": "Librispeech",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Transcriptions",
            "ASR training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S. Albanie",
            "A. Nagrani",
            "A. Vedaldi",
            "A. Zisserman"
        ],
        "dcterms:description": "The EmoVoxceleb dataset is a subset of VoxCeleb2, containing 100k videos for emotion recognition in speech, focusing on emotional content.",
        "dcterms:title": "EmoVoxceleb",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Video dataset",
            "Speech emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S.-Y. Tseng",
            "B. Baucom",
            "P. Georgiou"
        ],
        "dcterms:description": "The OpenSubtitles Corpus is used for extracting text-only embeddings, containing a large number of sentence pairs for training models.",
        "dcterms:title": "OpenSubtitles Corpus",
        "dcterms:issued": "2019",
        "dcterms:language": "Multiple",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Analysis"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Sentence pairs",
            "Multilingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Embedding Extraction"
        ]
    },
    {
        "dcterms:creator": [
            "S.-Y. Tseng",
            "P. Georgiou",
            "S. Narayanan"
        ],
        "dcterms:description": "The 1 Billion Word Language Model Benchmark is a large dataset used for training language models, providing a vast amount of text data.",
        "dcterms:title": "1 Billion Word Language Model Benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language model",
            "Text dataset",
            "Large corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    }
]