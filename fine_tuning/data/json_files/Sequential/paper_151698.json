[
    {
        "dcterms:creator": [],
        "dcterms:description": "A new 360° video saliency dataset containing challenging videos with saliency heatmap annotations, designed to evaluate saliency prediction methods in 360° videos.",
        "dcterms:title": "Wild-360",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "360° video",
            "saliency prediction",
            "saliency heatmap",
            "video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Saliency Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Bylinskii",
            "T. Judd",
            "A. Borji",
            "L. Itti",
            "F. Durand",
            "A. Oliva",
            "A. Torralba"
        ],
        "dcterms:description": "A benchmark dataset consisting of 300 images of indoor or outdoor scenes, collected from 39 observers using an eye tracker, used for evaluating saliency prediction methods.",
        "dcterms:title": "MIT300",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Saliency Detection"
        ],
        "dcat:keyword": [
            "saliency benchmark",
            "eye tracking",
            "image dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Saliency Detection"
        ]
    },
    {
        "dcterms:creator": [
            "M. Jiang",
            "S. Huang",
            "J. Duan",
            "Q. Zhao"
        ],
        "dcterms:description": "A dataset with 10,000 annotations on MS COCO images, collected using a mouse-contingent multi-resolution paradigm to simulate natural viewing behavior.",
        "dcterms:title": "SALICON",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Saliency Detection"
        ],
        "dcat:keyword": [
            "saliency in context",
            "image dataset",
            "human attention"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Saliency Detection"
        ]
    },
    {
        "dcterms:creator": [
            "J. Pont-Tuset",
            "F. Perazzi",
            "S. Caelles",
            "P. Arbeláez",
            "A. Sorkine-Hornung",
            "L. Van Gool"
        ],
        "dcterms:description": "A dataset for video object segmentation containing 50 high-resolution image sequences with pixel-level object masks.",
        "dcterms:title": "Densely-Annotated VIdeo Segmentation (DAVIS)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1704.00675",
        "dcat:theme": [
            "Computer Vision",
            "Video Segmentation"
        ],
        "dcat:keyword": [
            "video dataset",
            "object segmentation",
            "pixel-level annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Object Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "P. K. Mital",
            "T. J. Smith",
            "R. L. Hill",
            "J. M. Henderson"
        ],
        "dcterms:description": "A dataset that collects gaze data from over 250 participants watching 85 different videos, reporting fixations with respect to user gaze.",
        "dcterms:title": "DIEM",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cognitive Science",
            "Gaze Tracking"
        ],
        "dcat:keyword": [
            "gaze data",
            "video dataset",
            "human attention"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Gaze Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "P. Ochs",
            "J. Malik",
            "T. Brox"
        ],
        "dcterms:description": "A dataset comprising 720 frames annotated with pixel-accurate segmentation of moving objects, used for motion segmentation tasks.",
        "dcterms:title": "Freiburg-Berkeley Motion Segmentation Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Motion Segmentation"
        ],
        "dcat:keyword": [
            "motion segmentation",
            "video dataset",
            "pixel-level annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Motion Segmentation"
        ]
    }
]