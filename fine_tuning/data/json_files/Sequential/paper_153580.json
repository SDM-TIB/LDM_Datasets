[
    {
        "dcterms:creator": [
            "J. R. Hershey",
            "Z. Chen",
            "J. Le Roux",
            "S. Watanabe"
        ],
        "dcterms:description": "The WSJ0 two-talker mixed-speech separation task involves separating mixed speech from two speakers, evaluated using signal-to-distortion ratio (SDR).",
        "dcterms:title": "WSJ0 two-talker mixed-speech separation task",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Mixed Speech",
            "Two-Talker Separation",
            "Signal-to-Distortion Ratio"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Isik",
            "J. Le Roux",
            "Z. Chen",
            "S. Watanabe",
            "J. R. Hershey"
        ],
        "dcterms:description": "The WSJ0 corpus is a dataset used for training and evaluating speech separation models, containing a variety of utterances from different speakers.",
        "dcterms:title": "WSJ0 corpus",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech Corpus",
            "Multi-Speaker",
            "Speech Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Kolbæk",
            "D. Yu",
            "Z.-H. Tan",
            "J. Jensen"
        ],
        "dcterms:description": "The si_tr_s dataset is used for training models in speech separation tasks, containing utterances from multiple speakers.",
        "dcterms:title": "si_tr_s",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Training Dataset",
            "Speech Separation",
            "Multi-Speaker"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Kolbæk",
            "D. Yu",
            "Z.-H. Tan",
            "J. Jensen"
        ],
        "dcterms:description": "The si_dt_05 and si_et_05 datasets are used for testing models in speech separation tasks, containing utterances from multiple speakers.",
        "dcterms:title": "si_dt_05 and si_et_05",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Testing Dataset",
            "Speech Separation",
            "Multi-Speaker"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    }
]