To extract the datasets mentioned in the paper titled "Facial Expression Recognition and Image Description Generation in Vietnamese" by Khang Nhut Lam et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and proposed approach sections** to identify any datasets that are explicitly mentioned. In the abstract, the authors refer to the **KDEF dataset** and the **Flickr8k dataset**, indicating that these are key datasets used in their research.

Next, I will focus on **section 2 (Proposed Approach)**, particularly **subsection 2.1 (Datasets Pre-processing)**, where the authors provide detailed descriptions of the datasets used:

1. **KDEF Dataset**: The authors describe it as comprising 4,900 images of 70 individuals displaying 7 emotional expressions, viewed from 5 different angles. They also mention how the dataset is divided into training, validation, and test sets.

2. **Flickr8k Dataset**: This dataset consists of 8,092 images, each with 5 description sentences. The authors note that they translated the descriptions from English to Vietnamese.

3. **Flickr30k Dataset**: Similar to Flickr8k, this dataset contains 31,783 images, each with 5 description sentences. The authors mention that both Flickr8k and Flickr30k datasets are used for generating image descriptions.

In the **References section**, I will look for the full citations for these datasets. The citations I find are:

- For the **KDEF dataset**, the citation is:
  > Lundqvist D, Flykt A, Ã–hman A. *The Karolinska directed emotional faces (KDEF)*. CD ROM from Department of Clinical Neuroscience, Psychology section, Karolinska Institutet; 1998; 91(630).

- For the **Flickr8k dataset**, the citation is:
  > Hodosh M, Young P, Hockenmaier J. *Framing image description as a ranking task: Data, models and evaluation metrics*. Journal of Artificial Intelligence Research. 2013; 47:853-899.

- For the **Flickr30k dataset**, the citation is:
  > Young P, Lai A, Hodosh M, Hockenmaier J. *From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions*. Transactions of the Association for Computational Linguistics. 2014; 2:67-78.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding citations.