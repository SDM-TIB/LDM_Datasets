To extract datasets from the research paper titled "Depth estimation from 4D light field videos" by Takahiro Kinoshita and Satoshi Ono, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by reading the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract indicates that the authors constructed a medium-scale synthetic 4D LF video dataset for training deep learning methods, which suggests that a dataset is indeed present.

Next, I will look for specific details about the dataset in the **main body of the paper**, particularly in sections that discuss the methodology and experiments. In **section 4 (4D Light Field Video Dataset)**, the authors describe the Sintel 4D LFV dataset, which is derived from the open-source movie "Sintel." They provide details about the dataset, including its composition of 23 synthetic 4D LF videos, resolution, number of views, and the inclusion of ground-truth disparity values.

The key points about the Sintel 4D LFV dataset are:
- It consists of 23 synthetic 4D LF videos.
- Each video has a resolution of 1,204 × 436 pixels and includes 9 × 9 views with 20–50 frames.
- The dataset includes ground-truth disparity values for the central view.

Now, I will check the **References section** to find the full citation for the Sintel dataset. The authors reference the Sintel movie as follows:
> Roosendaal, T. (Producer), “Sintel. Durian Open Movie Project,” https://durian.blender.org/ (2010).

This citation provides the necessary details about the source of the dataset.

After gathering all this information, I will summarize the dataset in a clear and concise manner, ensuring that I include the full citation as required. The Sintel 4D LFV dataset will be the only dataset extracted from this paper.

Finally, I will compile the dataset entry, ensuring it is ready for any structured output or further processing.