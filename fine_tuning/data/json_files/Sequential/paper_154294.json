[
    {
        "dcterms:creator": [
            "H. Le",
            "L. Vial",
            "J. Frej",
            "V. Segonne",
            "M. Coavoux",
            "B. Lecouteux",
            "A. Allauzen",
            "B. Crabb√©",
            "L. Besacier",
            "D. Schwab"
        ],
        "dcterms:description": "The FLUE benchmark is a collection of five discriminative tasks designed for evaluating French language models, including sentiment analysis, paraphrase identification, and natural language inference.",
        "dcterms:title": "FLUE benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "French",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "French language",
            "discriminative tasks",
            "NLP benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Sentiment Analysis",
            "Paraphrase Identification",
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "A.-J. P. Tixier",
            "M. K. Eddine",
            "M. Vazirgiannis"
        ],
        "dcterms:description": "OrangeSum is a novel summarization dataset created for French, designed to evaluate generative tasks in NLP. It consists of articles scraped from the Orange Actu website along with their corresponding one-sentence summaries.",
        "dcterms:title": "OrangeSum",
        "dcterms:issued": "2023",
        "dcterms:language": "French",
        "dcterms:identifier": "https://github.com/Tixierae/OrangeSum",
        "dcat:theme": [
            "Natural Language Processing",
            "Summarization"
        ],
        "dcat:keyword": [
            "French summarization",
            "generative tasks",
            "abstractive summarization"
        ],
        "dcat:landingPage": "https://github.com/Tixierae/OrangeSum",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Abstractive Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Liu",
            "J. Gu",
            "N. Goyal",
            "X. Li",
            "S. Edunov",
            "M. Ghazvininejad",
            "M. Lewis",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "mBART is a multilingual denoising pre-training model for neural machine translation, which can also be adapted for various NLP tasks across multiple languages.",
        "dcterms:title": "mBART",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2001.08210",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "multilingual model",
            "denoising pre-training",
            "neural machine translation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2001.08210",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation",
            "Text Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A.-J. P. Tixier",
            "M. K. Eddine",
            "M. Vazirgiannis"
        ],
        "dcterms:description": "mBARThez is a multilingual adaptation of the BARThez model, which is a pretrained seq2seq model for French, aimed at improving generative performance on tasks such as summarization.",
        "dcterms:title": "mBARThez",
        "dcterms:issued": "2023",
        "dcterms:language": "French",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Generation"
        ],
        "dcat:keyword": [
            "multilingual model",
            "seq2seq",
            "generative tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Text Generation",
            "Summarization"
        ]
    }
]