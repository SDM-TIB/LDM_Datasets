To extract datasets from the research paper titled "Knowledge Guided Entity-aware Video Captioning and A Basketball Benchmark" by Zeyu Xi et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets that are mentioned. The abstract indicates that a new multimodal basketball video captioning dataset (VC NBA 2022) has been constructed, which is a strong indication that this is a dataset I need to extract.

Next, I will look for specific sections that detail the datasets. In this case, the **Proposed Benchmark** section provides a comprehensive overview of the datasets. Here, the authors describe the construction of two key datasets:

1. **KG NBA 2022**: This is a multimodal basketball game knowledge graph that includes various types of data related to basketball games, such as events, player information, and team information. The authors mention that this knowledge graph contains 11,489 events and 42,870 relationships.

2. **VC NBA 2022**: This dataset is specifically designed for video captioning and includes 9 types of fine-grained shooting events and knowledge about 286 players. The authors state that the dataset comprises 3,977 videos, each annotated with text descriptions and candidate player information.

In the **experiments** section, the authors confirm that they used the VC NBA 2022 dataset for their experiments, which validates its significance in the context of their research.

Now, I will gather the full citations for these datasets from the **References section** of the paper. The citations are as follows:

- For **KG NBA 2022**, the citation is not explicitly provided in the references, as it is a new dataset introduced in this paper. Therefore, I will cite it as:
  > Zeyu Xi, Ge Shi, Xuefen Li, Junchi Yan, Zun Li, Lifang Wu, Zilin Liu, Liang Wang. *KG NBA 2022: A Multimodal Basketball Game Knowledge Graph*. In Knowledge Guided Entity-aware Video Captioning and A Basketball Benchmark, 2023.

- For **VC NBA 2022**, similarly, it is a new dataset introduced in this paper, and I will cite it as:
  > Zeyu Xi, Ge Shi, Xuefen Li, Junchi Yan, Zun Li, Lifang Wu, Zilin Liu, Liang Wang. *VC NBA 2022: A Multimodal Basketball Game Video Captioning Dataset*. In Knowledge Guided Entity-aware Video Captioning and A Basketball Benchmark, 2023.

After gathering this information, I will compile the dataset entries into a structured format that includes the dataset names, descriptions, and citations, ensuring that each dataset is accurately represented and properly cited.