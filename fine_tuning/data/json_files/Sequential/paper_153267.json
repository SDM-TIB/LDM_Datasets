[
    {
        "dcterms:creator": [
            "M. Hodosh",
            "P. Young",
            "J. Hockenmaier"
        ],
        "dcterms:description": "Flickr8k contains 8,000 images taken from online photo sharing application Flickr.com, for which five English captions per image are available. Spoken captions for Flickr8k were collected by having Amazon Mechanical Turk workers pronounce the original written captions.",
        "dcterms:title": "Flickr8k",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Captioning",
            "Speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Caption Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Q. B. Nguyen",
            "J. Gehring",
            "M. Müller",
            "S. Stüker",
            "A. Waibel"
        ],
        "dcterms:description": "Mel Frequency Cepstral Coefficients (MFCCs) are features that can be computed for any speech signal without needing any other data, providing a representation of the audio signal.",
        "dcterms:title": "Mel Frequency Cepstral Coefficients (MFCCs)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Processing",
            "Acoustic Features"
        ],
        "dcat:keyword": [
            "Audio features",
            "Speech recognition",
            "Acoustic modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Fer",
            "P. Matejka",
            "F. Grezl",
            "O. Plchot",
            "K. Vesely",
            "J. H. Cernocky"
        ],
        "dcterms:description": "Multilingual Bottleneck (MBN) features are learned features that result from training a network on top of MFCCs in order to recognise phoneme states, useful in several speech recognition tasks.",
        "dcterms:title": "Multilingual Bottleneck (MBN) features",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Processing",
            "Acoustic Features"
        ],
        "dcat:keyword": [
            "Learned features",
            "Speech recognition",
            "Phoneme classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]