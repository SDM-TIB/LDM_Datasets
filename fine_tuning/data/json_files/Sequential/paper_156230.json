[
    {
        "dcterms:creator": [
            "Nitish Srivastava",
            "Elman Mansimov",
            "Ruslan Salakhudinov"
        ],
        "dcterms:description": "The moving MNIST dataset is a widely used synthetic dataset for evaluating video prediction models, consisting of sequences of handwritten digits moving and bouncing around a black canvas.",
        "dcterms:title": "Moving MNIST",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Video Prediction"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Handwritten digits",
            "Video prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Catalin Ionescu",
            "Dragos Papava",
            "Vlad Olaru",
            "Cristian Sminchisescu"
        ],
        "dcterms:description": "The human3.6m dataset contains 3.6 million different human poses and corresponding images, focusing on various scenarios for 3D human sensing.",
        "dcterms:title": "Human3.6m",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Pose Estimation",
            "3D Human Sensing"
        ],
        "dcat:keyword": [
            "Human poses",
            "3D sensing",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Images",
        "mls:task": [
            "Action Recognition",
            "Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Christian Schuldt",
            "Ivan Laptev",
            "Barbara Caputo"
        ],
        "dcterms:description": "The KTH dataset consists of video sequences of individuals performing various human actions in different scenarios, used for action recognition tasks.",
        "dcterms:title": "KTH",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Junbo Zhang",
            "Yu Zheng",
            "Dekang Qi"
        ],
        "dcterms:description": "TaxiBJ contains complex real-world taxi trajectory data collected from taxicab GPS monitors in Beijing, used for predicting citywide crowd flows.",
        "dcterms:title": "TaxiBJ",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Traffic Prediction",
            "Spatiotemporal Data"
        ],
        "dcat:keyword": [
            "Taxi trajectories",
            "Crowd flow prediction",
            "GPS data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Heatmap",
        "mls:task": [
            "Traffic Flow Prediction"
        ]
    }
]