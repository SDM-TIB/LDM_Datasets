[
    {
        "dcterms:creator": [
            "Naureen Mahmood",
            "Nima Ghorbani",
            "Nikolaus F. Troje",
            "Gerard Pons-Moll",
            "Michael J. Black"
        ],
        "dcterms:description": "AMASS is a large-scale motion capture dataset that provides a rich source of 3D human motion data, which is leveraged for adversarial training in the VIBE model to produce realistic and accurate human motions.",
        "dcterms:title": "AMASS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Motion Capture",
            "3D Human Motion"
        ],
        "dcat:keyword": [
            "3D motion data",
            "adversarial training",
            "human motion",
            "motion capture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation",
            "Motion Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Timo von Marcard",
            "Roberto Henschel",
            "Michael Black",
            "Bodo Rosenhahn",
            "Gerard Pons-Moll"
        ],
        "dcterms:description": "3DPW is an in-the-wild dataset that captures 3D human poses using IMU sensors and handheld cameras, providing a challenging benchmark for evaluating pose estimation methods.",
        "dcterms:title": "3DPW",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Human Pose Estimation",
            "In-the-Wild Data"
        ],
        "dcat:keyword": [
            "3D pose",
            "IMU sensors",
            "human motion",
            "video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Dushyant Mehta",
            "Helge Rhodin",
            "Dan Casas",
            "Pascal Fua",
            "Oleksandr Sotnychenko",
            "Weipeng Xu",
            "Christian Theobalt"
        ],
        "dcterms:description": "MPI-INF-3DHP is a multi-view dataset primarily focused on indoor environments, providing 3D human pose annotations for various actions, which are used to evaluate pose estimation methods.",
        "dcterms:title": "MPI-INF-3DHP",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Human Pose Estimation",
            "Indoor Data"
        ],
        "dcat:keyword": [
            "3D pose",
            "multi-view",
            "human motion",
            "pose estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Catalin Ionescu",
            "Dragos Papava",
            "Vlad Olaru",
            "Cristian Sminchisescu"
        ],
        "dcterms:description": "Human3.6M is a large-scale dataset containing 3D human pose annotations in a controlled environment, widely used for training and evaluating pose estimation models.",
        "dcterms:title": "Human3.6M",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Human Pose Estimation",
            "Controlled Environment Data"
        ],
        "dcat:keyword": [
            "3D pose",
            "large-scale dataset",
            "human motion",
            "pose estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Weiyu Zhang",
            "Menglong Zhu",
            "Konstantinos G Derpanis"
        ],
        "dcterms:description": "PennAction is a dataset consisting of video sequences with detailed 2D human keypoint annotations for various actions, used for training and evaluating action recognition and pose estimation models.",
        "dcterms:title": "PennAction",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "2D Human Pose Estimation"
        ],
        "dcat:keyword": [
            "video dataset",
            "human action",
            "2D keypoints",
            "pose estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action Recognition",
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Mykhaylo Andriluka",
            "Umar Iqbal",
            "Eldar Insafutdinov",
            "Leonid Pishchulin",
            "Anton Milan",
            "Juergen Gall",
            "Bernt Schiele"
        ],
        "dcterms:description": "PoseTrack is a benchmark dataset for multi-person pose estimation and tracking in videos, providing annotations for body keypoints and person IDs across multiple frames.",
        "dcterms:title": "PoseTrack",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Person Pose Estimation",
            "Tracking"
        ],
        "dcat:keyword": [
            "video dataset",
            "multi-person",
            "pose tracking",
            "keypoint annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation",
            "Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Angjoo Kanazawa",
            "Jason Y. Zhang",
            "Panna Felsen",
            "Jitendra Malik"
        ],
        "dcterms:description": "InstaVariety is a dataset curated from Instagram videos, providing 2D annotations for a variety of actions, used for training models in human dynamics and pose estimation.",
        "dcterms:title": "InstaVariety",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Dynamics",
            "2D Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Instagram videos",
            "2D annotations",
            "human dynamics",
            "pose estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation"
        ]
    }
]