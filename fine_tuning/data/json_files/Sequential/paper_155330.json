[
    {
        "dcterms:creator": [
            "J. Kominek",
            "A. W. Black"
        ],
        "dcterms:description": "The CMU-ARCTIC databases contain English speech data recorded from multiple speakers, designed for speech synthesis research.",
        "dcterms:title": "CMU-ARCTIC databases",
        "dcterms:issued": "2004",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Speech database",
            "English speech",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "K. Ito",
            "L. Johnson"
        ],
        "dcterms:description": "The LJ Speech Dataset is a public domain dataset for speech synthesis, containing 13,100 short audio clips of a single speaker reading passages from various texts.",
        "dcterms:title": "LJ Speech Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "https://keithito.com/LJ-Speech-Dataset/",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Single speaker",
            "Text-to-speech"
        ],
        "dcat:landingPage": "https://keithito.com/LJ-Speech-Dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Shen",
            "R. Pang",
            "R. J. Weiss",
            "M. Schuster",
            "N. Jaitly",
            "Z. Yang",
            "Z. Chen",
            "Y. Zhang",
            "Y. Wang",
            "R. Skerrv-Ryan"
        ],
        "dcterms:description": "Tacotron2 is a neural network architecture for text-to-speech synthesis that generates mel spectrograms from text input.",
        "dcterms:title": "Tacotron2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Text-to-speech",
            "Neural network",
            "Mel spectrogram"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "A. v. d. Oord",
            "S. Dieleman",
            "H. Zen",
            "K. Simonyan",
            "O. Vinyals",
            "A. Graves",
            "N. Kalchbrenner",
            "A. Senior",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "WaveNet is a deep generative model for raw audio that produces high-quality speech synthesis.",
        "dcterms:title": "WaveNet",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1609.03499",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Generative model",
            "Raw audio",
            "Speech synthesis"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1609.03499",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "R. Yamamoto",
            "E. Song",
            "J.-M. Kim"
        ],
        "dcterms:description": "WaveGAN is a fast waveform generation model based on generative adversarial networks that uses multi-resolution spectrograms.",
        "dcterms:title": "WaveGAN",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Generative adversarial networks",
            "Waveform generation",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Shen",
            "R. Pang",
            "R. J. Weiss",
            "M. Schuster",
            "N. Jaitly",
            "Z. Yang",
            "Z. Chen",
            "Y. Zhang",
            "Y. Wang",
            "R. Skerrv-Ryan"
        ],
        "dcterms:description": "NSF is a neural vocoder that uses fundamental frequency and voiced/unvoiced flags to simulate the excitation source.",
        "dcterms:title": "NSF",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Neural vocoder",
            "Excitation source",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "M. Morise",
            "F. Yokomori",
            "K. Ozawa"
        ],
        "dcterms:description": "WORLD is a vocoder-based high-quality speech synthesis system designed for real-time applications.",
        "dcterms:title": "WORLD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Vocoder",
            "Speech synthesis",
            "Real-time applications"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Speech Synthesis"
        ]
    }
]