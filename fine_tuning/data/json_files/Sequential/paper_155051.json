[
    {
        "dcterms:creator": [
            "O. Bodenreider"
        ],
        "dcterms:description": "The UMLS Metathesaurus is a biomedical terminology integration system that includes over 200 source vocabularies, organizing synonymous terms into concepts.",
        "dcterms:title": "UMLS Metathesaurus",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical Terminology",
            "Medical Informatics"
        ],
        "dcat:keyword": [
            "UMLS",
            "Metathesaurus",
            "Biomedical Vocabulary"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "V. Nguyen",
            "H. Y. Yip",
            "O. Bodenreider"
        ],
        "dcterms:description": "The UMLS Vocabulary Alignment (UVA) task is designed for synonymy prediction among terms in the UMLS Metathesaurus.",
        "dcterms:title": "UMLS Vocabulary Alignment (UVA) task",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Synonymy Prediction"
        ],
        "dcat:keyword": [
            "Vocabulary Alignment",
            "Synonymy Prediction",
            "UMLS"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Synonymy Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhang",
            "Q. Chen",
            "Z. Yang",
            "H. Lin",
            "Z. Lu"
        ],
        "dcterms:description": "BioWordVec improves biomedical word embeddings by incorporating subword information and MeSH.",
        "dcterms:title": "BioWordVec",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical NLP",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Word Embeddings",
            "Biomedical NLP",
            "Subword Information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Lee",
            "W. Yoon",
            "S. Kim",
            "D. Kim",
            "S. Kim",
            "C. H. So",
            "J. Kang"
        ],
        "dcterms:description": "BioBERT is a pre-trained biomedical language representation model designed for biomedical text mining.",
        "dcterms:title": "BioBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical NLP",
            "Text Mining"
        ],
        "dcat:keyword": [
            "Language Model",
            "Biomedical Text Mining",
            "BERT"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Peng",
            "S. Yan",
            "Z. Lu"
        ],
        "dcterms:description": "BlueBERT is a transfer learning model evaluated on ten benchmarking datasets in biomedical natural language processing.",
        "dcterms:title": "BlueBERT",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Transfer Learning",
            "Biomedical NLP"
        ],
        "dcat:keyword": [
            "Transfer Learning",
            "BERT",
            "Biomedical NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "F. Liu",
            "E. Shareghi",
            "Z. Meng",
            "M. Basaldella",
            "N. Collier"
        ],
        "dcterms:description": "SapBERT is a self-alignment pretraining model for biomedical entity representations.",
        "dcterms:title": "SapBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical NLP",
            "Entity Representation"
        ],
        "dcat:keyword": [
            "Entity Representation",
            "Self-Alignment",
            "Biomedical NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Michalopoulos",
            "Y. Wang",
            "H. Kaka",
            "H. Chen",
            "A. Wong"
        ],
        "dcterms:description": "UMLSBERT augments contextual embeddings with clinical domain knowledge using the UMLS Metathesaurus.",
        "dcterms:title": "UMLSBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Clinical NLP",
            "Contextual Embeddings"
        ],
        "dcat:keyword": [
            "Clinical NLP",
            "UMLS",
            "Contextual Embeddings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]