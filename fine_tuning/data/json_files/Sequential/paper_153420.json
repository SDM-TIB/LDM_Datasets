[
    {
        "dcterms:creator": [
            "Bochen Li",
            "Xinzhao Liu",
            "Karthik Dinesh",
            "Zhiyao Duan",
            "Gaurav Sharma"
        ],
        "dcterms:description": "The URMP database is designed for audio-visual analysis of musical performances, providing recordings of musical instruments in separate tracks and manually corrected F0 trajectories at the frame level.",
        "dcterms:title": "University of Rochester Music Performance (URMP) database",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Music Performance",
            "Audio Analysis"
        ],
        "dcat:keyword": [
            "Multitrack recordings",
            "Musical instruments",
            "F0 trajectories"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio synthesis",
            "Music analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Christophe Veaux",
            "Junichi Yamagishi",
            "Kirsten MacDonald"
        ],
        "dcterms:description": "The VCTK corpus is an English multi-speaker corpus designed for voice cloning, containing recordings from multiple speakers.",
        "dcterms:title": "VCTK speech corpus",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Voice Cloning"
        ],
        "dcat:keyword": [
            "Speech corpus",
            "Multi-speaker",
            "Voice synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech synthesis",
            "Voice cloning"
        ]
    },
    {
        "dcterms:creator": [
            "Jesse Engel",
            "Cinjon Resnick",
            "Adam Roberts",
            "Sander Dieleman",
            "Mohammad Norouzi",
            "Douglas Eck",
            "Karen Simonyan"
        ],
        "dcterms:description": "NSynth is a dataset for neural audio synthesis of musical notes, providing a large collection of musical notes synthesized using WaveNet autoencoders.",
        "dcterms:title": "NSynth",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Synthesis",
            "Music Generation"
        ],
        "dcat:keyword": [
            "Neural synthesis",
            "Musical notes",
            "WaveNet"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio synthesis",
            "Music generation"
        ]
    },
    {
        "dcterms:creator": [
            "Curtis Hawthorne",
            "Andriy Stasyuk",
            "Adam Roberts",
            "Ian Simon",
            "Cheng-Zhi Anna Huang",
            "Sander Dieleman",
            "Erich Elsen",
            "Jesse Engel",
            "Douglas Eck"
        ],
        "dcterms:description": "The MAESTRO dataset enables factorized piano music modeling and generation, providing a large collection of piano performances.",
        "dcterms:title": "MAESTRO Dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1810.12247",
        "dcat:theme": [
            "Piano Music",
            "Music Generation"
        ],
        "dcat:keyword": [
            "Piano performances",
            "Music modeling",
            "Music generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Music generation",
            "Piano modeling"
        ]
    }
]