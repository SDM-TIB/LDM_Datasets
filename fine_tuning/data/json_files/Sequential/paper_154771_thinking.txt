To extract datasets from the research paper titled "Sketch and Refine: Towards Faithful and Informative Table-to-Text Generation" by Peng Wang et al., I will follow a systematic approach to ensure I capture all relevant information accurately.

First, I will read through the **abstract** to identify any datasets mentioned. The abstract states that the authors conducted experiments on the **WikiPerson** and **WikiBio** datasets, which indicates that these datasets are crucial for the research.

Next, I will examine the **introduction** section for any additional context or details about these datasets. The introduction confirms that both datasets are used for generating biographies from Wikipedia tables, providing a clear understanding of their purpose.

I will then look at the **experiments section** (specifically section 4.1) where the authors provide statistics for both datasets. Here, they mention:

1. **WikiBio**: This dataset contains 582,657 training samples, 72,831 validation samples, and 72,831 test samples, with an average target length of 26.1.
2. **WikiPerson**: This dataset has 250,186 training samples, 30,487 validation samples, and 29,982 test samples, with an average target length of 70.6.

These details are essential for understanding the datasets' scale and characteristics.

Next, I will check the **References section** to find the full citations for these datasets. The citations are as follows:

- For **WikiBio**, the citation is:
  > R´emi Lebret, David Grangier, and Michael Auli. *Neural text generation from structured data with application to the biography domain*. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1203–1213, 2016.

- For **WikiPerson**, the citation is:
  > Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang, Jingren Zhou, and Hongxia Yang. *WikiPerson: A Dataset for Generating Biographies from Wikipedia Tables*. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9057–9064, 2020.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing.

In summary, the datasets extracted from the paper are:

1. **WikiBio**: 
   - Description: A dataset for generating biographies from Wikipedia tables.
   - Citation: R´emi Lebret, David Grangier, and Michael Auli. *Neural text generation from structured data with application to the biography domain*. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pages 1203–1213, 2016.

2. **WikiPerson**: 
   - Description: A dataset for generating biographies from Wikipedia tables.
   - Citation: Peng Wang, Junyang Lin, An Yang, Chang Zhou, Yichang Zhang, Jingren Zhou, and Hongxia Yang. *WikiPerson: A Dataset for Generating Biographies from Wikipedia Tables*. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 34, pages 9057–9064, 2020.

With this information, I am ready to proceed with any further tasks related to these datasets.