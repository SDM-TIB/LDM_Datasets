To extract datasets from the research paper titled "Pixel-wise object tracking using a global attention model and a local segmentation model" by Yilin Song et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract mentions demonstrating the framework on a "challenging VOT dataset," which suggests that a specific dataset is being used for evaluation.

Next, I will look for a dedicated **datasets section** or any mention of datasets in the **experiments** section. In this paper, the authors refer to the **VOT 2016 dataset** as the primary dataset used for their experiments. I will note down the details provided about this dataset, including its characteristics and significance in the context of the research.

In the **experiments section**, the authors discuss the challenges of the VOT dataset, indicating that it contains videos with varying resolutions and small target objects. This reinforces the importance of the dataset in evaluating their proposed method.

Now, I will check the **References section** to find the full citation for the VOT dataset. The citation for the VOT 2016 dataset is as follows:
> M. Kristan, A. Leonardis, J. Matas, M. Felsberg, R. Pflugfelder, L. ehovin, T. Vojr, G. Hager, A. Lukei, G. Fernandez Dominguez, A. Gupta, A. Petrosino, A. Memarmoghadam, A. Garcia-Martin, A. Sols Montero, A. Vedaldi, A. Robinson, A. Ma, A. Varfolomieiev, and Z. Chi. *The visual object tracking vot2016 challenge results*, 10 2016.

Since the paper primarily focuses on the VOT dataset, I will compile this information into a structured format, ensuring that I include the full citation for the dataset as required.

After gathering all necessary details, I will prepare the dataset entry for the VOT dataset, ensuring it is ready for any further processing or review.