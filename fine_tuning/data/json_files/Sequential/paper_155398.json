[
    {
        "dcterms:creator": [
            "Dima Damen",
            "Hazel Doughty",
            "Giovanni Maria Farinella",
            "Antonino Furnari",
            "Jian Ma",
            "Evangelos Kazakos",
            "Davide Moltisanti",
            "Jonathan Munro",
            "Toby Perrett",
            "Will Price",
            "Michael Wray"
        ],
        "dcterms:description": "EPIC-KITCHENS-100 is currently the largest dataset to support action anticipation task. It has 700 long videos of 100 hours about egocentric cooking activity. Each action class consists of a verb and a noun, leading to 4,053 action compositions.",
        "dcterms:title": "EPIC-KITCHENS-100",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Anticipation",
            "Egocentric Vision"
        ],
        "dcat:keyword": [
            "Cooking",
            "Egocentric Videos",
            "Action Recognition"
        ],
        "dcat:landingPage": "https://epic-kitchens.github.io/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "Dima Damen",
            "Hazel Doughty",
            "Giovanni Maria Farinella",
            "Sanja Fidler",
            "Antonino Furnari",
            "Evangelos Kazakos",
            "Davide Moltisanti",
            "Jonathan Munro",
            "Toby Perrett",
            "Will Price"
        ],
        "dcterms:description": "EPIC-KITCHENS-55 is an earlier version of EPIC-KITCHENS-100. It contains 432 videos in 55 hours with 39,596 action segments, each assigned with a verb and noun class.",
        "dcterms:title": "EPIC-KITCHENS-55",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Anticipation",
            "Egocentric Vision"
        ],
        "dcat:keyword": [
            "Cooking",
            "Egocentric Videos",
            "Action Recognition"
        ],
        "dcat:landingPage": "https://epic-kitchens.github.io/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "Yin Li",
            "Miao Liu",
            "James M. Rehg"
        ],
        "dcterms:description": "EGTEA GAZE+ is an egocentric dataset for the joint modeling of action and gaze. It contains 19 verbs, 51 nouns, and 106 action compositions with 10,325 segments in 86 videos.",
        "dcterms:title": "EGTEA GAZE+",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Anticipation",
            "Egocentric Vision"
        ],
        "dcat:keyword": [
            "Gaze",
            "Egocentric Videos",
            "Action Recognition"
        ],
        "dcat:landingPage": "http://cbs.ic.gatech.edu/fpv/#egtea_gaze_plus",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "Sebastian Stein",
            "Stephen J McKenna"
        ],
        "dcterms:description": "50-Salads is a dataset about salad preparation activities, containing nearly 0.9K action segments. Its action classes cannot be marginalized into verb and noun.",
        "dcterms:title": "50-Salads",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Food Preparation",
            "Third-Person Videos",
            "Action Recognition"
        ],
        "dcat:landingPage": "http://cvip.computing.dundee.ac.uk/datasets/foodpreparation/50salads/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]