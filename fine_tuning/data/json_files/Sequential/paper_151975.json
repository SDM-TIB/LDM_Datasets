[
    {
        "dcterms:creator": [
            "B. Schuller",
            "S. Steidl",
            "A. Batliner",
            "F. Burkhardt",
            "L. Devillers",
            "C. Muller",
            "S. Narayanan"
        ],
        "dcterms:description": "The IS10 feature set is used for emotion recognition tasks, particularly in scenarios involving long silence or non-speech voice fillers.",
        "dcterms:title": "Interspeech 2010 paralinguistic challenge feature set (IS10)",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Processing",
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion recognition",
            "Acoustic features",
            "Paralinguistic features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. Eyben",
            "K.R. Scherer",
            "B. Schuller",
            "J. Sundberg",
            "E. Andre",
            "C. Busso",
            "L.Y. Devillers",
            "J. Epps",
            "P. Laukka",
            "S.S. Narayanan",
            "K.P. Truong"
        ],
        "dcterms:description": "GeMAPs is a minimalistic acoustic parameter set designed for voice research and affective computing, focusing on capturing emotional nuances in speech.",
        "dcterms:title": "Geneva Minimalistic Acoustic Parameter Set (GeMAPs)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Research",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Acoustic parameters",
            "Voice analysis",
            "Emotion detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J.N. Chang",
            "S. Lee",
            "S.S. Narayanan"
        ],
        "dcterms:description": "The IEMOCAP corpus is an interactive emotional dyadic motion capture database that includes audio and video recordings of actors performing scripted and spontaneous scenarios.",
        "dcterms:title": "IEMOCAP corpus",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Speech Emotion Analysis"
        ],
        "dcat:keyword": [
            "Emotion classification",
            "Dyadic interaction",
            "Audio-visual data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]