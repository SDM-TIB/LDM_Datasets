[
    {
        "dcterms:creator": [
            "N. Srivastava",
            "E. Mansimov",
            "R. Salakhudinov"
        ],
        "dcterms:description": "MMNIST consists of 64 × 64 grayscale sequences of length 20 displaying pairs of digits moving around the image. The sequences are generated by randomly sampling pairs of digits and trajectories. It contains a fixed test partition with 10000 sequences. We generated a million extra samples for training.",
        "dcterms:title": "Moving MNIST (MMNIST)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Video Prediction"
        ],
        "dcat:keyword": [
            "Grayscale",
            "Video sequences",
            "Digits",
            "Motion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schuldt",
            "I. Laptev",
            "B. Caputo"
        ],
        "dcterms:description": "KTH consists of 600 videos of 15-20 seconds with 25 subjects performing 6 actions in 4 different settings. The videos are grayscale, at a resolution of 120 × 160 pixels and 25 fps. The dataset has been split into subjects 1 to 16 for training, and 17 to 25 for testing, resulting in 383 and 216 sequences, respectively.",
        "dcterms:title": "KTH",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Grayscale",
            "Motion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A.R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "UCF101 displays 101 actions, such as playing instruments, weight lifting or sports. It is the most challenging dataset considered, with a high intra-class variability. It contains 9950 training sequences and 3361 test sequences.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "RGB",
            "Intra-class variability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]