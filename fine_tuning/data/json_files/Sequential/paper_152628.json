[
    {
        "dcterms:creator": [
            "N. Xue",
            "F. Xia",
            "F.-D. Chiou",
            "M. Palmer"
        ],
        "dcterms:description": "The Penn Chinese Treebank provides phrase structure annotation of a large corpus, primarily used for Chinese word segmentation tasks.",
        "dcterms:title": "CTB6",
        "dcterms:issued": "2005",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Chinese Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese Treebank",
            "Phrase Structure Annotation",
            "Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "T. Emerson"
        ],
        "dcterms:description": "The PKU dataset is part of the second international Chinese word segmentation bakeoff, providing a standard data split for segmentation tasks.",
        "dcterms:title": "PKU",
        "dcterms:issued": "2005",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Chinese Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese Word Segmentation",
            "SIGHAN Bakeoff"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "T. Emerson"
        ],
        "dcterms:description": "The MSR dataset is also part of the second international Chinese word segmentation bakeoff, providing a standard data split for segmentation tasks.",
        "dcterms:title": "MSR",
        "dcterms:issued": "2005",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Chinese Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese Word Segmentation",
            "SIGHAN Bakeoff"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "X. Qiu",
            "P. Qian",
            "Z. Shi"
        ],
        "dcterms:description": "The Weibo dataset is collected from informal social media and is used for Chinese word segmentation tasks, particularly in the NLPCC 2016 shared task.",
        "dcterms:title": "Weibo",
        "dcterms:issued": "2016",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Chinese Word Segmentation"
        ],
        "dcat:keyword": [
            "Micro-blog Text",
            "Chinese Word Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    }
]