To extract the datasets mentioned in the research paper titled "Script Identification in Natural Scene Image and Video Frame using Attention based Convolutional-LSTM Network" by Ankan Kumar Bhunia et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets that are explicitly mentioned. The abstract indicates that the authors conducted experiments on **four public script identification datasets**, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4.1 (Datasets)**, where the authors provide a clear description of the datasets used in their experiments. Here, they mention the following datasets:

1. **C VSI-2015**: This dataset contains scene text images of ten different scripts, including English, Hindi, Bengali, and others. Each script has at least 1,000 text images collected from various sources, with a training set (60%), validation set (10%), and test set (30%).

2. **SIW-13**: This dataset consists of 16,291 multi-script text images across 13 classes, including Arabic, Chinese, English, and others. The images are sourced from Google Street View, making them challenging due to variations in orientation, font, color, and size.

3. **ICDAR-2017**: This dataset includes 68,613 cut-out word images for training and 16,255 for validation, covering nine languages such as Arabic, English, and French. The authors note that some languages share the same Latin script.

4. **MLe2e**: This dataset is designed for multi-language end-to-end tasks, containing 1,178 training and 643 testing word images for four scripts: Latin, Chinese, Kannada, and Hangul.

After identifying these datasets, I will check the **References section** to find the full citations for each dataset. The citations are as follows:

- For **C VSI-2015**, the citation is:
  > N. Sharma, R. Mandal, R. Sharma, U. Pal, M. Blumenstein. *ICDAR2015 competition on video script identification (CVSI 2015)*. In Document Analysis and Recognition (ICDAR), 2015 13th International Conference on IEEE, (2015) pp. 1196-1200.

- For **SIW-13**, the citation is:
  > B. Shi, X. Bai, C. Yao. *Script identification in the wild via discriminative convolutional neural network*. Pattern Recognition, 52 (2016) pp.448-458.

- For **ICDAR-2017**, the citation is:
  > N. Nayef, F. Yin, I. Bizid, H. Choi, Y. Feng, D. Karatzas, Z. Luo, U. Pal, C. Rigaud, J. Chazalon, W. Khlif. *ICDAR2017 Robust Reading Challenge on Multi-Lingual Scene Text Detection and Script Identification-RRC-MLT*. In Document Analysis and Recognition (ICDAR), 2017 14th IAPR International Conference IEEE, (2017) pp. 1454-1459.

- For **MLe2e**, the citation is:
  > L. Gomez, A. Nicolaou, D. Karatzas. *Improving patch-based scene text script identification with ensembles of conjoined networks*. Pattern Recognition, 67 (2017) pp.85-96.

Now that I have gathered the necessary information about the datasets and their citations, I will compile this into a structured format for further processing or review.