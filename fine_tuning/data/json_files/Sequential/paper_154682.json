[
    {
        "dcterms:creator": [],
        "dcterms:description": "A parallel corpus for training sequence-to-sequence models to generate Simplified App Representation (SAR) from natural language descriptions.",
        "dcterms:title": "NL-SAR Parallel Corpus",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "http://bit.ly/AppDescriptions",
        "dcat:theme": ["Natural Language Processing", "App Development"],
        "dcat:keyword": ["Natural Language", "App Description", "Parallel Corpus"],
        "dcat:landingPage": "http://bit.ly/AppDescriptions",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": ["Sequence-to-Sequence Learning", "App Generation"]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A pre-trained model for language understanding that can be used for data augmentation in natural language processing tasks.",
        "dcterms:title": "BERT-based Data Augmentation",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": ["Natural Language Processing", "Data Augmentation"],
        "dcat:keyword": ["BERT", "Data Augmentation", "Natural Language Processing"],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": ["Data Augmentation", "Text Generation"]
    },
    {
        "dcterms:creator": [
            "Zhangyin Feng",
            "Daya Guo",
            "Duyu Tang",
            "Nan Duan",
            "Xiaocheng Feng",
            "Ming Gong",
            "Linjun Shou",
            "Bing Qin",
            "Ting Liu",
            "Daxin Jiang",
            "Ming Zhou"
        ],
        "dcterms:description": "A pre-trained model designed for programming and natural languages, useful for code-related tasks.",
        "dcterms:title": "CodeBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": ["Natural Language Processing", "Code Understanding"],
        "dcat:keyword": ["CodeBERT", "Programming", "Natural Language Processing"],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": ["Code Generation", "Code Understanding"]
    },
    {
        "dcterms:creator": [
            "Yinhan Liu",
            "Myle Ott",
            "Naman Goyal",
            "Jingfei Du",
            "Mandar Joshi",
            "Danqi Chen",
            "Omer Levy",
            "Mike Lewis",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "A robustly optimized BERT pretraining approach that improves performance on various NLP tasks.",
        "dcterms:title": "RoBERTa",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": ["Natural Language Processing", "Model Optimization"],
        "dcat:keyword": ["RoBERTa", "BERT", "Natural Language Processing"],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": ["Text Classification", "Text Generation"]
    },
    {
        "dcterms:creator": [
            "Shuai Lu",
            "Daya Guo",
            "Shuo Ren",
            "Junjie Huang",
            "Alexey Svyatkovskiy",
            "Ambrosio Blanco",
            "Colin B. Clement",
            "Dawn Drain",
            "Daxin Jiang",
            "Duyu Tang",
            "Ge Li",
            "Lidong Zhou",
            "Linjun Shou",
            "Long Zhou",
            "Michele Tufano",
            "Ming Gong",
            "Ming Zhou",
            "Nan Duan",
            "Neel Sundaresan",
            "Shao Kun Deng",
            "Shengyu Fu",
            "Shujie Liu"
        ],
        "dcterms:description": "A benchmark dataset for machine learning tasks related to code understanding and generation.",
        "dcterms:title": "CodexGLUE",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/2102.04664",
        "dcat:theme": ["Machine Learning", "Code Understanding"],
        "dcat:keyword": ["CodexGLUE", "Machine Learning", "Code Generation"],
        "dcat:landingPage": "https://arxiv.org/abs/2102.04664",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": ["Code Understanding", "Code Generation"]
    }
]