[
    {
        "dcterms:creator": [
            "Daniel Cer",
            "Mona Diab",
            "Eneko Agirre",
            "IÃ±igo Lopez-Gazpio",
            "Lucia Specia"
        ],
        "dcterms:description": "A dataset for evaluating semantic textual similarity across multiple languages and domains.",
        "dcterms:title": "STS-B",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Textual Similarity"
        ],
        "dcat:keyword": [
            "Semantic similarity",
            "Multilingual evaluation",
            "Cross-lingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Textual Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Marco Marelli",
            "Stefano Menini",
            "Marco Baroni",
            "Luisa Bentivogli",
            "Raffaella Bernardi",
            "Roberto Zamparelli"
        ],
        "dcterms:description": "A dataset designed for evaluating compositional distributional semantic models.",
        "dcterms:title": "SICK-R",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Textual Similarity"
        ],
        "dcat:keyword": [
            "Compositional semantics",
            "Distributional semantics",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Textual Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "A large annotated corpus for learning natural language inference.",
        "dcterms:title": "SNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Annotated corpus",
            "Inference tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Alon Brutzkus",
            "Amir Globerson"
        ],
        "dcterms:description": "A dataset for evaluating the generalization capabilities of larger models.",
        "dcterms:title": "MultiNLI",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Generalization",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Taeuk Kim",
            "Kang Min Yoo",
            "Sang-goo Lee"
        ],
        "dcterms:description": "A dataset for evaluating self-guided contrastive learning for sentence representations.",
        "dcterms:title": "AskUbuntu",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Re-ranking"
        ],
        "dcat:keyword": [
            "Contrastive learning",
            "Sentence representations",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Re-ranking"
        ]
    },
    {
        "dcterms:creator": [
            "Arman Cohan",
            "Sergey Feldman",
            "Iz Beltagy",
            "Doug Downey",
            "Daniel S. Weld"
        ],
        "dcterms:description": "A dataset for document-level representation learning using citation-informed transformers.",
        "dcterms:title": "SciDocs",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Document Representation Learning"
        ],
        "dcat:keyword": [
            "Document-level learning",
            "Citation-informed",
            "Transformers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Document Representation Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Marco Marelli",
            "Stefano Menini",
            "Marco Baroni",
            "Luisa Bentivogli",
            "Raffaella Bernardi",
            "Roberto Zamparelli"
        ],
        "dcterms:description": "A dataset for evaluating compositional distributional semantic models.",
        "dcterms:title": "SICK-E",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Textual Similarity"
        ],
        "dcat:keyword": [
            "Compositional semantics",
            "Distributional semantics",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Textual Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Eneko Agirre",
            "Carmen Banea",
            "Claire Cardie",
            "Daniel Cer",
            "Mona Diab",
            "Aitor Gonzalez-Agirre",
            "Rada Mihalcea",
            "German Rigau",
            "Janyce Wiebe"
        ],
        "dcterms:description": "A collection of datasets for evaluating semantic textual similarity from 2012 to 2016.",
        "dcterms:title": "STS 2012-2016",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Textual Similarity"
        ],
        "dcat:keyword": [
            "Semantic similarity",
            "Evaluation datasets",
            "Temporal collection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Textual Similarity"
        ]
    }
]