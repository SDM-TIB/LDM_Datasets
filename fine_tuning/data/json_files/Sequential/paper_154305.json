[
    {
        "dcterms:creator": [
            "P. Lucey",
            "J. F. Cohn",
            "T. Kanade",
            "J. Saragih",
            "Z. Ambadar",
            "I. Matthews"
        ],
        "dcterms:description": "The CK+ dataset includes 583 image sequences from 123 subjects, with 327 sequences labeled for facial expressions such as Anger, Contempt, Disgust, Fear, Happiness, Sadness, and Surprise. Each sequence reflects the intensity of the expression from neutral to peak.",
        "dcterms:title": "CK+",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion recognition",
            "Image sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "G. Zhao",
            "X. Huang",
            "M. Taini",
            "S. Z. Li",
            "M. PietikÂ¨aInen"
        ],
        "dcterms:description": "The Oulu-CASIA dataset consists of 6 basic facial expressions from 80 subjects, with sequences recorded under different lighting conditions. Each sequence starts from a neutral stage and ends with the peak emotion.",
        "dcterms:title": "Oulu-CASIA",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion recognition",
            "Video sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Pantic",
            "M. Valstar",
            "R. Rademaker",
            "L. Maat"
        ],
        "dcterms:description": "The MMI dataset includes 30 subjects and 213 video sequences labeled with 6 basic expressions. The expressions transition from neutral to peak and back to neutral.",
        "dcterms:title": "MMI",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion recognition",
            "Video sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A. Dhall",
            "A. Kaur",
            "R. Goecke",
            "T. Gedeon"
        ],
        "dcterms:description": "AFEW 8.0 is a dataset used for audio-video emotion recognition, focusing on student engagement and group-level affect prediction.",
        "dcterms:title": "AFEW 8.0",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Interaction"
        ],
        "dcat:keyword": [
            "Audio-video",
            "Emotion recognition",
            "Engagement prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]