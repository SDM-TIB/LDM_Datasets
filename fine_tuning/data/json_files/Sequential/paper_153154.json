[
    {
        "dcterms:creator": [
            "Angela Fan",
            "Yacine Jernite",
            "Ethan Perez",
            "David Grangier",
            "Jason Weston",
            "Michael Auli"
        ],
        "dcterms:description": "A large-scale corpus for long-form question answering, comprising 270K threads from the Reddit forum 'Explain Like Iâ€™m Five' where an online community provides answers to questions comprehensible by five-year-olds.",
        "dcterms:title": "ELI5",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/facebookresearch/ELI5",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Long-form QA",
            "Open-ended questions",
            "Reddit",
            "Community answers"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/ELI5",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "Li Deng"
        ],
        "dcterms:description": "A human-generated machine reading comprehension dataset that includes crowdsourced responses to Bing queries.",
        "dcterms:title": "MS MARCO v2",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Information Retrieval"
        ],
        "dcat:keyword": [
            "Crowdsourced dataset",
            "Machine reading",
            "Bing queries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v2",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Mandar Joshi",
            "Eunsol Choi",
            "Daniel Weld",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "A large-scale distantly supervised challenge dataset for reading comprehension.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Trivia questions",
            "Distant supervision",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Tomas Kocisky",
            "Jonathan Schwarz",
            "Phil Blunsom",
            "Chris Dyer",
            "Karl Moritz Hermann",
            "Gabor Melis",
            "Edward Grefenstette"
        ],
        "dcterms:description": "The NarrativeQA reading comprehension challenge dataset, which includes questions based on movie and book summaries.",
        "dcterms:title": "NarrativeQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Narrative Understanding"
        ],
        "dcat:keyword": [
            "Narrative questions",
            "Movie summaries",
            "Book summaries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Siva Reddy",
            "Danqi Chen",
            "Christopher D Manning"
        ],
        "dcterms:description": "A conversational question answering challenge dataset that includes questions and answers in a dialogue format.",
        "dcterms:title": "CoQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Conversational AI",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Dialogue",
            "Conversational QA",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Conversational Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset that includes unanswerable questions for SQuAD, enhancing the challenge of reading comprehension.",
        "dcterms:title": "SQuAD (2.0)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Unanswerable questions",
            "SQuAD",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "2.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William W Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D Manning"
        ],
        "dcterms:description": "A dataset for diverse, explainable multi-hop question answering that requires reasoning across multiple documents.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-hop Reasoning",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop questions",
            "Explainable QA",
            "Diverse answers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-hop Question Answering"
        ]
    }
]