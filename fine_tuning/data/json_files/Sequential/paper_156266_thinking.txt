To extract the datasets mentioned in the paper titled "Glancing Future for Simultaneous Machine Translation" by Shoutao Guo et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors conducted experiments demonstrating the effectiveness of their method, which suggests that datasets are involved. 

Next, I will focus on **section 3 (Experiments)**, where the authors explicitly mention the datasets used for evaluation. In this section, they state that they evaluate their method on two datasets:

1. **IWSLT15 English→Vietnamese (En→Vi)**: The authors specify that for this task, they use TED tst2012 as the development set and TED tst2013 as the test set. This indicates that the IWSLT15 dataset is relevant for their experiments.

2. **WMT15 German→English (De→En)**: The authors mention using newstest2013 as the development set and newstest2015 as the test set for this task. This confirms that the WMT15 dataset is also utilized in their experiments.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **IWSLT15 dataset**, the citation is:
  > Cettolo, M., Girardi, C., & Federico, M. (2012). *WIT3: Web Inventory of Transcribed and Translated Talks*. In Proceedings of the Eighth International Workshop on Spoken Language Translation (IWSLT), 2012.

- For the **WMT15 dataset**, the citation is:
  > Bojar, O., Cettolo, M., & Federico, M. (2015). *Findings of the 2015 Conference on Machine Translation (WMT)*. In Proceedings of the Tenth Workshop on Statistical Machine Translation, 2015.

With these citations in hand, I will summarize the datasets and their citations clearly.

Finally, I will compile the dataset entries into a structured format that is ready for review or further processing, ensuring that each dataset is accurately represented with its full citation.