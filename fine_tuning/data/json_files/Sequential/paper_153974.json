[
    {
        "dcterms:creator": [
            "X. Lu",
            "B. Wang",
            "X. Zheng",
            "X. Li"
        ],
        "dcterms:description": "The RSCID dataset is the largest RS image captioning dataset, including 10921 images with varying spatial resolutions. Each image is described with multiple captions, with a total of 54605 captions in the dataset.",
        "dcterms:title": "RSCID",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Remote Sensing",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Remote sensing images",
            "Image captioning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "B. Qu",
            "X. Li",
            "D. Tao",
            "X. Lu"
        ],
        "dcterms:description": "The UCM-Captions dataset includes 2100 aerial images, each annotated with five captions, resulting in a total of 10500 captions. It is based on the UC Merced Land Use dataset.",
        "dcterms:title": "UCM-Captions",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Remote Sensing",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Aerial images",
            "Image captioning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "B. Qu",
            "X. Li",
            "D. Tao",
            "X. Lu"
        ],
        "dcterms:description": "The Sydney-Captions dataset includes 613 images, each annotated with five captions, providing a total of 3065 captions. It is built based on the Sydney scene classification dataset.",
        "dcterms:title": "Sydney-Captions",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Remote Sensing",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Remote sensing images",
            "Image captioning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Graff",
            "J. Kong",
            "K. Chen",
            "K. Maeda"
        ],
        "dcterms:description": "The Annotated Gigaword dataset is a corpus of article-headline pairs consisting of nearly 10 million documents sourced from various news services, with around 4 million articles after pre-processing.",
        "dcterms:title": "Annotated Gigaword",
        "dcterms:issued": "2003",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Article-headline pairs",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Summarization"
        ]
    }
]