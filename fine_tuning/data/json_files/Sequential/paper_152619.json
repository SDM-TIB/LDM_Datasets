[
    {
        "dcterms:creator": [
            "Hisashi Kawai",
            "Tomoki Toda",
            "Jinfu Ni",
            "Minoru Tsuzaki",
            "Keiichi Tokuda"
        ],
        "dcterms:description": "A Japanese speech corpus containing neutral reading speech uttered by a female speaker, used for training and testing speech synthesis models.",
        "dcterms:title": "Japanese speech corpus",
        "dcterms:issued": "2004",
        "dcterms:language": "Japanese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Linguistics"
        ],
        "dcat:keyword": [
            "Speech corpus",
            "Japanese language",
            "Text-to-speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Keiichi Tokuda",
            "Takao Kobayashi",
            "Takashi Masuko",
            "Satoshi Imai"
        ],
        "dcterms:description": "Mel-generalized cepstral coefficients (MGCs) used as acoustic features for speech synthesis.",
        "dcterms:title": "Mel-generalized cepstral coefficients (MGCs)",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Processing",
            "Acoustic Features"
        ],
        "dcat:keyword": [
            "Cepstral coefficients",
            "Speech synthesis",
            "Acoustic features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature extraction"
        ]
    },
    {
        "dcterms:creator": [
            "Masanori Morise",
            "Fumiya Yokomori",
            "Kenji Ozawa"
        ],
        "dcterms:description": "WORLD vocoder, a high-quality speech synthesis system for real-time applications, used for generating waveforms from acoustic features.",
        "dcterms:title": "WORLD vocoder",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Vocoder Technology"
        ],
        "dcat:keyword": [
            "Vocoder",
            "Speech synthesis",
            "Real-time applications"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Waveform generation"
        ]
    },
    {
        "dcterms:creator": [
            "Xin Wang",
            "Jaime Lorenzo-Trueba",
            "Shinji Takaki",
            "Lauri Juvela",
            "Junichi Yamagishi"
        ],
        "dcterms:description": "WAD model, a neural-network-based speech synthesis model that incorporates a condition module and dilated convolution blocks.",
        "dcterms:title": "WAD model",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural model",
            "Speech synthesis",
            "Waveform generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Wei Ping",
            "Kainan Peng",
            "Jitong Chen"
        ],
        "dcterms:description": "WAC model, a neural-network-based speech synthesis model that uses Gaussian distribution for raw waveform generation.",
        "dcterms:title": "WAC model",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural model",
            "Speech synthesis",
            "Waveform generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech synthesis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The NSF model is a proposed model in the paper, focusing on a neural source-filter approach for waveform generation.",
        "dcterms:title": "NSF model",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural model",
            "Speech synthesis",
            "Waveform generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech synthesis"
        ]
    }
]