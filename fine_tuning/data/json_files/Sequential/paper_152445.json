[
    {
        "dcterms:creator": [
            "Lyndsey C Pickup",
            "Zheng Pan",
            "Donglai Wei",
            "YiChang Shih",
            "Changshui Zhang",
            "Andrew Zisserman",
            "Bernhard Scholkopf",
            "William T Freeman"
        ],
        "dcterms:description": "The dataset contains 155 forward videos and 25 reverse videos, divided in three equal splits, used for evaluating arrow of time recognition.",
        "dcterms:title": "Pickup-Arrow",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Temporal Reasoning"
        ],
        "dcat:keyword": [
            "Arrow of time",
            "Video dataset",
            "Temporal asymmetry"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Arrow of Time Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Khurram Soomro",
            "Amir Roshan Zamir",
            "Mubarak Shah"
        ],
        "dcterms:description": "A dataset of 101 human actions classes from videos in the wild, used for action recognition.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Action dataset",
            "Human actions",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A derived dataset from UCF101 focusing on future frame prediction, specifically using 24 classes with a distinguishable arrow of time.",
        "dcterms:title": "UCF24-FutureFrame",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Future Frame Prediction"
        ],
        "dcat:keyword": [
            "Future frame selection",
            "Temporal continuity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Future Frame Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Raghav Goyal",
            "Samira Ebrahimi Kahou",
            "Vincent Michalski",
            "Joanna Materzynska",
            "Susanne Westphal",
            "Heuna Kim",
            "Valentin Haenel",
            "Ingo Fruend",
            "Peter Yianilos",
            "Moritz Mueller-Freitag"
        ],
        "dcterms:description": "A crowd-sourced dataset containing videos of physical actions represented by template-based textual descriptions, emphasizing the importance of temporal reasoning.",
        "dcterms:title": "Something-Something",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Template-based actions",
            "Physical actions",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Template Classification"
        ]
    }
]