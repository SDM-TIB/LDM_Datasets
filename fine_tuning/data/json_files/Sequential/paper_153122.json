[
    {
        "dcterms:creator": [
            "J. Yamagishi",
            "T. Nose",
            "H. Zen",
            "Z. Ling",
            "T. Toda",
            "K. Tokuda",
            "S. King",
            "S. Renals"
        ],
        "dcterms:description": "The VCTK dataset consists of audio recordings from 108 speakers, with approximately 400 utterances for each speaker and a total duration of approximately 44 hours. The audios are downsampled from 48 KHz to 24 KHz.",
        "dcterms:title": "VCTK dataset",
        "dcterms:issued": "2009",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Multi-speaker",
            "Text-to-speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "D. Snyder",
            "P. Ghahremani",
            "D. Povey",
            "D. Garcia-Romero",
            "Y. Carmiel",
            "S. Khudanpur"
        ],
        "dcterms:description": "The LibriSpeech dataset consists of 820 hours of audio data from 2484 speakers, used for training speaker verification models.",
        "dcterms:title": "LibriSpeech dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Verification",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speaker verification",
            "Deep learning",
            "Audio dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Verification"
        ]
    },
    {
        "dcterms:creator": [
            "H. Zen",
            "V. Dang",
            "R. Clark",
            "Y. Zhang",
            "R. J. Weiss",
            "Y. Jia",
            "Z. Chen",
            "Y. Wu"
        ],
        "dcterms:description": "LibriTTS is a corpus derived from LibriSpeech for text-to-speech synthesis.",
        "dcterms:title": "LibriTTS dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1904.02882",
        "dcat:theme": [
            "Text-to-Speech",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Text-to-speech dataset",
            "Speech synthesis",
            "Audio dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    }
]