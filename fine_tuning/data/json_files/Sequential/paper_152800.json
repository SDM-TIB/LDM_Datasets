[
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L.-J. Li",
            "D. A. Shamma",
            "M. Bernstein",
            "L. Fei-Fei"
        ],
        "dcterms:description": "A new dataset for real-world visual reasoning and compositional question answering, generating 22 million diverse reasoning questions based on Visual Genome scene graph structures.",
        "dcterms:title": "GQA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Visual reasoning",
            "Compositional question answering",
            "Scene graphs",
            "Diverse reasoning questions"
        ],
        "dcat:landingPage": "visualreasoning.net",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L.-J. Li",
            "D. A. Shamma",
            "M. Bernstein",
            "L. Fei-Fei"
        ],
        "dcterms:description": "A dataset providing dense image annotations connecting language and vision, used as a foundational resource for generating questions in GQA.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Annotation",
            "Language and Vision"
        ],
        "dcat:keyword": [
            "Dense annotations",
            "Scene graphs",
            "Language and vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Goyal",
            "T. Khot",
            "D. Summers-Stay",
            "D. Batra",
            "D. Parikh"
        ],
        "dcterms:description": "A dataset designed to elevate the role of image understanding in visual question answering, providing a benchmark for evaluating VQA models.",
        "dcterms:title": "VQA 2.0",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Image understanding",
            "Visual question answering",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Johnson",
            "B. Hariharan",
            "L. van der Maaten",
            "L. Fei-Fei",
            "C. L. Zitnick",
            "R. Girshick"
        ],
        "dcterms:description": "A diagnostic dataset for compositional language and elementary visual reasoning, used to assess models' reasoning capabilities.",
        "dcterms:title": "CLEVR",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning",
            "Compositional Language"
        ],
        "dcat:keyword": [
            "Compositional reasoning",
            "Visual reasoning",
            "Diagnostic dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "T.-Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C. L. Zitnick"
        ],
        "dcterms:description": "A dataset of common objects in context, providing a rich set of images for various computer vision tasks.",
        "dcterms:title": "COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Recognition",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Common objects",
            "Image dataset",
            "Computer vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "B. Thomee",
            "D. A. Shamma",
            "G. Friedland",
            "B. Elizalde",
            "K. Ni",
            "D. Poland",
            "D. Borth",
            "L.-J. Li"
        ],
        "dcterms:description": "A large-scale dataset for multimedia research, containing 100 million photos with associated metadata.",
        "dcterms:title": "YFCC100M",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimedia Research"
        ],
        "dcat:keyword": [
            "Large-scale dataset",
            "Multimedia",
            "Photo dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]