[
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Louis Martin",
            "Kevin Stone",
            "Peter Albert",
            "Amjad Almahairi",
            "Yasmine Babaei",
            "Nikolay Bashlykov",
            "Soumya Batra",
            "Prajjwal Bhargava",
            "Shruti Bhosale"
        ],
        "dcterms:description": "Llama-2-7b is a large language model used for evaluating performance in debates.",
        "dcterms:title": "Llama-2-7b",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Louis Martin",
            "Kevin Stone",
            "Peter Albert",
            "Amjad Almahairi",
            "Yasmine Babaei",
            "Nikolay Bashlykov",
            "Soumya Batra",
            "Prajjwal Bhargava",
            "Shruti Bhosale"
        ],
        "dcterms:description": "Llama-2-13b is a large language model used for evaluating performance in debates.",
        "dcterms:title": "Llama-2-13b",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Louis Martin",
            "Kevin Stone",
            "Peter Albert",
            "Amjad Almahairi",
            "Yasmine Babaei",
            "Nikolay Bashlykov",
            "Soumya Batra",
            "Prajjwal Bhargava",
            "Shruti Bhosale"
        ],
        "dcterms:description": "Llama-2-70b is a large language model used for evaluating performance in debates.",
        "dcterms:title": "Llama-2-70b",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Meta AI"
        ],
        "dcterms:description": "Llama-3-70b is the most capable openly available LLM to date.",
        "dcterms:title": "Llama-3-70b",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Wei-Lin Chiang",
            "Zhuohan Li",
            "Zi Lin",
            "Ying Sheng",
            "Zhanghao Wu",
            "Hao Zhang",
            "Lianmin Zheng",
            "Siyuan Zhuang",
            "Yonghao Zhuang",
            "Joseph E. Gonzalez",
            "Ion Stoica",
            "Eric P. Xing"
        ],
        "dcterms:description": "Vicuna-7b-v1.5 is an open-source chatbot impressing GPT-4 with 90%* ChatGPT quality.",
        "dcterms:title": "Vicuna-7b-v1.5",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Chatbot",
            "Open-source",
            "Performance evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Chatbot evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Wei-Lin Chiang",
            "Zhuohan Li",
            "Zi Lin",
            "Ying Sheng",
            "Zhanghao Wu",
            "Hao Zhang",
            "Lianmin Zheng",
            "Siyuan Zhuang",
            "Yonghao Zhuang",
            "Joseph E. Gonzalez",
            "Ion Stoica",
            "Eric P. Xing"
        ],
        "dcterms:description": "Vicuna-13b-v1.5 is an open-source chatbot impressing GPT-4 with 90%* ChatGPT quality.",
        "dcterms:title": "Vicuna-13b-v1.5",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Chatbot",
            "Open-source",
            "Performance evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Chatbot evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Albert Q Jiang",
            "Alexandre Sablayrolles",
            "Antoine Roux",
            "Arthur Mensch",
            "Blanche Savary",
            "Chris Bamford",
            "Devendra Singh Chaplot",
            "Diego de las Casas",
            "Emma Bou Hanna",
            "Florian Bressand"
        ],
        "dcterms:description": "Mixtral-8x7B is a dataset for evaluating performance in debates.",
        "dcterms:title": "Mixtral-8x7B",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Josh Achiam",
            "Steven Adler",
            "Sandhini Agarwal",
            "Lama Ahmad",
            "Ilge Akkaya",
            "Florencia Leoni Aleman",
            "Diogo Almeida",
            "Janko Altenschmidt",
            "Sam Altman",
            "Shyamal Anadkat"
        ],
        "dcterms:description": "GPT-3.5 is a large language model used for evaluating performance in debates.",
        "dcterms:title": "GPT-3.5",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Josh Achiam",
            "Steven Adler",
            "Sandhini Agarwal",
            "Lama Ahmad",
            "Ilge Akkaya",
            "Florencia Leoni Aleman",
            "Diogo Almeida",
            "Janko Altenschmidt",
            "Sam Altman",
            "Shyamal Anadkat"
        ],
        "dcterms:description": "GPT-4 is a large language model used for evaluating performance in debates.",
        "dcterms:title": "GPT-4",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model",
            "Debate evaluation",
            "Performance benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Debate evaluation"
        ]
    }
]