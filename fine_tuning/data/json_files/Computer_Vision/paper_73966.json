[
    {
        "dcterms:creator": [
            "J. Fu",
            "A. Kumar",
            "O. Nachum",
            "G. Tucker",
            "S. Levine"
        ],
        "dcterms:description": "The D4RL Locomotion dataset includes various locomotion tasks such as Hopper, HalfCheetah, and Walker2D, providing offline data with varying levels of expertise for training reinforcement learning algorithms.",
        "dcterms:title": "D4RL Locomotion",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Locomotion",
            "Offline Data",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Online Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Fu",
            "A. Kumar",
            "O. Nachum",
            "G. Tucker",
            "S. Levine"
        ],
        "dcterms:description": "The D4RL AntMaze dataset consists of sparse reward tasks where an agent learns to navigate through a maze using an 8-DoF Ant robot.",
        "dcterms:title": "D4RL AntMaze",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Navigation",
            "Sparse Rewards",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Online Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Fu",
            "A. Kumar",
            "O. Nachum",
            "G. Tucker",
            "S. Levine"
        ],
        "dcterms:description": "The D4RL Kitchen dataset involves controlling a 9-DoF robot to manipulate various objects in a kitchen environment, requiring the completion of multiple subtasks with sparse rewards.",
        "dcterms:title": "D4RL Kitchen",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Kitchen Tasks",
            "Robotic Manipulation",
            "Sparse Rewards"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Online Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "T. Yu",
            "D. Quillen",
            "Z. He",
            "R. Julian",
            "K. Hausman",
            "C. Finn",
            "S. Levine"
        ],
        "dcterms:description": "Meta-World is a benchmark suite for evaluating multi-task and meta reinforcement learning algorithms, featuring a variety of robotic manipulation tasks.",
        "dcterms:title": "Meta-World",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Multi-task Learning",
            "Robotic Manipulation",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-task Learning",
            "Meta Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Lu",
            "P. J. Ball",
            "T. G. J. Rudner",
            "J. Parker-Holder",
            "M. A. Osborne",
            "Y. W. Teh"
        ],
        "dcterms:description": "V-D4RL is a dataset that addresses challenges in offline reinforcement learning from visual observations, providing a benchmark for evaluating visual RL methods.",
        "dcterms:title": "V-D4RL",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2206.04779",
        "dcat:theme": [
            "Reinforcement Learning",
            "Visual Learning"
        ],
        "dcat:keyword": [
            "Visual Observations",
            "Offline Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Reinforcement Learning"
        ]
    }
]