To extract datasets from the research paper titled "Learning to Detect Keyword Parts and Whole by Smoothed Max Pooling" by Hyun-Jin Park et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by examining the **abstract** and **introduction** sections. The abstract mentions the use of a new loss function for keyword spotting systems, but it does not specify any datasets. However, the introduction discusses the importance of keyword detection and mentions that the experiments are conducted on various datasets, which indicates that I should look for specific dataset names later in the paper.

Next, I will focus on the **experimental setup** section (Section 3), where the authors typically describe the datasets used for training and evaluation. Here, I find that the authors mention the training data consists of **2.1 million anonymized utterances** with the keywords "Ok Google" and "Hey Google." This is a significant dataset for their experiments.

The authors also describe four evaluation datasets:
1. **Clean non-accented set**: Contains 170K non-accented English utterances of keywords in quiet conditions.
2. **Clean accented set**: Comprises 138K English utterances of keywords with Australian, British, and Indian accents in quiet conditions.
3. **Query logs**: Contains 58K utterances from anonymized voice search queries.
4. **In-vehicle set**: Includes 144K utterances with keywords recorded inside cars while driving, which includes significant noise from the environment.

Now, I will check the **References section** to find full citations for the datasets mentioned. However, since the datasets are not standalone datasets published in separate papers, I will note that the training data is based on internal data from Google, and the evaluation datasets are likely derived from various sources but are not explicitly cited in the references.

For the training data, I will note:
- **Training Data**: 2.1 million anonymized utterances with keywords "Ok Google" and "Hey Google." (No formal citation available as it is internal data.)

For the evaluation datasets, I will summarize them as follows:
- **Clean non-accented set**: 170K non-accented English utterances (No formal citation available).
- **Clean accented set**: 138K English utterances with various accents (No formal citation available).
- **Query logs**: 58K utterances from anonymized voice search queries (No formal citation available).
- **In-vehicle set**: 144K utterances recorded inside vehicles (No formal citation available).

Since these datasets are not published in the traditional sense, I will note that they are part of the experimental setup described in the paper.

Finally, I will compile the dataset entries into a structured format for clarity, ensuring that I highlight the lack of formal citations for the internal datasets used in the experiments.