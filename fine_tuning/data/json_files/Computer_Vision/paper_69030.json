[
    {
        "dcterms:creator": [
            "Robin Rombach",
            "Andreas Blattmann",
            "Dominik Lorenz",
            "Patrick Esser",
            "Björn Ommer"
        ],
        "dcterms:description": "Stable Diffusion is a diffusion model pretrained on large-scale text-image datasets, serving as a powerful backbone for text-to-image synthesis.",
        "dcterms:title": "Stable Diffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Synthesis",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Diffusion model",
            "Text-to-image synthesis",
            "Image generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image synthesis",
            "Toon shading"
        ]
    },
    {
        "dcterms:creator": [
            "Yuwei Guo",
            "Ceyuan Yang",
            "Anyi Rao",
            "Yaohui Wang",
            "Yu Qiao",
            "Dahua Lin",
            "Bo Dai"
        ],
        "dcterms:description": "AnimateDiff is a method that allows for the animation of personalized text-to-image diffusion models without specific tuning.",
        "dcterms:title": "AnimateDiff",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.04725",
        "dcat:theme": [
            "Animation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Animation",
            "Text-to-image",
            "Diffusion models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Animation",
            "Video synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Group DOMO.AI"
        ],
        "dcterms:description": "DOMO.AI provides various models for users, including those tailored for anime styles.",
        "dcterms:title": "DomoAI",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://ai.domo.com/",
        "dcat:theme": [
            "AI Models",
            "Video Synthesis"
        ],
        "dcat:keyword": [
            "AI models",
            "Video synthesis",
            "Anime style"
        ],
        "dcat:landingPage": "https://ai.domo.com/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Shuai Yang",
            "Yifan Zhou",
            "Ziwei Liu",
            "Chen Change Loy"
        ],
        "dcterms:description": "Rerender-a-video is a zero-shot text-guided video-to-video translation method.",
        "dcterms:title": "Rerender-a-video",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.07954",
        "dcat:theme": [
            "Video Processing",
            "Text-Guided Synthesis"
        ],
        "dcat:keyword": [
            "Video translation",
            "Text-guided synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video synthesis",
            "Video editing"
        ]
    },
    {
        "dcterms:creator": [
            "Hao Ouyang",
            "Qiuyu Wang",
            "Yuxi Xiao",
            "Qingyan Bai",
            "Juntao Zhang",
            "Kecheng Zheng",
            "Xiaowei Zhou",
            "Qifeng Chen",
            "Yujun Shen"
        ],
        "dcterms:description": "CoDeF provides content deformation fields for temporally consistent video processing.",
        "dcterms:title": "CoDeF",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2308.07926",
        "dcat:theme": [
            "Video Processing",
            "Consistency Enhancement"
        ],
        "dcat:keyword": [
            "Video processing",
            "Temporal consistency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video processing"
        ]
    },
    {
        "dcterms:creator": [
            "Duygu Ceylan",
            "Chun-Hao P Huang",
            "Niloy J Mitra"
        ],
        "dcterms:description": "Pix2Video is a method for video editing using image diffusion.",
        "dcterms:title": "Pix2Video",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Editing",
            "Image Diffusion"
        ],
        "dcat:keyword": [
            "Video editing",
            "Image diffusion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video editing"
        ]
    },
    {
        "dcterms:creator": [
            "René Ranftl",
            "Katrin Lasinger",
            "David Hafner",
            "Konrad Schindler",
            "Vladlen Koltun"
        ],
        "dcterms:description": "The depth estimation dataset is aimed at improving monocular depth estimation through dataset mixing.",
        "dcterms:title": "Depth estimation dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Depth Estimation",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Depth estimation",
            "Monocular depth"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Depth estimation"
        ]
    }
]