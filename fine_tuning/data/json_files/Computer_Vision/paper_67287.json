[
    {
        "dcterms:creator": [
            "T. Namgyal",
            "A. Hepburn",
            "R. Santos-Rodriguez",
            "V. Laparra",
            "J. Malo"
        ],
        "dcterms:description": "The MusicCaps dataset consists of 10-second music clips with human generated captions, which are used to train models for audio reconstruction.",
        "dcterms:title": "MusicCaps",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://research.google/resources/datasets/musicaps",
        "dcat:theme": [
            "Audio",
            "Music"
        ],
        "dcat:keyword": [
            "Music dataset",
            "Audio clips",
            "Human generated captions"
        ],
        "dcat:landingPage": "https://research.google/resources/datasets/musicaps",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio reconstruction",
            "Music generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Hilmkil",
            "C. Thom√©",
            "A. Arpteg"
        ],
        "dcterms:description": "The Perceived Music Quality Dataset (PMQD) contains 195 reference music clips used to evaluate audio quality through perceptual metrics.",
        "dcterms:title": "Perceived Music Quality Dataset (PMQD)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/carlthome/pmqd",
        "dcat:theme": [
            "Audio",
            "Quality Assessment"
        ],
        "dcat:keyword": [
            "Music quality",
            "Audio clips",
            "Perceptual metrics"
        ],
        "dcat:landingPage": "https://github.com/carlthome/pmqd",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality assessment",
            "Audio evaluation"
        ]
    }
]