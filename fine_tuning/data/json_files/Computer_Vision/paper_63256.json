[
    {
        "dcterms:creator": [
            "Andrea Agostinelli",
            "Timo I Denk",
            "Zal√°n Borsos",
            "Jesse Engel",
            "Mauro Verzetti",
            "Antoine Caillon",
            "Qingqing Huang",
            "Aren Jansen",
            "Adam Roberts",
            "Marco Tagliasacchi"
        ],
        "dcterms:description": "The Audiostock dataset contains 9000 music tracks for training and 1000 tracks for testing, providing a correct textual description of each music track.",
        "dcterms:title": "Audiostock Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Music Generation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Text-to-Music",
            "Music Dataset",
            "Audio Tracks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Music Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Benjamin Elizalde",
            "Soham Deshmukh",
            "Mahmoud Al Ismail",
            "Huaming Wang"
        ],
        "dcterms:description": "The CLAP dataset is used for learning audio concepts from natural language supervision.",
        "dcterms:title": "CLAP Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Audio Concepts",
            "Natural Language Supervision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Classification",
            "Text-Audio Alignment"
        ]
    },
    {
        "dcterms:creator": [
            "Honglie Chen",
            "Weidi Xie",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "VGGSound is a large-scale audio-visual dataset.",
        "dcterms:title": "VGGSound Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-Visual Dataset",
            "Sound Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Audio Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Karol J. Piczak"
        ],
        "dcterms:description": "ESC-50 is a dataset for environmental sound classification.",
        "dcterms:title": "ESC-50 Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Environmental Sound Classification"
        ],
        "dcat:keyword": [
            "Environmental Sounds",
            "Sound Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Ho-Hsiang Wu",
            "Prem Seetharaman",
            "Kundan Kumar",
            "Juan Pablo Bello"
        ],
        "dcterms:description": "UrbanSound 8K is a dataset for urban sound research.",
        "dcterms:title": "UrbanSound 8K Dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Urban Sound Classification"
        ],
        "dcat:keyword": [
            "Urban Sounds",
            "Sound Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound Classification"
        ]
    },
    {
        "dcterms:creator": [
            "George Tzanetakis",
            "Perry Cook"
        ],
        "dcterms:description": "GTZAN is a dataset for musical genre classification of audio signals.",
        "dcterms:title": "GTZAN Dataset",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Music Genre Classification"
        ],
        "dcat:keyword": [
            "Music Genres",
            "Audio Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Genre Classification"
        ]
    }
]