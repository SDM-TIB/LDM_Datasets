[
    {
        "dcterms:creator": [
            "Sijie Zhu",
            "Taojiannan Yang",
            "Chen Chen"
        ],
        "dcterms:description": "The VIGOR dataset contains geo-tagged ground-level panoramas and aerial images collected in four cities in the US. Each aerial patch corresponds to a ground area of approximately 70m × 70m. The dataset provides 105,214 panoramas for geo-localization experiments.",
        "dcterms:title": "VIGOR",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Geo-localization",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Geo-tagged images",
            "Panoramas",
            "Aerial images",
            "Cross-view localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Geo-localization"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Christoph Stiller",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI dataset contains ground-level images captured by a moving vehicle with a forward-facing viewpoint. Each aerial patch corresponds to a ground area of approximately 100m × 100m, and it is used for evaluating localization tasks.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Ground-level images",
            "Aerial images",
            "Localization",
            "Autonomous driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Menghua Zhai",
            "Zachary Bessinger",
            "Scott Workman",
            "Nathan Jacobs"
        ],
        "dcterms:description": "The CVUSA dataset is used for predicting ground-level scene layout from aerial imagery. It provides images from different cities to test model generalization ability.",
        "dcterms:title": "CVUSA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cross-view localization",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Aerial imagery",
            "Ground-level scene layout",
            "Generalization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Scene layout prediction"
        ]
    }
]