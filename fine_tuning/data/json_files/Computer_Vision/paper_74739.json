[
    {
        "dcterms:creator": [
            "Anand Siththaranjan",
            "Cassidy Laidlaw",
            "Dylan Hadfield-Menell"
        ],
        "dcterms:description": "A dataset of preferences used to understand and account for hidden context in reinforcement learning from human feedback (RLHF).",
        "dcterms:title": "Preferences Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Preferences",
            "Hidden Context",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference Learning",
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Louis Martin",
            "Kevin Stone",
            "Peter Albert",
            "Amjad Almahairi",
            "Yasmine Babaei",
            "Nikolay Bashlykov",
            "Soumya Batra",
            "Prajjwal Bhargava",
            "Shruti Bhosale"
        ],
        "dcterms:description": "A dataset used for fine-tuning chat models, providing a foundation for reinforcement learning from human feedback.",
        "dcterms:title": "HH-RLHF Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.09288",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Chat Models",
            "Fine-tuning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Fine-tuning",
            "Chatbot Development"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Brown",
            "Scott Niekum",
            "Marek Petrik"
        ],
        "dcterms:description": "A dataset for Bayesian Robust Optimization in imitation learning, focusing on learning from human preferences.",
        "dcterms:title": "B-REx Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper/2020/hash/1a669e81c8093745261889539694be7f-Abstract.html",
        "dcat:theme": [
            "Imitation Learning",
            "Bayesian Optimization"
        ],
        "dcat:keyword": [
            "Bayesian Learning",
            "Imitation Learning",
            "Human Preferences"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper/2020/hash/1a669e81c8093745261889539694be7f-Abstract.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Imitation Learning",
            "Preference Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Maxime Chevalier-Boisvert",
            "Bolun Dai",
            "Mark Towers",
            "Rodrigo de Lazcano",
            "Lucas Willems",
            "Salem Lahlou",
            "Suman Pal",
            "Pablo Samuel Castro",
            "Jordan Terry"
        ],
        "dcterms:description": "A modular and customizable dataset for reinforcement learning environments, designed for goal-oriented tasks.",
        "dcterms:title": "Minigrid Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "abs/2306.13831",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation Environments"
        ],
        "dcat:keyword": [
            "Modular Environments",
            "Goal-oriented Tasks",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Environment Simulation"
        ]
    },
    {
        "dcterms:creator": [
            "Alexander Wei",
            "Nika Haghtalab",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A dataset of prompts used to analyze the failures of safety training in large language models.",
        "dcterms:title": "Jailbreak Prompts Dataset",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Safety in AI",
            "Language Models"
        ],
        "dcat:keyword": [
            "Jailbreaking",
            "Safety Training",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Safety Analysis",
            "Prompt Engineering"
        ]
    }
]