[
    {
        "dcterms:creator": [
            "Ben Mildenhall",
            "Pratul P. Srinivasan",
            "Matthew Tancik",
            "Jonathan T. Barron",
            "Ravi Ramamoorthi",
            "Ren Ng"
        ],
        "dcterms:description": "NeRF is a technique that uses a neural network to learn the relationship between 3D positions and the color and density of light at those positions, allowing for the generation of realistic views of the scene from any angle.",
        "dcterms:title": "NeRF (Neural Radiance Fields)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2003.08934",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Neural Radiance Fields",
            "3D maps",
            "View synthesis"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2003.08934",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "Thomas Müller",
            "Alex Evans",
            "Christoph Schied",
            "Alexander Keller"
        ],
        "dcterms:description": "Instant NGP addresses the real-time limitations of NeRF, enabling practical, interactive applications in augmented reality and robotics by optimizing NeRF's training and rendering processes.",
        "dcterms:title": "Instant Neural Graphics Primitives",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2201.05989",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Real-time rendering",
            "Neural Graphics",
            "Augmented Reality"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2201.05989",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "Jonathan T. Barron",
            "Ben Mildenhall",
            "Dor Verbin",
            "Pratul P. Srinivasan",
            "Peter Hedman"
        ],
        "dcterms:description": "Zip-NeRF enhances the efficiency and speed of neural radiance fields, making them more scalable and efficient for large-scale scenes by optimizing the inference process.",
        "dcterms:title": "Zip-NeRF",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2304.06706",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Neural Radiance Fields",
            "Efficiency",
            "Large-scale scenes"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2304.06706",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "Bernhard Kerbl",
            "Georgios Kopanas",
            "Thomas Leimkühler",
            "George Drettakis"
        ],
        "dcterms:description": "3D Gaussian Splatting is a technique that achieves real-time rendering of high-quality radiance fields, even for large and complex scenes, by representing the radiance field as a set of 3D Gaussians.",
        "dcterms:title": "3D Gaussian Splatting",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2308.04079",
        "dcat:theme": [
            "3D Rendering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Real-time rendering",
            "3D Gaussians",
            "Radiance Fields"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2308.04079",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Rendering"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "COLMAP is a photogrammetry software that allows for the recovery of camera poses from images, which is essential for creating 3D models from 2D images.",
        "dcterms:title": "COLMAP",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://liwen.site/archives/2196",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Camera poses",
            "Photogrammetry"
        ],
        "dcat:landingPage": "https://liwen.site/archives/2196",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Camera Pose Recovery"
        ]
    },
    {
        "dcterms:creator": [
            "Sagar"
        ],
        "dcterms:description": "The Laplacian variance method is used for blur detection in images, which is crucial for ensuring high-quality input data for 3D reconstruction.",
        "dcterms:title": "Laplacian Variance for Blur Detection",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://medium.com/@sagardhungel/laplacian-and-its-use-in-blur-detection-fbac689f0f88",
        "dcat:theme": [
            "Image Processing"
        ],
        "dcat:keyword": [
            "Blur Detection",
            "Image Quality"
        ],
        "dcat:landingPage": "https://medium.com/@sagardhungel/laplacian-and-its-use-in-blur-detection-fbac689f0f88",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Quality Assessment"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Google Satellite View provides aerial images that can be used for reconstructing 3D building models from multiple perspectives.",
        "dcterms:title": "Google Satellite View",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.sciencedirect.com/science/article/abs/pii/S0924271603000583",
        "dcat:theme": [
            "3D Reconstruction",
            "Geospatial Data"
        ],
        "dcat:keyword": [
            "Aerial Images",
            "3D Models"
        ],
        "dcat:landingPage": "https://www.sciencedirect.com/science/article/abs/pii/S0924271603000583",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Structure from Motion (SFM) is a technique used to estimate 3D structures from 2D image sequences, which is essential for creating 3D models.",
        "dcterms:title": "Structure from Motion (SFM)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://en.wikipedia.org/wiki/Structure_from_motion",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "3D Structure",
            "Image Sequences"
        ],
        "dcat:landingPage": "https://en.wikipedia.org/wiki/Structure_from_motion",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Reconstruction"
        ]
    }
]