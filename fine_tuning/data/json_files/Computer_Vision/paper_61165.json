[
    {
        "dcterms:creator": [
            "H. Chen",
            "W. Xie",
            "A. Vedaldi",
            "A. Zisserman"
        ],
        "dcterms:description": "The VGGSound dataset is derived from a collection of YouTube videos with corresponding audio-visual data. It contains 200,000 samples, each lasting ten seconds, and is annotated with 309 classes.",
        "dcterms:title": "VGGSound",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Data",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Audio dataset",
            "Video dataset",
            "YouTube",
            "Sound classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Audio Classification",
            "Image Generation"
        ]
    }
]