[
    {
        "dcterms:creator": [
            "M. Deitke",
            "W. Han",
            "A. Herrasti",
            "A. Kembhavi",
            "E. Kolve",
            "R. Mottaghi",
            "J. Salvador",
            "D. Schwenk",
            "E. VanderBilt",
            "M. Wallingford",
            "L. Weihs",
            "M. Yatskar",
            "A. Farhadi"
        ],
        "dcterms:description": "RoboTHOR is an open simulation-to-real embodied AI platform that provides a suite of environments for training and evaluating embodied agents in navigation tasks.",
        "dcterms:title": "RoboTHOR",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Embodied AI",
            "Simulation"
        ],
        "dcat:keyword": [
            "Simulation",
            "Embodied AI",
            "Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Savva",
            "A. Kadian",
            "O. Maksymets",
            "Y. Zhao",
            "E. Wijmans",
            "B. Jain",
            "J. Straub",
            "J. Liu",
            "V. Koltun",
            "J. Malik",
            "D. Parikh",
            "D. Batra"
        ],
        "dcterms:description": "AI Habitat is a platform designed for embodied AI research, providing a suite of environments and tools for training and evaluating agents in navigation and interaction tasks.",
        "dcterms:title": "AI Habitat",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Embodied AI",
            "Simulation"
        ],
        "dcat:keyword": [
            "Simulation",
            "Embodied AI",
            "Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. W. Kim",
            "C. Hallacy",
            "A. Ramesh",
            "G. Goh",
            "S. Agarwal",
            "G. Sastry",
            "A. Askell",
            "P. Mishkin",
            "J. Clark"
        ],
        "dcterms:description": "CLIP is a large pre-trained Vision-Language model capable of zero-shot object detection and understanding natural language descriptions.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Vision-Language",
            "Zero-shot Learning",
            "Object Detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "L. H. Li",
            "P. Zhang",
            "H. Zhang",
            "J. Yang",
            "C. Li",
            "Y. Zhong",
            "L. Wang",
            "L. Yuan",
            "L. Zhang",
            "J.-N. Hwang",
            "K.-W. Chang",
            "J. Gao"
        ],
        "dcterms:description": "GLIP is a pre-trained Vision-Language model designed for zero-shot object grounding, capable of identifying objects based on natural language descriptions.",
        "dcterms:title": "GLIP",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Vision-Language",
            "Object Grounding",
            "Zero-shot Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "M. Minderer",
            "A. Gritsenko",
            "A. Stone",
            "M. Neumann",
            "D. Weissenborn",
            "A. Dosovitskiy",
            "A. Mahendran",
            "A. Arnab",
            "M. Dehghani",
            "Z. Shen"
        ],
        "dcterms:description": "OWL-ViT is a vision transformer model designed for open-vocabulary object detection, allowing for the detection of objects not seen during training.",
        "dcterms:title": "OWL-ViT",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Open-Vocabulary",
            "Object Detection",
            "Vision Transformer"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wu",
            "A. Kirillov",
            "F. Massa",
            "W.-Y. Lo",
            "R. Girshick"
        ],
        "dcterms:description": "Detectron2 is a high-performance codebase for object detection and segmentation tasks, providing a flexible framework for building detection models.",
        "dcterms:title": "Detectron2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/facebookresearch/detectron2",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Object Detection",
            "Segmentation",
            "Framework"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/detectron2",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "X. Zhou",
            "R. Girdhar",
            "A. Joulin",
            "P. Krähenbühl",
            "I. Misra"
        ],
        "dcterms:description": "Detic is a model designed for detecting a large number of object classes using image-level supervision, enabling zero-shot detection capabilities.",
        "dcterms:title": "Detic",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Zero-shot Detection",
            "Image-level Supervision",
            "Object Detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection"
        ]
    }
]