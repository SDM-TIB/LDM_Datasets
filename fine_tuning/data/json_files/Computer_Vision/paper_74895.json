[
    {
        "dcterms:creator": [
            "Makoto Takamoto",
            "Timothy Praditia",
            "Raphael Leiteritz",
            "Dan MacKinlay",
            "Francesco Alesiani",
            "Dirk Pflüger",
            "Mathias Niepert"
        ],
        "dcterms:description": "The shallow-water equations are derived from the compressible Navier-Stokes equations. The data is comprised of 900 sets of 101 images, each of which is a time step.",
        "dcterms:title": "SWE (Shallow Water Equation)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Scientific Computing",
            "Fluid Dynamics"
        ],
        "dcat:keyword": [
            "PDE",
            "Shallow Water Equation",
            "Time Series",
            "Image Sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Time Series Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Junbo Zhang",
            "Yu Zheng",
            "Dekang Qi"
        ],
        "dcterms:description": "The CloudCast dataset comprises 70,080 satellite images captured every 15 minutes and has a resolution of 3712 × 3712 pixels, covering the entire disk of Earth.",
        "dcterms:title": "CloudCast",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Remote Sensing",
            "Meteorology"
        ],
        "dcat:keyword": [
            "Satellite Images",
            "Weather Prediction",
            "Time Series",
            "Earth Observation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Weather Prediction",
            "Time Series Forecasting"
        ]
    },
    {
        "dcterms:creator": [
            "Angel Villar-Corrales",
            "Ani J. Karapetyan",
            "Andreas Boltres",
            "Sven Behnke"
        ],
        "dcterms:description": "The Moving MNIST dataset is a synthetic video dataset designed to test sequence prediction models. It features 20-frame sequences where two MNIST digits move with random trajectories.",
        "dcterms:title": "Moving MNIST",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Video Prediction"
        ],
        "dcat:keyword": [
            "Synthetic Dataset",
            "Video Sequences",
            "Digit Recognition",
            "Trajectory Prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Nal Kalchbrenner",
            "Aäron van den Oord",
            "Karen Simonyan",
            "Ivo Danihelka",
            "Oriol Vinyals",
            "Alex Graves",
            "Koray Kavukcuoglu"
        ],
        "dcterms:description": "The KITTI is a widely recognized dataset extensively used in mobile robotics and autonomous driving, and it also serves as a benchmark for computer vision algorithms.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Robotics",
            "Benchmark Dataset",
            "Image Sequences",
            "Object Detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Video Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Junbo Zhang",
            "Yu Zheng",
            "Dekang Qi"
        ],
        "dcterms:description": "TaxiBJ is a collection of real-world GPS spatiotemporal data of taxis recorded as frames of 32x32x2 heat maps every half an hour, quantifying traffic flow in Beijing.",
        "dcterms:title": "TaxiBJ",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Traffic Prediction",
            "Urban Computing"
        ],
        "dcat:keyword": [
            "GPS Data",
            "Traffic Flow",
            "Heat Maps",
            "Spatiotemporal Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Heat Map",
        "mls:task": [
            "Traffic Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Ruben Villegas",
            "Jimei Yang",
            "Seunghoon Hong",
            "Xunyu Lin",
            "Honglak Lee"
        ],
        "dcterms:description": "The KTH dataset features 25 individuals executing six types of actions: walking, jogging, running, boxing, hand waving, and hand clapping.",
        "dcterms:title": "KTH Action",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Action Recognition",
            "Video Dataset",
            "Human Motion",
            "Behavior Analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]