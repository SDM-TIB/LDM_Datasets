To extract datasets from the research paper titled "Deep Sliding Shapes for Amodal 3D Object Detection in RGB-D Images" by Shuran Song and Jianxiong Xiao, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the research focus, and the introduction often discusses the context and significance of the datasets used.

In the **introduction**, the authors mention the use of RGB-D images for 3D object detection, which suggests that they may reference specific datasets related to RGB-D images. I will look for any explicit mentions of datasets or benchmarks.

Next, I will examine the **experiments section** where the authors typically describe the datasets used for training and evaluation. Here, I will look for any specific dataset names, descriptions, and the context in which they are used.

Upon reviewing the paper, I find that the authors evaluate their method on two primary datasets:

1. **NYUv2 Dataset**: This dataset is a well-known benchmark for indoor scene understanding, containing RGB-D images with annotated object instances. The authors mention that they evaluate their 3D region proposal and object detection algorithm on this dataset.

2. **SUN RGB-D Dataset**: This dataset is another significant benchmark for RGB-D object detection, containing a diverse set of indoor scenes with 3D bounding box annotations for various object categories. The authors state that they obtain amodal 3D bounding boxes from this dataset.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **NYUv2 Dataset**, the citation is:
  > Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. *Indoor Segmentation and Support Inference from RGBD Images*. In Proceedings of the European Conference on Computer Vision (ECCV), 2012.

- For the **SUN RGB-D Dataset**, the citation is:
  > S. Gupta, P. Arbelaez, R. B. Girshick, and J. Malik. *Learning Rich Features from RGB-D Images for Object Detection and Segmentation*. In Proceedings of the European Conference on Computer Vision (ECCV), 2014.

With these citations in hand, I will now prepare to create structured entries for each dataset, ensuring that I include the full citations as required. This will provide a comprehensive overview of the datasets utilized in the research.