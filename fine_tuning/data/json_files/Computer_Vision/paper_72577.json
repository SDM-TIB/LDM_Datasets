[
    {
        "dcterms:creator": [
            "R. Rombach",
            "A. Blattmann",
            "D. Lorenz",
            "P. Esser",
            "B. Ommer"
        ],
        "dcterms:description": "A diffusion model that generates high-resolution images based on textual prompts, showcasing impressive capabilities in generating diverse and realistic images.",
        "dcterms:title": "Stable Diffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Text-to-Image",
            "High-Resolution",
            "Image Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Saharia",
            "W. Chan",
            "S. Saxena",
            "L. Li",
            "J. Whang",
            "E. L. Denton",
            "K. Ghasemipour",
            "R. Gontijo Lopes",
            "B. Karagol Ayan",
            "T. Salimans"
        ],
        "dcterms:description": "A text-to-image diffusion model that generates photorealistic images with deep language understanding.",
        "dcterms:title": "Imagen",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Text-to-Image",
            "Photorealism",
            "Deep Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "G. Parmar",
            "K. Kumar Singh",
            "R. Zhang",
            "Y. Li",
            "J. Lu",
            "J.-Y. Zhu"
        ],
        "dcterms:description": "A model for zero-shot image-to-image translation, enabling the generation of images based on textual descriptions.",
        "dcterms:title": "DALL-E",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Image Translation",
            "Zero-Shot Learning",
            "Text-to-Image"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Liu",
            "S. Li",
            "Y. Du",
            "A. Torralba",
            "J. B. Tenenbaum"
        ],
        "dcterms:description": "A compositional visual generation method using composable diffusion models to enhance image synthesis.",
        "dcterms:title": "ComposableDiffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Compositional Generation",
            "Image Synthesis",
            "Diffusion Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "W. Feng",
            "X. He",
            "T.-J. Fu",
            "V. Jampani",
            "A. Akula",
            "P. Narayana",
            "S. Basu",
            "X. E. Wang",
            "W. Y. Wang"
        ],
        "dcterms:description": "A method for structured diffusion guidance in compositional text-to-image synthesis that does not require training.",
        "dcterms:title": "StructureDiffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Structured Guidance",
            "Text-to-Image",
            "Compositional Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "O. Bar-Tal",
            "L. Yariv",
            "Y. Lipman",
            "T. Dekel"
        ],
        "dcterms:description": "A method that fuses multiple diffusion paths for controlled image generation.",
        "dcterms:title": "MultiDiffusion",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Controlled Generation",
            "Diffusion Models",
            "Image Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Chefer",
            "Y. Alaluf",
            "Y. Vinker",
            "L. Wolf",
            "D. Cohen-Or"
        ],
        "dcterms:description": "An attention-based semantic guidance method for text-to-image diffusion models.",
        "dcterms:title": "Attend-and-Excite",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Attention Mechanism",
            "Text-to-Image",
            "Semantic Guidance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Li",
            "M. Keuper",
            "D. Zhang",
            "A. Khoreva"
        ],
        "dcterms:description": "A method that improves generative semantic nursing by dividing and binding attention.",
        "dcterms:title": "Divide-and-Bind",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Attention Binding",
            "Text-to-Image",
            "Generative Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Liu",
            "C. Li",
            "Q. Wu",
            "Y. J. Lee"
        ],
        "dcterms:description": "A dataset for visual instruction tuning.",
        "dcterms:title": "Llava1.5",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Instruction Tuning"
        ],
        "dcat:keyword": [
            "Visual Instruction",
            "Tuning",
            "Image Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "1.5",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Bai",
            "S. Bai",
            "S. Yang",
            "S. Wang",
            "S. Tan",
            "P. Wang",
            "J. Lin",
            "C. Zhou",
            "J. Zhou"
        ],
        "dcterms:description": "A large vision-language model with versatile abilities.",
        "dcterms:title": "QWEN",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Vision-Language",
            "Large Model",
            "Versatile Abilities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Mixed",
        "mls:task": [
            "Image Generation",
            "Text Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "J. Li",
            "D. Li",
            "S. Savarese",
            "S. Hoi"
        ],
        "dcterms:description": "A model that bootstraps language-image pre-training with frozen image encoders and large language models.",
        "dcterms:title": "BLIP2",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Language-Image Pre-training",
            "Image Generation",
            "Large Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Mixed",
        "mls:task": [
            "Image Generation",
            "Text Understanding"
        ]
    }
]