[
    {
        "dcterms:creator": [
            "Zhangdie Yuan",
            "Chenxi Whitehouse",
            "Eric Chamoun",
            "Rami Aly",
            "Andreas Vlachos"
        ],
        "dcterms:description": "PROBELM is a benchmark designed to assess language modelsâ€™ ability to discern more plausible from less plausible scenarios through their parametric knowledge, constructed from a dataset curated from Wikidata edit histories.",
        "dcterms:title": "PROBELM",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/zhangdiey/PRobELM",
        "dcat:theme": [
            "Natural Language Processing",
            "Plausibility Assessment"
        ],
        "dcat:keyword": [
            "Plausibility ranking",
            "Language models",
            "Wikidata",
            "Benchmark"
        ],
        "dcat:landingPage": "https://github.com/zhangdiey/PRobELM",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Plausibility assessment",
            "Scenario ranking"
        ]
    },
    {
        "dcterms:creator": [
            "Stephanie Lin",
            "Jacob Hilton",
            "Owain Evans"
        ],
        "dcterms:description": "TruthfulQA is designed to assess the truthfulness or factual correctness of language models, evaluating their ability to retrieve and apply information encoded during training.",
        "dcterms:title": "TruthfulQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2022.acl-long.229",
        "dcat:theme": [
            "Natural Language Processing",
            "Factual Accuracy"
        ],
        "dcat:keyword": [
            "Truthfulness",
            "Factual correctness",
            "Language models"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.acl-long.229",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Truthfulness evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Melissa Roemmele",
            "Cosmin Adrian Bejan",
            "Andrew S Gordon"
        ],
        "dcterms:description": "COPA evaluates models through causal reasoning tasks, asking the model to choose the more plausible scenarios from two options for a given premise.",
        "dcterms:title": "COPA (Choice of Plausible Alternatives)",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "https://cdn.aaai.org/ocs/2418/2418-10878-1-PB.pdf",
        "dcat:theme": [
            "Natural Language Processing",
            "Causal Reasoning"
        ],
        "dcat:keyword": [
            "Causal reasoning",
            "Plausibility",
            "Language models"
        ],
        "dcat:landingPage": "https://cdn.aaai.org/ocs/2418/2418-10878-1-PB.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Causal reasoning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Rowan Zellers",
            "Ari Holtzman",
            "Yonatan Bisk",
            "Ali Farhadi",
            "Yejin Choi"
        ],
        "dcterms:description": "HellaSwag evaluates commonsense reasoning within physically situated contexts, challenging models to complete sentences in a plausible manner.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/P19-1472",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Sentence completion",
            "Language models"
        ],
        "dcat:landingPage": "https://aclanthology.org/P19-1472",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Commonsense reasoning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Keisuke Sakaguchi",
            "Ronan Le Bras",
            "Chandra Bhagavatula",
            "Yejin Choi"
        ],
        "dcterms:description": "Winogrande is an adversarial Winograd Schema Challenge at scale, designed to evaluate models' understanding of pronoun resolution in context.",
        "dcterms:title": "Winogrande",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://dl.acm.org/doi/10.1145/3474381",
        "dcat:theme": [
            "Natural Language Processing",
            "Pronoun Resolution"
        ],
        "dcat:keyword": [
            "Pronoun resolution",
            "Adversarial evaluation",
            "Language models"
        ],
        "dcat:landingPage": "https://dl.acm.org/doi/10.1145/3474381",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Pronoun resolution evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Peter Clark",
            "Isaac Cowhey",
            "Oren Etzioni",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Carissa Schoenick",
            "Oyvind Tafjord"
        ],
        "dcterms:description": "ARC (AI2 Reasoning Challenge) is designed to test the reasoning capabilities of models through a diverse set of questions.",
        "dcterms:title": "ARC (AI2 Reasoning Challenge)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1803.05457",
        "dcat:theme": [
            "Natural Language Processing",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Reasoning challenge",
            "Question answering",
            "Language models"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1803.05457",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reasoning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Qingyun Wang",
            "Doug Downey",
            "Heng Ji",
            "Tom Hope"
        ],
        "dcterms:description": "SciMON is designed to optimize scientific inspiration machines for novelty, assessing their ability to generate novel hypotheses.",
        "dcterms:title": "SciMON",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2305.14259",
        "dcat:theme": [
            "Natural Language Processing",
            "Scientific Discovery"
        ],
        "dcat:keyword": [
            "Scientific discovery",
            "Hypothesis generation",
            "Language models"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2305.14259",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Hypothesis generation evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Joel Jang",
            "Seonghyeon Ye",
            "Changho Lee",
            "Sohee Yang",
            "Joongbo Shin",
            "Janghoon Han",
            "Gyeonghun Kim",
            "Minjoon Seo"
        ],
        "dcterms:description": "TemporalWiki is a lifelong benchmark for training and evaluating ever-evolving language models, focusing on their ability to adapt to temporal changes.",
        "dcterms:title": "TemporalWiki",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2022.emnlp-main.418",
        "dcat:theme": [
            "Natural Language Processing",
            "Temporal Reasoning"
        ],
        "dcat:keyword": [
            "Temporal reasoning",
            "Language models",
            "Benchmark"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.emnlp-main.418",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Temporal reasoning evaluation"
        ]
    }
]