[
    {
        "dcterms:creator": [
            "K. Ito",
            "L. Johnson"
        ],
        "dcterms:description": "A single-speaker dataset used for training and evaluating text-to-speech models, consisting of 13,100 short audio clips totaling roughly 24 hours.",
        "dcterms:title": "LJSpeech",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "https://keithito.com/LJ-Speech-Dataset/",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Single-speaker",
            "Audio clips",
            "Text-to-Speech"
        ],
        "dcat:landingPage": "https://keithito.com/LJ-Speech-Dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Yamagishi",
            "C. Veaux",
            "K. MacDonald"
        ],
        "dcterms:description": "A multi-speaker corpus consisting of nearly 44,000 short clips from 109 native speakers with various accents, used for training and evaluating text-to-speech models.",
        "dcterms:title": "VCTK",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Multi-speaker",
            "Accent diversity",
            "Audio clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "version 0.92",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "H. Zen",
            "V. Dang",
            "R. Clark",
            "Y. Zhang",
            "R. J. Weiss",
            "Y. Jia",
            "Z. Chen",
            "Y. Wu"
        ],
        "dcterms:description": "A corpus derived from LibriSpeech for text-to-speech synthesis, containing about 245 hours of audio from 1,151 speakers, used for zero-shot speaker adaptation.",
        "dcterms:title": "LibriTTS",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Zero-shot adaptation",
            "Multi-speaker",
            "Audio corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "train-clean-460 subset",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    }
]