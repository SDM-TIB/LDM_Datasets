To extract datasets from the research paper titled "TRB: A Novel Triplet Representation for Understanding 2D Human Body" by Haodong Duan et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract indicates that the authors constructed several large-scale TRB estimation datasets based on popular 2D pose datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 3.2 (TRB Estimation Task, Dataset and Evaluation)**, where the authors explicitly mention the datasets they built. They state that they constructed three TRB datasets based on existing pose estimation datasets: **MPII**, **LSP**, and **COCO**. 

1. **MPII TRB Dataset**: This dataset is based on the MPII dataset, which contains around 40,000 annotated poses. The authors annotated contour keypoints on all the train-validation data of MPII to create the MPII TRB dataset.

2. **LSP TRB Dataset**: Similarly, this dataset is based on the LSP dataset, which contains approximately 12,000 annotated poses. The authors also annotated contour keypoints on all the train-validation data of LSP to form the LSP TRB dataset.

3. **COCO TRB Dataset**: This dataset is derived from the COCO dataset, which is much larger, containing around 150,000 annotated people. The authors randomly annotated half of its train-validation data to create the COCO TRB dataset.

Now, I will look at the **References section** to find the full citations for the original datasets used to create the TRB datasets:

- For the **MPII dataset**, the citation is:
  > Mykhaylo Andriluka, Leonid Pishchulin, Peter Gehler, and Bernt Schiele. *2D human pose estimation: New benchmark and state of the art analysis*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3686–3693, 2014.

- For the **LSP dataset**, the citation is:
  > Sam Johnson and Mark Everingham. *Clustered pose and nonlinear appearance models for human pose estimation*. In Proceedings of the British Machine Vision Conference, 2010.

- For the **COCO dataset**, the citation is:
  > Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. *Microsoft coco: Common objects in context*. In European conference on computer vision, pages 740–755. Springer, 2014.

With this information, I can now summarize the datasets and their citations clearly.

Finally, I will compile the dataset entries into a structured format for easy reference and further processing.