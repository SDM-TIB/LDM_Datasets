[
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Yuke Zhu",
            "Oliver Groth",
            "Justin Johnson",
            "Kenji Hata",
            "Joshua Kravitz",
            "Stephanie Chen",
            "Yannis Kalantidis",
            "Li-Jia Li",
            "David A Shamma"
        ],
        "dcterms:description": "Visual Genome is a knowledge-based scene graph dataset that connects structured image concepts with semantic relations, serving as a benchmark for various vision tasks, such as visual grounding and scene graph generation.",
        "dcterms:title": "Visual-Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Knowledge Graph"
        ],
        "dcat:keyword": [
            "Scene graph",
            "Image concepts",
            "Semantic relations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Graph",
        "mls:task": [
            "Visual grounding",
            "Scene graph generation"
        ]
    },
    {
        "dcterms:creator": [
            "Robyn Speer",
            "Joshua Chin",
            "Catherine Havasi"
        ],
        "dcterms:description": "ConceptNet is a language-based knowledge graph that connects words and phrases of natural language with labeled edges, built from various sources including expert-created resources and crowd-sourcing.",
        "dcterms:title": "ConceptNet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Knowledge Graph"
        ],
        "dcat:keyword": [
            "Language graph",
            "Semantic relations",
            "Natural language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Graph",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Houda Alberts",
            "Teresa Huang",
            "Yash Deshpande",
            "Yibo Liu",
            "Kyunghyun Cho",
            "Clara Vania",
            "Iacer Calixto"
        ],
        "dcterms:description": "VisualSem is a high-quality multi-modal knowledge graph dataset for vision and language concepts, including entities with multilingual glosses, multiple illustrative images, and visually relevant relations.",
        "dcterms:title": "VisualSem",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2008.09150",
        "dcat:theme": [
            "Computer Vision",
            "Knowledge Graph"
        ],
        "dcat:keyword": [
            "Multi-modal graph",
            "Vision-language concepts",
            "Entities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Graph",
        "mls:task": []
    }
]