[
    {
        "dcterms:creator": [
            "J. Pennington",
            "R. Socher",
            "C. Manning"
        ],
        "dcterms:description": "GloVe is a word embedding model that uses global word-word co-occurrence statistics to create vector representations of words.",
        "dcterms:title": "GloVe",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Word representation",
            "Co-occurrence statistics",
            "Vector space"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "T. Mikolov",
            "K. Chen",
            "G. Corrado",
            "J. Dean"
        ],
        "dcterms:description": "word2vec is a group of related models that are used to produce word embeddings, which are vector representations of words.",
        "dcterms:title": "word2vec",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Word representation",
            "Neural networks",
            "Vector space"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "S. Bowman",
            "G. Angeli",
            "C. Potts",
            "C. D. Manning"
        ],
        "dcterms:description": "SNLI is a large annotated corpus for learning natural language inference, containing pairs of sentences labeled with entailment, contradiction, or neutrality.",
        "dcterms:title": "SNLI (Stanford Natural Language Inference)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Annotated corpus",
            "Entailment",
            "Contradiction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "T. Mikolov",
            "Q. V. Le",
            "I. Sutskever"
        ],
        "dcterms:description": "Common Crawl is a dataset that contains web data collected from the internet, used for various natural language processing tasks.",
        "dcterms:title": "Common Crawl",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Web Data"
        ],
        "dcat:keyword": [
            "Web corpus",
            "Data collection",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "A. Caliskan",
            "J. J. Bryson",
            "A. Narayanan"
        ],
        "dcterms:description": "WEAT is a test designed to measure biases in word embeddings by examining the associations between words and concepts.",
        "dcterms:title": "WEAT (Word Embedding Association Test)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Bias Measurement"
        ],
        "dcat:keyword": [
            "Bias test",
            "Word embeddings",
            "Associations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "M. Peters",
            "M. Neumann",
            "M. Iyyer",
            "M. Gardner",
            "C. Clark",
            "K. Lee",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "ELMo is a deep contextualized word representation model that generates embeddings based on the context of words in sentences.",
        "dcterms:title": "ELMo",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Contextual embeddings",
            "Deep learning",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [
            "J. Devlin",
            "M. Chang",
            "K. Lee",
            "K. Toutanova"
        ],
        "dcterms:description": "BERT is a transformer-based model for natural language understanding that pre-trains deep bidirectional representations by jointly conditioning on both left and right context in all layers.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Transformers",
            "Bidirectional context",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text"
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "DemonymTest is a dataset used to evaluate biases in word embeddings based on the associations of demonyms with various attributes.",
        "dcterms:title": "DemonymTest",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": ""
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "AdherentTest is a dataset used to evaluate biases in word embeddings based on the associations of adherents to various religions with different attributes.",
        "dcterms:title": "AdherentTest",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": ""
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "SIRT is a test designed to measure the retention of sentence inference capabilities in word embeddings after debiasing.",
        "dcterms:title": "SIRT (Sentence Inference Retention Test)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": ""
    }
]