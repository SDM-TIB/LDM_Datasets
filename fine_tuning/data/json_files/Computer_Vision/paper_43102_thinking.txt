To extract the datasets from the research paper titled "Multi-modal Datasets for Super-resolution" by Haoran Li et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets that are mentioned. The abstract indicates that the authors propose two datasets: **OID-RW** and **MDD400**. This is a good starting point, as it suggests that these datasets are central to the paper's contributions.

Next, I will look for detailed descriptions of these datasets in the **subsequent sections**, particularly in sections III and IV, which focus on the construction of the datasets. In section III, the authors describe the **OID-RW dataset**, which consists of 82 groups of images, including character and architecture types. They explain how the dataset was constructed using old black-and-white photos and digital images taken with a DSLR camera.

In section IV, the authors detail the **MDD400 dataset**, which simulates real-world degradation using various methods, including interpolation, CNN, GAN, and video capture. They explain that this dataset is built upon a new dataset called **NRD300**.

Now, I will gather the necessary information to create full citations for these datasets. I will check the **References section** of the paper for any citations related to the datasets mentioned. 

For the **OID-RW dataset**, the authors do not provide a specific citation in the references, but they describe its construction in detail. Therefore, I will note that it is a new dataset proposed by the authors.

For the **MDD400 dataset**, similarly, it is also a new dataset introduced in this paper, and no external citation is provided. 

Next, I will summarize the datasets as follows:

1. **OID-RW Dataset**: A dataset of old black-and-white photos constructed using film cameras and digital cameras, containing 82 groups of images (22 character type and 60 architecture type). This dataset aims to improve the robustness of super-resolution models in practical applications.

2. **MDD400 Dataset**: A multi-modal degradation dataset that simulates real-world image degradation using various methods, including interpolation, CNN, GAN, and video capture. This dataset is designed to enhance the generalization capability of super-resolution models.

Since both datasets are newly proposed in this paper, I will note that the citations for these datasets are the authors themselves:

- For **OID-RW Dataset**: 
  > Haoran Li, Weihong Quan, Meijun Yan, Jin Zhang, Xiaoli Gong, and Jin Zhou. *Multi-modal Datasets for Super-resolution*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2023.

- For **MDD400 Dataset**: 
  > Haoran Li, Weihong Quan, Meijun Yan, Jin Zhang, Xiaoli Gong, and Jin Zhou. *Multi-modal Datasets for Super-resolution*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2023.

Finally, I will compile the dataset entries into a structured format for further processing or review.