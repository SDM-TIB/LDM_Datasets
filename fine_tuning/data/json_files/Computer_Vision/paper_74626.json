[
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge J. Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C. Lawrence Zitnick"
        ],
        "dcterms:description": "A dataset containing images of common objects in context, along with their corresponding annotations.",
        "dcterms:title": "COCO 2017",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "https://api.semanticscholar.org/CorpusID:14113767",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Segmentation"
        ],
        "dcat:landingPage": "https://api.semanticscholar.org/CorpusID:14113767",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Christoph Schuhmann",
            "Romain Beaumont",
            "Richard Vencu",
            "Cade W Gordon",
            "Ross Wightman",
            "Mehdi Cherti",
            "Theo Coombes",
            "Aarush Katta",
            "Clayton Mullis",
            "Mitchell Wortsman",
            "Patrick Schramowski",
            "Srivatsa R Kundurthy",
            "Katherine Crowson",
            "Ludwig Schmidt",
            "Robert Kaczmarczyk",
            "Jenia Jitsev"
        ],
        "dcterms:description": "An open large-scale dataset for training next generation image-text models.",
        "dcterms:title": "LAION-COCO",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://openreview.net/forum?id=M3Y74vmsMcY",
        "dcat:theme": [
            "Image-Text Models",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Image-text dataset",
            "Large-scale dataset",
            "Training data"
        ],
        "dcat:landingPage": "https://openreview.net/forum?id=M3Y74vmsMcY",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Text",
        "mls:task": [
            "Image-Text Matching",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [
            "Zijie J. Wang",
            "Evan Montoya",
            "David Munechika",
            "Haoyang Yang",
            "Benjamin Hoover",
            "Duen Horng Chau"
        ],
        "dcterms:description": "A large-scale prompt gallery dataset for text-to-image generative models.",
        "dcterms:title": "DiffusionDB",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2210.14896",
        "dcat:theme": [
            "Text-to-Image Generation",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Prompt dataset",
            "Text-to-image",
            "Generative models"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2210.14896",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text, Image",
        "mls:task": [
            "Text-to-Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Keqiang Sun",
            "Junting Pan",
            "Yuying Ge",
            "Hao Li",
            "Haodong Duan",
            "Xiaoshi Wu",
            "Renrui Zhang",
            "Aojun Zhou",
            "Zipeng Qin",
            "Yi Wang",
            "Jifeng Dai",
            "Yu Qiao",
            "Limin Wang",
            "Hongsheng Li"
        ],
        "dcterms:description": "A benchmark for generative image understanding.",
        "dcterms:title": "JourneyDB",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://openreview.net/forum?id=vfzXDRTcF4",
        "dcat:theme": [
            "Generative Models",
            "Image Understanding"
        ],
        "dcat:keyword": [
            "Benchmark dataset",
            "Generative image understanding"
        ],
        "dcat:landingPage": "https://openreview.net/forum?id=vfzXDRTcF4",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Understanding",
            "Benchmarking"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset comprising human-curated prompts, processed natural language captions, synthetic images, and attention maps.",
        "dcterms:title": "StableSemantics",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Semantic Understanding",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Language-vision dataset",
            "Attention maps"
        ],
        "dcat:landingPage": "https://stablesemantics.github.io/StableSemantics/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Text",
        "mls:task": [
            "Visual Semantic Understanding",
            "Image Generation"
        ]
    }
]