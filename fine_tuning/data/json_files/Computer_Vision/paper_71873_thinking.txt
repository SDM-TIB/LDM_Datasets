To extract datasets from the research paper titled "OccGaussian: 3D Gaussian Splatting for Occluded Human Rendering" by Jingrui Ye et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors conducted experiments on two datasets, which indicates that datasets are indeed present.

Next, I will focus on **section 4 (Experiments)**, where the authors explicitly describe the datasets used. In **section 4.2 (Datasets)**, they mention:

1. **ZJU-MoCap Dataset**: This dataset is widely used for human modeling and provides human masks and SMPL parameters. The authors specify that they selected six human subjects for their experiments and simulated occlusions for training.

2. **OcMotion Dataset**: This dataset is designed for human pose estimation under occlusion and contains 43 motions with 300K frames and 3D annotations. The authors detail how they evaluated their method on videos with varying levels of occlusion.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **ZJU-MoCap Dataset**, the citation is:
  > Sida Peng, Yuanqing Zhang, Yinghao Xu, Qianqian Wang, Qing Shuai, Hujun Bao, and Xiaowei Zhou. *Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9054–9063, 2021.

- For the **OcMotion Dataset**, the citation is:
  > Buzhen Huang, Yuan Shu, Jingyi Ju, and Yangang Wang. *Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion Prior*. arXiv preprint arXiv:2207.05375, 2022.

With these citations in hand, I can now summarize the datasets:

1. **ZJU-MoCap Dataset**: A benchmark dataset for human modeling that includes human masks and SMPL parameters, used for training and testing in the experiments.
   - Citation: Sida Peng, Yuanqing Zhang, Yinghao Xu, Qianqian Wang, Qing Shuai, Hujun Bao, and Xiawei Zhou. *Neural body: Implicit neural representations with structured latent codes for novel view synthesis of dynamic humans*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 9054–9063, 2021.

2. **OcMotion Dataset**: A dataset specifically built for human pose estimation under occlusion, containing 43 motions and 300K frames with 3D annotations.
   - Citation: Buzhen Huang, Yuan Shu, Jingyi Ju, and Yangang Wang. *Occluded Human Body Capture with Self-Supervised Spatial-Temporal Motion Prior*. arXiv preprint arXiv:2207.05375, 2022.

Finally, I will compile this information into a structured format for further processing or review.