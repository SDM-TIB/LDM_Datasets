[
    {
        "dcterms:creator": [
            "Ben Poole",
            "Ajay Jain",
            "Jonathan T Barron",
            "Ben Mildenhall"
        ],
        "dcterms:description": "DreamFusion is a text-to-3D generation method that utilizes the Score Distillation Sampling (SDS) algorithm to generate diverse 3D objects from textual prompts.",
        "dcterms:title": "DreamFusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2209.14988",
        "dcat:theme": [
            "3D Generation",
            "Text-to-3D"
        ],
        "dcat:keyword": [
            "Text-to-3D",
            "Diffusion Models",
            "SDS",
            "3D Objects"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Object Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Lvmin Zhang",
            "Maneesh Agrawala"
        ],
        "dcterms:description": "ControlNet is a method that adds conditional control to text-to-image diffusion models, enhancing the generation process by incorporating additional constraints.",
        "dcterms:title": "ControlNet",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2302.05543",
        "dcat:theme": [
            "Image Generation",
            "Conditional Control"
        ],
        "dcat:keyword": [
            "Text-to-Image",
            "Diffusion Models",
            "Conditional Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Robin Rombach",
            "Andreas Blattmann",
            "Dominik Lorenz",
            "Patrick Esser",
            "Bj√∂rn Ommer"
        ],
        "dcterms:description": "Stable Diffusion is a latent diffusion model that enables high-resolution image synthesis, leveraging a powerful generative framework.",
        "dcterms:title": "Stable Diffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Synthesis",
            "Latent Diffusion"
        ],
        "dcat:keyword": [
            "Image Generation",
            "Diffusion Models",
            "High-Resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Nataniel Ruiz",
            "Yuanzhen Li",
            "Varun Jampani",
            "Yael Pritch",
            "Michael Rubinstein",
            "Kfir Aberman"
        ],
        "dcterms:description": "DreamBooth is a method for fine-tuning text-to-image diffusion models to enable subject-driven generation, allowing for personalized outputs.",
        "dcterms:title": "DreamBooth",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Personalization"
        ],
        "dcat:keyword": [
            "Text-to-Image",
            "Fine-Tuning",
            "Subject-Driven Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Ben Poole",
            "Ajay Jain",
            "Jonathan T Barron",
            "Ben Mildenhall"
        ],
        "dcterms:description": "Score Distillation Sampling (SDS) is a technique introduced in DreamFusion that allows for the generation of diverse 3D objects using textual prompts.",
        "dcterms:title": "SDS (Score Distillation Sampling)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2209.14988",
        "dcat:theme": [
            "3D Generation",
            "Text-to-3D"
        ],
        "dcat:keyword": [
            "Text-to-3D",
            "Diffusion Models",
            "SDS"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Object Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Eric R Chan",
            "Connor Z Lin",
            "Matthew A Chan",
            "Koki Nagano",
            "Boxiao Pan",
            "Shalini De Mello",
            "Orazio Gallo",
            "Leonidas J Guibas",
            "Jonathan Tremblay",
            "Sameh Khamis"
        ],
        "dcterms:description": "EG3D is an efficient geometry-aware 3D generative adversarial network that focuses on high-quality 3D generation.",
        "dcterms:title": "EG3D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Generation",
            "Generative Adversarial Networks"
        ],
        "dcat:keyword": [
            "3D Generation",
            "GAN",
            "Geometry-Aware"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Object Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Chen-Hsuan Lin",
            "Jun Gao",
            "Luming Tang",
            "Towaki Takikawa",
            "Xiaohui Zeng",
            "Xun Huang",
            "Karsten Kreis",
            "Sanja Fidler",
            "Ming-Yu Liu",
            "Tsung-Yi Lin"
        ],
        "dcterms:description": "Magic3D is a high-resolution text-to-3D content creation method that enhances the generation of 3D objects from textual descriptions.",
        "dcterms:title": "Magic3D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2211.10440",
        "dcat:theme": [
            "3D Generation",
            "Text-to-3D"
        ],
        "dcat:keyword": [
            "Text-to-3D",
            "High-Resolution",
            "Content Creation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Object Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Ayaan Haque",
            "Matthew Tancik",
            "Alexei A Efros",
            "Aleksander Holynski",
            "Angjoo Kanazawa"
        ],
        "dcterms:description": "Instruct-nerf2nerf is a method for editing 3D scenes based on instructions, allowing for interactive modifications of 3D models.",
        "dcterms:title": "Instruct-nerf2nerf",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2303.12789",
        "dcat:theme": [
            "3D Editing",
            "Scene Modification"
        ],
        "dcat:keyword": [
            "3D Editing",
            "Instructions",
            "Scene Modification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Scene Editing"
        ]
    }
]