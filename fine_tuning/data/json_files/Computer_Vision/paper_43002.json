[
    {
        "dcterms:creator": [
            "C. Doersch"
        ],
        "dcterms:description": "Variational Autoencoder (VAE) is a generative model that uses a probabilistic approach to generate new data points similar to the training data.",
        "dcterms:title": "Variational Autoencoder (VAE)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.05908",
        "dcat:theme": [
            "Generative Models",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Variational Autoencoder",
            "Generative Model",
            "Probabilistic Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Li",
            "K. Swersky",
            "R. Zemel"
        ],
        "dcterms:description": "Generative Moment Matching Networks (GMMN) are designed to match the moments of the generated data distribution with the moments of the real data distribution.",
        "dcterms:title": "Generative Moment Matching Networks (GMMN)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Generative Models",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Moment Matching",
            "Generative Model",
            "Kernel Methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ren",
            "J. Zhu",
            "J. Li",
            "Y. Luo"
        ],
        "dcterms:description": "Conditional Generative Moment-Matching Networks extend GMMN by incorporating conditional information to improve the generation process.",
        "dcterms:title": "Conditional Generative Moment-Matching Networks",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Generative Models",
            "Conditional Generation"
        ],
        "dcat:keyword": [
            "Conditional Generation",
            "Moment Matching",
            "Generative Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Makhzani",
            "J. Shlens",
            "N. Jaitly",
            "I. Goodfellow",
            "B. Frey"
        ],
        "dcterms:description": "Adversarial Autoencoders (AAE) combine the principles of autoencoders and adversarial training to improve the quality of generated data.",
        "dcterms:title": "Adversarial Autoencoders (AAE)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1511.05644",
        "dcat:theme": [
            "Generative Models",
            "Adversarial Learning"
        ],
        "dcat:keyword": [
            "Adversarial Training",
            "Autoencoder",
            "Generative Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "I. Goodfellow",
            "J. Pouget-Abadie",
            "M. Mirza",
            "B. Xu",
            "D. Warde-Farley",
            "S. Ozair",
            "A. Courville",
            "Y. Bengio"
        ],
        "dcterms:description": "Generative Adversarial Networks (GAN) are a class of generative models that use adversarial training to generate new data points.",
        "dcterms:title": "Generative Adversarial Networks (GAN)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Generative Models",
            "Adversarial Learning"
        ],
        "dcat:keyword": [
            "Adversarial Training",
            "Generative Model",
            "Data Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Mirza",
            "S. Osindero"
        ],
        "dcterms:description": "Conditional Generative Adversarial Nets extend GANs by conditioning the generation process on additional information.",
        "dcterms:title": "Conditional Generative Adversarial Nets",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1411.1784",
        "dcat:theme": [
            "Generative Models",
            "Conditional Generation"
        ],
        "dcat:keyword": [
            "Conditional Generation",
            "Adversarial Training",
            "Generative Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "X. Mao",
            "Q. Li",
            "H. Xie",
            "R.Y. Lau",
            "Z. Wang",
            "S. Paul Smolley"
        ],
        "dcterms:description": "Least Squares Generative Adversarial Networks (LSGAN) modify the GAN framework to use least squares loss for training.",
        "dcterms:title": "Least Squares Generative Adversarial Networks (LSGAN)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Generative Models",
            "Adversarial Learning"
        ],
        "dcat:keyword": [
            "Least Squares Loss",
            "Adversarial Training",
            "Generative Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Wang",
            "A.C. Bovik",
            "H.R. Sheikh",
            "E.P. Simoncelli"
        ],
        "dcterms:description": "Structural Similarity Index (SSIM) is a perceptual measure of image quality that considers changes in structural information.",
        "dcterms:title": "Structural Similarity Index (SSIM)",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Quality Assessment"
        ],
        "dcat:keyword": [
            "Image Quality",
            "Perceptual Measure",
            "Structural Similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Quality Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "B. Ghojogh",
            "F. Karray",
            "M. Crowley"
        ],
        "dcterms:description": "Image Structure Subspace Learning uses SSIM to capture intrinsic features of images in terms of structural similarity.",
        "dcterms:title": "Image Structure Subspace Learning",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Image Structure",
            "Subspace Learning",
            "Structural Similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Analysis"
        ]
    }
]