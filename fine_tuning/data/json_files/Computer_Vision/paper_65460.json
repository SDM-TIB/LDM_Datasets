[
    {
        "dcterms:creator": [
            "K. Cobbe",
            "V. Kosaraju",
            "M. Bavarian",
            "M. Chen",
            "H. Jun",
            "L. Kaiser",
            "M. Plappert",
            "J. Tworek",
            "J. Hilton",
            "R. Nakano",
            "C. Hesse",
            "J. Schulman"
        ],
        "dcterms:description": "The Grade School Math dataset (GSM) is used to assess the reasoning proficiency of models, requiring them to produce a chain-of-thought process and the final numerical answer for math problems.",
        "dcterms:title": "Grade School Math dataset (GSM)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2110.14168",
        "dcat:theme": [
            "Mathematics",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Math problems",
            "Reasoning",
            "Chain-of-thought"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2110.14168",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Basart",
            "A. Zou",
            "M. Mazeika",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "The Massive Multitask Language Understanding dataset (MMLU) encompasses questions about 57 subjects, formatted as multiple-choice questions, spanning a spectrum of difficulty levels from elementary to advanced professional tiers.",
        "dcterms:title": "Massive Multitask Language Understanding dataset (MMLU)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://openreview.net/forum?id=d7KBjmI3GmQ",
        "dcat:theme": [
            "Language Understanding",
            "Multitask Learning"
        ],
        "dcat:keyword": [
            "Multiple-choice questions",
            "Language understanding",
            "Professional knowledge"
        ],
        "dcat:landingPage": "https://openreview.net/forum?id=d7KBjmI3GmQ",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Multitask learning"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wang",
            "S. Mishra",
            "P. Alipoormolabashi",
            "Y. Kordi",
            "A. Mirzaei",
            "A. Naik",
            "A. Ashok",
            "A. Dhanasekaran",
            "A. Arunkumar",
            "D. Stap",
            "E. Pathak",
            "G. Karamanolakis",
            "H. Lai",
            "I. Purohit",
            "I. Mondal",
            "J. Anderson",
            "K. Kuznia",
            "K. Doshi",
            "K. Kumar Pal",
            "M. Patel",
            "M. Moradshahi",
            "M. Parmar",
            "M. Purohit",
            "N. Varshney",
            "P. Kaza",
            "P. Verma",
            "R. Singh Puri",
            "R. Karia",
            "S. Doshi",
            "S. Sampat",
            "S. Mishra",
            "S. Reddy A.",
            "S. Patro",
            "T. Dixit",
            "X. Shen"
        ],
        "dcterms:description": "The Super Natural Instructions (Super NI) dataset comprises 1,616 varied NLP tasks alongside their expert-written instructions, evaluating a model's capability in adhering to instructions.",
        "dcterms:title": "Super Natural Instructions (Super NI)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/2022.emnlp-main.340",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "NLP tasks",
            "Instructions",
            "Task generalization"
        ],
        "dcat:landingPage": "https://doi.org/10.18653/v1/2022.emnlp-main.340",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following",
            "NLP task execution"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Dubois",
            "X. Li",
            "R. Taori",
            "T. Zhang",
            "I. Gulrajani",
            "J. Ba",
            "C. Guestrin",
            "P. Liang",
            "T. B. Hashimoto"
        ],
        "dcterms:description": "AlpacaFarm is a simulation framework for methods that learn from human feedback, containing 805 instructions including subsets from various evaluations.",
        "dcterms:title": "AlpacaFarm",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.48550/arXiv.2305.14387",
        "dcat:theme": [
            "Human Feedback",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Human feedback",
            "Instruction following",
            "Simulation framework"
        ],
        "dcat:landingPage": "https://doi.org/10.48550/arXiv.2305.14387",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following",
            "Human feedback learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Zhou",
            "P. Liu",
            "P. Xu",
            "S. Iyer",
            "J. Sun",
            "Y. Mao",
            "X. Ma",
            "A. Efrat",
            "P. Yu",
            "L. Yu",
            "S. Zhang",
            "G. Ghosh",
            "M. Lewis",
            "L. Zettlemoyer",
            "O. Levy"
        ],
        "dcterms:description": "LIMA is a dataset that emphasizes the principle of 'less is more' for alignment, focusing on efficient training and alignment of models.",
        "dcterms:title": "LIMA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.48550/arXiv.2305.11206",
        "dcat:theme": [
            "Model Alignment",
            "Efficient Training"
        ],
        "dcat:keyword": [
            "Alignment",
            "Efficient training",
            "Model performance"
        ],
        "dcat:landingPage": "https://doi.org/10.48550/arXiv.2305.11206",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model alignment",
            "Training efficiency"
        ]
    }
]