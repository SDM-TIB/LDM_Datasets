[
    {
        "dcterms:creator": [
            "A. Ramesh",
            "P. Dhariwal",
            "A. Nichol",
            "C. Chu",
            "M. Chen"
        ],
        "dcterms:description": "A dataset used for evaluating text-to-image generation models, providing a benchmark for image fidelity and text relevance.",
        "dcterms:title": "MS-COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image-text pairs",
            "Text-to-image generation",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation",
            "Text-to-Image Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "H. Zhang",
            "W. Yin",
            "Y. Fang",
            "L. Li",
            "B. Duan",
            "Z. Wu",
            "Y. Sun",
            "H. Tian",
            "H. Wang"
        ],
        "dcterms:description": "A bilingual prompt set designed for evaluating and comparing Chinese and English text-to-image models.",
        "dcterms:title": "ViLG-300",
        "dcterms:issued": "2021",
        "dcterms:language": "Chinese, English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Bilingual Evaluation"
        ],
        "dcat:keyword": [
            "Bilingual prompts",
            "Text-to-image evaluation",
            "Image fidelity"
        ],
        "dcat:landingPage": "https://github.com/PaddlePaddle/ERNIE/tree/ernie-kit-open-v1.0/Research/ERNIE-ViLG2/data/ViLG-300.csv",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Generation",
            "Text-to-Image Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schuhmann",
            "R. Vencu",
            "R. Beaumont",
            "R. Kaczmarczyk",
            "C. Mullis",
            "A. Katta",
            "T. Coombes",
            "J. Jitsev",
            "A. Komatsuzaki"
        ],
        "dcterms:description": "An open dataset containing 400 million image-text pairs filtered using CLIP, aimed at facilitating research in vision-language tasks.",
        "dcterms:title": "LAION",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Vision-Language"
        ],
        "dcat:keyword": [
            "Image-text pairs",
            "CLIP-filtered dataset",
            "Open dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation",
            "Text-to-Image Synthesis"
        ]
    }
]