[
    {
        "dcterms:creator": [
            "Olga Russakovsky",
            "Jia Deng",
            "Hao Su",
            "Jonathan Krause",
            "Sanjeev Satheesh",
            "Sean Ma",
            "Zhiheng Huang",
            "Andrej Karpathy",
            "Aditya Khosla",
            "Michael Bernstein"
        ],
        "dcterms:description": "ImageNet is a large-scale dataset used for visual recognition tasks, containing millions of labeled images across thousands of categories. It serves as a benchmark for evaluating the performance of various computer vision models.",
        "dcterms:title": "ImageNet",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Visual recognition",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Soravit Changpinyo",
            "Piyush Sharma",
            "Nan Ding",
            "Radu Soricut"
        ],
        "dcterms:description": "CC12M is a dataset designed for image-text pre-training, consisting of 12 million image-text pairs sourced from the web, aimed at improving the recognition of long-tail visual concepts.",
        "dcterms:title": "CC12M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image-Text Pairing",
            "Web-scale Dataset"
        ],
        "dcat:keyword": [
            "Image-text dataset",
            "Web-scale",
            "Long-tail concepts"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text Pair",
        "mls:task": [
            "Image-Text Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Minwoo Byeon",
            "Beomhee Park",
            "Haecheon Kim",
            "Sungjun Lee",
            "Woonhyuk Baek",
            "Saehoon Kim"
        ],
        "dcterms:description": "COYO-700M is an image-text pair dataset containing 700 million pairs, aimed at enhancing the performance of models in understanding and generating visual content based on textual descriptions.",
        "dcterms:title": "COYO-700M",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/kakaobrain/coyo-dataset",
        "dcat:theme": [
            "Image-Text Pairing",
            "Large-scale Dataset"
        ],
        "dcat:keyword": [
            "Image-text dataset",
            "Large-scale",
            "Visual understanding"
        ],
        "dcat:landingPage": "https://github.com/kakaobrain/coyo-dataset",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text Pair",
        "mls:task": [
            "Image-Text Generation"
        ]
    }
]