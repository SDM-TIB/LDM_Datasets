To extract the datasets mentioned in the research paper titled "Chain-based Discriminative Autoencoders for Speech Recognition" by Hung-Shin Lee et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. In the abstract, the authors mention that they evaluated their models on the **WSJ and Aurora-4 corpora**, indicating that these are the datasets used in their experiments.

Next, I will look closely at **section 3 (Experiments and Results)**, where the authors provide detailed descriptions of the datasets. Here, they explicitly mention:

1. **WSJ Dataset**: This dataset consists of WSJ0 (LDC93S6B) and WSJ1 (LDC94S13B), with a training set that includes 81 hours of speech. The authors specify that they used dev93 and eval92 as test sets.

2. **Aurora-4 Dataset**: This dataset is described as a medium-level vocabulary task based on WSJ0 (LDC93S6B). It contains 7,138 utterance pairs from 83 speakers, with each pair consisting of clean speech and speech corrupted by various types of noise at different signal-to-noise ratios (SNR).

Now, I will check the **References section** to find the full citations for these datasets:

- For the **WSJ Dataset**, the citation is:
  > D. B. Paul and J. M. Baker. *The design for the wall street journal-based CSR corpus*. In Proceedings of the DARPA Speech and Natural Language Workshop, 1992.

- For the **Aurora-4 Dataset**, the citation is:
  > N. Parihar and J. Picone. *Aurora working group: DSR front end LVCSR evaluation AU/384/02*. Inst. for Signal & Inform. Process., Mississippi State Univ., Tech. Rep., 2002. Available: http://aurora.hsnr.de/aurora-4.html

Having gathered all the necessary information, I will now prepare to create structured entries for each dataset, ensuring that the full citations are included for proper attribution.