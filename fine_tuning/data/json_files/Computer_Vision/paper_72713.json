[
    {
        "dcterms:creator": [
            "R. Calandra",
            "A. Owens",
            "D. Jayaraman",
            "J. Lin",
            "W. Yuan",
            "J. Malik",
            "E. H. Adelson",
            "S. Levine"
        ],
        "dcterms:description": "A dataset used to learn grasping and regrasping using both vision and touch, focusing on the integration of tactile feedback with visual data.",
        "dcterms:title": "More Than a Feeling",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Grasping",
            "Regrasping",
            "Vision",
            "Touch"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Grasp Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "R. Calandra",
            "A. Owens",
            "M. Upadhyaya",
            "W. Yuan",
            "J. Lin",
            "E. H. Adelson",
            "S. Levine"
        ],
        "dcterms:description": "This dataset investigates whether touch sensing can help predict the outcomes of grasping actions.",
        "dcterms:title": "Feeling of Success",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Grasp Outcomes",
            "Touch Sensing",
            "Prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Grasp Outcome Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Li",
            "J. Zhu",
            "R. Tedrake",
            "A. Torralba"
        ],
        "dcterms:description": "A dataset that connects touch and vision through cross-modal prediction, facilitating the understanding of tactile properties from visual data.",
        "dcterms:title": "VisGel",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Cross-Modal Prediction",
            "Touch",
            "Vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Touch Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "J. Kerr",
            "H. Huang",
            "A. Wilcox",
            "R. Hoque",
            "J. Ichnowski",
            "R. Calandra",
            "K. Goldberg"
        ],
        "dcterms:description": "A dataset for self-supervised visuo-tactile pretraining aimed at locating and following garment features.",
        "dcterms:title": "SSVTP",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Self-Supervised Learning",
            "Visuo-Tactile",
            "Garment Features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature Localization"
        ]
    },
    {
        "dcterms:creator": [
            "R. Gao",
            "Y.-Y. Chang",
            "S. Mall",
            "L. Fei-Fei",
            "J. Wu"
        ],
        "dcterms:description": "A dataset containing objects with implicit visual, auditory, and tactile representations, aimed at enhancing multisensory learning.",
        "dcterms:title": "ObjectFolder 1.0",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multisensory Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Object Recognition",
            "Multisensory Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "1.0",
        "dcterms:format": "",
        "mls:task": [
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Gao",
            "Z. Si",
            "Y.-Y. Chang",
            "S. Clarke",
            "J. Bohg",
            "L. Fei-Fei",
            "W. Yuan",
            "J. Wu"
        ],
        "dcterms:description": "An updated version of the ObjectFolder dataset, providing multisensory data for sim-to-real transfer.",
        "dcterms:title": "ObjectFolder 2.0",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multisensory Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Sim-to-Real Transfer",
            "Multisensory Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "2.0",
        "dcterms:format": "",
        "mls:task": [
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Gao",
            "Y. Dou",
            "H. Li",
            "T. Agarwal",
            "J. Bohg",
            "Y. Li",
            "L. Fei-Fei",
            "J. Wu"
        ],
        "dcterms:description": "A benchmark dataset for multisensory learning that includes both neural and real objects.",
        "dcterms:title": "ObjectFolder Real",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multisensory Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Multisensory Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "F. Yang",
            "C. Ma",
            "J. Zhang",
            "J. Zhu",
            "W. Yuan",
            "A. Owens"
        ],
        "dcterms:description": "A dataset that learns from human-collected vision and touch data to improve tactile sensing.",
        "dcterms:title": "Touch and Go",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Human-Collected Data",
            "Vision",
            "Touch"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Tactile Learning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Suresh",
            "Z. Si",
            "S. Anderson",
            "M. Kaess",
            "M. Mukadam"
        ],
        "dcterms:description": "A dataset that uses Monte-Carlo inference over distributions across sliding touch to enhance tactile sensing.",
        "dcterms:title": "YCB-Slide",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Monte-Carlo Inference",
            "Touch Sensing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Tactile Learning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Zhong",
            "A. Albini",
            "O. Parker Jones",
            "P. Maiolino",
            "I. Posner"
        ],
        "dcterms:description": "A dataset that leverages neural radiance fields for generating tactile sensory data.",
        "dcterms:title": "Touching a NeRF",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Neural Radiance Fields",
            "Tactile Data Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Tactile Data Generation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset collected by the authors that contains spatially aligned visual and tactile data.",
        "dcterms:title": "TaRF (Ours)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Tactile Sensing"
        ],
        "dcat:keyword": [
            "Visual-Tactile Data",
            "Scene Representation"
        ],
        "dcat:landingPage": "https://dou-yiming.github.io/TaRF",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Cross-Modal Learning"
        ]
    }
]