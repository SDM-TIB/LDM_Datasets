[
    {
        "dcterms:creator": [
            "Jun Liu",
            "Amir Shahroudy",
            "Mauricio Perez",
            "Gang Wang",
            "Ling-Yu Duan",
            "Alex C Kot"
        ],
        "dcterms:description": "A large-scale multi-view action recognition dataset, consisting of 56,880 videos from 60 distinct action classes, recorded from 40 subjects using Kinect-v2, with activities captured from three viewpoints.",
        "dcterms:title": "NTU-60",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Multi-view videos",
            "Action classes",
            "Kinect-v2"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jun Liu",
            "Amir Shahroudy",
            "Mauricio Perez",
            "Gang Wang",
            "Ling-Yu Duan",
            "Alex C Kot"
        ],
        "dcterms:description": "The extended version of the NTU-60 dataset, containing 114,480 videos spanning 120 action categories, with established protocols for evaluation.",
        "dcterms:title": "NTU-120",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Multi-view videos",
            "Action categories"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jinhyeok Jang",
            "Dohyung Kim",
            "Cheonshu Park",
            "Minsu Jang",
            "Jaeyeon Lee",
            "Jaehong Kim"
        ],
        "dcterms:description": "A large-scale multi-view action recognition dataset consisting of activities of daily living for elderly care, with 112,620 videos captured from 55 action classes across 8 synchronized viewpoints.",
        "dcterms:title": "ETRI",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Elderly Care"
        ],
        "dcat:keyword": [
            "Multi-view videos",
            "Elderly activities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jiang Wang",
            "Xiaohan Nie",
            "Yin Xia",
            "Ying Wu",
            "Song-Chun Zhu"
        ],
        "dcterms:description": "A multi-view action recognition dataset consisting of 1493 videos spanning 10 action classes, captured from three viewpoints, following the cross-view protocol.",
        "dcterms:title": "NUCLA",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Multi-view videos",
            "Action classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Chunhui Liu",
            "Yueyu Hu",
            "Yanghao Li",
            "Sijie Song",
            "Jiaying Liu"
        ],
        "dcterms:description": "A large scale benchmark for continuous multi-modal human action understanding, consisting of 6945 videos from 51 activity classes.",
        "dcterms:title": "PKU-MMD-II",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Human Action Understanding"
        ],
        "dcat:keyword": [
            "Multi-modal",
            "Action classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Arun V Reddy",
            "Ketul Shah",
            "William Paul",
            "Rohita Mocharla",
            "Judy Hoffman",
            "Kapil D Katyal",
            "Dinesh Manocha",
            "Celso M de Melo",
            "Rama Chellappa"
        ],
        "dcterms:description": "A dataset for synthetic-to-real domain adaptation for action recognition, providing baseline performances.",
        "dcterms:title": "ROCOG-v2",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Domain Adaptation"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]