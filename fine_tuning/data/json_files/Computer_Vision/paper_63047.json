[
    {
        "dcterms:creator": [
            "Z. Cao",
            "G. Hidalgo Martinez",
            "T. Simon",
            "S. Wei",
            "Y. A. Sheikh"
        ],
        "dcterms:description": "OpenPose is utilized for real-time multi-person 2D pose estimation using part affinity fields, providing keypoint detection for human figures in images.",
        "dcterms:title": "OpenPose",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Pose estimation",
            "2D keypoints",
            "Multi-person detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Rıza Alp Güler",
            "Natalia Neverova",
            "Iasonas Kokkinos"
        ],
        "dcterms:description": "DensePose maps 2D RGB images to 3D models, providing detailed human pose estimation and segmentation.",
        "dcterms:title": "DensePose",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "3D modeling",
            "Human pose",
            "Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Ke Gong",
            "Yiming Gao",
            "Xiaodan Liang",
            "Xiaohui Shen",
            "Meng Wang",
            "Liang Lin"
        ],
        "dcterms:description": "Graphonomy is a model for universal human parsing via graph transfer learning, enabling detailed segmentation of human body parts.",
        "dcterms:title": "Graphonomy",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Parsing"
        ],
        "dcat:keyword": [
            "Human parsing",
            "Graph learning",
            "Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Human Parsing"
        ]
    },
    {
        "dcterms:creator": [
            "MMPose Contributors"
        ],
        "dcterms:description": "MMPose is an open-source pose estimation toolbox and benchmark that provides various models and datasets for pose estimation tasks.",
        "dcterms:title": "MMPose",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/open-mmlab/mmpose",
        "dcat:theme": [
            "Computer Vision",
            "Pose Estimation"
        ],
        "dcat:keyword": [
            "Pose estimation",
            "Benchmark",
            "Open-source"
        ],
        "dcat:landingPage": "https://github.com/open-mmlab/mmpose",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Yuming Jiang",
            "Shuai Yang",
            "Haonan Qiu",
            "Wayne Wu",
            "Chen Change Loy",
            "Ziwei Liu"
        ],
        "dcterms:description": "Text2Human is a dataset for text-driven controllable human image generation, allowing for the generation of human images based on textual descriptions.",
        "dcterms:title": "Text2Human",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Text-driven generation",
            "Human images",
            "Controllable generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Martin Pernuš",
            "Clinton Fookes",
            "Vitomir Štruc",
            "Simon Dobrišek"
        ],
        "dcterms:description": "FICE is a dataset for text-conditioned fashion image editing using guided GAN inversion, enabling modifications of fashion images based on textual prompts.",
        "dcterms:title": "FICE",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2301.02110",
        "dcat:theme": [
            "Computer Vision",
            "Fashion Editing"
        ],
        "dcat:keyword": [
            "Fashion editing",
            "Text-conditioned",
            "GAN inversion"
        ],
        "dcat:landingPage": "arXiv:2301.02110",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Editing"
        ]
    },
    {
        "dcterms:creator": [
            "Robin Rombach",
            "Andreas Blattmann",
            "Dominik Lorenz",
            "Patrick Esser",
            "Björn Ommer"
        ],
        "dcterms:description": "Stable Diffusion is a high-resolution image synthesis model that utilizes latent diffusion models for generating images from text prompts.",
        "dcterms:title": "Stable Diffusion",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Image synthesis",
            "Latent diffusion",
            "Text-to-image"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Lvmin Zhang",
            "Maneesh Agrawala"
        ],
        "dcterms:description": "ControlNet adds conditional control to text-to-image diffusion models, allowing for more precise image generation based on conditions.",
        "dcterms:title": "ControlNet",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Conditional control",
            "Text-to-image",
            "Diffusion models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Alexander Kirillov",
            "Eric Mintun",
            "Nikhila Ravi",
            "Hanzi Mao",
            "Chloe Rolland",
            "Laura Gustafson",
            "Tete Xiao",
            "Spencer Whitehead",
            "Alexander C. Berg",
            "Wan-Yen Lo",
            "Piotr Dollár",
            "Ross Girshick"
        ],
        "dcterms:description": "Grounded-SAM is a model that achieves open-domain segmentation through text prompts, combining grounding techniques with segmentation.",
        "dcterms:title": "Grounded-SAM",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.02643",
        "dcat:theme": [
            "Computer Vision",
            "Segmentation"
        ],
        "dcat:keyword": [
            "Open-domain segmentation",
            "Text prompts",
            "Segmentation model"
        ],
        "dcat:landingPage": "arXiv:2304.02643",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Jiachen Li",
            "Jitesh Jain",
            "Humphrey Shi"
        ],
        "dcterms:description": "MattingAnything is a model that allows for matting of any object with rich details, improving upon traditional segmentation methods.",
        "dcterms:title": "MattingAnything",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.05399",
        "dcat:theme": [
            "Computer Vision",
            "Image Matting"
        ],
        "dcat:keyword": [
            "Image matting",
            "Segmentation",
            "Detail enhancement"
        ],
        "dcat:landingPage": "arXiv:2306.05399",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Matting"
        ]
    }
]