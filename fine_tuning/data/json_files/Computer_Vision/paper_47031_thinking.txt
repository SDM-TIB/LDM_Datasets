To extract datasets from the research paper titled "Preventing Oversmoothing in VAE via Generalized Variance Parameterization" by Yuhta Takida et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract** to see if any datasets are mentioned. The abstract states that the authors evaluated their method on the **MNIST** and **CelebA** datasets, which indicates that these datasets are relevant to the research.

Next, I will check the **introduction** section for any additional context or details about these datasets. The introduction discusses the challenges of variational autoencoders (VAEs) and mentions the use of these datasets for empirical validation, confirming their importance in the study.

I will then look into the **experiments** section, specifically section 6, where the authors describe their experimental setup. Here, they detail how they used the **MNIST** dataset, which consists of handwritten digits, and the **CelebA** dataset, which contains celebrity images. The authors mention that they used these datasets to evaluate the quality of generation and to demonstrate the effectiveness of their proposed method.

After identifying the datasets, I will refer to the **References section** to find the full citations for each dataset:

1. **MNIST Dataset**: The citation is:
   > Y. LeCun, L. Bottou, Y. Bengio, P. Haﬀner. *Gradient-based learning applied to document recognition*. Proc. IEEE 86 (11) (1998) 2278–2324.

2. **CelebA Dataset**: The citation is:
   > Z. Liu, P. Luo, X. Wang, X. Tang. *Deep learning face attributes in the wild*. Proc. IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015, pp. 3730–3738.

Now that I have the datasets and their citations, I will summarize the findings:

- **MNIST Dataset**: A dataset of handwritten digits used for evaluating the generative quality of the proposed VAE extensions.
- **CelebA Dataset**: A dataset of celebrity images used for testing the performance of the proposed method in generating high-fidelity images.

Finally, I will compile this information into a structured format for further use or processing.