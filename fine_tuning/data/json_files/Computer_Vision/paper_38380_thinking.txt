To extract datasets from the research paper titled "A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos" by Joshua Gleason et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract indicates that the authors evaluated their method on the **DIVA dataset** and the **THUMOS’14 dataset**, which suggests that these are the primary datasets used in their experiments.

Next, I will look for detailed descriptions of these datasets in the **Methods section**. In section 3, titled **DIVA dataset**, the authors provide a comprehensive overview of the DIVA dataset, stating that it consists of untrimmed security videos with specific annotations for various actions. They mention that the dataset includes 455 video clips with a total duration of 12 hours and 40 minutes, and it focuses on actions relevant to public security.

The authors also reference the **THUMOS’14 dataset** in the introduction, indicating that it is used for comparison. I will check the references section to find the full citation for both datasets.

For the **DIVA dataset**, the citation is:
> Gleason, J., Ranjan, R., Schwarcz, S., Castillo, C. D., Chen, J.-C., & Chellappa, R. (2019). A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos. In Proceedings of the IEEE Winter Conference on Applications of Computer Vision (WACV), 2019.

For the **THUMOS’14 dataset**, the citation is:
> Jiang, Y.-G., Liu, J., Zamir, A. R., Toderici, G., Laptev, I., Shah, M., & Sukthankar, R. (2014). THUMOS challenge: Action recognition with a large number of classes. http://crcv.ucf.edu/THUMOS14/.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing. Each dataset will be described with its name, a brief description, and the full citation.