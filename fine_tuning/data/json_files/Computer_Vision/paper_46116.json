[
    {
        "dcterms:creator": [
            "Ben Mildenhall",
            "Pratul P. Srinivasan",
            "Matthew Tancik",
            "Jonathan T. Barron",
            "Ravi Ramamoorthi",
            "Ren Ng"
        ],
        "dcterms:description": "NeRF is a neural rendering framework that combines a volume represented by a coordinate-based network with a neural volume renderer to achieve state-of-the-art image quality for view synthesis tasks.",
        "dcterms:title": "NeRF Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Rendering",
            "View Synthesis"
        ],
        "dcat:keyword": [
            "Neural Radiance Fields",
            "View Synthesis",
            "3D Scene Representation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "View Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Ben Mildenhall",
            "Pratul P. Srinivasan",
            "Rodrigo Ortiz-Cayon",
            "Nima Khademi Kalantari",
            "Ravi Ramamoorthi",
            "Ren Ng",
            "Abhishek Kar"
        ],
        "dcterms:description": "The Local Light Field Fusion dataset consists of captured, forward-facing image data used for practical view synthesis with prescriptive sampling guidelines.",
        "dcterms:title": "Local Light Field Fusion Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "View Synthesis",
            "Light Field Rendering"
        ],
        "dcat:keyword": [
            "Light Field",
            "View Synthesis",
            "Image Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "View Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Vincent Sitzmann",
            "Justus Thies",
            "Felix Heide",
            "Matthias Nießner",
            "Gordon Wetzstein",
            "Michael Zollhöfer"
        ],
        "dcterms:description": "The DeepVoxels dataset is used for learning persistent 3D feature embeddings.",
        "dcterms:title": "DeepVoxels Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Reconstruction",
            "Feature Learning"
        ],
        "dcat:keyword": [
            "3D Features",
            "Deep Learning",
            "Embeddings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Feature Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Stephen Lombardi",
            "Tomas Simon",
            "Jason Saragih",
            "Gabriel Schwartz",
            "Andreas Lehrmann",
            "Yaser Sheikh"
        ],
        "dcterms:description": "The Blender dataset consists of synthetic scenes rendered from 100 different camera positions using the Blender Cycles engine.",
        "dcterms:title": "Blender Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data",
            "3D Rendering"
        ],
        "dcat:keyword": [
            "Blender",
            "Synthetic Scenes",
            "3D Rendering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Scene Rendering"
        ]
    }
]