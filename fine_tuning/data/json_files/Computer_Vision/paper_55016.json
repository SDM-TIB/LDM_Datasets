[
    {
        "dcterms:creator": [
            "T.Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C.L. Zitnick"
        ],
        "dcterms:description": "Microsoft COCO is a large-scale dataset designed for object detection, segmentation, and captioning, containing images with complex scenes and multiple objects.",
        "dcterms:title": "MS-COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Object Detection",
            "Image Segmentation",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "L.J. Li",
            "D.A. Shamma"
        ],
        "dcterms:description": "Visual Genome is a dataset that connects language and vision through dense image annotations, providing a rich set of visual relationships and attributes.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Image Annotations",
            "Visual Relationships",
            "Dense Annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Reasoning",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "P. Sharma",
            "N. Ding",
            "S. Goodman",
            "R. Soricut"
        ],
        "dcterms:description": "Conceptual Captions is a dataset for automatic image captioning, providing cleaned and hypernymed image alt-text.",
        "dcterms:title": "Conceptual Captions",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image Alt-Text",
            "Automatic Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "V. Ordonez",
            "G. Kulkarni",
            "T. Berg"
        ],
        "dcterms:description": "SBU Captions is a dataset consisting of 1 million captioned photographs, aimed at describing images.",
        "dcterms:title": "SBU Captions",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Captioned Photographs",
            "Image Description"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Suhr",
            "S. Zhou",
            "A. Zhang",
            "I. Zhang",
            "H. Bai",
            "Y. Artzi"
        ],
        "dcterms:description": "NLVR2 is a dataset designed for reasoning about natural language grounded in photographs, focusing on visual reasoning tasks.",
        "dcterms:title": "NLVR2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Visual Reasoning",
            "Natural Language Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "B.A. Plummer",
            "L. Wang",
            "C.M. Cervantes",
            "J.C. Caicedo",
            "J. Hockenmaier",
            "S. Lazebnik"
        ],
        "dcterms:description": "Flickr30K is a dataset that collects region-to-phrase correspondences for richer image-to-sentence models.",
        "dcterms:title": "Flickr30K",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Region-to-Phrase Correspondences",
            "Image Description"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    }
]