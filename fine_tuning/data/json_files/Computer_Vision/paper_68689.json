[
    {
        "dcterms:creator": [
            "Naureen Mahmood",
            "Nima Ghorbani",
            "Nikolaus F. Troje",
            "Gerard Pons-Moll",
            "Michael J. Black"
        ],
        "dcterms:description": "AMASS is a large-scale motion capture dataset collecting high-quality 3D human pose and shape annotations, used for training and evaluation in various motion reconstruction tasks.",
        "dcterms:title": "AMASS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Motion Capture",
            "3D Human Pose Estimation"
        ],
        "dcat:keyword": [
            "3D motion capture",
            "human pose",
            "shape annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Motion Reconstruction",
            "Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Mohamed Hassan",
            "Vasileios Choutas",
            "Dimitrios Tzionas",
            "Michael J. Black"
        ],
        "dcterms:description": "PROX collects monocular RGB-D videos of people interacting with various 3D indoor scenes, used to evaluate physical plausibility in motion reconstruction.",
        "dcterms:title": "PROX",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "RGB-D Video",
            "Human Interaction"
        ],
        "dcat:keyword": [
            "RGB-D videos",
            "3D scenes",
            "human interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Motion Reconstruction",
            "Physical Plausibility Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Siwei Zhang",
            "Qianli Ma",
            "Yan Zhang",
            "Zhiyin Qian",
            "Taein Kwon",
            "Marc Pollefeys",
            "Federica Bogo",
            "Siyu Tang"
        ],
        "dcterms:description": "EgoBody collects sequences of people interacting with each other in various 3D indoor environments, capturing multi-modal input streams with both head-mounted and external cameras, providing ground-truth SMPL/SMPL-X annotations.",
        "dcterms:title": "EgoBody",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Interaction",
            "3D Motion Capture"
        ],
        "dcat:keyword": [
            "first-person view",
            "third-person view",
            "human interaction",
            "3D environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Motion Reconstruction",
            "Pose Estimation"
        ]
    }
]