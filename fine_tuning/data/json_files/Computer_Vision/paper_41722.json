[
    {
        "dcterms:creator": [
            "Mohamed Hassan",
            "Vasileios Choutas",
            "Dimitrios Tzionas",
            "Michael J. Black"
        ],
        "dcterms:description": "The PROX-Qualitative dataset records how people interact with various indoor environments, capturing 3D human body meshes in individual frames estimated by fitting the SMPL-X body model to RGB-D data subject to scene constraints.",
        "dcterms:title": "PROX-Qualitative (PROX-Q)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Human Interaction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "3D human bodies",
            "indoor environments",
            "human-scene interaction",
            "RGB-D data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Mesh",
        "mls:task": [
            "Human-Scene Interaction Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Angel Chang",
            "Angela Dai",
            "Thomas Funkhouser",
            "Maciej Halber",
            "Matthias Niessner",
            "Manolis Savva",
            "Shuran Song",
            "Andy Zeng",
            "Yinda Zhang"
        ],
        "dcterms:description": "MP3D-R is derived from the Matterport3D dataset, extracting 7 different rooms according to annotated bounding boxes and capturing snapshots from various views using a virtual agent in the Habitat simulator.",
        "dcterms:title": "MP3D-R",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Indoor Environments",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Matterport3D",
            "room extraction",
            "virtual agent",
            "RGB-D data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Mesh",
        "mls:task": [
            "Scene Understanding",
            "3D Body Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Manolis Savva",
            "Abhishek Kadian",
            "Oleksandr Maksymets",
            "Yili Zhao",
            "Erik Wijmans",
            "Bhavana Jain",
            "Julian Straub",
            "Jia Liu",
            "Vladlen Koltun",
            "Jitendra Malik",
            "Devi Parikh",
            "Dhruv Batra"
        ],
        "dcterms:description": "The Habitat Simulator provides a platform for embodied AI research, allowing for the development of scene understanding methods from embodied views, facilitating indoor robot navigation and AR/VR applications.",
        "dcterms:title": "Habitat Simulator",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Embodied AI",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "scene understanding",
            "robot navigation",
            "AR/VR"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation Environment",
        "mls:task": [
            "Embodied AI Research"
        ]
    }
]