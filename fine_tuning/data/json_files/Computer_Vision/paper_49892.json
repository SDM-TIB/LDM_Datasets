[
    {
        "dcterms:creator": [
            "R. Chavarriaga",
            "H. Sagha",
            "A. Calatroni",
            "S. T. Digumarti",
            "G. Tröster",
            "J. d. R. Millán",
            "D. Roggen"
        ],
        "dcterms:description": "The Opportunity challenge dataset contains 18 short-term and non-repeated kitchen activities including opening & closing doors, fridges, dishwashers, and drawers, cleaning tables, drinking from cups, toggling switches, and null activities. Its multimodal data are measured by on-body sensors including accelerometers, gyroscopes, and magnetic sensors.",
        "dcterms:title": "Opportunity (Opp) challenge dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Sensor Data"
        ],
        "dcat:keyword": [
            "Activity recognition",
            "Multimodal data",
            "On-body sensors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor data",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "O. Banos",
            "R. Garcia",
            "J. A. Holgado-Terriza",
            "M. Damas",
            "H. Pomares",
            "I. Rojas",
            "A. Saez",
            "C. Villalonga"
        ],
        "dcterms:description": "The mHealth dataset contains 13 daily living and exercise activities including standing still, sitting & relaxing, lying down, walking, climbing stairs, waist bending forward, frontal elevation of arms, knees bending, cycling, jogging, running, jumping front & back, and null activities. The activities are measured by multimodal on-body sensors including accelerometers, ECG sensors, gyroscopes, and magnetometers.",
        "dcterms:title": "mHealth dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Health Monitoring"
        ],
        "dcat:keyword": [
            "Activity recognition",
            "Wearable sensors",
            "Health data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor data",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "B. Kwolek",
            "M. Kepski"
        ],
        "dcterms:description": "The UR Fall Detection dataset contains 70 video clips recorded by a RGB camera and a depth camera of human activities including not lying on the ground, and temporary poses. Each video frame is labelled and paired with sensory data from accelerometers.",
        "dcterms:title": "UR Fall Detection dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Fall Detection",
            "Human Activity Recognition"
        ],
        "dcat:keyword": [
            "Fall detection",
            "Video data",
            "Sensor data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video and sensor data",
        "mls:task": [
            "Fall Detection"
        ]
    }
]