To extract datasets from the research paper titled "Rotation-Invariant Autoencoders for Signals on Spheres" by Suhas Lohit and Shubhendu Trivedi, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experimental results sections** to identify any datasets mentioned. The abstract indicates that the authors conducted extensive experiments on multiple datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on the **experiments section** (Section 5), where the authors typically describe the datasets used for their experiments. In this section, they mention two datasets:

1. **Spherical MNIST**: This dataset is a spherical version of the MNIST dataset, created by projecting handwritten digits onto the northern hemisphere of a unit sphere. The authors specify that there are two versions of this dataset: one where all digits are aligned (NR) and another where they are randomly rotated (R). Each version consists of 60,000 training and 10,000 test examples.

2. **SHREC17 Shape Retrieval**: This dataset consists of 51,300 3D meshes belonging to 55 classes, such as chairs and airplanes. The authors note that they use a variant of the dataset where both the training and test sets are randomly rotated.

Now, I will check the **References section** to find the full citations for these datasets:

- For **Spherical MNIST**, the citation is:
  > Taco S Cohen, Mario Geiger, Jonas KÃ¶hler, and Max Welling. *Spherical CNNs*. International Conference on Learning Representations, 2018.

- For **SHREC17 Shape Retrieval**, the citation is:
  > Manolis Savva, Fisher Yu, Hao Su, Song Bai, Xiang Bai, et al. *SHREC16 Track: Large-scale 3D Shape Retrieval from ShapeNet Core55*. In Eurographics Workshop on 3D Object Retrieval, 2017.

With these details in hand, I will compile the dataset entries, ensuring to include the full citations as required. This will provide a comprehensive overview of the datasets used in the research paper.