[
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI Vision dataset contains a large collection of urban traffic based scenes captured by cameras mounted on the roof of a car. Each sample is manually annotated with bounding boxes of different object classes like 'Pedestrian', 'Car', 'Cyclist', etc. The intended use is autonomous driving and driver-assistance systems.",
        "dcterms:title": "KITTI Vision dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Urban traffic",
            "Object detection",
            "Autonomous driving",
            "Annotated images"
        ],
        "dcat:landingPage": "http://www.cvlibs.net/datasets/kitti/eval_object.php",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Guillermo Gallego",
            "Tobi Delbruck",
            "Garrick Michael Orchard",
            "Chiara Bartolozzi",
            "Brian Taba",
            "Andrea Censi",
            "Stefan Leutenegger",
            "Andrew Davison",
            "Jörg Conradt",
            "Kostas Daniilidis",
            "Davide Scaramuzza"
        ],
        "dcterms:description": "Event-based image representations are fundamentally different from traditional dense images, posing challenges for applying current state-of-the-art models for object detection.",
        "dcterms:title": "Event-based image representations",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1109/tpami.2020.3008413",
        "dcat:theme": [],
        "dcat:keyword": [
            "Event-based vision",
            "Image representation",
            "Neuromorphic cameras"
        ],
        "dcat:landingPage": "https://doi.org/10.1109/tpami.2020.3008413",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Daniel Gehrig",
            "Mathias Gehrig",
            "Javier Hidalgo-Carrió",
            "Davide Scaramuzza"
        ],
        "dcterms:description": "The Video to Events approach allows for recycling video datasets for event cameras, enabling the conversion of dense video data into event-based formats.",
        "dcterms:title": "Video to Events",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Video datasets",
            "Event cameras",
            "Data recycling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Nico Messikommer",
            "Daniel Gehrig",
            "Antonio Loquercio",
            "Davide Scaramuzza"
        ],
        "dcterms:description": "Event-histograms are a common format that accumulates all events into a single frame, showing changes of brightness during a defined interval instead of absolute brightness values.",
        "dcterms:title": "Event-histograms",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "http://rpg.ifi.uzh.ch/docs/ECCV20_Messikommer.pdf",
        "dcat:theme": [],
        "dcat:keyword": [
            "Event representation",
            "Histogram",
            "Brightness changes"
        ],
        "dcat:landingPage": "http://rpg.ifi.uzh.ch/docs/ECCV20_Messikommer.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]