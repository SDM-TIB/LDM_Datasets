To extract the datasets from the research paper titled "Multi-range Reasoning for Machine Comprehension" by Yi Tay et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. In the abstract, the authors mention conducting experiments on **three challenging MC datasets**, which indicates that datasets are indeed present.

Next, I will focus on the **introduction section** where the authors discuss the importance of machine comprehension tasks and mention the datasets used for evaluation. This section will likely provide context for the datasets and their significance.

I will then examine **section 4 (Empirical Evaluation)**, specifically **subsection 4.1 (Datasets)**, where the authors explicitly list the datasets used in their experiments. Here, they mention:

1. **RACE (Reading Comprehension from Examinations)**: This dataset is constructed from real-world examinations and includes multiple-choice questions based on passages. It has two subsets: RACE-M (Middle school) and RACE-H (High school).

2. **SearchQA**: This dataset is designed to emulate a real-world question-answering system, requiring models to extract answers from search engine results.

3. **NarrativeQA**: This dataset focuses on story-based reading comprehension, where answers are handwritten by human annotators.

To ensure I have the correct citations, I will refer to the **References section** of the paper. The citations for the datasets are as follows:

- For **RACE**, the citation is:
  > Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. *RACE: Large-scale reading comprehension dataset from examinations*. arXiv preprint arXiv:1704.04683, 2017.

- For **SearchQA**, the citation is:
  > Matthew Dunn, Levent Sagun, Mike Higgins, Ugur Guney, Volkan Cirik, and Kyunghyun Cho. *SearchQA: A new Q&A dataset augmented with context from a search engine*. arXiv preprint arXiv:1704.05179, 2017.

- For **NarrativeQA**, the citation is:
  > Tomáš Kočiský, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, Gábor Melis, and Edward Grefenstette. *The NarrativeQA reading comprehension challenge*. arXiv preprint arXiv:1712.07040, 2017.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding references.