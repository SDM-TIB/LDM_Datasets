[
    {
        "dcterms:creator": [
            "Junichi Yamagishi",
            "Christophe Veaux",
            "Kirsten MacDonald"
        ],
        "dcterms:description": "An English multi-speaker dataset consisting of approximately 400 utterances per 109 speakers, used for training and evaluating TTS models.",
        "dcterms:title": "VCTK dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Multi-Speaker TTS"
        ],
        "dcat:keyword": [
            "English",
            "multi-speaker",
            "TTS",
            "voice cloning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "0.92",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Kun Zhou",
            "Berrak Sisman",
            "Rui Liu",
            "Haizhou Li"
        ],
        "dcterms:description": "A dataset containing emotional speech from 10 English and 10 Chinese speakers, with 400 sentences per speaker for five emotions (happy, sad, neutral, surprise, and angry).",
        "dcterms:title": "Emotional Speech Dataset (ESD)",
        "dcterms:issued": "2021",
        "dcterms:language": "English, Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "emotional speech",
            "style transfer",
            "voice conversion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition",
            "Text-to-Speech"
        ]
    }
]