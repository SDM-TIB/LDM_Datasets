[
    {
        "dcterms:creator": [
            "T. Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Dollár",
            "C. L. Zitnick"
        ],
        "dcterms:description": "The COCO2014 validation set is used for evaluating the performance of image generation models, particularly in the context of text-to-image generation tasks.",
        "dcterms:title": "COCO2014 validation set",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Validation set",
            "Text-to-image generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Podell",
            "Z. English",
            "K. Lacey",
            "A. Blattmann",
            "T. Dockhorn",
            "J. Müller",
            "J. Penna",
            "R. Rombach"
        ],
        "dcterms:description": "Stable Diffusion XL is a model used for high-resolution image synthesis, serving as a baseline for comparison in text-to-image generation tasks.",
        "dcterms:title": "Stable Diffusion XL",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.01952",
        "dcat:theme": [
            "Image Synthesis",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Image synthesis",
            "Diffusion model",
            "High-resolution generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "1.0",
        "dcterms:format": "Image",
        "mls:task": [
            "Text-to-Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "W. Feng",
            "X. He",
            "T. J. Fu",
            "V. Jampani",
            "A. Akula",
            "P. Narayana",
            "S. Basu",
            "X. E. Wang",
            "W. Y. Wang"
        ],
        "dcterms:description": "Structured Diffusion is a method that enhances compositional text-to-image synthesis by focusing attention on different entities in the prompt.",
        "dcterms:title": "Structured Diffusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2212.05032",
        "dcat:theme": [
            "Image Generation",
            "Attention Mechanisms"
        ],
        "dcat:keyword": [
            "Compositional synthesis",
            "Attention control",
            "Text-to-image generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Text-to-Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Hessel",
            "A. Holtzman",
            "M. Forbes",
            "R. L. Bras",
            "Y. Choi"
        ],
        "dcterms:description": "CLIP Score is a reference-free evaluation metric used for assessing the quality of image captioning and is utilized in the evaluation of generated images.",
        "dcterms:title": "CLIP Score",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2104.08718",
        "dcat:theme": [
            "Evaluation Metrics",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Evaluation metric",
            "Image captioning",
            "Reference-free assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Heusel",
            "H. Ramsauer",
            "T. Unterthiner",
            "B. Nessler",
            "S. Hochreiter"
        ],
        "dcterms:description": "FID is a metric used to evaluate the quality of generated images by comparing them to real images, serving as a benchmark in the evaluation of generative models.",
        "dcterms:title": "FID",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Evaluation Metrics",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Image quality",
            "Generative evaluation",
            "Fréchet Inception Distance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xu",
            "X. Liu",
            "Y. Wu",
            "Y. Tong",
            "Q. Li",
            "M. Ding",
            "J. Tang",
            "Y. Dong"
        ],
        "dcterms:description": "ImageReward is a framework for learning and evaluating human preferences in text-to-image generation, providing insights into the alignment of generated images with user expectations.",
        "dcterms:title": "ImageReward",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.05977",
        "dcat:theme": [
            "Human Preferences",
            "Image Generation"
        ],
        "dcat:keyword": [
            "Human evaluation",
            "Text-to-image generation",
            "Preference learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Evaluation"
        ]
    }
]