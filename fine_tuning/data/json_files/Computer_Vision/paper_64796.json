[
    {
        "dcterms:creator": [
            "M. Hassan",
            "V. Choutas",
            "D. Tzionas",
            "M. J. Black"
        ],
        "dcterms:description": "PROX provides paired 3D scenes and human motions extracted from RGB videos, useful for modeling human behaviors in contextual environments.",
        "dcterms:title": "PROX",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Motion Modeling"
        ],
        "dcat:keyword": [
            "3D scenes",
            "Human motion",
            "RGB videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Motion Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "V. Guzov",
            "A. Mir",
            "T. Sattler",
            "G. Pons-Moll"
        ],
        "dcterms:description": "HPS contributes a dataset of paired scenes, egocentric video, and human motion captured with an IMU-based suit, aimed at 3D human pose estimation and self-localization.",
        "dcterms:title": "HPS",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "3D human pose",
            "Self-localization",
            "IMU-based sensors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Zhang",
            "Q. Ma",
            "Y. Zhang",
            "Z. Qian",
            "T. Kwon",
            "M. Pollefeys",
            "F. Bogo",
            "S. Tang"
        ],
        "dcterms:description": "EgoBody collects a dataset consisting of 3D scenes, egocentric video, eye gaze, and human motions extracted from multi-view RGBD frames, focusing on social interactions.",
        "dcterms:title": "EgoBody",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Motion Analysis"
        ],
        "dcat:keyword": [
            "3D scenes",
            "Egocentric video",
            "Social interactions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Motion Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zheng",
            "Y. Yang",
            "K. Mo",
            "J. Li",
            "T. Yu",
            "Y. Liu",
            "K. Liu",
            "L. Guibas"
        ],
        "dcterms:description": "GIMO explores gaze-informed human motion prediction in context, utilizing a dataset that aids in understanding how gaze influences motion.",
        "dcterms:title": "GIMO",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Motion Prediction"
        ],
        "dcat:keyword": [
            "Gaze-informed",
            "Human motion prediction",
            "Contextual data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Motion Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "M. Hassan",
            "D. Ceylan",
            "R. Villegas",
            "J. Saito",
            "J. Yang",
            "Y. Zhou",
            "M. Black"
        ],
        "dcterms:description": "SAMP contains a dataset of sitting and lying down motions while interacting with chairs and sofas, focusing on stochastic scene-aware motion prediction.",
        "dcterms:title": "SAMP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human-Object Interaction"
        ],
        "dcat:keyword": [
            "Sitting motions",
            "Lying down motions",
            "Chairs and sofas"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Object Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "X. Zhang",
            "B. L. Bhatnagar",
            "S. Starke",
            "V. Guzov",
            "G. Pons-Moll"
        ],
        "dcterms:description": "COUCH is dedicated to data collection for sitting on different chairs, focusing on controllable human-chair interactions.",
        "dcterms:title": "COUCH",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human-Object Interaction"
        ],
        "dcat:keyword": [
            "Sitting interactions",
            "Chairs",
            "Human-chair interactions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Object Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "O. Taheri",
            "N. Ghorbani",
            "M. J. Black",
            "D. Tzionas"
        ],
        "dcterms:description": "GRAB focuses on the interaction between humans and small-sized objects, involving mostly hand motions.",
        "dcterms:title": "GRAB",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://grab.is.tue.mpg.de",
        "dcat:theme": [
            "Computer Vision",
            "Human-Object Interaction"
        ],
        "dcat:keyword": [
            "Grasping",
            "Human-object interaction",
            "Small-sized objects"
        ],
        "dcat:landingPage": "https://grab.is.tue.mpg.de",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Object Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "B. L. Bhatnagar",
            "X. Xie",
            "I. A. Petrov",
            "C. Sminchisescu",
            "C. Theobalt",
            "G. Pons-Moll"
        ],
        "dcterms:description": "BEHAVE records interactions with larger-sized objects, providing a dataset and method for tracking human-object interactions.",
        "dcterms:title": "BEHAVE",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human-Object Interaction"
        ],
        "dcat:keyword": [
            "Human-object interactions",
            "Tracking",
            "Larger-sized objects"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Object Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "J. P. Araujo",
            "J. Li",
            "K. Vetrivel",
            "R. Agarwal",
            "D. Gopinath",
            "J. Wu",
            "A. Clegg",
            "C. K. Liu"
        ],
        "dcterms:description": "CIRCLE integrates VR and MoCap techniques to collect high-quality motion within virtual scenes, focusing on capturing human motion in rich contextual environments.",
        "dcterms:title": "CIRCLE",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Motion Capture"
        ],
        "dcat:keyword": [
            "Virtual scenes",
            "Human motion",
            "MoCap techniques"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human Motion Capture"
        ]
    }
]