[
    {
        "dcterms:creator": [
            "T.-Y. Lin",
            "M. Maire",
            "S. J. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Dollár",
            "C. L. Zitnick"
        ],
        "dcterms:description": "MSCOCO is a dataset that contains images with annotations for object detection, segmentation, and captioning, widely used in training and evaluating vision-language models.",
        "dcterms:title": "MSCOCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object annotations",
            "Image captioning",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "S. Shao",
            "Z. Li",
            "T. Zhang",
            "C. Peng",
            "G. Yu",
            "X. Zhang",
            "J. Sun"
        ],
        "dcterms:description": "Objects365 is a large-scale dataset for object detection that includes a diverse set of object classes and annotations, providing a more extensive inventory than MSCOCO.",
        "dcterms:title": "Objects365",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Large-scale dataset",
            "Object detection",
            "Diverse object classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "S. Kazemzadeh",
            "V. Ordonez",
            "M. Matten",
            "T. L. Berg"
        ],
        "dcterms:description": "RefCOCO is a dataset designed for referring expression comprehension, where models are tasked with identifying objects in images based on natural language descriptions.",
        "dcterms:title": "RefCOCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Referring expressions",
            "Object identification",
            "Natural language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "B. A. Plummer",
            "L. Wang",
            "C. M. Cervantes",
            "J. C. Caicedo",
            "J. Hockenmaier",
            "S. Lazebnik"
        ],
        "dcterms:description": "Flickr30k Entities is a dataset that collects region-to-phrase correspondences for richer image-to-sentence models, enhancing the understanding of visual content.",
        "dcterms:title": "Flickr30k Entities",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Region-to-phrase correspondence",
            "Image captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Goyal",
            "T. Khot",
            "D. Summers-Stay",
            "D. Batra",
            "D. Parikh"
        ],
        "dcterms:description": "VQAv2 is a dataset for visual question answering that includes a variety of questions about images, enhancing the interaction between vision and language.",
        "dcterms:title": "VQAv2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Image dataset",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L.-J. Li",
            "D. A. Shamma",
            "L. Fei-Fei"
        ],
        "dcterms:description": "Visual Genome is a dataset that connects language and vision using crowdsourced dense image annotations, providing a rich source of information for various tasks.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Dense annotations",
            "Image dataset",
            "Language and vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Annotation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Gupta",
            "P. Dollár",
            "R. B. Girshick"
        ],
        "dcterms:description": "LVIS is a dataset for large vocabulary instance segmentation, providing a comprehensive set of annotations for a wide range of object categories.",
        "dcterms:title": "LVIS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Instance Segmentation"
        ],
        "dcat:keyword": [
            "Instance segmentation",
            "Large vocabulary",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Instance Segmentation"
        ]
    }
]