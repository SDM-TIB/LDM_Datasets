To extract datasets from the research paper titled "iHuman: Instant Animatable Digital Humans From Monocular Videos" by Pramish Paudel et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors conducted experiments on three different benchmark datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4 (Experiments)**, where the authors explicitly mention the datasets used for their experiments. In **section 4.2 (Datasets)**, the authors list three datasets:

1. **PeopleSnapshot**: This dataset comprises various monocular RGB videos of different subjects recorded in natural settings, where individuals assume an A-pose and rotate in place facing a stationary camera.

2. **UBC-Fashion**: This dataset contains videos of subjects in loose clothing turning around in front of a stationary camera, used to evaluate the method on in-the-wild clothing variations.

3. **Multi-Garment dataset**: This dataset features 3D scanned models of the human body with textures and corresponding SMPL-D models, which are registered for use in animation.

I will also check the **References section** to find the full citations for these datasets:

- For **PeopleSnapshot**, the citation is:
  > Alldieck, T., Magnor, M., Xu, W., Theobalt, C., Pons-Moll, G. (2018). *Detailed human avatars from monocular video*. In Proceedings of the 2018 International Conference on 3D Vision (3DV), pp. 98–109. IEEE.

- For **UBC-Fashion**, the citation is:
  > Zablotskaia, P., Siarohin, A., Zhao, B., Sigal, L. (2019). *DWNet: Dense warp-based network for pose-guided human video generation*. arXiv preprint arXiv:1910.09139.

- For **Multi-Garment dataset**, the citation is:
  > Bhatnagar, B.L., Tiwari, G., Theobalt, C., Pons-Moll, G. (2019). *Multi-garment net: Learning to dress 3D people from images*. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 5420–5430.

After gathering this information, I will ensure that I accurately represent each dataset's details and citations in the required format for further processing or review. This structured approach will help me extract the necessary dataset information efficiently and comprehensively.