[
    {
        "dcterms:creator": [
            "Bhuwan Dhingra",
            "Kathryn Mazaitis",
            "William W. Cohen"
        ],
        "dcterms:description": "A dataset composed of 147K positive pairs of questions that have the same meaning, used for paraphrase generation.",
        "dcterms:title": "Quota Question Pairs (QQP)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Generation"
        ],
        "dcat:keyword": [
            "Paraphrase dataset",
            "Question pairs",
            "Text similarity"
        ],
        "dcat:landingPage": "https://www.kaggle.com/c/quora-question-pairs",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Chao Jiang",
            "Mounica Maddela",
            "Wuwei Lan",
            "Yang Zhong",
            "Wei Xu"
        ],
        "dcterms:description": "A dataset containing 666K complex-simplified sentence pairs used for text simplification.",
        "dcterms:title": "NEWSELA-AUTO",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Simplification"
        ],
        "dcat:keyword": [
            "Text simplification",
            "Sentence alignment",
            "Complex sentences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Simplification"
        ]
    },
    {
        "dcterms:creator": [
            "Bhuwan Dhingra",
            "Kathryn Mazaitis",
            "William W. Cohen"
        ],
        "dcterms:description": "A dataset processed for question generation, consisting of 119K document-question pairs.",
        "dcterms:title": "QUASAR-T",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Generation"
        ],
        "dcat:keyword": [
            "Question generation",
            "Document-question pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Moritz Hermann",
            "Tomas Kocisky",
            "Edward Grefenstette",
            "Lasse Espeholt",
            "Will Kay",
            "Mustafa Suleyman",
            "Phil Blunsom"
        ],
        "dcterms:description": "A dataset comprising 300K articles and their corresponding summaries, used for summarization tasks.",
        "dcterms:title": "CNN-DailyMail",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Summarization"
        ],
        "dcat:keyword": [
            "Summarization dataset",
            "News articles",
            "Text summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A multi-task benchmark consisting of various datasets for natural language understanding tasks.",
        "dcterms:title": "GLUE benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmark"
        ],
        "dcat:keyword": [
            "Natural language understanding",
            "Benchmarking",
            "Multi-task learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Richard Socher",
            "Alex Perelygin",
            "Jean Wu",
            "Jason Chuang",
            "Christopher D. Manning",
            "Andrew Ng",
            "Christopher Potts"
        ],
        "dcterms:description": "A dataset for sentiment classification, containing binary sentiment labels for sentences.",
        "dcterms:title": "SST-2",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment classification",
            "Sentiment analysis",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "A dataset for natural language inference tasks, part of the GLUE benchmark.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Text entailment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel Bowman"
        ],
        "dcterms:description": "A dataset for assessing linguistic acceptability, used for evaluating sentence grammaticality.",
        "dcterms:title": "CoLA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistic Acceptability"
        ],
        "dcat:keyword": [
            "Linguistic acceptability",
            "Grammaticality judgment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Linguistic Acceptability"
        ]
    },
    {
        "dcterms:creator": [
            "William B. Dolan",
            "Chris Brockett"
        ],
        "dcterms:description": "A dataset of paraphrase pairs used for evaluating paraphrase detection models.",
        "dcterms:title": "MRPC",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Detection"
        ],
        "dcat:keyword": [
            "Paraphrase detection",
            "Text similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset for question answering, containing over 100,000 questions for machine comprehension of text.",
        "dcterms:title": "QNLI",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Machine comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Cer",
            "Mona Diab",
            "Eneko Agirre",
            "IÃ±igo Lopez-Gazpio",
            "Lucia Specia"
        ],
        "dcterms:description": "A dataset for evaluating semantic textual similarity, used in the SemEval-2017 task.",
        "dcterms:title": "STS-B",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Semantic textual similarity",
            "Text similarity evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [
            "Ido Dagan",
            "Oren Glickman",
            "Bernardo Magnini"
        ],
        "dcterms:description": "A dataset for recognizing textual entailment, used in the PASCAL RTE challenge.",
        "dcterms:title": "RTE",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Textual Entailment"
        ],
        "dcat:keyword": [
            "Textual entailment",
            "Natural language inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    }
]