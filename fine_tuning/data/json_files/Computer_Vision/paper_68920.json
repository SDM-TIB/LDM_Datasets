[
    {
        "dcterms:creator": [],
        "dcterms:description": "A specialized scientific MMIR benchmark comprising 530K meticulously curated image-text pairs, extracted from figures and tables with detailed captions in scientific documents.",
        "dcterms:title": "SciMMIR",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Information Retrieval",
            "Scientific Data"
        ],
        "dcat:keyword": [
            "Image-Text Pairing",
            "Scientific Documents",
            "Benchmark",
            "Evaluation",
            "Annotation"
        ],
        "dcat:landingPage": "https://github.com/Wusiwei0410/SciMMIR",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Information Retrieval",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "A dataset consisting of over 200,000 images across various categories including people, animals, everyday objects, and indoor scenes.",
        "dcterms:title": "COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Recognition"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Object Detection",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Yuke Zhu",
            "Oliver Groth",
            "Justin Johnson",
            "Kenji Hata",
            "Joshua Kravitz",
            "Stephanie Chen",
            "Yannis Kalantidis",
            "Li-Jia Li",
            "David A Shamma"
        ],
        "dcterms:description": "A dataset that connects language and vision using crowdsourced dense image annotations.",
        "dcterms:title": "VG (Visual Genome)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Annotation"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Dense Annotations",
            "Visual Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Piyush Sharma",
            "Nan Ding",
            "Sebastian Goodman",
            "Radu Soricut"
        ],
        "dcterms:description": "A cleaned, hypernymed image alt-text dataset for automatic image captioning.",
        "dcterms:title": "CC3M",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Automatic Captioning",
            "Hypernymed Captions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Soravit Changpinyo",
            "Piyush Sharma",
            "Nan Ding",
            "Radu Soricut"
        ],
        "dcterms:description": "A dataset containing 12.4 million image-text pairs, which is three times larger in scale compared to CC3M.",
        "dcterms:title": "CC12M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Large Scale",
            "Image-Text Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Vicente Ordonez",
            "Girish Kulkarni",
            "Tamara Berg"
        ],
        "dcterms:description": "A dataset designed to describe images using 1 million captioned photographs.",
        "dcterms:title": "SBU",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Captioned Photographs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Christoph Schuhmann",
            "Richard Vencu",
            "Romain Beaumont",
            "Robert Kaczmarczyk",
            "Clayton Mullis",
            "Aarush Katta",
            "Theo Coombes",
            "Jenia Jitsev",
            "Aran Komatsuzaki"
        ],
        "dcterms:description": "An open dataset of 400 million image-text pairs, filtered for CLIP.",
        "dcterms:title": "LAION-400M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2111.02114",
        "dcat:theme": [
            "Image-Text Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Large Scale",
            "Image-Text Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Christoph Schuhmann",
            "Romain Beaumont",
            "Richard Vencu",
            "Cade Gordon",
            "Ross Wightman",
            "Mehdi Cherti",
            "Theo Coombes",
            "Aarush Katta",
            "Clayton Mullis",
            "Mitchell Wortsman"
        ],
        "dcterms:description": "An open large-scale dataset for training next generation image-text models, consisting of 5.85 billion image-text pairs.",
        "dcterms:title": "LAION-5B",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image-Text Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Large Scale",
            "Image-Text Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Minwoo Byeon",
            "Beomhee Park",
            "Haecheon Kim",
            "Sungjun Lee",
            "Woonhyuk Baek",
            "Saehoon Kim"
        ],
        "dcterms:description": "A large-scale dataset containing 747M image-text pairs.",
        "dcterms:title": "COYO",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/kakaobrain/coyo-dataset",
        "dcat:theme": [
            "Image-Text Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Large Scale",
            "Image-Text Pairs"
        ],
        "dcat:landingPage": "https://github.com/kakaobrain/coyo-dataset",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Wanrong Zhu",
            "Jack Hessel",
            "Anas Awadalla",
            "Samir Yitzhak Gadre",
            "Jesse Dodge",
            "Alex Fang",
            "Youngjae Yu",
            "Ludwig Schmidt",
            "William Yang Wang",
            "Yejin Choi"
        ],
        "dcterms:description": "An open, billion-scale corpus of images interleaved with text.",
        "dcterms:title": "MMC4",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.06939",
        "dcat:theme": [
            "Image-Text Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Large Scale",
            "Image-Text Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Zhiliang Peng",
            "Wenhui Wang",
            "Li Dong",
            "Yaru Hao",
            "Shaohan Huang",
            "Shuming Ma",
            "Furu Wei"
        ],
        "dcterms:description": "A large-scale dataset of Grounded Image-Text pairs.",
        "dcterms:title": "GRIT",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.14824",
        "dcat:theme": [
            "Image-Text Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Grounded Image-Text Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Samir Yitzhak Gadre",
            "Gabriel Ilharco",
            "Alex Fang",
            "Jonathan Hayase",
            "Georgios Smyrnis",
            "Thao Nguyen",
            "Ryan Marten",
            "Mitchell Wortsman",
            "Dhruba Ghosh",
            "Jieyu Zhang"
        ],
        "dcterms:description": "A participatory benchmark that focuses on dataset curation for large image-text datasets.",
        "dcterms:title": "DataComp",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.14108",
        "dcat:theme": [
            "Dataset Curation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image Dataset",
            "Dataset Curation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]