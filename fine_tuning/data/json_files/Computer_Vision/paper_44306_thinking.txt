To extract datasets from the research paper titled "Generalizing Variational Autoencoders with Hierarchical Empirical Bayes" by Wei Cheng et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** to identify any datasets mentioned. The abstract states that the authors illustrate their method using data from **MNIST** and **CelebA**, which indicates that these datasets are likely used in their experiments.

Next, I will examine the **introduction** section for any additional context or details about the datasets. The introduction discusses generative modeling and mentions the use of MNIST and CelebA, confirming their relevance to the study.

I will then look at the **experiments section** to gather specific details about how these datasets were utilized. In this section, the authors describe the MNIST dataset as containing 60,000 training images and 10,000 test images, while the CelebA dataset contains 202,599 images in total. This provides a clearer understanding of the datasets' sizes and purposes.

After identifying the datasets, I will check the **References section** for full citations. The citations for the datasets are as follows:

- For the **MNIST dataset**, the citation is:
  > Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. *Gradient-based learning applied to document recognition*. Proceedings of the IEEE, 86(11):2278–2324, 1998.

- For the **CelebA dataset**, the citation is:
  > Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. *Deep Learning Face Attributes in the Wild*. In Proceedings of the International Conference on Computer Vision (ICCV), 2015.

Now that I have gathered all necessary information about the datasets, I will compile the dataset entries, ensuring to include the full citations as required. This will allow for a comprehensive understanding of the datasets used in the research.