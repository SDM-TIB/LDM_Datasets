To extract the datasets mentioned in the paper titled "Human Action Recognition Based on Multi-scale Feature Maps from Depth Video Sequences" by Chang Li et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets that are explicitly mentioned. In the abstract, the authors state that their method yields recognition accuracy on three public datasets: **MSRAction3D**, **UTD-MHAD**, and **DHA**. This indicates that these datasets are crucial for their experiments.

Next, I will look into **section 4.1 (Datasets and experimental settings)**, where the authors provide detailed descriptions of the datasets used:

1. **MSRAction3D**: This dataset contains 557 depth video sequences and 557 skeleton sequences for 20 actions captured by a Kinect sensor. The actions include high arm wave, horizontal arm wave, hammer, hand catch, and others, performed by 10 subjects.

2. **UTD-MHAD**: This dataset consists of 861 samples from 8 subjects performing 27 actions, with each action repeated 4 times. The actions include right arm swipe, right hand wave, two hand front clap, and more.

3. **DHA**: This dataset is organized with 483 depth video sequences for 23 actions, performed by 21 subjects. The actions include bend, jack, jump, run, and others.

To ensure I have the correct citations for each dataset, I will refer to the **References section** of the paper:

- For **MSRAction3D**, the citation is:
  > Chen, C., Jafari, R., & Kehtarnavaz, N. (2015). UTD-MHAD: A multimodal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor. In *2015 IEEE International Conference on Image Processing (ICIP)*. doi:10.1109/icip.2015.7350781.

- For **UTD-MHAD**, the citation is the same as above since it is part of the same dataset description.

- For **DHA**, the citation is:
  > Kamel, A., Sheng, B., Yang, P., Li, P., Shen, R., & Feng, D. D. (2019). Deep Convolutional Neural Networks for Human Action Recognition Using Depth Maps and Postures. *IEEE Transactions on Systems, Man, and Cybernetics: Systems*, 49(9), 1806-1819. doi:10.1109/TSMC.2018.2850149.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This will ensure that I have accurately captured the datasets used in the research and their corresponding citations.