[
    {
        "dcterms:creator": [
            "Fan Bao",
            "Shen Nie",
            "Kaiwen Xue",
            "Yue Cao",
            "Chongxuan Li",
            "Hang Su",
            "Jun Zhu"
        ],
        "dcterms:description": "U-ViT is a backbone for diffusion models that enables scalability and long sequence modeling for video generation.",
        "dcterms:title": "U-ViT",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Video generation",
            "Diffusion models",
            "U-ViT"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Lvmin Zhang",
            "Anyi Rao",
            "Maneesh Agrawala"
        ],
        "dcterms:description": "ControlNet adds conditional control to text-to-image diffusion models, enhancing the generation process.",
        "dcterms:title": "ControlNet",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Conditional control",
            "Text-to-image",
            "Diffusion models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Nataniel Ruiz",
            "Yuanzhen Li",
            "Varun Jampani",
            "Yael Pritch",
            "Michael Rubinstein",
            "Kfir Aberman"
        ],
        "dcterms:description": "DreamBooth is a technique for fine-tuning text-to-image diffusion models for subject-driven generation.",
        "dcterms:title": "DreamBooth",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Fine-tuning",
            "Text-to-image",
            "Subject-driven generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Andreas Blattmann",
            "Tim Dockhorn",
            "Sumith Kulal",
            "Daniel Mendelevitch",
            "Maciej Kilian",
            "Dominik Lorenz",
            "Yam Levi",
            "Zion English",
            "Vikram Voleti",
            "Adam Letts"
        ],
        "dcterms:description": "Stable Video Diffusion scales latent video diffusion models to large datasets for improved video generation.",
        "dcterms:title": "Stable Video Diffusion",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2311.15127",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Video generation",
            "Latent diffusion models",
            "Large datasets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jonathan Ho",
            "William Chan",
            "Chitwan Saharia",
            "Jay Whang",
            "Ruiqi Gao",
            "Alexey Gritsenko",
            "Diederik P Kingma",
            "Ben Poole",
            "Mohammad Norouzi",
            "David J Fleet"
        ],
        "dcterms:description": "Imagen Video is a high-definition video generation model using diffusion techniques.",
        "dcterms:title": "Imagen Video",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2210.02303",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "High-definition video",
            "Diffusion models",
            "Video generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Rohit Girdhar",
            "Mannat Singh",
            "Andrew Brown",
            "Quentin Duval",
            "Samaneh Azadi",
            "Sai Saketh Rambhatla",
            "Akbar Shah",
            "Xi Yin",
            "Devi Parikh",
            "Ishan Misra"
        ],
        "dcterms:description": "Emu Video factorizes text-to-video generation by explicit image conditioning.",
        "dcterms:title": "Emu Video",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2311.10709",
        "dcat:theme": [
            "Computer Vision",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Text-to-video",
            "Image conditioning",
            "Video generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]