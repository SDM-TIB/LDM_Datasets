[
    {
        "dcterms:creator": [
            "Stavros Petridis",
            "Brais Martinez",
            "Maja Pantic"
        ],
        "dcterms:description": "The MAHNOB laughter database contains audiovisual recordings of laughter, designed for research in emotion and affect.",
        "dcterms:title": "MAHNOB",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Laughter",
            "Audiovisual data",
            "Emotion database"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition",
            "Laughter Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Jérôme Urbain",
            "Elisabetta Bevacqua",
            "Thierry Dutoit",
            "Alexis Moinet",
            "Radoslaw Niewiadomski",
            "Catherine Pelachaud",
            "Benjamin Picart",
            "Joëlle Tilmanne",
            "Johannes Wagner"
        ],
        "dcterms:description": "The AVLaughterCycle database consists of audiovisual recordings of laughter, aimed at studying laughter dynamics and synthesis.",
        "dcterms:title": "AVLaughterCycle",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Laughter",
            "Audiovisual data",
            "Emotion database"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition",
            "Laughter Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Björn Schuller",
            "Ronald Müller",
            "Florian Eyben",
            "Jürgen Gast",
            "Benedikt Hörnler",
            "Martin Wöllmer",
            "Gerhard Rigoll",
            "Anja Höthker",
            "Hitoshi Konosu"
        ],
        "dcterms:description": "The AVIC dataset is designed for recognizing natural interest through extensive audiovisual integration.",
        "dcterms:title": "AVIC",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Interest Recognition",
            "Audiovisual data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition",
            "Laughter Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Ellen Douglas-Cowie",
            "Roddy Cowie",
            "Cate Cox",
            "Noam Amir",
            "Dirk Heylen"
        ],
        "dcterms:description": "The SAL dataset is focused on generating emotionally colored conversations, serving as a resource for affective computing research.",
        "dcterms:title": "SAL",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Emotion Generation",
            "Conversational data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition",
            "Laughter Generation"
        ]
    }
]