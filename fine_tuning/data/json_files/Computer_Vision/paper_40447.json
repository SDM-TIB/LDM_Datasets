[
    {
        "dcterms:creator": [
            "J. Uhrig",
            "N. Schneider",
            "L. Schneider",
            "U. Franke",
            "T. Brox",
            "A. Geiger"
        ],
        "dcterms:description": "The KITTI depth completion dataset contains 86,898 frames for training, 1,000 frames for validation, and another 1,000 frames for testing. It provides public leaderboard for ranking submissions. The ground truth depth is generated by registering LiDAR scans temporally.",
        "dcterms:title": "KITTI Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Depth Completion",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Depth completion",
            "LiDAR",
            "RGB images",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Completion"
        ]
    },
    {
        "dcterms:creator": [
            "A. Gaidon",
            "Q. Wang",
            "Y. Cabon",
            "E. Vig"
        ],
        "dcterms:description": "Virtual KITTI dataset is a synthetic dataset, where the virtual scenes are cloned from the real world KITTI video sequences. It generates the corresponding image sequences under various lighting and weather conditions.",
        "dcterms:title": "Virtual KITTI Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data",
            "Depth Completion"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Virtual scenes",
            "Lighting conditions",
            "Weather conditions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Completion"
        ]
    },
    {
        "dcterms:creator": [
            "N. Silberman",
            "D. Hoiem",
            "P. Kohli",
            "R. Fergus"
        ],
        "dcterms:description": "NYUv2 dataset consists of RGB images and depth images captured by Microsoft Kinect in 464 indoor scenes. It is used for training and testing depth completion methods.",
        "dcterms:title": "NYUv2 Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Indoor Scene Understanding",
            "Depth Completion"
        ],
        "dcat:keyword": [
            "RGB-D images",
            "Indoor scenes",
            "Depth estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Completion"
        ]
    },
    {
        "dcterms:creator": [
            "S. Song",
            "S. P. Lichtenberg",
            "J. Xiao"
        ],
        "dcterms:description": "The SUN RGBD dataset is an indoor dataset containing RGB-D images from various sources. It is used for cross-dataset evaluation in depth completion tasks.",
        "dcterms:title": "SUN RGBD Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Indoor Scene Understanding",
            "Depth Completion"
        ],
        "dcat:keyword": [
            "RGB-D images",
            "Indoor scenes",
            "Cross-dataset evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Completion"
        ]
    }
]