[
    {
        "dcterms:creator": [
            "M. Cordts",
            "M. Omran",
            "S. Ramos",
            "T. Rehfeld",
            "M. Enzweiler",
            "R. Benenson",
            "U. Franke",
            "S. Roth",
            "B. Schiele"
        ],
        "dcterms:description": "The Cityscapes dataset consists of urban scene videos recorded from a car driving on the street. It contains 2,975 training, 500 validation, and 1,525 test video sequences, each containing 30 frames. The ground truth semantic segmentation mask is only available for the 20th frame of every video.",
        "dcterms:title": "Cityscapes Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Urban scenes",
            "Video sequences",
            "Semantic segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Generation",
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "K. Soomro",
            "A. R. Zamir",
            "M. Shah"
        ],
        "dcterms:description": "The UCF101 dataset contains 13,220 videos of 101 action classes, providing a diverse set of human actions in various environments.",
        "dcterms:title": "UCF101 Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "I. Laptev",
            "B. Caputo"
        ],
        "dcterms:description": "The KTH Action dataset consists of 600 videos of people performing one of six actions: walking, jogging, running, boxing, handwaving, and hand-clapping.",
        "dcterms:title": "KTH Action Dataset",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Action classification",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A. Geiger",
            "P. Lenz",
            "C. Stiller",
            "R. Urtasun"
        ],
        "dcterms:description": "The KITTI dataset is similar to Cityscapes and was recorded from a car traversing streets, providing a rich set of data for various computer vision tasks.",
        "dcterms:title": "KITTI Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Robotics"
        ],
        "dcat:keyword": [
            "Autonomous driving",
            "Street scenes",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Detection",
            "Semantic Segmentation"
        ]
    }
]