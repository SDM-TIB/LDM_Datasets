[
    {
        "dcterms:creator": [
            "A. Das",
            "S. Kottur",
            "K. Gupta",
            "A. Singh",
            "D. Yadav",
            "J. M. Moura",
            "D. Parikh",
            "D. Batra"
        ],
        "dcterms:description": "The largest visual dialog dataset, VisDial, is created by pairing two subjects on Amazon Mechanical Turk to chat about an image, formulated as a multi-round VQA task.",
        "dcterms:title": "VisDial",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Visual dialog",
            "Multi-round VQA",
            "Image conversation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v0.9",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialog generation",
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "T.-Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C. L. Zitnick"
        ],
        "dcterms:description": "MS COCO contains multiple objects in everyday scenes and is used as the image source for the VisDial dataset.",
        "dcterms:title": "MS COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Dataset",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Common objects",
            "Contextual images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "N. Mostafazadeh",
            "C. Brockett",
            "B. Dolan",
            "M. Galley",
            "J. Gao",
            "G. P. Spithourakis",
            "L. Vanderwende"
        ],
        "dcterms:description": "Image Grounded Conversation (IGC) dataset requires a model to generate natural-sounding conversations about a shared image.",
        "dcterms:title": "Image Grounded Conversation (IGC)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1701.08251",
        "dcat:theme": [
            "Natural Language Processing",
            "Image Conversation"
        ],
        "dcat:keyword": [
            "Multimodal context",
            "Natural question generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialog generation"
        ]
    },
    {
        "dcterms:creator": [
            "H. de Vries",
            "F. Strub",
            "S. Chandar",
            "O. Pietquin",
            "H. Larochelle",
            "A. Courville"
        ],
        "dcterms:description": "GuessWhat?! is a visual object discovery dataset where one person asks questions about an image to guess which object has been selected.",
        "dcterms:title": "GuessWhat?!",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Dialog",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Object discovery",
            "Multi-modal dialogue"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialog generation"
        ]
    }
]