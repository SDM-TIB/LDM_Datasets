[
    {
        "dcterms:creator": [
            "T. Brooks",
            "A. Holynski",
            "A. A. Efros"
        ],
        "dcterms:description": "InstructPix2Pix is an image-conditioned diffusion model that enables instruction-based 2D image editing.",
        "dcterms:title": "InstructPix2Pix",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Editing",
            "Diffusion Models"
        ],
        "dcat:keyword": [
            "Image editing",
            "Diffusion model",
            "Text instructions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Editing"
        ]
    },
    {
        "dcterms:creator": [
            "J. L. Schonberger",
            "J.-M. Frahm"
        ],
        "dcterms:description": "COLMAP is a structure-from-motion system that reconstructs camera parameters from a collection of images.",
        "dcterms:title": "COLMAP",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Reconstruction",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Structure-from-motion",
            "Camera calibration",
            "3D reconstruction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Camera Pose Estimation",
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "M. Tancik",
            "E. Weber",
            "E. Ng",
            "R. Li",
            "B. Yi",
            "J. Kerr",
            "T. Wang",
            "A. Kristoffersen",
            "J. Austin",
            "K. Salahi",
            "A. Ahuja",
            "D. McAllister",
            "A. Kanazawa"
        ],
        "dcterms:description": "Nerfstudio is a modular framework for developing neural radiance fields.",
        "dcterms:title": "Nerfstudio",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2302.04264",
        "dcat:theme": [
            "3D Rendering",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural radiance fields",
            "3D scene representation",
            "Modular framework"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Scene Reconstruction",
            "Neural Rendering"
        ]
    },
    {
        "dcterms:creator": [
            "B. Poole",
            "A. Jain",
            "J. T. Barron",
            "B. Mildenhall"
        ],
        "dcterms:description": "DreamFusion is a method for generating 3D models from text using 2D diffusion.",
        "dcterms:title": "DreamFusion",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Generation",
            "Text-to-3D"
        ],
        "dcat:keyword": [
            "Text-to-3D",
            "Diffusion models",
            "3D content generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "3D Model Generation"
        ]
    },
    {
        "dcterms:creator": [
            "B. Mildenhall",
            "P. P. Srinivasan",
            "M. Tancik",
            "J. T. Barron",
            "R. Ramamoorthi",
            "R. Ng"
        ],
        "dcterms:description": "NeRF represents scenes as neural radiance fields for view synthesis.",
        "dcterms:title": "NeRF",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Rendering",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural radiance fields",
            "View synthesis",
            "3D scene representation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "View Synthesis",
            "3D Scene Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "T. Nguyen-Phuoc",
            "F. Liu",
            "L. Xiao"
        ],
        "dcterms:description": "SNeRF is a method for stylized neural implicit representations for 3D scenes.",
        "dcterms:title": "SNeRF",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Rendering",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Stylized rendering",
            "Neural implicit representations",
            "3D scenes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Stylized 3D Rendering"
        ]
    },
    {
        "dcterms:creator": [
            "R. Gal",
            "O. Patashnik",
            "H. Maron",
            "G. Chechik",
            "D. Cohen-Or"
        ],
        "dcterms:description": "StyleGAN-NADA is a method for domain adaptation of image generators using CLIP guidance.",
        "dcterms:title": "StyleGAN-NADA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2108.00946",
        "dcat:theme": [
            "Image Generation",
            "Domain Adaptation"
        ],
        "dcat:keyword": [
            "Image generation",
            "Domain adaptation",
            "CLIP guidance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. W. Kim",
            "C. Hallacy",
            "A. Ramesh",
            "G. Goh",
            "S. Agarwal",
            "G. Sastry",
            "A. Askell",
            "P. Mishkin",
            "J. Clark"
        ],
        "dcterms:description": "CLIP is a model that learns transferable visual representations from natural language supervision.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Visual models",
            "Natural language supervision",
            "Transfer learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Representation Learning"
        ]
    }
]