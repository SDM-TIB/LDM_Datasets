[
    {
        "dcterms:creator": [
            "Bryan A. Plummer",
            "Liwei Wang",
            "Chris M. Cervantes",
            "Juan C. Caicedo",
            "Julia Hockenmaier",
            "Svetlana Lazebnik"
        ],
        "dcterms:description": "A dataset for grounding that collects region-to-phrase correspondences for richer image-to-sentence models.",
        "dcterms:title": "Flickr30k entities",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Understanding"
        ],
        "dcat:keyword": [
            "Image-to-Sentence",
            "Grounding",
            "Region-to-Phrase Correspondences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Phrase Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Junhua Mao",
            "Jonathan Huang",
            "Alexander Toshev",
            "Oana Camburu",
            "Alan L. Yuille",
            "Kevin Murphy"
        ],
        "dcterms:description": "Datasets for referring expression comprehension (REC) that provide unambiguous object descriptions.",
        "dcterms:title": "RefCOCO/RefCOCO+/RefCOCOg",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Understanding"
        ],
        "dcat:keyword": [
            "Referring Expression Comprehension",
            "Object Descriptions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Yuke Zhu",
            "Oliver Groth",
            "Justin Johnson",
            "Kenji Hata",
            "Joshua Kravitz",
            "Stephanie Chen",
            "Yannis Kalantidis",
            "Li-Jia Li",
            "David A. Shamma",
            "Michael S. Bernstein",
            "Li Fei-Fei"
        ],
        "dcterms:description": "A dataset that connects language and vision using crowdsourced dense image annotations for dense captioning.",
        "dcterms:title": "Visual Genome (VG)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Understanding"
        ],
        "dcat:keyword": [
            "Dense Captioning",
            "Image Annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Dense Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Drew A Hudson",
            "Christopher D Manning"
        ],
        "dcterms:description": "A new dataset for real-world visual reasoning and compositional question answering.",
        "dcterms:title": "GQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Understanding"
        ],
        "dcat:keyword": [
            "Visual Reasoning",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge J. Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C. Lawrence Zitnick"
        ],
        "dcterms:description": "A dataset for common objects in context, providing bounding box annotations for object detection.",
        "dcterms:title": "COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection"
        ],
        "dcat:keyword": [
            "Object Detection",
            "Bounding Box Annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Ivan Krasin",
            "Tom Duerig",
            "Neil Alldrin",
            "Vittorio Ferrari",
            "Sami Abu-El-Haija",
            "Alina Kuznetsova",
            "Hassan Rom",
            "Jasper Uijlings",
            "Stefan Popov",
            "Andreas Veit"
        ],
        "dcterms:description": "A public dataset for large-scale multi-label and multi-class image classification.",
        "dcterms:title": "OpenImages",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/openimages",
        "dcat:theme": [
            "Image Classification"
        ],
        "dcat:keyword": [
            "Multi-label Classification",
            "Multi-class Classification"
        ],
        "dcat:landingPage": "https://github.com/openimages",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Piyush Sharma",
            "Nan Ding",
            "Sebastian Goodman",
            "Radu Soricut"
        ],
        "dcterms:description": "A cleaned, hypernymed image alt-text dataset for automatic image captioning.",
        "dcterms:title": "GCC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image Alt-text",
            "Automatic Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Jordi Pont-Tuset",
            "Jasper R. R. Uijlings",
            "Soravit Changpinyo",
            "Radu Soricut",
            "Vittorio Ferrari"
        ],
        "dcterms:description": "A dataset that connects vision and language with localized narratives.",
        "dcterms:title": "LocNar",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Understanding"
        ],
        "dcat:keyword": [
            "Localized Narratives",
            "Vision-Language Connection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Vision-Language Tasks"
        ]
    },
    {
        "dcterms:creator": [
            "Agrim Gupta",
            "Piotr Dollar",
            "Ross Girshick"
        ],
        "dcterms:description": "A dataset for large vocabulary instance segmentation.",
        "dcterms:title": "LVIS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Instance Segmentation"
        ],
        "dcat:keyword": [
            "Instance Segmentation",
            "Large Vocabulary"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Instance Segmentation"
        ]
    }
]