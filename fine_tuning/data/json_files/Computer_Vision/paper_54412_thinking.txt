To extract datasets from the research paper titled "GLD-Net: Improving Monaural Speech Enhancement by Learning Global and Local Dependency Features with GLD Block" by Xinmeng Xu et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experimental setup sections** to identify any datasets mentioned. The abstract indicates that the authors compare their method with existing state-of-the-art methods on the **WSJ0** and **DEMAND** datasets, which suggests that these datasets are crucial for their experiments.

Next, I will look into the **experimental setup section** to gather more details about these datasets. In this section, the authors specify that they evaluate their models on the **WSJ0 SI-84 training set**, which includes 7,138 utterances from 83 speakers, and they also mention using the **DEMAND dataset** for noise signals. This confirms that both datasets are used in their experiments.

Now, I will check the **References section** to find the full citations for these datasets:

1. For the **WSJ0 SI-84 training set**, the citation is:
   > D. B. Paul and J. Baker. *The design for the wall street journal-based CSR corpus*. In Speech and Natural Language: Proceedings of a Workshop Held at Harriman, New York, February 23-26, 1992.

2. For the **DEMAND dataset**, the citation is:
   > J. Thiemann, N. Ito, and E. Vincent. *DEMAND: a collection of multi-channel recordings of acoustic noise in diverse environments*. In Proc. Meetings Acoust, 2013, pp. 1â€“6.

Having gathered the necessary information, I will now prepare to create structured entries for each dataset, ensuring that I include the full citations as required. This will allow for a comprehensive representation of the datasets used in the research.