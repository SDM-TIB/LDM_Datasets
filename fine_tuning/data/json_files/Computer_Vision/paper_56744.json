[
    {
        "dcterms:creator": [
            "Stephan R Richter",
            "Zeeshan Hayder",
            "Vladlen Koltun"
        ],
        "dcterms:description": "VIPER is a synthetic dataset generated with the game ‘Grand Theft Auto V’. It contains 134K video frames and corresponding segmentation labels.",
        "dcterms:title": "VIPER",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Video frames",
            "Segmentation labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "German Ros",
            "Laura Sellart",
            "Joanna Materzynska",
            "David Vazquez",
            "Antonio M Lopez"
        ],
        "dcterms:description": "SYNTHIA-Seq is another synthetic dataset containing 8000 frames and corresponding segmentation labels.",
        "dcterms:title": "SYNTHIA-Seq",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Urban scenes",
            "Segmentation labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Marius Cordts",
            "Mohamed Omran",
            "Sebastian Ramos",
            "Timo Rehfeld",
            "Markus Enzweiler",
            "Rodrigo Benenson",
            "Uwe Franke",
            "Stefan Roth",
            "Bernt Schiele"
        ],
        "dcterms:description": "Cityscapes-Seq is a benchmark set consisting of 5000 video clips captured from real streets, split into training, validation, and testing sets. Each video clip consists of 30 frames, and the ground truth label is provided only in a single frame.",
        "dcterms:title": "Cityscapes-Seq",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Real-world dataset",
            "Urban scenes",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Semantic Segmentation"
        ]
    }
]