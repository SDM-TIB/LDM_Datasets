[
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee"
        ],
        "dcterms:description": "Natural Questions (NQ) is a question answering dataset that provides both short and long answer labels. In this study, a subset of 1,000 open questions was selected to evaluate the generative capabilities of large language models.",
        "dcterms:title": "Natural Questions (NQ)",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Q&A dataset",
            "Open questions",
            "Generative capabilities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Robustness Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R Bowman"
        ],
        "dcterms:description": "GLUE is a multi-task benchmark and analysis platform for natural language understanding, commonly used to evaluate the performance of language models.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Understanding"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Multi-task",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Yixin Nie",
            "Adina Williams",
            "Emily Dinan",
            "Mohit Bansal",
            "Jason Weston",
            "Douwe Kiela"
        ],
        "dcterms:description": "ANLI is an adversarial natural language inference benchmark designed to evaluate the robustness of natural language understanding models.",
        "dcterms:title": "ANLI",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Adversarial",
            "Natural Language Understanding",
            "Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference",
            "Robustness Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Andrew Maas",
            "Raymond E Daly",
            "Peter T Pham",
            "Dan Huang",
            "Andrew Y Ng",
            "Christopher Potts"
        ],
        "dcterms:description": "IMDB is a dataset used for sentiment analysis, containing movie reviews labeled with positive or negative sentiments.",
        "dcterms:title": "IMDB",
        "dcterms:issued": "2011",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment dataset",
            "Movie reviews",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis",
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Xiang Zhang",
            "Junbo Zhao",
            "Yann LeCun"
        ],
        "dcterms:description": "AG News is a dataset for news categorization, containing articles labeled with one of four categories.",
        "dcterms:title": "AG News",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Classification"
        ],
        "dcat:keyword": [
            "News categorization",
            "Text dataset",
            "Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Mandar Joshi",
            "Eunsol Choi",
            "Daniel S Weld",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "TriviaQA is a large-scale dataset for reading comprehension, containing question-answer pairs derived from trivia questions.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Trivia questions",
            "Reading comprehension",
            "Q&A dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Lifu Huang",
            "Ronan Le Bras",
            "Chandra Bhagavatula",
            "Yejin Choi"
        ],
        "dcterms:description": "CosmosQA is a dataset for machine reading comprehension that requires contextual commonsense reasoning.",
        "dcterms:title": "CosmosQA",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Reading comprehension",
            "Q&A dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Rowan Zellers",
            "Ari Holtzman",
            "Yonatan Bisk",
            "Ali Farhadi",
            "Yejin Choi"
        ],
        "dcterms:description": "HellaSwag is a dataset designed to evaluate the ability of models to complete sentences in a coherent manner.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Completion"
        ],
        "dcat:keyword": [
            "Sentence completion",
            "Text dataset",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Completion"
        ]
    }
]