To extract datasets from the research paper titled "DuNST: Dual Noisy Self Training for Semi-Supervised Controllable Text Generation" by Yuxi Feng et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset mentioned.

First, I will start by examining the **abstract** and **introduction** sections of the paper. The abstract provides a brief overview of the research and may mention specific datasets used for experiments. The introduction often elaborates on the context and significance of the datasets in relation to the research objectives.

Next, I will look for a dedicated **datasets section** or any mention of datasets in the **methodology** or **experiments** sections. In this paper, the authors discuss their experiments on three controllable generation tasks, which suggests that they likely used specific datasets for these tasks. I will pay close attention to any descriptions or names of datasets in these sections.

In the **experiments section**, the authors mention using the following datasets:

1. **IMDb Dataset**: This dataset is used for sentiment control tasks. It is a well-known dataset for movie reviews, where each review is labeled as positive or negative.

2. **AGNews Dataset**: This dataset is utilized for topic control tasks. It consists of news articles categorized into four topics: World, Sports, Business, and Science/Technology.

3. **Jigsaw Toxicity Dataset**: This dataset is employed for the text detoxification task. It contains comments labeled for toxicity, which is crucial for evaluating the model's ability to generate non-toxic text.

After identifying these datasets, I will refer to the **References section** of the paper to find the full citations for each dataset. This is crucial for proper attribution and to allow others to access the datasets used in the research.

The full citations for the datasets are as follows:

- **IMDb Dataset**:
  > Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. *Learning word vectors for sentiment analysis*. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 142–150, 2011.

- **AGNews Dataset**:
  > Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. *Character-level convolutional networks for text classification*. In NIPS, 2015.

- **Jigsaw Toxicity Dataset**:
  > Samuel Gehman, Suchin Gururangan, Maarten Sap, Yejin Choi, and Noah A. Smith. *RealToxicityPrompts: Evaluating neural toxic degeneration in language models*. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 3356–3369, 2020.

Now that I have gathered the necessary information about the datasets and their citations, I will compile this into a structured format for further processing or review.