[
    {
        "dcterms:creator": [
            "Gunnar A Sigurdsson",
            "GÂ´ul Varol",
            "Xiaolong Wang",
            "Ali Farhadi",
            "Ivan Laptev",
            "Abhinav Gupta"
        ],
        "dcterms:description": "Charades is a video dataset for multi-label action classification, containing 8k training videos, 1.2k validation videos, and 2k test videos, with a total of 157 unit-action classes. Each video is approximately 30 seconds long and includes an average of 6 different unit-actions.",
        "dcterms:title": "Charades",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Analysis",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Multi-label classification",
            "Video dataset",
            "Human activities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Hilde Kuehne",
            "Ali Arslan",
            "Thomas Serre"
        ],
        "dcterms:description": "Breakfast is a dataset for unscripted cooking-oriented human activities, containing 1712 videos, with 1357 for training and 335 for testing. Each video represents one of 10 categories of breakfast activities and has an average length of 2.3 minutes, consisting of 5 unit-actions.",
        "dcterms:title": "Breakfast",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Analysis",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Cooking activities",
            "Video dataset",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Serena Yeung",
            "Olga Russakovsky",
            "Ning Jin",
            "Mykhaylo Andriluka",
            "Greg Mori",
            "Li Fei-Fei"
        ],
        "dcterms:description": "MultiThumos is a dataset for untrimmed human activities in videos, focusing on temporal localization. It contains 400 videos with 65 action classes, where each video can be considered a complex action comprising an average of 11 unit-actions.",
        "dcterms:title": "MultiThumos",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Analysis",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Temporal localization",
            "Video dataset",
            "Human activities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Temporal Localization"
        ]
    }
]