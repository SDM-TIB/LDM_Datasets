[
    {
        "dcterms:creator": [
            "Christoph Schuhmann",
            "Romain Beaumont",
            "Richard Vencu",
            "Cade Gordon",
            "Ross Wightman",
            "Mehdi Cherti",
            "Theo Coombes",
            "Aarush Katta",
            "Clayton Mullis",
            "Mitchell Wortsman"
        ],
        "dcterms:description": "A large-scale dataset containing 600 million image-text pairs with predicted aesthetics scores of 5 or higher, used for training image generation models.",
        "dcterms:title": "LAION-Aesthetics-5+",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Generation",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Image-text pairs",
            "Aesthetics scores",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "A dataset containing images of common objects in context, widely used for image captioning and object detection tasks.",
        "dcterms:title": "MS-COCO 2017",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Image captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Peter Young",
            "Alice Lai",
            "Micah Hodosh",
            "Julia Hockenmaier"
        ],
        "dcterms:description": "A dataset consisting of 30,000 images with corresponding captions, used for training and evaluating image captioning models.",
        "dcterms:title": "Flickr30k",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Image captions",
            "Visual denotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    }
]