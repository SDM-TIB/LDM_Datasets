[
    {
        "dcterms:creator": [
            "M.-J. Hwang",
            "R. Yamamoto",
            "E. Song",
            "J.-M. Kim"
        ],
        "dcterms:description": "A phonetically balanced Korean corpus recorded by a Korean female professional speaker, consisting of 1,000 utterances for training, 270 for validation, and 130 for testing.",
        "dcterms:title": "Korean Corpus",
        "dcterms:issued": "2021",
        "dcterms:language": "Korean",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Data Augmentation"
        ],
        "dcat:keyword": [
            "Korean language",
            "speech corpus",
            "text-to-speech",
            "phonetic balance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wang",
            "R. Skerry-Ryan",
            "D. Stanton",
            "Y. Wu",
            "R. Weiss",
            "N. Jaitly",
            "Z. Yang",
            "Y. Xiao",
            "Z. Chen",
            "S. Bengio",
            "Q. Le",
            "Y. Agiomyrgian-nakis",
            "R. Clark",
            "R. Saurous"
        ],
        "dcterms:description": "A text-to-speech model that generates speech from text using an end-to-end approach.",
        "dcterms:title": "Tacotron 2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "end-to-end synthesis",
            "text-to-speech",
            "neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ren",
            "C. Hu",
            "T. Qin",
            "S. Zhao",
            "Z. Zhao",
            "T.-Y. Liu"
        ],
        "dcterms:description": "An improved version of the FastSpeech model that provides fast and high-quality end-to-end text-to-speech synthesis.",
        "dcterms:title": "FastSpeech 2",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "fast synthesis",
            "text-to-speech",
            "neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "F. Eyben",
            "M. WÃ¶llmer",
            "B. Schuller"
        ],
        "dcterms:description": "An open-source audio feature extractor designed for various audio processing tasks.",
        "dcterms:title": "OpenSMILE",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing"
        ],
        "dcat:keyword": [
            "audio features",
            "feature extraction",
            "open-source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Yamamoto",
            "E. Song",
            "J. Kim"
        ],
        "dcterms:description": "A fast waveform generation model based on generative adversarial networks that utilizes multi-resolution spectrograms.",
        "dcterms:title": "Parallel WaveGAN",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "waveform generation",
            "generative adversarial networks",
            "speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Y.-J. Zhang",
            "S. Pan",
            "L. He",
            "Z.-H. Ling"
        ],
        "dcterms:description": "A model that learns latent representations for style control and transfer in end-to-end speech synthesis.",
        "dcterms:title": "VAE-Tacotron 2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "variational autoencoder",
            "style control",
            "text-to-speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis"
        ]
    }
]