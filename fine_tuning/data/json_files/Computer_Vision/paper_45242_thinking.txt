To extract datasets from the research paper titled "Neural, Symbolic and Neural-Symbolic Reasoning on Knowledge Graphs" by Jing Zhang et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations.

First, I will read through the **abstract, introduction, and sections that discuss experiments or methodologies** to identify any datasets mentioned. The abstract provides a general overview, but specific datasets are likely to be detailed in the methodology or experimental sections.

Next, I will look for sections explicitly labeled as **"Datasets"** or similar. In this paper, I will focus on sections that discuss knowledge graphs, as these are likely to contain references to datasets used for training or evaluation.

As I read through the paper, I will take note of any datasets mentioned, including their names, descriptions, and any relevant statistics (e.g., number of entities, types of relations). For instance, if the authors mention using a specific knowledge graph like **Freebase, DBpedia, or YAGO**, I will note these down.

After identifying the datasets, I will check the **References section** of the paper to find the full citations for each dataset. This is crucial for proper attribution and to allow others to access the datasets.

For example, if the paper mentions **Freebase**, I would look for its citation, which might be formatted as follows:
> Bollacker, K., Evans, C., Paritosh, P., Sturge, T., & Taylor, J. (2008). Freebase: A collaboratively created graph database for structuring human knowledge. In Proceedings of the ACM SIGMOD International Conference on Management of Data (pp. 1247-1250).

Once I have gathered all the necessary information, I will compile the dataset details, including their names, descriptions, and full citations, ensuring that each dataset is clearly documented.

Finally, I will prepare the dataset entries for any required output format, ensuring that all information is accurate and complete for future reference or analysis.