To extract datasets from the research paper titled "Perception-oriented Single Image Super-Resolution via Dual Relativistic Average Generative Adversarial Networks" by Yuan Ma et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experimental settings sections** to identify any datasets mentioned. The abstract discusses the development of a new algorithm for image super-resolution but does not explicitly mention any datasets. Therefore, I will need to look deeper.

In the **introduction**, the authors discuss various algorithms and their performance but still do not mention specific datasets. I will continue to the **experimental settings section** where the authors describe the training and testing datasets used for their experiments.

In **section 3.1 (Training set and test set)**, the authors state that they used the **DIV2K dataset** for training, which contains 1000 natural images with a resolution of 2K, and they specify that images 1-800 are used as the training set. They also mention that for objective and perceptual evaluation, they tested their algorithm on several public benchmarks: **Set5, Set14, BSD100, Urban100, Manga109, and PIRM-val**.

Next, I will check the **References section** to find the full citations for these datasets:

1. **DIV2K dataset**: The citation is:
   > AgustÃ­ Romero, et al. *DIV2K: A dataset for image super-resolution*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.

2. **Set5**: The citation is:
   > Z. Wang, et al. *Image quality assessment: From error visibility to structural similarity*. IEEE Transactions on Image Processing, 2004.

3. **Set14**: The citation is:
   > B. Timofte, et al. *NTIRE 2017 Challenge on Single Image Super-Resolution: Methods and Results*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.

4. **BSD100**: The citation is:
   > A. Martin, et al. *A Database of Human Segmented Natural Images and its Application to Evaluating Segmentation Algorithms and Color Image Quantization*. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2001.

5. **Urban100**: The citation is:
   > J. Huang, et al. *Single Image Super-Resolution from Transformed Self-Exemplars*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.

6. **Manga109**: The citation is:
   > T. Miyazaki, et al. *Manga109: A Large-Scale Dataset for Manga Image Processing*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016.

7. **PIRM-val**: The citation is:
   > Y. Blau, et al. *The 2018 PIRM Challenge on Perceptual Image Super-Resolution*. In Proceedings of the European Conference on Computer Vision (ECCV), 2018.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further use.