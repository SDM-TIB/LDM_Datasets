[
    {
        "dcterms:creator": [
            "T.Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Dollár",
            "C.L. Zitnick"
        ],
        "dcterms:description": "Microsoft COCO is a large-scale dataset designed for object detection, segmentation, and captioning, containing images of common objects in context.",
        "dcterms:title": "COCO2017",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Segmentation",
            "Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "T.Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Dollár",
            "C.L. Zitnick"
        ],
        "dcterms:description": "Microsoft COCO is a large-scale dataset designed for object detection, segmentation, and captioning, containing images of common objects in context.",
        "dcterms:title": "COCO2014",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Segmentation",
            "Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schuhmann",
            "R. Vencu",
            "R. Beaumont",
            "R. Kaczmarczyk",
            "C. Mullis",
            "A. Katta",
            "T. Coombes",
            "J. Jitsev",
            "A. Komatsuzaki"
        ],
        "dcterms:description": "Laion-400m is an open dataset containing 400 million image-text pairs filtered using CLIP.",
        "dcterms:title": "Laion-400m",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2111.02114",
        "dcat:theme": [
            "Machine Learning",
            "Image-Text Pairing"
        ],
        "dcat:keyword": [
            "Image-text dataset",
            "CLIP-filtered",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text Pair",
        "mls:task": [
            "Image-Text Matching",
            "Training Language Models"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An internal dataset consisting of high-quality images and captions used for training.",
        "dcterms:title": "Internal Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Internal dataset",
            "High-quality images",
            "Captions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text Pair",
        "mls:task": []
    }
]