[
    {
        "dcterms:creator": [
            "T. Lin",
            "M. Maire",
            "S. Belongie",
            "L. Bourdev",
            "R. Girshick",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C. Zitnick"
        ],
        "dcterms:description": "The MSCOCO dataset consists of around 80K training images and 40K development images, each accompanied by five descriptive captions, making it a rich resource for image captioning tasks.",
        "dcterms:title": "MSCOCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Image captions",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "B. Plummer",
            "L. Wang",
            "C. Cervantes",
            "J. Caicedo",
            "J. Hockenmaier",
            "S. Lazebnik"
        ],
        "dcterms:description": "Flickr30k entities dataset collects region-to-phrase correspondences for richer image-to-sentence models, providing a valuable resource for understanding visual content in relation to language.",
        "dcterms:title": "Flickr30k",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Region-to-phrase correspondences",
            "Visual grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    }
]