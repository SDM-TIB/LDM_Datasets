[
    {
        "dcterms:creator": [],
        "dcterms:description": "A large dataset containing billions of image-text pairs, used for training and evaluating text-to-image generation models.",
        "dcterms:title": "LAION-5B",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Image-text pairs",
            "Text-to-image generation",
            "Large dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset used for training and evaluating diffusion models in text-to-image generation.",
        "dcterms:title": "DiffusionDB",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Diffusion models",
            "Text-to-image generation",
            "Training dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Kaiyi Huang",
            "Kaiyue Sun",
            "Enze Xie",
            "Zhenguo Li",
            "Xihui Liu"
        ],
        "dcterms:description": "A comprehensive benchmark for open-world compositional text-to-image generation, providing evaluation metrics and datasets.",
        "dcterms:title": "T2ICompBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.06350",
        "dcat:theme": [
            "Text-to-image generation",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Compositional generation",
            "Evaluation metrics",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jack Hessel",
            "Ari Holtzman",
            "Maxwell Forbes",
            "Ronan Le Bras",
            "Yejin Choi"
        ],
        "dcterms:description": "A reference-free evaluation metric for image captioning that assesses the alignment between generated images and input texts.",
        "dcterms:title": "CLIPScore",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image captioning",
            "Evaluation metrics"
        ],
        "dcat:keyword": [
            "Reference-free evaluation",
            "Image-text alignment",
            "Captioning metric"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jiazheng Xu",
            "Xiao Liu",
            "Yuchen Wu",
            "Yuxuan Tong",
            "Qinkai Li",
            "Ming Ding",
            "Jie Tang",
            "Yuxiao Dong"
        ],
        "dcterms:description": "A dataset designed to learn and evaluate human preferences for text-to-image generation, focusing on alignment and aesthetic quality.",
        "dcterms:title": "ImageReward",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-image generation",
            "Human preferences"
        ],
        "dcat:keyword": [
            "Human preference learning",
            "Text-image alignment",
            "Aesthetic evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]