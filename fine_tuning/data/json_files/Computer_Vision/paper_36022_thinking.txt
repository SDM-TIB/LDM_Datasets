To extract datasets from the research paper titled "Restricted Deformable Convolution based Road Scene Semantic Segmentation Using Surround View Cameras" by Liuyuan Deng et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the paper discusses a method for semantic segmentation using surround view cameras, which suggests that datasets related to road scenes may be involved.

Next, I will focus on the **introduction** section, where the authors mention the need for large-scale pixel-level annotated images for training deep learning models. They reference existing datasets, which may provide clues about the datasets used in their experiments.

In the **experiments section**, specifically section VI, the authors explicitly mention two datasets used for their experiments:

1. **Cityscapes Dataset**: This dataset is described as a large-scale dataset captured by a forward-looking conventional camera, containing 3475 images used in the experiments. The authors note that it is widely used for semantic urban scene understanding.

2. **SYNTHIA-Seqs Dataset**: This dataset consists of synthetic images captured in a virtual city using four conventional cameras from different directions, totaling 34,696 images. The authors specify that certain sub-sequences from this dataset are used in their experiments.

To ensure accuracy, I will check the **References section** for full citations of these datasets:

- For the **Cityscapes Dataset**, the citation is:
  > Cordts, M., Omran, M., Ramos, S., Rehfeld, T., Enzweiler, M., Benenson, R., Franke, U., Roth, S., & Schiele, B. (2016). The cityscapes dataset for semantic urban scene understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3213-3223.

- For the **SYNTHIA-Seqs Dataset**, the citation is:
  > Ros, G., Sellart, L., Materzynska, J., Vazquez, D., & Lopez, A. M. (2016). The synthia dataset: A large collection of synthetic images for semantic segmentation of urban scenes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3234-3243.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding citations.