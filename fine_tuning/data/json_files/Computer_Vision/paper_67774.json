[
    {
        "dcterms:creator": [
            "Josh Abramson",
            "Arun Ahuja",
            "Arthur Brussee",
            "Federico Carnevale",
            "Mary Cassin",
            "Felix Fischer",
            "Petko Georgiev",
            "Alex Goldin",
            "Mansi Gupta",
            "Tim Harley",
            "Felix Hill",
            "Peter C Humphreys",
            "Alden Hung",
            "Jessica Landon",
            "Timothy Lillicrap",
            "Hamza Merzic",
            "Alistair Muldal",
            "Adam Santoro",
            "Guy Scully",
            "Tamara von Glehn",
            "Greg Wayne",
            "Nathaniel Wong",
            "Chen Yan",
            "Rui Zhu"
        ],
        "dcterms:description": "A Unity-based environment with an egocentric view inside a procedurally-generated home, used for various tasks including Find, Lift, and Pick and Place.",
        "dcterms:title": "Playhouse",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Interactive Agents"
        ],
        "dcat:keyword": [
            "Unity environment",
            "Procedurally-generated",
            "Task-based learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Goal achievement",
            "Task completion"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Toyama",
            "Philippe Hamel",
            "Anita Gergely",
            "Gheorghe Comanici",
            "Amelia Glaese",
            "Zafarali Ahmed",
            "Tyler Jackson",
            "Shibl Mourad",
            "Doina Precup"
        ],
        "dcterms:description": "An open-source environment built on the Android operating system, allowing agents to interact through touchscreen gestures on an emulated Android device in real-time.",
        "dcterms:title": "AndroidEnv",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Android Interaction"
        ],
        "dcat:keyword": [
            "Android emulator",
            "Touchscreen interaction",
            "Real-time control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "App interaction",
            "Task execution"
        ]
    },
    {
        "dcterms:creator": [
            "Linxi Fan",
            "Guanzhi Wang",
            "Yunfan Jiang",
            "Ajay Mandlekar",
            "Yuncong Yang",
            "Haoyi Zhu",
            "Andrew Tang",
            "De-An Huang",
            "Yuke Zhu",
            "Anima Anandkumar"
        ],
        "dcterms:description": "A dataset that builds open-ended embodied agents with internet-scale knowledge, specifically designed for training agents in Minecraft.",
        "dcterms:title": "MineDojo",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Embodied Agents"
        ],
        "dcat:keyword": [
            "Minecraft",
            "Open-ended learning",
            "Agent training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Agent training",
            "Goal achievement"
        ]
    },
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark",
            "Gretchen Krueger",
            "Ilya Sutskever"
        ],
        "dcterms:description": "A dataset used for training vision-language models that learn transferable visual models from natural language supervision.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.mlr.press/v139/radford21a.html",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Vision-language model",
            "Transfer learning",
            "Natural language supervision"
        ],
        "dcat:landingPage": "https://proceedings.mlr.press/v139/radford21a.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual recognition",
            "Language understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Ziluo Ding",
            "Hao Luo",
            "Ke Li",
            "Junpeng Yue",
            "Tiejun Huang",
            "Zongqing Lu"
        ],
        "dcterms:description": "A vision-language model specifically designed for Minecraft, providing a reinforcement learning-friendly framework.",
        "dcterms:title": "CLIP4MC",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2303.10571",
        "dcat:theme": [
            "Reinforcement Learning",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Minecraft",
            "Vision-language model",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2303.10571",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task completion",
            "Goal achievement"
        ]
    },
    {
        "dcterms:creator": [
            "Yuqing Du",
            "Ksenia Konyushkova",
            "Misha Denil",
            "Akhil Raju",
            "Jessica Landon",
            "Felix Hill",
            "Nando de Freitas",
            "Serkan Cabi"
        ],
        "dcterms:description": "A dataset that fine-tunes smaller models to act as success detectors by formulating the problem as Visual Question Answering.",
        "dcterms:title": "SuccessVQA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Success Detection"
        ],
        "dcat:keyword": [
            "Success detection",
            "Visual question answering",
            "Language goals"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Goal achievement",
            "Task evaluation"
        ]
    }
]