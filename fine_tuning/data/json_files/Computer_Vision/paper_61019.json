[
    {
        "dcterms:creator": [
            "Yash Goyal",
            "Tejas Khot",
            "Douglas Summers-Stay",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "A benchmark dataset for visual question answering that emphasizes the importance of image understanding in answering questions about images.",
        "dcterms:title": "VQAv2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "VQA",
            "Image understanding",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Aishwarya Agrawal",
            "Dhruv Batra",
            "Devi Parikh",
            "Aniruddha Kembhavi"
        ],
        "dcterms:description": "An out-of-distribution benchmark for visual question answering that addresses the issue of language priors in VQA.",
        "dcterms:title": "VQA-CPv2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Bias Mitigation"
        ],
        "dcat:keyword": [
            "VQA",
            "Out-of-distribution",
            "Bias reduction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]