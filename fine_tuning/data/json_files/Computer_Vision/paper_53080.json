[
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark",
            "Gretchen Krueger",
            "Ilya Sutskever"
        ],
        "dcterms:description": "CLIP is a model that learns visual representations from natural language supervision, enabling robust image representation learning.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2103.00020",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image representation",
            "Natural language supervision",
            "Contrastive learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Image classification",
            "Image generation"
        ]
    },
    {
        "dcterms:creator": [
            "Aditya Ramesh",
            "Mikhail Pavlov",
            "Gabriel Goh",
            "Scott Gray",
            "Chelsea Voss",
            "Alec Radford",
            "Mark Chen",
            "Ilya Sutskever"
        ],
        "dcterms:description": "DALL-E is a model for zero-shot text-to-image generation, capable of creating images from textual descriptions.",
        "dcterms:title": "DALL-E",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2102.12092",
        "dcat:theme": [
            "Image Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Text-to-image generation",
            "Zero-shot learning",
            "Generative models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Text-to-image synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "Lubomir Bourdev",
            "Ross Girshick",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "C. Lawrence Zitnick",
            "Piotr Doll√°r"
        ],
        "dcterms:description": "MS-COCO is a large-scale dataset of images with corresponding captions, widely used for training and evaluating image captioning models.",
        "dcterms:title": "MS-COCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1405.0312",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Captioning",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image captioning",
            "Object detection"
        ]
    },
    {
        "dcterms:creator": [
            "Naila Murray",
            "Luca Marchesotti",
            "Florent Perronnin"
        ],
        "dcterms:description": "AVA is a large-scale database designed for aesthetic visual analysis, containing images annotated with aesthetic scores.",
        "dcterms:title": "AVA",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "10.1109/CVPR.2012.6247954",
        "dcat:theme": [
            "Aesthetic Analysis",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Aesthetic quality",
            "Visual analysis",
            "Image dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Aesthetic evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Alexey Dosovitskiy",
            "Lucas Beyer",
            "Alexander Kolesnikov",
            "Dirk Weissenborn",
            "Xiaohua Zhai",
            "Thomas Unterthiner",
            "Mostafa Dehghani",
            "Matthias Minderer",
            "Georg Heigold",
            "Sylvain Gelly",
            "Jakob Uszkoreit",
            "Neil Houlsby"
        ],
        "dcterms:description": "ImageNet is a large visual database designed for use in visual object recognition software research.",
        "dcterms:title": "ImageNet",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2010.11929",
        "dcat:theme": [
            "Image Classification",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Object recognition",
            "Image dataset",
            "Visual recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image classification"
        ]
    }
]