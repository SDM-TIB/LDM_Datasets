[
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A large dataset containing video clips with 13 joints annotated in all frames, including head, shoulders, elbows, wrists, hips, knees, and ankles.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human pose",
            "Joint estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. ZufÔ¨Å",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "A dataset designed for understanding action recognition, containing video clips with annotated actions.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Alekh Agarwal",
            "Sham M. Kakade",
            "Jason D. Lee",
            "Gaurav Mahajan"
        ],
        "dcterms:description": "A theoretical framework for policy gradient methods focusing on optimality, approximation, and distribution shift.",
        "dcterms:title": "Natural Policy Gradient (NPG) methods",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Policy gradient",
            "Reinforcement learning",
            "Natural gradient"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Carlo Alfano",
            "Patrick Rebeschini"
        ],
        "dcterms:description": "A study on the linear convergence of natural policy gradient methods with log-linear policy parametrization.",
        "dcterms:title": "Q-NPG methods",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Natural policy gradient",
            "Linear convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Tuomas Haarnoja",
            "Aurick Zhou",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "dcterms:description": "A framework for off-policy maximum entropy deep reinforcement learning with a stochastic actor.",
        "dcterms:title": "Soft Actor-Critic",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Maximum entropy",
            "Off-policy learning",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Shun-ichi Amari"
        ],
        "dcterms:description": "A foundational paper on the natural gradient method and its efficiency in learning.",
        "dcterms:title": "Entropy-regularized NPG",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Optimization",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Natural gradient",
            "Learning efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Shalabh Bhatnagar",
            "Richard S. Sutton",
            "Mohammad Ghavamzadeh",
            "Mark Lee"
        ],
        "dcterms:description": "An algorithmic framework for natural actor-critic algorithms.",
        "dcterms:title": "Natural Actor-Critic (NAC)",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Actor-Critic Methods"
        ],
        "dcat:keyword": [
            "Actor-critic",
            "Natural gradient"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Richard S. Sutton",
            "Andrew G. Barto"
        ],
        "dcterms:description": "A comprehensive introduction to reinforcement learning, covering various algorithms and theories.",
        "dcterms:title": "Policy Gradient Methods",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Policy gradient"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Zaiwei Chen",
            "Sajad Khodadadian",
            "Siva Theja Maguluri"
        ],
        "dcterms:description": "An analysis of off-policy natural actor-critic with linear function approximation.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Q-learning"
        ],
        "dcat:keyword": [
            "Off-policy learning",
            "Natural actor-critic"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jincheng Mei",
            "Chenjun Xiao",
            "Csaba Szepesvari",
            "Dale Schuurmans"
        ],
        "dcterms:description": "A study on the global convergence rates of softmax policy gradient methods.",
        "dcterms:title": "Variance-reduced Policy Gradient",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Variance reduction",
            "Policy gradient"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]