[
    {
        "dcterms:creator": [
            "Z. Liu",
            "B. Mak"
        ],
        "dcterms:description": "The VCTK dataset includes 44242 voice samples from 110 speakers, among which are 47 male, 61 female, and 2 speakers of unknown gender. It is used for training baselines and the proposed model in voice conversion tasks.",
        "dcterms:title": "VCTK dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Voice Conversion"
        ],
        "dcat:keyword": [
            "Voice samples",
            "Multi-speaker",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "A. Polyak",
            "L. Wolf",
            "Y. Taigman"
        ],
        "dcterms:description": "TTS Skins is a method for speaker conversion via ASR, which is referenced in the context of the proposed voice conversion system.",
        "dcterms:title": "TTS Skins",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Speaker conversion",
            "ASR"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "K. Qian",
            "Y. Zhang",
            "S. Chang",
            "X. Yang",
            "M. Hasegawa-Johnson"
        ],
        "dcterms:description": "AutoVC is a zero-shot voice style transfer method that utilizes only autoencoder loss, referenced in the context of comparing voice conversion methods.",
        "dcterms:title": "AutoVC",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion"
        ],
        "dcat:keyword": [
            "Voice style transfer",
            "Autoencoder"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "D. Wang",
            "L. Deng",
            "Y. T. Yeung",
            "X. Chen",
            "X. Liu",
            "H. Meng"
        ],
        "dcterms:description": "VQMIVC is a method for one-shot voice conversion that utilizes vector quantization and mutual information-based unsupervised speech representation disentanglement.",
        "dcterms:title": "VQMIVC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion"
        ],
        "dcat:keyword": [
            "One-shot voice conversion",
            "Unsupervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "B. Nguyen",
            "F. Cardinaux"
        ],
        "dcterms:description": "NVC-Net is an end-to-end adversarial voice conversion method referenced in the context of comparing voice conversion systems.",
        "dcterms:title": "NVC-Net",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion"
        ],
        "dcat:keyword": [
            "Adversarial learning",
            "Voice conversion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Voice Conversion"
        ]
    }
]