[
    {
        "dcterms:creator": [
            "J. Lee",
            "M. Grey",
            "S. Ha",
            "T. Kunz",
            "S. Jain",
            "Y. Ye",
            "S. Srinivasa",
            "M. Stilman",
            "C. Liu"
        ],
        "dcterms:description": "A task involving the insertion of a peg into a hole, used to evaluate the effectiveness of adaptable recovery behaviors in robotics.",
        "dcterms:title": "Peg-in-a-hole task",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://joss.theoj.org/papers/10.21105/joss.00500",
        "dcat:theme": [
            "Robotics",
            "Task Execution"
        ],
        "dcat:keyword": [
            "Peg insertion",
            "Robotic tasks",
            "Recovery behaviors"
        ],
        "dcat:landingPage": "https://joss.theoj.org/papers/10.21105/joss.00500",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task execution",
            "Failure recovery"
        ]
    },
    {
        "dcterms:creator": [
            "F. Rovida",
            "M. Crosby",
            "D. Holz",
            "A. S. Polydoros",
            "B. Großmann",
            "R. P. Petrick",
            "V. Krüger"
        ],
        "dcterms:description": "A skill-based robot control platform built on ROS, utilized for managing robot skills and behaviors.",
        "dcterms:title": "SkiROS2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Robot control",
            "Skill-based platform",
            "ROS"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Lee",
            "M. Grey",
            "S. Ha",
            "T. Kunz",
            "S. Jain",
            "Y. Ye",
            "S. Srinivasa",
            "M. Stilman",
            "C. Liu"
        ],
        "dcterms:description": "A simulation environment used for testing robotic tasks and behaviors, particularly in the context of the peg-in-a-hole task.",
        "dcterms:title": "DART simulator",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://joss.theoj.org/papers/10.21105/joss.00500",
        "dcat:theme": [
            "Robotics",
            "Simulation"
        ],
        "dcat:keyword": [
            "Simulation",
            "Robotic tasks",
            "DART"
        ],
        "dcat:landingPage": "https://joss.theoj.org/papers/10.21105/joss.00500",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "F. Rovida",
            "D. Wuthier",
            "B. Grossmann",
            "M. Fumagalli",
            "V. Krüger"
        ],
        "dcterms:description": "A framework that combines behavior trees with motion generators to model robotic skills and behaviors.",
        "dcterms:title": "Behavior Trees and Motion Generators (BTMG)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Behavior Modeling"
        ],
        "dcat:keyword": [
            "Behavior trees",
            "Motion generation",
            "Robotic skills"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Mayr",
            "F. Ahmad",
            "K. Chatzilygeroudis",
            "L. Nardi",
            "V. Krueger"
        ],
        "dcterms:description": "Parameters used in reinforcement learning to optimize robotic task performance, particularly in multi-objective scenarios.",
        "dcterms:title": "Reinforcement Learning (RL) parameters",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Parameter optimization",
            "Robotic tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]