[
    {
        "dcterms:creator": [
            "A. Gokaslan",
            "V. Cohen",
            "E. Pavlick",
            "S. Tellex"
        ],
        "dcterms:description": "The OpenWebText dataset is a collection of web pages that were selected to be similar to the kinds of content found on Reddit, providing a diverse corpus for training language models.",
        "dcterms:title": "OpenWebText",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Data"
        ],
        "dcat:keyword": [
            "Web corpus",
            "Language modeling",
            "Text data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "L. Gao",
            "S. Biderman",
            "S. Black",
            "L. Golding",
            "T. Hoppe",
            "C. Foster",
            "J. Phang",
            "H. He",
            "A. Thite",
            "N. Nabeshima",
            "S. Presser",
            "C. Leahy"
        ],
        "dcterms:description": "The Pile is an 800GB dataset of diverse text for language modeling, designed to provide a comprehensive training resource for large language models.",
        "dcterms:title": "Pile",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Data"
        ],
        "dcat:keyword": [
            "Large dataset",
            "Language modeling",
            "Diverse text"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. Wu",
            "R. Child",
            "D. Luan",
            "D. Amodei",
            "I. Sutskever"
        ],
        "dcterms:description": "GPT-2 is a language model that is trained to predict the next word in a sentence, showcasing the capabilities of unsupervised learning in natural language processing.",
        "dcterms:title": "GPT-2",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Data"
        ],
        "dcat:keyword": [
            "Language model",
            "Unsupervised learning",
            "Text generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Biderman",
            "H. Schoelkopf",
            "Q. Anthony",
            "H. Bradley",
            "K. Oâ€™Brien",
            "E. Hallahan",
            "M. Aflah Khan",
            "S. Purohit",
            "U. S. V. S. N. Sai Prashanth",
            "E. Raff",
            "A. Skowron",
            "L. Sutawika",
            "O. van der Wal"
        ],
        "dcterms:description": "Pythia is a suite for analyzing large language models across training and scaling, providing tools and datasets for comprehensive evaluation.",
        "dcterms:title": "Pythia",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Analysis"
        ],
        "dcat:keyword": [
            "Language model analysis",
            "Training evaluation",
            "Scaling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation"
        ]
    }
]