[
    {
        "dcterms:creator": [
            "Yu Ying Chiu",
            "Liwei Jiang",
            "Maria Antoniak",
            "Chan Young Park",
            "Shuyue Stella Li",
            "Mehar Bhatia",
            "Sahithya Ravi",
            "Yulia Tsvetkov",
            "Vered Shwartz",
            "Yejin Choi"
        ],
        "dcterms:description": "A compact yet high-quality evaluation dataset with users’ red-teaming attempts, containing 252 carefully-reviewed challenging questions spanning across 34 distinct cultures for testing LLMs’ multicultural knowledge.",
        "dcterms:title": "CULTURALBENCH-V0.1",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "https://huggingface.co/datasets/kellycyy/CulturalBench",
        "dcat:theme": [
            "Multicultural Knowledge Assessment",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Evaluation dataset",
            "Cultural knowledge",
            "Red-teaming",
            "Multicultural",
            "LLMs"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/kellycyy/CulturalBench",
        "dcterms:hasVersion": "0.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Cultural knowledge assessment",
            "Question generation"
        ]
    },
    {
        "dcterms:creator": [
            "Yu Ying Chiu",
            "Liwei Jiang",
            "Maria Antoniak",
            "Chan Young Park",
            "Shuyue Stella Li",
            "Mehar Bhatia",
            "Sahithya Ravi",
            "Yulia Tsvetkov",
            "Vered Shwartz",
            "Yejin Choi"
        ],
        "dcterms:description": "A compact yet high-quality evaluation dataset with users’ red-teaming attempts, containing 252 carefully-reviewed challenging questions spanning across 34 distinct cultures for testing LLMs’ multicultural knowledge.",
        "dcterms:title": "CULTURALBENCH-V0.12",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multicultural Knowledge Assessment",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Evaluation dataset",
            "Cultural knowledge",
            "Red-teaming",
            "Multicultural",
            "LLMs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "0.12",
        "dcterms:format": "Text",
        "mls:task": [
            "Cultural knowledge assessment",
            "Question generation"
        ]
    }
]