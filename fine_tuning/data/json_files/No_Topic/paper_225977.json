[
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing 100,000+ questions for machine comprehension of text, where the answers are spans in the passage.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Machine Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question generation",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Automatic Question Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William W. Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D. Manning"
        ],
        "dcterms:description": "A multi-document and multi-hop QA dataset that provides supporting facts leading to the answer, with answers being either yes/no or answer spans.",
        "dcterms:title": "HOTPOT-QA",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Multi-hop Reasoning"
        ],
        "dcat:keyword": [
            "Multi-document QA",
            "Explainable AI",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Automatic Question Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Dheeru Dua",
            "Yizhong Wang",
            "Pradeep Dasigi",
            "Gabriel Stanovsky",
            "Sameer Singh",
            "Matt Gardner"
        ],
        "dcterms:description": "A reading comprehension benchmark requiring discrete reasoning over paragraphs, containing 96K questions that require operations like addition, counting, or sorting to obtain the answer.",
        "dcterms:title": "DROP",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Discrete Reasoning"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Discrete operations",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Automatic Question Generation"
        ]
    }
]