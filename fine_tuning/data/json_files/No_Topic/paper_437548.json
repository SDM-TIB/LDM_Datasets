[
    {
        "dcterms:creator": [
            "X. Chen",
            "C. Wang",
            "Y. Xue",
            "N. Zhang",
            "X. Yang",
            "Q. Li",
            "Y. Shen",
            "L. Liang",
            "J. Gu",
            "H. Chen"
        ],
        "dcterms:description": "AVHalluBench is a comprehensive audio-visual hallucination benchmark dataset that includes 175 videos selected from six video understanding datasets, covering various styles and elements such as visual text, speech, and music.",
        "dcterms:title": "AVHalluBench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Processing",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Audio-Visual",
            "Hallucination Benchmark",
            "Video Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Hallucination Ranking",
            "Video Description"
        ]
    },
    {
        "dcterms:creator": [
            "P. Manakul",
            "A. Liusie",
            "M. Gales"
        ],
        "dcterms:description": "WikiBio is a dataset containing biographical passages from Wikipedia, used for evaluating hallucination detection methods in generative models.",
        "dcterms:title": "WikiBio",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2023.emnlp-main.557",
        "dcat:theme": [
            "Biography Generation",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Biography",
            "Hallucination Detection",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.emnlp-main.557",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation",
            "Hallucination Detection"
        ]
    },
    {
        "dcterms:creator": [
            "X. Chen",
            "C. Wang",
            "Y. Xue",
            "N. Zhang",
            "X. Yang",
            "Q. Li",
            "Y. Shen",
            "L. Liang",
            "J. Gu",
            "H. Chen"
        ],
        "dcterms:description": "MHaluBench is an image-captioning hallucination dataset designed to evaluate the hallucination levels in visual language models.",
        "dcterms:title": "MHaluBench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Image Captioning",
            "Hallucination Benchmark",
            "Visual Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Hallucination Ranking",
            "Image Description"
        ]
    },
    {
        "dcterms:creator": [
            "M. Han",
            "M. Kang",
            "H. Jung",
            "S. J. Hwang"
        ],
        "dcterms:description": "TriviaQA is a dataset designed for question answering, containing a large collection of trivia questions and their corresponding answers.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/P19-1434",
        "dcat:theme": [
            "Question Answering",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Trivia Questions",
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/P19-1434",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Hallucination Detection"
        ]
    },
    {
        "dcterms:creator": [
            "S. Lin",
            "J. Hilton",
            "O. Evans"
        ],
        "dcterms:description": "TruthfulQA is a benchmark for evaluating the truthfulness of language models, measuring how well they mimic human falsehoods.",
        "dcterms:title": "TruthfulQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2022.acl-long.229",
        "dcat:theme": [
            "Truthfulness Evaluation",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Truthfulness",
            "Falsehoods",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.acl-long.229",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Truthfulness Evaluation",
            "Hallucination Detection"
        ]
    },
    {
        "dcterms:creator": [
            "J. Li",
            "X. Cheng",
            "X. Zhao",
            "J.-Y. Nie",
            "J.-R. Wen"
        ],
        "dcterms:description": "HaluEval is a large-scale hallucination evaluation benchmark for large language models, providing a comprehensive set of tasks to assess hallucination levels.",
        "dcterms:title": "HaluEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2023.emnlp-main.397",
        "dcat:theme": [
            "Hallucination Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Hallucination Evaluation",
            "Language Models",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.emnlp-main.397",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Hallucination Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Narayan",
            "S. B. Cohen",
            "M. Lapata"
        ],
        "dcterms:description": "XSum is a dataset for extreme summarization, focusing on generating concise summaries from news articles.",
        "dcterms:title": "XSum",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/D18-1206",
        "dcat:theme": [
            "Summarization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Extreme Summarization",
            "News Articles",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/D18-1206",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "A. See",
            "P. J. Liu",
            "C. D. Manning"
        ],
        "dcterms:description": "CNN-DM is a dataset for summarization tasks, consisting of news articles and their corresponding summaries.",
        "dcterms:title": "CNN-DM",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/P17-1099",
        "dcat:theme": [
            "Summarization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "News Summarization",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "https://aclanthology.org/P17-1099",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "I. R. McKenzie",
            "A. Lyzhov",
            "M. Pieler",
            "A. Parrish",
            "A. Mueller",
            "A. Prabhu",
            "E. McLean",
            "A. Kirtland",
            "A. Ross",
            "A. Liu",
            "A. Gritsevskiy",
            "D. Wurgaft",
            "D. Kauffman",
            "G. Recchia",
            "J. Liu",
            "J. Cavanagh",
            "M. Weiss",
            "S. Huang",
            "T. F. Droid",
            "T. Tseng",
            "T. Korbak",
            "X. Shen",
            "Y. Zhang",
            "Z. Zhou",
            "N. Kim",
            "S. R. Bowman",
            "E. Perez"
        ],
        "dcterms:description": "MemoTrap is a dataset designed to evaluate the memorization capabilities of language models, assessing their tendency to memorize specific examples.",
        "dcterms:title": "MemoTrap",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Memorization Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Memorization",
            "Language Models",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Memorization Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Dziri",
            "E. Kamalloo",
            "S. Milton",
            "O. Zaiane",
            "M. Yu",
            "E. Ponti",
            "S. Reddy"
        ],
        "dcterms:description": "FaithDial is a benchmark for evaluating the faithfulness of information-seeking dialogue systems, focusing on the accuracy of generated responses.",
        "dcterms:title": "FaithDial",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Dialogue Evaluation",
            "Faithfulness",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Dialogue Evaluation"
        ]
    }
]