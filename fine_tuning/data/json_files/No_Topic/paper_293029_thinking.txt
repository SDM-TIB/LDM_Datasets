To extract datasets from the research paper titled "Vote from the Center: 6 DoF Pose Estimation in RGB-D Images by Radial Keypoint Voting" by Yangzheng Wu et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, methodology, and experiments sections** of the paper. The abstract mentions that the proposed method achieves state-of-the-art results on specific datasets, which indicates that datasets are likely discussed in detail later in the paper.

Next, I will focus on **section 4.1 (Datasets)**, where the authors explicitly list the datasets used for their experiments. In this section, they mention three datasets:

1. **LINEMOD Dataset**: This dataset includes 1200 images per object, with a training set of 180 samples. The authors describe how they augmented this dataset to increase the training set size.

2. **Occlusion LINEMOD Dataset**: This is a re-annotation of the LINEMOD dataset, consisting of 1215 challenging test images of partially occluded objects.

3. **YCB-Video Dataset**: A larger dataset containing 130K key frames of 21 objects over 92 videos, with specific splits for training and testing.

After identifying these datasets, I will check the **References section** to find the full citations for each dataset mentioned. The citations are crucial for proper attribution and to allow others to access the datasets.

The citations I will extract are:

- For **LINEMOD Dataset**:
  > Hinterstoisser, S., Lepetit, V., Ilic, S., Holzer, S., Bradski, G., Konolige, K., & Navab, N. (2012). Model based training, detection and pose estimation of texture-less 3D objects in heavily cluttered scenes. In Asian Conference on Computer Vision (pp. 548–562). Springer.

- For **Occlusion LINEMOD Dataset**:
  > Brachmann, E., Krull, A., Michel, F., Gumhold, S., Shotton, J., Rother, C., & Matas, J. (2014). Learning 6D object pose estimation using 3D object coordinates. In European Conference on Computer Vision (pp. 536–551). Springer.

- For **YCB-Video Dataset**:
  > Xiang, Y., Schmidt, T., Narayanan, V., & Fox, D. (2018). PoseCNN: A convolutional neural network for 6D object pose estimation in cluttered scenes. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 292–301).

Now that I have identified the datasets and their citations, I will compile this information into a structured format that clearly outlines each dataset's name, description, and citation. This will ensure that the datasets are accurately represented and easily accessible for future reference.