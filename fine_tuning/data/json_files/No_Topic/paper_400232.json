[
    {
        "dcterms:creator": [
            "Simion-Vlad Bogolin",
            "Ioana Croitoru",
            "Marius Leordeanu"
        ],
        "dcterms:description": "A dataset containing multiple text descriptions for the same video, used to build ground truth GEST representations for video to text comparisons.",
        "dcterms:title": "Videos-to-Paragraphs Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Text descriptions",
            "Ground truth",
            "Text-to-text comparison"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text-to-Text Comparison",
            "Video Generation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A virtual environment based on the game GTA San Andreas with Multi Theft Auto, used for generating videos from GEST representations.",
        "dcterms:title": "GTA San Andreas with Multi Theft Auto (MTA)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Generation",
            "Virtual Environments"
        ],
        "dcat:keyword": [
            "Video generation",
            "Virtual environment",
            "Game mechanics"
        ],
        "dcat:landingPage": "https://multitheftauto.com/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Thibault Sellam",
            "Dipanjan Das",
            "Ankur Parikh"
        ],
        "dcterms:description": "A metric for evaluating text generation that is robust and can be used to improve text similarity metrics.",
        "dcterms:title": "BLEURT",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Evaluation"
        ],
        "dcat:keyword": [
            "Text evaluation",
            "Text generation",
            "Robust metrics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Sihan Chen",
            "Xingjian He",
            "Longteng Guo",
            "Xinxin Zhu",
            "Weining Wang",
            "Jinhui Tang",
            "Jing Liu"
        ],
        "dcterms:description": "A vision-audio-language omni-perception pretraining model and dataset.",
        "dcterms:title": "VALOR",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.08345",
        "dcat:theme": [
            "Multimodal Learning",
            "Vision and Language"
        ],
        "dcat:keyword": [
            "Vision-audio-language",
            "Pretraining",
            "Multimodal dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Wenyi Hong",
            "Ming Ding",
            "Wendi Zheng",
            "Xinghan Liu",
            "Jie Tang"
        ],
        "dcterms:description": "A large-scale pretraining dataset for text-to-video generation using transformers.",
        "dcterms:title": "CogVideo",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2205.15868",
        "dcat:theme": [
            "Video Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Text-to-video generation",
            "Pretraining",
            "Transformers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Levon Khachatryan",
            "Andranik Movsisyan",
            "Vahram Tadevosyan",
            "Roberto Henschel",
            "Zhangyang Wang",
            "Shant Navasardyan",
            "Humphrey Shi"
        ],
        "dcterms:description": "A dataset and method for generating videos from text using zero-shot text-to-image diffusion models.",
        "dcterms:title": "Text2VideoZero",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2303.13439",
        "dcat:theme": [
            "Video Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Zero-shot generation",
            "Text-to-video",
            "Diffusion models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]