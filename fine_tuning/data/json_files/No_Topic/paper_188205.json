[
    {
        "dcterms:creator": [
            "Marcus Hutter"
        ],
        "dcterms:description": "A universal prior that causes argmax ties for the first m steps, making all actions equally preferable to AIXI.",
        "dcterms:title": "Indiï¬€erence Prior",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Algorithmic Information Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Universal Prior",
            "AIXI",
            "Argmax Ties"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Marcus Hutter"
        ],
        "dcterms:description": "A universal prior that assigns very high probability of going to hell if the agent deviates from a given computable policy, making it conform to that policy.",
        "dcterms:title": "Dogmatic Prior",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Algorithmic Information Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Universal Prior",
            "AIXI",
            "Policy Conformity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Marcus Hutter"
        ],
        "dcterms:description": "AIXI is defined as a policy that is optimal in the universal mixture, targeted at the general reinforcement learning problem.",
        "dcterms:title": "AIXI",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "Optimal Policy",
            "Reinforcement Learning",
            "Bayesian Agent"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Shane Legg",
            "Marcus Hutter"
        ],
        "dcterms:description": "A mathematical performance measure for general reinforcement learning agents, defined as the discounted rewards achieved across all computable environments.",
        "dcterms:title": "Legg-Hutter Intelligence",
        "dcterms:issued": "2007",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Artificial Intelligence",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Intelligence Measure",
            "Reinforcement Learning",
            "Universal Intelligence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Tor Lattimore",
            "Marcus Hutter"
        ],
        "dcterms:description": "A universal mixture that is time consistent for discounting, providing a framework for evaluating policies in reinforcement learning.",
        "dcterms:title": "Universal Mixture",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithmic Information Theory"
        ],
        "dcat:keyword": [
            "Universal Mixture",
            "Discounting",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jan Leike",
            "Marcus Hutter"
        ],
        "dcterms:description": "A universal mixture that allows AIXI to emulate computable policies, providing insights into the computability of AIXI.",
        "dcterms:title": "AIXI Emulating Computable Policies",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "AIXI",
            "Computable Policies",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Peter Sunehag",
            "Marcus Hutter"
        ],
        "dcterms:description": "A discussion on universal priors that lead to poor performance in reinforcement learning, illustrating the challenges of optimality.",
        "dcterms:title": "Bad Universal Priors",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithmic Information Theory"
        ],
        "dcat:keyword": [
            "Universal Priors",
            "Reinforcement Learning",
            "Optimality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]