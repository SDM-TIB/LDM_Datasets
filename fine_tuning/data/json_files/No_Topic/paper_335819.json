[
    {
        "dcterms:creator": [
            "K. Soomro",
            "A. Roshan Zamir",
            "M. Shah"
        ],
        "dcterms:description": "The UCF101 dataset consists of 13.3K videos from 101 classes, providing a diverse set of human actions captured in real-world scenarios.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Hilde Kuehne",
            "Hueihan Jhuang",
            "Est´ıbaliz Garrote",
            "Tomaso Poggio",
            "Thomas Serre"
        ],
        "dcterms:description": "The HMDB51 dataset consists of 6.8K examples from 51 action classes, providing a benchmark for human motion recognition.",
        "dcterms:title": "HMDB51",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human motion",
            "Video dataset",
            "Action classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Raghav Goyal",
            "Samira Ebrahimi Kahou",
            "Vincent Michalski",
            "Joanna Materzynska",
            "Susanne Westphal",
            "Heuna Kim",
            "Valentin Haenel",
            "Ingo Freund",
            "Peter Yianilos",
            "Moritz Mueller-Freitag"
        ],
        "dcterms:description": "The Something-Something V2 dataset is a large-scale motion-sensitive dataset containing 169K training and 25K test videos from 174 action classes, requiring better temporal reasoning.",
        "dcterms:title": "Something-Something V2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Motion-sensitive",
            "Video dataset",
            "Temporal reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]