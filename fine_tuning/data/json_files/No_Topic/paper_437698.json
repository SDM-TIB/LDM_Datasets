[
    {
        "dcterms:creator": [],
        "dcterms:description": "The etami project focuses on ethical and trustworthy artificial and machine intelligence, aiming to enhance transparency and accountability in ML systems.",
        "dcterms:title": "etami",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://etami.eu",
        "dcat:theme": [],
        "dcat:keyword": [
            "Ethical AI",
            "Machine Learning",
            "Transparency",
            "Accountability"
        ],
        "dcat:landingPage": "https://etami.eu",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Geriatronics project focuses on developing service robotics platforms to assist elderly people in their daily life activities, integrating ethical, social, and legal considerations.",
        "dcterms:title": "Geriatronics project",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://geriatronics.mirmi.tum.de/",
        "dcat:theme": [],
        "dcat:keyword": [
            "Service Robotics",
            "Elderly Assistance",
            "Ethics",
            "Social Issues"
        ],
        "dcat:landingPage": "https://geriatronics.mirmi.tum.de/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The AI, Algorithmic and Automation Incident & Controversy database provides a repository of incidents and controversies related to AI and automation, serving as a resource for understanding past failures.",
        "dcterms:title": "AI, Algorithmic and Automation Incident & Controversy database",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://charliepownall.com/ai-algorithimic-incident-controversy-database/",
        "dcat:theme": [],
        "dcat:keyword": [
            "AI Incidents",
            "Automation",
            "Controversies",
            "Risk Assessment"
        ],
        "dcat:landingPage": "https://charliepownall.com/ai-algorithimic-incident-controversy-database/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Matthew Arnold",
            "Rachel KE Bellamy",
            "Michael Hind",
            "Stephanie Houde",
            "Sameep Mehta",
            "Aleksandra Mojsilović",
            "Ravi Nair",
            "K Natesan Ramamurthy",
            "Alexandra Olteanu",
            "David Piorkowski"
        ],
        "dcterms:description": "FactSheets provide a comprehensive documentation framework to increase trust in AI services through supplier’s declarations of conformity.",
        "dcterms:title": "FactSheets",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Documentation",
            "AI Trust",
            "Supplier Declarations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Vijay Arya",
            "Rachel KE Bellamy",
            "Pin-Yu Chen",
            "Amit Dhurandhar",
            "Michael Hind",
            "Samuel C Hoffman",
            "Stephanie Houde",
            "Q Vera Liao",
            "Ronny Luss",
            "Aleksandra Mojsilović"
        ],
        "dcterms:description": "AI Explainability 360 is an extensible toolkit designed to help users understand data and machine learning models.",
        "dcterms:title": "AI Explainability 360",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Explainability",
            "Machine Learning",
            "Toolkit"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Timnit Gebru",
            "Jamie Morgenstern",
            "Briana Vecchione",
            "Jennifer Wortman Vaughan",
            "Hanna Wallach",
            "Hal Daumé III",
            "Kate Crawford"
        ],
        "dcterms:description": "Datasheets for datasets provide a framework for documenting datasets to ensure transparency and accountability in AI research.",
        "dcterms:title": "Datasheets for datasets",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Datasheets",
            "Documentation",
            "Transparency",
            "Accountability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Pedro Saleiro",
            "Benedict Kuester",
            "Loren Hinkson",
            "Jesse London",
            "Abby Stevens",
            "Ari Anisfeld",
            "Kit T Rodolfa",
            "Rayid Ghani"
        ],
        "dcterms:description": "Aequitas is a bias and fairness audit toolkit designed to assess and mitigate bias in machine learning models.",
        "dcterms:title": "Aequitas",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Bias",
            "Fairness",
            "Audit Toolkit"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]