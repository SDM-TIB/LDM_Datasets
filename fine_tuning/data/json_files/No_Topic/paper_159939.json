[
    {
        "dcterms:creator": [
            "Fisher Yu",
            "Haofeng Chen",
            "Xin Wang",
            "Wenqi Xian",
            "Yingying Chen",
            "Fangchen Liu",
            "Vashisht Madhavan",
            "Trevor Darrell"
        ],
        "dcterms:description": "BDD100K is the largest driving video dataset with 100K videos and 10 tasks to evaluate image recognition algorithms on autonomous driving. It possesses geographic, environmental, and weather diversity, useful for training models that are less likely to be surprised by new conditions.",
        "dcterms:title": "BDD100K",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://bdd-data.berkeley.edu",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Driving videos",
            "Multitask learning",
            "Image recognition",
            "Diversity",
            "Annotations"
        ],
        "dcat:landingPage": "https://bdd-data.berkeley.edu",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Image tagging",
            "Lane detection",
            "Drivable area segmentation",
            "Road object detection",
            "Semantic segmentation",
            "Instance segmentation",
            "Multi-object detection tracking",
            "Multi-object segmentation tracking",
            "Domain adaptation",
            "Imitation learning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Cordts",
            "M. Omran",
            "S. Ramos",
            "T. Rehfeld",
            "M. Enzweiler",
            "R. Benenson",
            "U. Franke",
            "S. Roth",
            "B. Schiele"
        ],
        "dcterms:description": "Cityscapes provides instance-level semantic segmentation on sampled frames of videos collected by their own vehicle, focusing on urban street scenes.",
        "dcterms:title": "Cityscapes",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Urban Scene Understanding"
        ],
        "dcat:keyword": [
            "Urban scenes",
            "Semantic segmentation",
            "Instance segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Geiger",
            "P. Lenz",
            "C. Stiller",
            "R. Urtasun"
        ],
        "dcterms:description": "KITTI is a dataset that provides data of multiple sources such as LiDAR scanned points, focusing on various tasks in the context of autonomous driving.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "LiDAR",
            "Object detection",
            "Tracking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object detection",
            "Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "M. Aly"
        ],
        "dcterms:description": "Caltech Lanes Dataset focuses on real-time detection of lane markers in urban streets, providing a limited number of images for lane marking tasks.",
        "dcterms:title": "Caltech Lanes Dataset",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Lane Detection"
        ],
        "dcat:keyword": [
            "Lane marking",
            "Urban streets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Lane marking detection"
        ]
    },
    {
        "dcterms:creator": [
            "T. Wu",
            "A. Ranganathan"
        ],
        "dcterms:description": "Road Marking Dataset provides images labeled in various classes of lane markings, focusing on road marking detection and recognition.",
        "dcterms:title": "Road Marking Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Lane Detection"
        ],
        "dcat:keyword": [
            "Road markings",
            "Detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Road marking detection"
        ]
    },
    {
        "dcterms:creator": [
            "S. Lee",
            "J. Kim",
            "J. S. Yoon",
            "S. Shin",
            "O. Bailo",
            "N. Kim",
            "T.-H. Lee",
            "H. S. Hong",
            "S.-H. Han",
            "I. S. Kweon"
        ],
        "dcterms:description": "VPGNet is a dataset that focuses on vanishing point guided network for lane and road marking detection and recognition.",
        "dcterms:title": "VPGNet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Lane Detection"
        ],
        "dcat:keyword": [
            "Vanishing point",
            "Lane marking detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Lane marking detection"
        ]
    },
    {
        "dcterms:creator": [
            "A. Milan",
            "L. Leal-Taixé",
            "I. Reid",
            "S. Roth",
            "K. Schindler"
        ],
        "dcterms:description": "MOT17 is a benchmark for multi-object tracking, providing a dataset for evaluating tracking algorithms.",
        "dcterms:title": "MOT17",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking"
        ],
        "dcat:keyword": [
            "Tracking",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-object tracking"
        ]
    },
    {
        "dcterms:creator": [
            "P. Sun",
            "H. Kretzschmar",
            "X. Dotiwalla",
            "A. Chouard",
            "V. Patnaik",
            "P. Tsui",
            "J. Guo",
            "Y. Zhou",
            "Y. Chai",
            "B. Caine"
        ],
        "dcterms:description": "Waymo Open Dataset focuses on scalability in perception for autonomous driving, providing a large-scale dataset for various tasks.",
        "dcterms:title": "Waymo Open Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Perception",
            "Autonomous driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Perception tasks"
        ]
    },
    {
        "dcterms:creator": [
            "G. Neuhold",
            "T. Ollmann",
            "S. R. Bul`o",
            "P. Kontschieder"
        ],
        "dcterms:description": "Mapillary Vistas dataset provides fine-grained annotations for user-uploaded data, focusing on semantic understanding of street scenes.",
        "dcterms:title": "Mapillary Vistas",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Street scenes",
            "Semantic understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Abu-El-Haija",
            "N. Kothari",
            "J. Lee",
            "P. Natsev",
            "G. Toderici",
            "B. Varadarajan",
            "S. Vijayanarasimhan"
        ],
        "dcterms:description": "YouTube-8M is a large-scale video classification benchmark, providing a dataset for video classification tasks.",
        "dcterms:title": "YouTube-8M",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Classification"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video classification"
        ]
    },
    {
        "dcterms:creator": [
            "J. Pont-Tuset",
            "F. Perazzi",
            "S. Caelles",
            "P. Arbeláez",
            "A. Sorkine-Hornung",
            "L. Van Gool"
        ],
        "dcterms:description": "DAVIS 2017 is a challenge on video object segmentation, providing a dataset for evaluating segmentation algorithms.",
        "dcterms:title": "DAVIS 2017",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Object Segmentation"
        ],
        "dcat:keyword": [
            "Segmentation",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video object segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Xu",
            "L. Yang",
            "Y. Fan",
            "D. Yue",
            "Y. Liang",
            "J. Yang",
            "T. Huang"
        ],
        "dcterms:description": "YouTube VOS is a large-scale video object segmentation benchmark, providing a dataset for evaluating segmentation algorithms.",
        "dcterms:title": "YouTube VOS",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Object Segmentation"
        ],
        "dcat:keyword": [
            "Segmentation",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video object segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "F. Yu",
            "A. Seff",
            "Y. Zhang",
            "S. Song",
            "T. Funkhouser",
            "J. Xiao"
        ],
        "dcterms:description": "LSUN is a large-scale image dataset constructed using deep learning with human involvement, focusing on scene understanding.",
        "dcterms:title": "LSUN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Dataset"
        ],
        "dcat:keyword": [
            "Large-scale dataset",
            "Scene understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": []
    }
]