[
    {
        "dcterms:creator": [
            "Stanislaw Antol",
            "Aishwarya Agrawal",
            "Jiasen Lu",
            "Margaret Mitchell",
            "Dhruv Batra",
            "C Lawrence Zitnick",
            "Devi Parikh"
        ],
        "dcterms:description": "The VQA dataset consists of image-question pairs, where questions are open-ended and require understanding of the image context to answer.",
        "dcterms:title": "VQA dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image-question pairs",
            "Open-ended questions",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "The MS COCO dataset contains images with annotations for object detection, segmentation, and captioning, providing a rich set of images for various computer vision tasks.",
        "dcterms:title": "MS COCO dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object recognition",
            "Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Yash Goyal",
            "Tejas Khot",
            "Douglas Summers-Stay",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "The VQA v2.0 dataset is an improved version of the original VQA dataset, designed to reduce bias and enhance the role of image understanding in visual question answering.",
        "dcterms:title": "VQA v2.0 dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image understanding",
            "Reduced bias",
            "Open-ended questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v2.0",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]