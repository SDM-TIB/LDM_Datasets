[
    {
        "dcterms:creator": [
            "Gedas Bertasius",
            "Hyun Soo Park",
            "Stella X. Yu",
            "Jianbo Shi"
        ],
        "dcterms:description": "A dataset containing first-person RGBD images annotated with important object labels, used for detecting important objects in first-person videos.",
        "dcterms:title": "First-Person Important Object RGBD Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "First-person videos",
            "RGBD images",
            "Object detection",
            "Unsupervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Yin Li",
            "Zhefan Ye",
            "James M. Rehg"
        ],
        "dcterms:description": "A dataset focused on egocentric actions, capturing various activities and gaze information, used for understanding actions in first-person videos.",
        "dcterms:title": "GTEA Gaze+ Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric actions",
            "Gaze tracking",
            "Activity recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Gedas Bertasius",
            "Hyun Soo Park",
            "Stella X. Yu",
            "Jianbo Shi"
        ],
        "dcterms:description": "A dataset used for first-person action-object detection, focusing on the relationship between actions and objects in egocentric videos.",
        "dcterms:title": "EgoNet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Egocentric videos",
            "Action-object detection",
            "Unsupervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "K. Simonyan",
            "A. Zisserman"
        ],
        "dcterms:description": "A dataset for large-scale image recognition, providing a benchmark for semantic segmentation tasks.",
        "dcterms:title": "Pascal VOC Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1409.1556",
        "dcat:theme": [
            "Computer Vision",
            "Image Segmentation"
        ],
        "dcat:keyword": [
            "Image recognition",
            "Semantic segmentation",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Segmentation"
        ]
    }
]