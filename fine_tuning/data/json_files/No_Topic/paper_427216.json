[
    {
        "dcterms:creator": [
            "K. Grauman",
            "A. Westbury",
            "E. Byrne",
            "Z. Chavis",
            "A. Furnari",
            "R. Girdhar",
            "J. Hamburger",
            "H. Jiang",
            "M. Liu",
            "X. Liu"
        ],
        "dcterms:description": "The Ego4D NLQ dataset is designed for locating temporal windows in videos that best answer natural language queries, focusing on egocentric video understanding.",
        "dcterms:title": "Ego4D NLQ",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Egocentric video",
            "Natural language queries",
            "Temporal localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Temporal localization",
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xiao",
            "X. Shang",
            "A. Yao",
            "T.S. Chua"
        ],
        "dcterms:description": "NExT-QA is a video question answering benchmark that includes temporal, causal, and descriptive questions, requiring models to select the correct option from multiple choices.",
        "dcterms:title": "NExT-QA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Video QA",
            "Temporal reasoning",
            "Causal reasoning",
            "Descriptive reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "K. Mangalam",
            "R. Akshulakov",
            "J. Malik"
        ],
        "dcterms:description": "EgoSchema is a diagnostic benchmark focusing on complex questions about long-form videos, requiring models to reason about video-level activities and interactions.",
        "dcterms:title": "EgoSchema",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Long-form video",
            "Complex reasoning",
            "Video question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering",
            "Reasoning"
        ]
    }
]