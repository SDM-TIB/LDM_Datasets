[
    {
        "dcterms:creator": [
            "Natalie Holz",
            "Pauline Larrouy-Maestri",
            "David Poeppel"
        ],
        "dcterms:description": "The Variably Intense Vocalizations of Affect and Emotion Corpus (VOC-C) is used for classifying the expression of six different emotions through non-verbal vocal expressions.",
        "dcterms:title": "Variably Intense Vocalizations of Affect and Emotion Corpus (VOC-C)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Vocalization Analysis"
        ],
        "dcat:keyword": [
            "Vocal expressions",
            "Emotional states",
            "Non-verbal communication"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Sebastian P. Bayerl",
            "Florian Hönig",
            "Joëlle Reister",
            "Korbinian Riedhammer"
        ],
        "dcterms:description": "The Kassel State of Fluency Corpus (KSF-C) is used for monitoring stuttering, featuring segments of speech annotated for various disfluency phenomena.",
        "dcterms:title": "Kassel State of Fluency Corpus (KSF-C)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Disorder Analysis",
            "Stuttering Detection"
        ],
        "dcat:keyword": [
            "Stuttering",
            "Speech segments",
            "Disfluency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Classification"
        ]
    },
    {
        "dcterms:creator": [
            "A. Mallol-Ragolta",
            "A. Semertzidou",
            "M. Pateraki",
            "B. Schuller"
        ],
        "dcterms:description": "The Human Activity Recognition Corpus (HAR-C) is a multimodal dataset collected with smartwatch sensor data for recognizing various physical activities.",
        "dcterms:title": "Human Activity Recognition Corpus (HAR-C)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Activity Recognition",
            "Wearable Technology"
        ],
        "dcat:keyword": [
            "Smartwatch data",
            "Physical activity",
            "Sensor measurements"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "I. Kiskin",
            "M. Sinka",
            "A.D. Cobb",
            "W. Rafique",
            "L. Wang",
            "D. Zilli",
            "B. Gutteridge",
            "R. Dam",
            "T. Marinos",
            "Y. Li",
            "D. Msaky"
        ],
        "dcterms:description": "The Mosquito Corpus (MOS-C) is a large-scale audio database consisting of over 20 hours of mosquito flight recordings for detecting mosquito events.",
        "dcterms:title": "Mosquito Corpus (MOS-C)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sound Event Detection",
            "Ecology"
        ],
        "dcat:keyword": [
            "Mosquito detection",
            "Audio recordings",
            "Sound events"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound Event Detection"
        ]
    }
]