To extract datasets from the research paper titled "Channel Exchanging Networks for Multimodal and Multitask Dense Image Prediction" by Yikai Wang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the validity of the proposed method is tested by extensive experiments on semantic segmentation via RGB-D data and image translation through multi-domain input. This indicates that datasets are likely involved.

Next, I will focus on the **experiments section** (section 4), where the authors typically describe the datasets used for their evaluations. In this section, they mention two specific datasets for semantic segmentation:

1. **NYUDv2 Dataset**: This dataset is used for indoor semantic segmentation and contains RGB-D images. The authors specify that they follow the standard settings and adopt a specific train/test split.

2. **SUN RGB-D Dataset**: Another dataset mentioned for semantic segmentation, which contains a large number of RGB-D images and is noted for its challenging nature.

I will also check the **image-to-image translation** subsection within the experiments section, where they refer to the **Taskonomy Dataset**. This dataset includes multimodal representations of indoor scenes and is used for various image translation tasks.

After identifying these datasets, I will look at the **References section** to find the full citations for each dataset:

- For the **NYUDv2 Dataset**, the citation is:
  > Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. *Indoor segmentation and support inference from RGBD images*. In Proceedings of the European Conference on Computer Vision (ECCV), 2012.

- For the **SUN RGB-D Dataset**, the citation is:
  > Sanja F. S. Song, Shai Avidan, and J. Xiao. *SUN RGB-D: A RGB-D scene understanding benchmark suite*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2015.

- For the **Taskonomy Dataset**, the citation is:
  > A. R. Zamir, A. Sax, W. B. Shen, L. J. Guibas, J. Malik, and S. Savarese. *Taskonomy: Disentangling task transfer learning*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further use or processing.