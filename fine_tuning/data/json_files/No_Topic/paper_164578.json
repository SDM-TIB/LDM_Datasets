[
    {
        "dcterms:creator": [
            "Jean Carletta",
            "Simone Ashby",
            "Sebastien Bourban",
            "Mike Flynn",
            "Mael Guillemot",
            "Thomas Hain",
            "Jaroslav Kadlec",
            "Vasilis Karaiskos",
            "Wessel Kraaij",
            "Melissa Kronenthal"
        ],
        "dcterms:description": "The AMI meeting corpus provides 100 hours of meeting conversations recorded by individual headset microphones and single distant microphones, useful for training and evaluating speech recognition systems.",
        "dcterms:title": "AMI corpus",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Meeting conversations",
            "Speech recognition",
            "Distant speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Mirco Ravanelli",
            "Philemon Brakel",
            "Maurizio Omologo",
            "Yoshua Bengio"
        ],
        "dcterms:description": "CHiME4 corpus is used for distant speech recognition tasks, providing a challenging dataset with various noise conditions.",
        "dcterms:title": "CHiME4",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1703.08002",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Distant speech recognition",
            "Noise conditions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Konstantin Markov",
            "Tomoko Matsui"
        ],
        "dcterms:description": "Aurora2 corpus is utilized for robust speech recognition, providing a dataset with various noise levels and distortions.",
        "dcterms:title": "Aurora2",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Robust speech recognition",
            "Noise levels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Povey",
            "Arnab Ghoshal",
            "Gilles Boulianne",
            "Lukas Burget",
            "Ondrej Glembek",
            "Nagendra Goel",
            "Mirko Hannemann",
            "Petr Motlicek",
            "Yanmin Qian",
            "Petr Schwarz",
            "Jan Silovsky",
            "Georg Stemmer",
            "Karel Vesely"
        ],
        "dcterms:description": "Kaldi is a toolkit for speech recognition that provides tools for training and decoding speech recognition models.",
        "dcterms:title": "Kaldi",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "IEEE Catalog No.: CFP11SRW-USB",
        "dcat:theme": [
            "Speech Recognition",
            "Toolkit"
        ],
        "dcat:keyword": [
            "Speech recognition toolkit",
            "Model training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Dong Yu",
            "Adam Eversole",
            "Mike Seltzer",
            "Kaisheng Yao",
            "Zhiheng Huang",
            "Brian Guenter",
            "Oleksii Kuchaiev",
            "Yu Zhang",
            "Frank Seide",
            "Huaming Wang"
        ],
        "dcterms:description": "Microsoft Cognitive Toolkit (CNTK) is a deep learning toolkit that provides tools for building and training neural networks.",
        "dcterms:title": "Microsoft Cognitive Toolkit (CNTK)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "research.microsoft.com/apps/pubs",
        "dcat:theme": [
            "Deep Learning",
            "Toolkit"
        ],
        "dcat:keyword": [
            "Deep learning toolkit",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Deep Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Xavier Anguera",
            "Chuck Wooters",
            "Javier Hernando"
        ],
        "dcterms:description": "BeamformIt is a tool for acoustic beamforming used in speaker diarization of meetings.",
        "dcterms:title": "BeamformIt",
        "dcterms:issued": "2007",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Processing",
            "Speaker Diarization"
        ],
        "dcat:keyword": [
            "Acoustic beamforming",
            "Speaker diarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Speaker Diarization"
        ]
    }
]