[
    {
        "dcterms:creator": [
            "J. Ross Quinlan"
        ],
        "dcterms:description": "The Gini index is a measure of statistical dispersion intended to represent the income inequality or wealth inequality within a nation or a social group.",
        "dcterms:title": "Gini index",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Statistics",
            "Economics"
        ],
        "dcat:keyword": [
            "Gini index",
            "Inequality measure",
            "Statistical dispersion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Leo Breiman"
        ],
        "dcterms:description": "Empirical entropy is a measure of the uncertainty associated with a random variable, indicating the level of unpredictability in the data.",
        "dcterms:title": "Empirical entropy",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Theory",
            "Statistics"
        ],
        "dcat:keyword": [
            "Entropy",
            "Uncertainty",
            "Information measure"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Don Coppersmith",
            "Se June Hong",
            "Jonathan RM Hosking"
        ],
        "dcterms:description": "Frequency weighted concave impurity is a class of impurity functions used in decision trees that considers the frequency of occurrences of nominal attributes.",
        "dcterms:title": "Frequency weighted concave impurity",
        "dcterms:issued": "1999",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Mining",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Impurity function",
            "Decision trees",
            "Nominal attributes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "David Burshtein",
            "Vincent Della Pietra",
            "Dimitri Kanevsky",
            "Arthur Nadas"
        ],
        "dcterms:description": "Minimum impurity partitions refer to partitions of a dataset that minimize a given impurity measure, facilitating optimal decision-making in classification tasks.",
        "dcterms:title": "Minimum impurity partitions",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Statistics",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Partitioning",
            "Impurity minimization",
            "Decision trees"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "DJ Strouse",
            "David J Schwab"
        ],
        "dcterms:description": "The deterministic information bottleneck is a method that seeks to find an optimal representation of data that retains the most relevant information while minimizing the output entropy.",
        "dcterms:title": "Deterministic Information Bottleneck",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Theory",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Information bottleneck",
            "Data representation",
            "Entropy minimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Sergio Verdu"
        ],
        "dcterms:description": "Channel capacity per unit cost refers to the maximum rate at which information can be reliably transmitted over a communication channel, normalized by the cost associated with transmission.",
        "dcterms:title": "Channel capacity per unit cost",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Theory",
            "Communications"
        ],
        "dcat:keyword": [
            "Channel capacity",
            "Transmission cost",
            "Information theory"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]