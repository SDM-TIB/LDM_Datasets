[
    {
        "dcterms:creator": [
            "C Brown Duane"
        ],
        "dcterms:description": "The Brown-Conrady distortion model is a widely used model for characterizing radial and tangential distortions in camera images, particularly for close-range camera calibration.",
        "dcterms:title": "Brown-Conrady distortion model",
        "dcterms:issued": "1971",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Camera Calibration",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Radial distortion",
            "Tangential distortion",
            "Camera calibration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    },
    {
        "dcterms:creator": [
            "J. Kannala",
            "S.S. Brandt"
        ],
        "dcterms:description": "The Kannala-Brandt distortion model adapts lens distortion modeling for wide-angle, ultra wide-angle, and fish-eye lenses, providing a smoother parameterization based on the incidence angle of light.",
        "dcterms:title": "Kannala-Brandt distortion model",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Camera Calibration",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Wide-angle lenses",
            "Fish-eye lenses",
            "Radial distortion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    },
    {
        "dcterms:creator": [
            "Chris Harris",
            "Mike Stephens"
        ],
        "dcterms:description": "Harris corner detection is a method for detecting corners in images, which can be used for various applications including image rectification.",
        "dcterms:title": "Harris corner detection",
        "dcterms:issued": "1988",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Feature Detection"
        ],
        "dcat:keyword": [
            "Corner detection",
            "Image features"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature detection"
        ]
    },
    {
        "dcterms:creator": [
            "Jianbo Shi"
        ],
        "dcterms:description": "The Shi-Tomasi corner detection method is an enhancement of the Harris corner detection, providing better performance in detecting good features to track.",
        "dcterms:title": "Shi-Tomasi corner detection",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Feature Detection"
        ],
        "dcat:keyword": [
            "Corner detection",
            "Feature tracking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature detection"
        ]
    },
    {
        "dcterms:creator": [
            "David G Lowe"
        ],
        "dcterms:description": "SIFT (Scale-Invariant Feature Transform) is a feature detection method that extracts distinctive image features from scale-invariant keypoints, useful for matching and recognition tasks.",
        "dcterms:title": "SIFT feature points",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Feature Detection"
        ],
        "dcat:keyword": [
            "Feature detection",
            "Keypoints",
            "Image matching"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature matching"
        ]
    },
    {
        "dcterms:creator": [
            "Herbert Bay",
            "Tinne Tuytelaars",
            "Luc Van Gool"
        ],
        "dcterms:description": "SURF (Speeded Up Robust Features) is a robust feature detection method that is faster than SIFT and is used for object recognition and image registration.",
        "dcterms:title": "SURF feature points",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Feature Detection"
        ],
        "dcat:keyword": [
            "Feature detection",
            "Object recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Feature matching"
        ]
    },
    {
        "dcterms:creator": [
            "Richard O Duda",
            "Peter E Hart"
        ],
        "dcterms:description": "The Hough transform is a technique used to detect lines and curves in images, which can be applied in various image processing tasks.",
        "dcterms:title": "Hough transform",
        "dcterms:issued": "1972",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Feature Detection"
        ],
        "dcat:keyword": [
            "Line detection",
            "Curve detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Line detection"
        ]
    },
    {
        "dcterms:creator": [
            "Bruce D Lucas",
            "Takeo Kanade"
        ],
        "dcterms:description": "The Lucas-Kanade method is an optical flow technique used for image registration and motion tracking, particularly useful in video analysis.",
        "dcterms:title": "Lucas-Kanade method",
        "dcterms:issued": "1981",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Motion Tracking"
        ],
        "dcat:keyword": [
            "Optical flow",
            "Image registration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Motion tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Jiangpeng Rong",
            "Shiyao Huang",
            "Zeyu Shang",
            "Xianghua Ying"
        ],
        "dcterms:description": "This dataset involves the use of Convolutional Neural Networks (CNNs) for correcting radial lens distortion using synthesized images.",
        "dcterms:title": "Convolutional Neural Networks (CNNs) for radial lens distortion correction",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Radial distortion correction",
            "Convolutional Neural Networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    },
    {
        "dcterms:creator": [
            "Tejas S Borkar",
            "Lina J Karam"
        ],
        "dcterms:description": "Deepcorrect is a method for correcting deep neural network models against image distortions, enhancing the robustness of models in distorted environments.",
        "dcterms:title": "Deepcorrect",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Image Processing"
        ],
        "dcat:keyword": [
            "DNN correction",
            "Image distortions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Model correction"
        ]
    },
    {
        "dcterms:creator": [
            "Yongjie Shi",
            "Danfeng Zhang",
            "Jingsi Wen",
            "Xin Tong",
            "Xianghua Ying",
            "Hongbin Zha"
        ],
        "dcterms:description": "This dataset focuses on radial lens distortion correction by adding a weight layer with inverted foveal models to convolutional neural networks.",
        "dcterms:title": "Radial lens distortion correction with weight layer",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Radial distortion correction",
            "Weight layer",
            "Convolutional Neural Networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    },
    {
        "dcterms:creator": [
            "Bruno Arsenali",
            "Prashanth Viswanath",
            "Jelena Novosel"
        ],
        "dcterms:description": "RotInvMTL is a rotation invariant multi-task network designed for fish-eye images, particularly for applications in autonomous driving.",
        "dcterms:title": "RotInvMTL",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Multi-task learning",
            "Fish-eye images",
            "Autonomous driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Yongle Li",
            "Maojun Zhang",
            "Yu Liu",
            "Zhihui Xiong"
        ],
        "dcterms:description": "This dataset presents a method for fish-eye distortion correction based on the midpoint circle algorithm, aimed at real-time applications.",
        "dcterms:title": "GAN for distortion rectification",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Fish-eye distortion",
            "Midpoint circle algorithm",
            "Real-time correction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    },
    {
        "dcterms:creator": [
            "Kang Liao",
            "Chunyu Lin",
            "Yao Zhao",
            "Moncef Gabbouj"
        ],
        "dcterms:description": "DR-GAN is a conditional generative adversarial network designed for automatic radial distortion rectification in real-time.",
        "dcterms:title": "DR-GAN",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Image Processing"
        ],
        "dcat:keyword": [
            "Radial distortion",
            "Generative adversarial network",
            "Real-time correction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Distortion correction"
        ]
    }
]