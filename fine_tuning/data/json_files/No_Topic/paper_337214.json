[
    {
        "dcterms:creator": [
            "A. Saxena",
            "M. Sun",
            "A. Y. Ng"
        ],
        "dcterms:description": "The Make3D dataset contains 534 outdoor images, with 400 images for training and 134 images for testing. The images have a resolution of 2272×1704 and depth maps with 55×305, which are resized to 512×512 for processing.",
        "dcterms:title": "Make3D",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "Outdoor images",
            "Depth maps",
            "Single image depth estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Geiger",
            "P. Lenz",
            "C. Stiller"
        ],
        "dcterms:description": "The KITTI depth dataset contains 42,382 rectified stereo pairs from 61 scenes, with images resized to 620×188 for model input. It is evaluated using various metrics including REL, SqRel, RMS, and accuracy thresholds.",
        "dcterms:title": "KITTI depth",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "Stereo pairs",
            "Rectified images",
            "Depth estimation metrics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Silberman",
            "D. Hoiem",
            "P. Kohli"
        ],
        "dcterms:description": "The NYU Depth v2 dataset consists of 464 indoor video scenes captured by a Microsoft Kinect camera, with images resized to 512×512 for model input. It is evaluated using six commonly used metrics.",
        "dcterms:title": "NYUv2",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "Indoor scenes",
            "RGBD images",
            "Depth estimation metrics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation"
        ]
    }
]