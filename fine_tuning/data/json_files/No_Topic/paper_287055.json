[
    {
        "dcterms:creator": [
            "M. Menze",
            "A. Geiger"
        ],
        "dcterms:description": "The KITTI dataset is a benchmark for evaluating visual odometry and SLAM, providing a diverse set of outdoor scenes captured from a moving vehicle, including various weather conditions and times of day.",
        "dcterms:title": "KITTI Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Autonomous Vehicles"
        ],
        "dcat:keyword": [
            "Depth estimation",
            "Visual odometry",
            "SLAM",
            "Outdoor scenes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation",
            "Visual Odometry"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Cabon",
            "N. Murray",
            "M. Humenberger"
        ],
        "dcterms:description": "Virtual KITTI is a synthetic dataset designed to mimic the KITTI dataset, providing a controlled environment for training and evaluating depth estimation algorithms without the variability of real-world data.",
        "dcterms:title": "Virtual KITTI Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Synthetic Data"
        ],
        "dcat:keyword": [
            "Depth estimation",
            "Synthetic dataset",
            "Autonomous vehicles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Silberman",
            "D. Hoiem",
            "P. Kohli",
            "R. Fergus"
        ],
        "dcterms:description": "The NYU v2 dataset is a large-scale dataset for indoor scene understanding, providing RGB-D images with pixel-wise annotations for depth and semantic segmentation.",
        "dcterms:title": "NYU v2 Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Indoor Scene Understanding"
        ],
        "dcat:keyword": [
            "Depth estimation",
            "RGB-D images",
            "Indoor scenes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation",
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "J.-W. Bian",
            "H. Zhan",
            "N. Wang",
            "T.-J. Chin",
            "C. Shen",
            "I. Reid"
        ],
        "dcterms:description": "The NYU v2 dataset is a large-scale dataset for indoor scene understanding, providing RGB-D images with pixel-wise annotations for depth and semantic segmentation.",
        "dcterms:title": "NYU v2 Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Indoor Scene Understanding"
        ],
        "dcat:keyword": [
            "Depth estimation",
            "RGB-D images",
            "Indoor scenes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Depth Estimation",
            "Semantic Segmentation"
        ]
    }
]