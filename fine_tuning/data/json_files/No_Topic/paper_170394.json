[
    {
        "dcterms:creator": [
            "P. Lucey",
            "J. Cohn",
            "T. Kanade",
            "J. Saragih",
            "Z. Ambadar",
            "I. Matthews"
        ],
        "dcterms:description": "The Extended Cohn-Kanade database (CK+) contains 593 facial activity videos from 210 subjects with various ethnicities. The peak frames are FACS coded with 30 facial action units. 28 facial landmarks are manually labeled on the peak frames from each sequence.",
        "dcterms:title": "Extended Cohn-Kanade database (CK+)",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Facial activity videos",
            "Facial action units",
            "Facial landmarks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Facial Action Unit Recognition",
            "Facial Landmark Detection"
        ]
    },
    {
        "dcterms:creator": [
            "G. McKeown",
            "M. Valstar",
            "R. Cowie",
            "M. Pantic",
            "M. Schroder"
        ],
        "dcterms:description": "The SEMAINE database contains annotated multimodal records of emotionally colored conversations between a person and a limited agent. The dataset includes 180 images from 8 sessions where the emotionally related facial activity of subjects is naturally induced by the agent.",
        "dcterms:title": "SEMAINE database",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Interaction"
        ],
        "dcat:keyword": [
            "Emotionally colored conversations",
            "Facial activity",
            "Human-agent interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Facial Action Unit Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Valstar",
            "B. Jiang",
            "M. Mehu",
            "M. Pantic",
            "K. Scherer"
        ],
        "dcterms:description": "The FER A database contains 87 action unit related sequences of 7 actors, with conversion also involved. 50 action unit annotations for each frame are provided, and 28 facial landmarks are manually annotated on 260 frames for the experiments.",
        "dcterms:title": "FER A database",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Action Unit Detection"
        ],
        "dcat:keyword": [
            "Action unit sequences",
            "Facial landmarks",
            "Facial expression analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Facial Action Unit Recognition",
            "Facial Landmark Detection"
        ]
    }
]