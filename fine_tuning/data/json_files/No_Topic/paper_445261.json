[
    {
        "dcterms:creator": [
            "Xiaoqing Ellen Tan",
            "Prangthip Hansanti",
            "Carleigh Wood",
            "Bokai Yu",
            "Christophe Ropers",
            "Marta R. Costa-jussà"
        ],
        "dcterms:description": "The MASSIVE MULTILINGUAL HOLISTICBIAS (MMHB) dataset consists of approximately 6 million sentences representing 13 demographic axes, created to evaluate and mitigate demographic biases in multilingual language generation systems.",
        "dcterms:title": "MASSIVE MULTILINGUAL HOLISTICBIAS (MMHB)",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Demographic Bias",
            "Multilingual NLP"
        ],
        "dcat:keyword": [
            "Bias evaluation",
            "Language generation",
            "Demographic representation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias analysis",
            "Machine translation evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Eric M. Smith",
            "Melissa Hall",
            "Melanie Kambadur",
            "Eleonora Presani",
            "Adina Williams"
        ],
        "dcterms:description": "HOLISTICBIAS is an English-only demographic templated dataset that combines patterns and descriptors to generate hundreds of thousands of unique sentences for bias analysis in language models.",
        "dcterms:title": "HOLISTICBIAS",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "https://aclanthology.org/2022.emnlp-main.625",
        "dcat:theme": [
            "Bias Measurement",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Demographic bias",
            "Language models",
            "Template dataset"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.emnlp-main.625",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias detection",
            "Language generation"
        ]
    },
    {
        "dcterms:creator": [
            "Marta R. Costa-jussà",
            "Pierre Andrews",
            "Eric Smith",
            "Prangthip Hansanti",
            "Christophe Ropers",
            "Elahe Kalbassi",
            "Carleigh Wood"
        ],
        "dcterms:description": "MULTILINGUALHOLISTICBIAS is an extension of HOLISTICBIAS that includes multilingual translations of demographic descriptors and patterns to evaluate gender bias in machine translation models.",
        "dcterms:title": "MULTILINGUALHOLISTICBIAS",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2023.emnlp-main.874",
        "dcat:theme": [
            "Multilingual Bias Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Gender bias",
            "Translation evaluation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.emnlp-main.874",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias analysis",
            "Machine translation evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Boxin Wang",
            "Weixin Chen",
            "Hengzhi Pei",
            "Chulin Xie",
            "Mintong Kang",
            "Chenhui Zhang",
            "Chejian Xu",
            "Ritik Dutta",
            "Rylan Schaeffer",
            "Sang Truong",
            "Simran Arora",
            "Mantas Mazeika",
            "Dan Hendrycks",
            "Zinan Lin",
            "Yu Cheng",
            "Sanmi Koyejo",
            "Dawn Song",
            "Bo Li"
        ],
        "dcterms:description": "DecodingTrust is a comprehensive assessment framework for evaluating the trustworthiness of GPT models, focusing on various aspects including bias and demographic representation.",
        "dcterms:title": "DecodingTrust",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Trustworthiness Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Trust evaluation",
            "Language models",
            "Bias assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Trust evaluation",
            "Bias analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Benjamin Muller",
            "Belen Alastruey",
            "Prangthip Hansanti",
            "Elahe Kalbassi",
            "Christophe Ropers",
            "Eric Smith",
            "Adina Williams",
            "Luke Zettlemoyer",
            "Pierre Andrews",
            "Marta R. Costa-jussà"
        ],
        "dcterms:description": "The Gender-GAP pipeline is a gender-aware polyglot pipeline designed for gender characterization across 55 languages, facilitating the study of gender representation in machine translation datasets.",
        "dcterms:title": "Gender-GAP",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2023.wmt-1.48",
        "dcat:theme": [
            "Gender Representation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Gender characterization",
            "Multilingual datasets",
            "Machine translation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.wmt-1.48",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Gender analysis",
            "Representation study"
        ]
    },
    {
        "dcterms:creator": [
            "NLLB Team",
            "Marta R. Costa-jussà",
            "James Cross",
            "Onur Çelebi",
            "Maha Elbayad",
            "Kenneth Heafield",
            "Kevin Heffernan",
            "Elahe Kalbassi",
            "Janice Lam",
            "Daniel Licht",
            "Jean Maillard",
            "Anna Sun",
            "Skyler Wang",
            "Guillaume Wenzek",
            "Al Youngblood",
            "Bapi Akula",
            "Loic Barrault",
            "Gabriel Mejia Gonzalez",
            "Prangthip Hansanti",
            "John Hoffman",
            "Semarley Jarrett",
            "Kaushik Ram Sadagopan",
            "Dirk Rowe",
            "Shannon Spruit",
            "Chau Tran",
            "Pierre Andrews",
            "Necip Fazil Ayan",
            "Shruti Bhosale",
            "Sergey Edunov",
            "Angela Fan",
            "Cynthia Gao",
            "Vedanuj Goswami",
            "Francisco Guzmán",
            "Philipp Koehn",
            "Alexandre Mourachko",
            "Christophe Ropers",
            "Safiyyah Saleem",
            "Holger Schwenk",
            "Jeff Wang"
        ],
        "dcterms:description": "FLORES-200 is a dataset aimed at scaling human-centered machine translation, ensuring that no language is left behind in the translation process.",
        "dcterms:title": "FLORES-200",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2207.04672",
        "dcat:theme": [
            "Machine Translation",
            "Language Diversity"
        ],
        "dcat:keyword": [
            "Human-centered translation",
            "Language coverage",
            "Multilingual datasets"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2207.04672",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine translation",
            "Language evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Jwala Dhamala",
            "Tony Sun",
            "Varun Kumar",
            "Satyapriya Krishna",
            "Yada Pruksachatkun",
            "Kai-Wei Chang",
            "Rahul Gupta"
        ],
        "dcterms:description": "BOLD is a dataset and metrics designed for measuring biases in open-ended language generation, providing insights into the biases present in generated text.",
        "dcterms:title": "BOLD",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Measurement",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Open-ended generation",
            "Bias metrics",
            "Language evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias analysis",
            "Language generation"
        ]
    },
    {
        "dcterms:creator": [
            "Marta R. Costa-jussà",
            "Mariano Coria Meglioli",
            "Pierre Andrews",
            "David Dale",
            "Prangthip Hansanti",
            "Elahe Kalbassi",
            "Alex Mourachko",
            "Christophe Ropers",
            "Carleigh Wood"
        ],
        "dcterms:description": "MuTox is a universal multilingual audio-based toxicity dataset and zero-shot detector, aimed at assessing toxicity in multilingual contexts.",
        "dcterms:title": "MuTox",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Assessment",
            "Multilingual NLP"
        ],
        "dcat:keyword": [
            "Audio toxicity",
            "Zero-shot detection",
            "Multilingual datasets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Toxicity detection",
            "Language evaluation"
        ]
    }
]