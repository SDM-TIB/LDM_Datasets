To extract the datasets mentioned in the paper titled "Video Summarization Using Fully Convolutional Sequence Networks" by Mrigank Rochan et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets that are explicitly mentioned. The abstract indicates that the authors conducted extensive experiments on two benchmark datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4.1 (Datasets)**, where the authors explicitly describe the datasets used for their experiments. Here, they mention:

1. **SumMe Dataset**: This dataset consists of 25 videos covering various events, with lengths ranging from 1.5 to 6.5 minutes. It is specifically designed for video summarization tasks.

2. **TVSum Dataset**: This dataset includes 50 YouTube videos categorized into 10 different categories, with video lengths typically between 1 to 5 minutes. It is also tailored for video summarization research.

Additionally, the authors mention using supplementary datasets for training, specifically:

- **YouTube Dataset**: This dataset contains various videos, including news, sports, and cartoons, used to augment the training data.

- **Open Video Project (OVP) Dataset**: This dataset includes videos of different genres, also used for training augmentation.

Now, I will check the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution and to provide context for future researchers.

- For the **SumMe Dataset**, the citation is:
  > Gygli, M., Grabner, H., Riemenschneider, H., & Van Gool, L. (2014). Creating summaries from user videos. In *European Conference on Computer Vision*.

- For the **TVSum Dataset**, the citation is:
  > Song, Y., Vallmitjana, J., Stent, A., & Jaimes, A. (2015). TVSum: Summarizing web videos using titles. In *IEEE Conference on Computer Vision and Pattern Recognition*.

- For the **YouTube Dataset**, the citation is:
  > De Avila, S.E.F., Lopes, A.P.B., da Luz, A., & de Albuquerque AraÃºjo, A. (2011). Vsumm: A mechanism designed to produce static video summaries and a novel evaluation method. *Pattern Recognition Letters*.

- For the **Open Video Project (OVP) Dataset**, the citation is:
  > Open Video Project. (n.d.). Retrieved from https://open-video.org/

With this information gathered, I will compile the dataset entries, ensuring that each dataset is accurately represented with its full citation for clarity and proper referencing.