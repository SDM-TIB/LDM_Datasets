To extract datasets from the research paper titled "SEMBED: Semantic Embedding of Egocentric Action Videos" by Michael Wray et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and results sections** to identify any datasets mentioned. The abstract indicates that the authors tested their method on a dataset of 1,225 freely annotated egocentric videos, which suggests that a dataset is indeed present.

Next, I will focus on **section 4 (Datasets, Experiments and Results)**, where the authors explicitly list the datasets used in their experiments. They mention three publicly available datasets that focus on object interactions from egocentric videos:

1. **CMU Multimodal Activity (CMU-MMAC) Dataset**: This dataset is referenced as [7] in the paper. The authors describe it as containing 516 segments of object interactions, with annotations provided for the activity of making brownies.

2. **GTEA+ Dataset**: Cited as [9], this dataset includes 3,371 segments and allows for verb-noun pairings in annotations. The authors note that they sampled 1,000 videos due to the dataset's size.

3. **BEOID Dataset**: This dataset is referenced as [6] and contains 1,225 segments with free annotations. The authors explain that they annotated this dataset to allow for variability in verb choices.

Now, I will check the **References section** to retrieve the full citations for each dataset:

- For the **CMU Multimodal Activity (CMU-MMAC) Dataset**, the citation is:
  > De La Torre, F., Hodgins, J., Bargteil, A., Martin, X., Macey, J., Collado, A., Beltran, P. *Guide to the Carnegie Mellon University Multimodal Activity (CMU-MMAC) database*. Robotics Institute, 2008.

- For the **GTEA+ Dataset**, the citation is:
  > Fathi, A., Li, Y., Rehg, J. *Learning to recognize daily actions using gaze*. In: ECCV, 2012.

- For the **BEOID Dataset**, the citation is:
  > Damen, D., Leelasawassuk, T., Haines, O., Calway, A., Mayol-Cuevas, W. *You-do, I-learn: Discovering task relevant objects and their modes of interaction from multi-user egocentric video*. In: BMVC, 2014.

After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described with its full citation, ready for further processing or review.