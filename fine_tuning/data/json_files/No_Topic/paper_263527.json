[
    {
        "dcterms:creator": [
            "F. Schroff",
            "D. Kalenichenko",
            "J. Philbin"
        ],
        "dcterms:description": "A dataset used for training and evaluating facial recognition systems, known for its high accuracy in identifying individuals.",
        "dcterms:title": "LFW (Labeled Faces in the Wild)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Face recognition",
            "Facial identification",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Face Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Su",
            "K. Sakurai",
            "D. Vasconcellos Vargas"
        ],
        "dcterms:description": "A dataset used to demonstrate the effectiveness of adversarial attacks on deep neural networks by altering a single pixel in an image.",
        "dcterms:title": "One-Pixel Attack",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Machine Learning"
        ],
        "dcat:keyword": [
            "Adversarial attack",
            "Deep learning",
            "Image classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "T. Yamada",
            "S. Gohshi",
            "I. Echizen"
        ],
        "dcterms:description": "A dataset that explores the use of invisible noise signals to prevent privacy invasion through face recognition from camera images.",
        "dcterms:title": "IR (Infrared)",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Privacy Protection",
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Infrared light",
            "Privacy invasion",
            "Face recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Face Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Z.-A. Zhu",
            "Y.-Z. Lu",
            "C.-K. Chiang"
        ],
        "dcterms:description": "A dataset that investigates the generation of adversarial examples through makeup attacks on face recognition systems.",
        "dcterms:title": "Makeup Attacks on Face Recognition",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Machine Learning",
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Adversarial examples",
            "Makeup attacks",
            "Face recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Face Recognition"
        ]
    }
]