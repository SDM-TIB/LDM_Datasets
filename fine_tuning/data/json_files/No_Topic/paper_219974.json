[
    {
        "dcterms:creator": [
            "A. Arlotto",
            "I. Gurvich"
        ],
        "dcterms:description": "The Online Stochastic Knapsack problem involves a controller with an initial resource budget who must decide whether to accept or reject sequentially arriving requests to maximize rewards while satisfying budget constraints.",
        "dcterms:title": "Online Stochastic Knapsack",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Optimization",
            "Resource Allocation"
        ],
        "dcat:keyword": [
            "Knapsack problem",
            "Online decision making",
            "Budget constraints"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing rewards",
            "Decision making under uncertainty"
        ]
    },
    {
        "dcterms:creator": [
            "A. Gupta",
            "V. Nagarajan"
        ],
        "dcterms:description": "Online Probing allows a controller to probe requests to observe their realized rewards before deciding to accept or reject them, introducing a trade-off between resource and probing budgets.",
        "dcterms:title": "Online Probing",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Optimization",
            "Resource Allocation"
        ],
        "dcat:keyword": [
            "Probing",
            "Decision making",
            "Budget constraints"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing rewards",
            "Decision making under uncertainty"
        ]
    },
    {
        "dcterms:creator": [
            "S. Jasin"
        ],
        "dcterms:description": "Dynamic Pricing involves posting prices for sequential customers based on their private valuations, with the goal of maximizing revenue while managing inventory.",
        "dcterms:title": "Dynamic Pricing",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Revenue Management",
            "Dynamic Pricing"
        ],
        "dcat:keyword": [
            "Pricing strategies",
            "Customer valuation",
            "Revenue maximization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing revenue",
            "Pricing optimization"
        ]
    },
    {
        "dcterms:creator": [
            "S. Bubeck",
            "N. Cesa-Bianchi",
            "et al."
        ],
        "dcterms:description": "Knapsack with Distribution Learning involves learning the distribution of rewards from accepted items while making decisions on whether to accept or reject incoming requests.",
        "dcterms:title": "Knapsack with Distribution Learning",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Optimization",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Distribution learning",
            "Knapsack problem",
            "Decision making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning distributions",
            "Maximizing rewards"
        ]
    },
    {
        "dcterms:creator": [
            "A. Badanidiyuru",
            "J. Langford",
            "A. Slivkins"
        ],
        "dcterms:description": "Contextual Bandits with Knapsacks extend the bandit problem by incorporating resource constraints, where the controller must decide which items to accept based on contextual information.",
        "dcterms:title": "Contextual Bandits with Knapsacks",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Resource Allocation"
        ],
        "dcat:keyword": [
            "Contextual bandits",
            "Resource constraints",
            "Decision making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing rewards",
            "Decision making under uncertainty"
        ]
    },
    {
        "dcterms:creator": [
            "A. Vera",
            "S. Banerjee"
        ],
        "dcterms:description": "The Bayesian Prophet framework provides a low-regret approach for online decision making, allowing for adaptive pricing and allocation strategies.",
        "dcterms:title": "Bayesian Prophet",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Optimization",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Bayesian methods",
            "Online decision making",
            "Low-regret strategies"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision making under uncertainty",
            "Maximizing rewards"
        ]
    },
    {
        "dcterms:creator": [
            "S. Bubeck",
            "V. Perchet",
            "P. Rigollet"
        ],
        "dcterms:description": "Multi-armed Bandit Problems involve making sequential decisions to maximize rewards based on limited information about the distributions of rewards.",
        "dcterms:title": "Multi-armed Bandit Problems",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Bandit algorithms",
            "Sequential decision making",
            "Maximizing rewards"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing rewards",
            "Decision making under uncertainty"
        ]
    },
    {
        "dcterms:creator": [
            "M. Babaioff",
            "S. Dughmi",
            "R. Kleinberg",
            "A. Slivkins"
        ],
        "dcterms:description": "Dynamic Posted Pricing involves setting prices dynamically based on customer demand and inventory levels to maximize revenue.",
        "dcterms:title": "Dynamic Posted Pricing",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Revenue Management",
            "Dynamic Pricing"
        ],
        "dcat:keyword": [
            "Dynamic pricing",
            "Revenue maximization",
            "Customer demand"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing revenue",
            "Pricing optimization"
        ]
    },
    {
        "dcterms:creator": [
            "H. Wu",
            "R. Srikant",
            "X. Liu",
            "C. Jiang"
        ],
        "dcterms:description": "Contextual Bandits involve making decisions based on contextual information to maximize rewards, with algorithms designed to minimize regret.",
        "dcterms:title": "Contextual Bandits",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Contextual bandits",
            "Regret minimization",
            "Decision making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Maximizing rewards",
            "Decision making under uncertainty"
        ]
    },
    {
        "dcterms:creator": [
            "R. Kleinberg",
            "S. M. Weinberg"
        ],
        "dcterms:description": "Prophet Inequalities provide a framework for decision making under uncertainty, particularly in online settings where future rewards are uncertain.",
        "dcterms:title": "Prophet Inequalities",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Optimization",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Prophet inequalities",
            "Online decision making",
            "Uncertainty"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision making under uncertainty",
            "Maximizing rewards"
        ]
    }
]