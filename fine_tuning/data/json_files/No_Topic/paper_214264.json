[
    {
        "dcterms:creator": [
            "Justin Johnson",
            "Ranjay Krishna",
            "Michael Stark",
            "Li-Jia Li",
            "David Shamma",
            "Michael Bernstein",
            "Li Fei-Fei"
        ],
        "dcterms:description": "The IRSG dataset is used for image retrieval tasks where scene graphs are employed to ground natural language descriptions in images. It consists of 5,000 images with annotations for objects, attributes, and relationships.",
        "dcterms:title": "IRSG Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Retrieval",
            "Visual Grounding"
        ],
        "dcat:keyword": [
            "Scene Graphs",
            "Image Retrieval",
            "Object Relationships"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Retrieval",
            "Visual Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Ines Chami",
            "Michael Bernstein",
            "Li Fei-Fei"
        ],
        "dcterms:description": "The Visual Relationship Dataset (VRD) is used for grounding referring relationships in images, where queries consist of subject-predicate-object triples.",
        "dcterms:title": "Visual Relationship Dataset (VRD)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Relationship Detection",
            "Visual Grounding"
        ],
        "dcat:keyword": [
            "Referring Relationships",
            "Object Detection",
            "Visual Grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Relationship Detection",
            "Visual Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Junhua Mao",
            "Jonathan Huang",
            "Alexander Toshev",
            "Oana Camburu",
            "Alan L. Yuille",
            "Kevin Murphy"
        ],
        "dcterms:description": "Google-Ref is a dataset for grounding referring expressions in images, which has been shown to contain exploitable biases.",
        "dcterms:title": "Google-Ref",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Referring Expression Grounding",
            "Visual Grounding"
        ],
        "dcat:keyword": [
            "Referring Expressions",
            "Image Retrieval",
            "Biases"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Referring Expression Grounding",
            "Visual Grounding"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Clean Dataset is a modified version of the original dataset used for experiments, focusing on queries that avoid ambiguities and biases.",
        "dcterms:title": "Clean Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Retrieval",
            "Visual Grounding"
        ],
        "dcat:keyword": [
            "Clean Queries",
            "Bias Reduction",
            "Visual Grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Retrieval",
            "Visual Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Justin Johnson",
            "Bharath Hariharan",
            "Laurens van der Maaten",
            "Li Fei-Fei",
            "C Lawrence Zitnick",
            "Ross Girshick"
        ],
        "dcterms:description": "CLEVR is a diagnostic dataset designed for compositional language and elementary visual reasoning, often used in visual grounding tasks.",
        "dcterms:title": "CLEVR",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning",
            "Visual Grounding"
        ],
        "dcat:keyword": [
            "Compositional Language",
            "Visual Reasoning",
            "Diagnostic Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Reasoning",
            "Visual Grounding"
        ]
    }
]