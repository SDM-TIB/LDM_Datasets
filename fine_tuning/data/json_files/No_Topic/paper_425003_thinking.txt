To extract datasets from the research paper titled "KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection" by Yuexin Li et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets that are explicitly mentioned or described. The abstract indicates that the authors evaluate their approach on a "manually validated dataset" and a "field study under Singaporeâ€™s local context," which suggests that datasets are involved.

Next, I will focus on the **experiments section** where the authors provide details about the datasets used for their evaluations. In this section, they mention two primary datasets:

1. **TR-OP Dataset**: This dataset is described as a manually labeled and balanced dataset comprising 10,000 samples, with 5,000 benign and 5,000 phishing webpages. It is used for various research questions related to effectiveness and efficiency.

2. **SG-SCAN Dataset**: This dataset consists of 10,000 webpages sampled from Singapore's local webpage traffic over six months. The authors note that this dataset is unlabelled, and it is used to evaluate the phishing detection approaches in a local context.

After identifying the datasets, I will check the **References section** to find the full citations for these datasets. However, since these datasets are created or compiled by the authors themselves, they may not have external citations. Instead, I will document the details provided in the paper.

Now, I will compile the information into a structured format, ensuring to include the dataset names, descriptions, and any relevant details as outlined in the paper.

Finally, I will prepare the dataset entries for review, ensuring that each dataset is clearly defined and that the citations (if applicable) are accurately represented.