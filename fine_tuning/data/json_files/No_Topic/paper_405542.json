[
    {
        "dcterms:creator": [
            "A. Geiger",
            "P. Lenz",
            "R. Urtasun"
        ],
        "dcterms:description": "KITTI is one of the most popular benchmark datasets for 3D object detection and orientation estimation in autonomous driving, comprising more than 200,000 annotated point cloud scenarios consisting of cars and pedestrians.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "3D Object Detection"
        ],
        "dcat:keyword": [
            "Point Cloud",
            "3D Object Detection",
            "Autonomous Driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Point Cloud",
        "mls:task": [
            "3D Object Detection",
            "Orientation Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Caesar",
            "V. Bankiti",
            "A. H. Lang",
            "S. Vora",
            "V. E. Liong",
            "Q. Xu",
            "A. Krishnan",
            "Y. Pan",
            "G. Baldan",
            "O. Beijbom"
        ],
        "dcterms:description": "nuScenes is a multi-modal autonomous driving dataset provided by a full sensor suite, including cameras, radars, and LiDARs, containing 1,000 scenes with approximately 40,000 frames.",
        "dcterms:title": "nuScenes",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "3D Object Detection",
            "3D Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Multi-modal",
            "3D Object Detection",
            "Semantic Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Multi-modal",
        "mls:task": [
            "3D Object Detection",
            "3D Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Behley",
            "M. Garbade",
            "A. Milioto",
            "J. Quenzel",
            "S. Behnke",
            "C. Stachniss",
            "J. Gall"
        ],
        "dcterms:description": "SemanticKITTI is a large-scale outdoor-scene dataset for 3D semantic segmentation, providing dense point-wise annotations for the complete 360 field-of-view of the employed automotive LiDAR.",
        "dcterms:title": "SemanticKITTI",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Semantic Segmentation"
        ],
        "dcat:keyword": [
            "LiDAR",
            "Semantic Segmentation",
            "Outdoor Scene"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Point Cloud",
        "mls:task": [
            "3D Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Z. Chen",
            "A. X. Chang",
            "M. Nie√üner"
        ],
        "dcterms:description": "ScanRefer is a large-scale dataset for 3D visual grounding and dense captioning, containing 51,583 human-written free-form descriptions of 11,046 objects based on the 800 ScanNet scenes.",
        "dcterms:title": "ScanRefer",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Visual Grounding",
            "Dense Captioning"
        ],
        "dcat:keyword": [
            "3D Visual Grounding",
            "Dense Captioning",
            "ScanNet"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "3D Visual Grounding",
            "Dense Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Azuma",
            "T. Miyanishi",
            "S. Kurita",
            "M. Kawanabe"
        ],
        "dcterms:description": "ScanQA is a large-scale dataset for 3D object-grounded question answering on point cloud, consisting of 41,363 questions and 58,191 answers, including 32,337 unique questions.",
        "dcterms:title": "ScanQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Question Answering"
        ],
        "dcat:keyword": [
            "Question Answering",
            "3D Object Localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "3D Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "X. Ma",
            "S. Yong",
            "Z. Zheng",
            "Q. Li",
            "Y. Liang",
            "S.-C. Zhu",
            "S. Huang"
        ],
        "dcterms:description": "SQA3D is the largest dataset of grounded 3D scene understanding with human-annotated question-answering pairs, comprising 20.4k descriptions of 6.8k unique situations collected from 650 ScanNet scenes.",
        "dcterms:title": "SQA3D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Question Answering"
        ],
        "dcat:keyword": [
            "Grounded Question Answering",
            "3D Scene Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "3D Question Answering"
        ]
    }
]