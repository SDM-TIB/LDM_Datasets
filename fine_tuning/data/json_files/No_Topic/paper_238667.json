[
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD2.0 includes over 43,000 human-curated unanswerable questions designed to evaluate reading comprehension models.",
        "dcterms:title": "SQuAD2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "Unanswerable questions",
            "Adversarial attacks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Adam Trischler",
            "Tong Wang",
            "Xingdi Yuan",
            "Justin Harris",
            "Alessandro Sordoni",
            "Philip Bachman",
            "Kaheer Suleman"
        ],
        "dcterms:description": "NewsQA is a machine comprehension dataset that includes questions about news articles, with a focus on evaluating models' ability to handle unanswerable questions.",
        "dcterms:title": "NewsQA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "News articles",
            "Unanswerable questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "ADDSENT is a dataset of adversarial examples for evaluating reading comprehension systems, focusing on the robustness of models against adversarially crafted inputs.",
        "dcterms:title": "ADDSENT",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Examples",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Adversarial attacks",
            "Reading comprehension",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "ADDONESENT is another dataset of adversarial examples for evaluating reading comprehension systems, similar to ADDSENT.",
        "dcterms:title": "ADDONESENT",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Examples",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Adversarial attacks",
            "Reading comprehension",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Liu",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD1.1 is a dataset containing over 100,000 questions for machine comprehension of text, focusing on answerable questions.",
        "dcterms:title": "SQuAD1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "Answerable questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    }
]