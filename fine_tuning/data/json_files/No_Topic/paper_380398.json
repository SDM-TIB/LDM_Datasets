[
    {
        "dcterms:creator": [
            "Khurram Soomro",
            "Amir Roshan Zamir",
            "Mubarak Shah"
        ],
        "dcterms:description": "A dataset of 101 human actions classes from videos in the wild, used for visual action recognition and video retrieval tasks.",
        "dcterms:title": "UCF51",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Human Action Recognition"
        ],
        "dcat:keyword": [
            "Human actions",
            "Video dataset",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Visual Action Recognition",
            "Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Bernard Ghanem",
            "Fabian Caba Heilbron",
            "Victor Escorcia",
            "Juan Carlos Niebles"
        ],
        "dcterms:description": "A large-scale video benchmark for human activity understanding, utilized for visual action recognition and video retrieval tasks.",
        "dcterms:title": "ActivityNet",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Human Activity Recognition"
        ],
        "dcat:keyword": [
            "Human activities",
            "Video dataset",
            "Activity recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Visual Action Recognition",
            "Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Relja Arandjelovic",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A dataset designed for audio tagging tasks, used to distill visual knowledge to auditory modality.",
        "dcterms:title": "Kinetics-Sound",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Understanding",
            "Sound Recognition"
        ],
        "dcat:keyword": [
            "Audio events",
            "Sound dataset",
            "Audio tagging"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Tagging"
        ]
    },
    {
        "dcterms:creator": [
            "Jort F Gemmeke",
            "Daniel PW Ellis",
            "Dylan Freedman",
            "Aren Jansen",
            "Wade Lawrence",
            "R Channing Moore",
            "Manoj Plakal",
            "Marvin Ritter"
        ],
        "dcterms:description": "An ontology and human-labeled dataset for audio events, used as a teacher model for audio knowledge distillation.",
        "dcterms:title": "AudioSet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Understanding",
            "Sound Recognition"
        ],
        "dcat:keyword": [
            "Audio events",
            "Sound dataset",
            "Audio classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Tagging"
        ]
    }
]