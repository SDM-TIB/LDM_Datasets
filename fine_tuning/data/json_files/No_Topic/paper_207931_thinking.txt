To extract datasets from the research paper titled "Multiview Based 3D Scene Understanding On Partial Point Sets" by Ye Zhu et al., I will follow a systematic approach to identify and document the datasets mentioned throughout the paper.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned or referenced. The abstract discusses the use of point clouds and mentions a specific dataset, the **Stanford dataset**, which is a good starting point.

Next, I will focus on the **experiments section**, particularly **section IV (Experiments and Discussions)**, where the authors detail their experimental setup. Here, they mention the **Stanford dataset** again, providing specific details about its use in their experiments. They describe how the dataset is divided into areas and how many point clouds are used for training and testing.

In this section, I will extract the following datasets:

1. **Stanford Dataset**: The authors describe it as covering an area of more than 6,000 mÂ² and containing over 215 million points, with annotations for various indoor scenes and object categories.

Next, I will check the **References section** to find the full citation for the Stanford dataset. The citation provided in the references is:

- For the **Stanford dataset**, the citation is:
  > I. Armeni, O. Sener, A. R. Zamir, H. Jiang, I. Brilakis, M. Fischer, and S. Savarese. *3D Semantic Parsing of Large-Scale Indoor Spaces*. In Proceedings of the IEEE International Conference on Computer Vision and Pattern Recognition, 2016.

After identifying the dataset and its citation, I will ensure that I have all the necessary details to describe the dataset accurately, including its purpose, size, and any relevant characteristics mentioned in the paper.

Finally, I will compile the dataset information into a structured format for easy reference, ensuring that the full citation is included for each dataset extracted from the paper.