[
    {
        "dcterms:creator": [
            "M. Cordts",
            "M. Omran",
            "S. Ramos",
            "T. Rehfeld",
            "M. Enzweiler",
            "R. Benenson",
            "U. Franke",
            "S. Roth",
            "B. Schiele"
        ],
        "dcterms:description": "A challenging dataset containing high quality pixel-level annotations for 5000 images, with a standard dataset split of 2975, 500, and 1525 for training, validation, and test sets respectively. It defines 19 semantic labels including both objects and stuff.",
        "dcterms:title": "Cityscapes",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Urban Scene Understanding"
        ],
        "dcat:keyword": [
            "Pixel-level annotations",
            "Urban scenes",
            "Semantic labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "G. J. Brostow",
            "J. Shotton",
            "J. Fauqueur",
            "R. Cipolla"
        ],
        "dcterms:description": "A dataset focusing on semantic segmentation for driving scenarios, composed of 701 densely annotated images from five video sequences, with a total of 32 classes provided.",
        "dcterms:title": "CamVid",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Driving Scenarios"
        ],
        "dcat:keyword": [
            "Densely annotated images",
            "Driving scenarios",
            "Semantic segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Geiger",
            "P. Lenz",
            "R. Urtasun"
        ],
        "dcterms:description": "The KITTI Vision Benchmark Suite, which includes updated semantic segmentation ground truth, consists of 200 training and 200 test images with a different image resolution of 375 Ã— 1242.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Semantic segmentation",
            "Driving scenarios",
            "Benchmark suite"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "G. Neuhold",
            "T. Ollmann",
            "S. R. Bul",
            "P. Kontschieder"
        ],
        "dcterms:description": "The Mapillary Vistas Dataset contains street-level scenes annotated for autonomous driving, featuring a larger training set and more classes compared to other datasets.",
        "dcterms:title": "Mapillary Vistas",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Street Scenes"
        ],
        "dcat:keyword": [
            "Street-level scenes",
            "Autonomous driving",
            "Semantic understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    }
]