To extract datasets from the research paper titled "Undersensitivity in Neural Reading Comprehension" by Johannes Welbl et al., I will follow a systematic approach to identify and document each dataset mentioned in the paper, ensuring to include full citations for each.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to locate any references to datasets. The abstract mentions that the authors experimented with **SQuAD2.0** and **NewsQA**, indicating that these are datasets of interest.

Next, I will focus on the **introduction** where the authors discuss the vulnerabilities of models to adversarial inputs and mention the datasets used for training and evaluation. They specifically highlight **SQuAD2.0** and **NewsQA** as datasets that include unanswerable questions, which is crucial for their experiments.

In the **methodology section**, the authors describe their experimental setup and confirm that they are using **SQuAD2.0** and **NewsQA** for their experiments. They detail how these datasets are structured and the nature of the questions they contain, which reinforces their relevance to the study.

I will also check the **experiments section** where the authors present results based on these datasets. They provide performance metrics for models trained on **SQuAD2.0** and **NewsQA**, further solidifying the importance of these datasets in their research.

Now, I will look at the **References section** to find the full citations for these datasets:

1. **SQuAD2.0**:
   > Pranav Rajpurkar, Robin Jia, and Percy Liang. *Know what you don’t know: Unanswerable questions for SQuAD*. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 784–789, Melbourne, Australia, 2018.

2. **NewsQA**:
   > Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bachman, and Kaheer Suleman. *NewsQA: A machine comprehension dataset*. In Proceedings of the 2nd Workshop on Representation Learning for NLP, pages 191–200, Vancouver, Canada, 2017.

After gathering this information, I will compile the dataset entries, ensuring that each dataset is clearly described along with its full citation, ready for structured output or further processing.