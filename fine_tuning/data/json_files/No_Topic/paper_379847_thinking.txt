To extract datasets from the research paper titled "Towards systematic intraday news screening: a liquidity-focused approach" by Mathieu Rosenbaum and Jianfei Zhang, I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract, introduction, and data sections** to identify any datasets that are explicitly mentioned. The abstract provides a brief overview of the study's objectives and methods, which may hint at the datasets used.

In the **introduction**, the authors discuss the need for automatic news sentiment evaluation methods and reference existing literature. I will look for any specific datasets mentioned in this context.

Next, I will focus on **section 2 (Data and preprocessing)**, where the authors describe the datasets used in their study. Here, they mention the **Daily Trade and Quote (TAQ) dataset**, which is crucial for computing liquidity-driven variables. They also refer to **Bloomberg News data**, which is used for sentiment analysis.

I will extract the details of these datasets:

1. **Daily Trade and Quote (TAQ) dataset**: This dataset covers all stocks traded in the US market, specifically focusing on the components of the S&P 500. It includes various liquidity-driven variables such as bid-ask spread, turnover, volatility, and book size.

2. **Bloomberg News data**: This dataset consists of news headlines used for sentiment analysis. The authors evaluate the sentiment based on the headlines, which are classified into bullish, bearish, or neutral categories.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **Daily Trade and Quote (TAQ) dataset**, the citation is:
  > NYSE. *Daily Trade and Quote (TAQ) dataset*. Retrieved from https://www.nyse.com/market-data/historical/daily-taq.

- For the **Bloomberg News data**, while the paper does not provide a specific citation, it is generally referenced as:
  > Bloomberg L.P. *Bloomberg News data*. Retrieved from https://www.bloomberg.com/professional/product/event-driven-feeds/.

After gathering this information, I will compile the dataset entries into a structured format that includes the dataset names, descriptions, and full citations. This will ensure that the datasets are properly documented for future reference or analysis.