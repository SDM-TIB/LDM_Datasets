[
    {
        "dcterms:creator": [
            "A. W. Moore"
        ],
        "dcterms:description": "A classic control problem where a cart balances a pole. The actions of the agent are to push the cart left or right. The state space is a four-tuple with the position and velocity of the cart and the angle and angular velocity of the pole.",
        "dcterms:title": "Cartpole",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Problems"
        ],
        "dcat:keyword": [
            "Cartpole",
            "Control",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Balancing",
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "A. W. Moore"
        ],
        "dcterms:description": "A classic control problem where a car must climb a valley. The actions of the agent are to push the car left, push the car right, or do nothing.",
        "dcterms:title": "Mountaincar",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Problems"
        ],
        "dcat:keyword": [
            "Mountaincar",
            "Control",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Climbing",
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Richard S. Sutton"
        ],
        "dcterms:description": "A classic control problem where a joint actuates two links such that one end is fixed and the other is free. The actions of the agent are to apply a negative torque to the joint, apply a positive torque to the joint, or do nothing.",
        "dcterms:title": "Acrobot",
        "dcterms:issued": "1995",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Problems"
        ],
        "dcat:keyword": [
            "Acrobot",
            "Control",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Balancing",
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "A. W. Moore"
        ],
        "dcterms:description": "A collection of classic control problems used to evaluate reinforcement learning algorithms.",
        "dcterms:title": "Classic control problems",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Problems"
        ],
        "dcat:keyword": [
            "Classic Control",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Richard S. Sutton"
        ],
        "dcterms:description": "A set of classic counter-examples used to demonstrate the divergence of Q-learning with linear function approximation.",
        "dcterms:title": "Classic counter-examples",
        "dcterms:issued": "1995",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Counter-examples"
        ],
        "dcat:keyword": [
            "Counter-examples",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]