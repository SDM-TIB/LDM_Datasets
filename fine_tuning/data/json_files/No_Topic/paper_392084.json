[
    {
        "dcterms:creator": [
            "Yash Goyal",
            "Tejas Khot",
            "Douglas Summers-Stay",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "A dataset for visual question answering that emphasizes the importance of image understanding.",
        "dcterms:title": "VQAv2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Visual Question Answering",
            "Image Understanding",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Xinlei Chen",
            "Hao Fang",
            "Tsung-Yi Lin",
            "Ramakrishna Vedantam",
            "Saurabh Gupta",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "A dataset providing human-generated captions for images, used for evaluating image captioning models.",
        "dcterms:title": "COCO Caption",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image Captions",
            "Dataset",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Drew A Hudson",
            "Christopher D Manning"
        ],
        "dcterms:description": "A dataset for real-world visual reasoning and compositional question answering.",
        "dcterms:title": "GQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Visual Reasoning",
            "Compositional Question Answering",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Reasoning",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Kenneth Marino",
            "Mohammad Rastegari",
            "Ali Farhadi",
            "Roozbeh Mottaghi"
        ],
        "dcterms:description": "A visual question answering benchmark that requires external knowledge.",
        "dcterms:title": "OK-VQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Knowledge-based Reasoning"
        ],
        "dcat:keyword": [
            "Visual Question Answering",
            "External Knowledge",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Harsh Agrawal",
            "Karan Desai",
            "Yufei Wang",
            "Xinlei Chen",
            "Rishabh Jain",
            "Mark Johnson",
            "Dhruv Batra",
            "Devi Parikh",
            "Stefan Lee",
            "Peter Anderson"
        ],
        "dcterms:description": "A dataset for novel object captioning at scale.",
        "dcterms:title": "Nocaps",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Novel Object Captioning",
            "Dataset",
            "Image Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Amanpreet Singh",
            "Vivek Natarajan",
            "Meet Shah",
            "Yu Jiang",
            "Xinlei Chen",
            "Dhruv Batra",
            "Devi Parikh",
            "Marcus Rohrbach"
        ],
        "dcterms:description": "A dataset that proposes questions about text shown in images, involving OCR tasks.",
        "dcterms:title": "TextVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "OCR"
        ],
        "dcat:keyword": [
            "Text in Images",
            "OCR",
            "Visual Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering",
            "OCR"
        ]
    },
    {
        "dcterms:creator": [
            "Pan Lu",
            "Swaroop Mishra",
            "Tanglin Xia",
            "Liang Qiu",
            "Kai-Wei Chang",
            "Song-Chun Zhu",
            "Oyvind Tafjord",
            "Peter Clark",
            "Ashwin Kalyan"
        ],
        "dcterms:description": "A dataset focusing on scientific topics, requiring integration of commonsense into reasoning.",
        "dcterms:title": "ScienceQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Science Question Answering",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Science Questions",
            "Commonsense Reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Luowei Zhou",
            "Chenliang Xu",
            "Jason Corso"
        ],
        "dcterms:description": "A dataset aimed at automatic learning of procedures from web instructional videos.",
        "dcterms:title": "Youcook2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Instructional Learning"
        ],
        "dcat:keyword": [
            "Instructional Videos",
            "Procedure Learning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Qinghao Ye",
            "Haiyang Xu",
            "Guohai Xu",
            "Jiabo Ye",
            "Mingshi Yan",
            "Anwen Hu",
            "Haowei Liu",
            "Qi Qian",
            "Ji Zhang",
            "Fei Huang",
            "Jingren Zhou"
        ],
        "dcterms:description": "A modular evaluation benchmark for large language models with multimodality.",
        "dcterms:title": "OwlEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Evaluation Benchmark",
            "Multimodal Models"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Multimodal",
            "Large Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Peng Xu",
            "Wenqi Shao",
            "Kaipeng Zhang",
            "Peng Gao",
            "Shuo Liu",
            "Meng Lei",
            "Fanqing Meng",
            "Siyuan Huang",
            "Yu Jiao Qiao",
            "Ping Luo"
        ],
        "dcterms:description": "A comprehensive evaluation benchmark for large vision-language models.",
        "dcterms:title": "LVLM-eHub",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Evaluation Benchmark",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Vision-Language Models",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Model Evaluation"
        ]
    }
]