To extract datasets from the research paper titled "CISRNet: Compressed Image Super-Resolution Network" by Agus Gunawan and Sultan Rizky Hikmawan Madjid, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the research focus, and the introduction often discusses the datasets used for evaluation or training.

In the **introduction**, the authors mention that they tackle the problem of Single Image Super-Resolution (SISR) for compressed images, but they do not specify any datasets yet. I will need to look further into the paper.

Next, I will focus on the **experiments section**. Here, the authors explicitly mention the datasets used for training and testing. They state that the training dataset consists of **800 training images from the DIV2K dataset** and that they use several datasets for testing: **Set5, Set14, B100, Urban100, and Manga109**. This is crucial information as it identifies the datasets relevant to their experiments.

Now, I will check the **References section** to find the full citations for each dataset mentioned:

1. **DIV2K Dataset**: The citation is:
   > Eirikur Agustsson and Radu Timofte. *Ntire 2017 challenge on single image super-resolution: Dataset and study*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 126–135, 2017.

2. **Set5 Dataset**: The citation is:
   > David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. *A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics*. In Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, volume 2, pages 416–423. IEEE, 2001.

3. **Set14 Dataset**: The citation is:
   > Roman Zeyde, Michael Elad, and Matan Protter. *On single image scale-up using sparse-representations*. In International conference on curves and surfaces, pages 711–730. Springer, 2010.

4. **B100 Dataset**: The citation is:
   > David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. *A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics*. In Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001, volume 2, pages 416–423. IEEE, 2001.

5. **Urban100 Dataset**: The citation is:
   > Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, Toshihiko Yamasaki, and Kiyoharu Aizawa. *Sketch-based manga retrieval using manga109 dataset*. Multimedia Tools and Applications, 76(20):21811–21838, 2017.

6. **Manga109 Dataset**: The citation is:
   > Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, Toshihiko Yamasaki, and Kiyoharu Aizawa. *Sketch-based manga retrieval using manga109 dataset*. Multimedia Tools and Applications, 76(20):21811–21838, 2017.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding citations.