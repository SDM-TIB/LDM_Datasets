[
    {
        "dcterms:creator": [
            "N. Srivastava",
            "E. Mansimov",
            "R. Salakhudinov"
        ],
        "dcterms:description": "Moving MNIST is a video sequence dataset generated from the MNIST dataset, comprising 10,000 sequences, each consisting of 20 frames. Each frame is a grayscale image with dimensions 64x64 and contains two randomly moving digits. The objective is to input the first 10 frames and predict the positions and shapes of the digits in the subsequent 10 frames.",
        "dcterms:title": "Moving MNIST",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Spatio-temporal Prediction"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Digit recognition",
            "Spatio-temporal prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Spatio-temporal prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Zhang",
            "Y. Zheng",
            "Q. Yang"
        ],
        "dcterms:description": "TaxiBJ is a dataset that contains GPS data from taxis in Beijing, including both inflow and outflow channels. The objective is to predict future urban population flow based on historical data.",
        "dcterms:title": "TaxiBJ",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Urban Traffic Prediction",
            "Spatio-temporal Prediction"
        ],
        "dcat:keyword": [
            "Traffic dataset",
            "GPS data",
            "Urban flow prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Tabular",
        "mls:task": [
            "Urban traffic prediction"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schuldt",
            "I. Laptev",
            "B. Caputo"
        ],
        "dcterms:description": "KTH is a dataset designed for human action recognition, including six different actions performed by 25 individuals in various scenarios. The goal is to recognize human action categories based on video sequences.",
        "dcterms:title": "KTH",
        "dcterms:issued": "2004",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Action recognition",
            "Video dataset",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human action recognition"
        ]
    }
]