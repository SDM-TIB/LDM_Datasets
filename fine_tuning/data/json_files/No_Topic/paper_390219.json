[
    {
        "dcterms:creator": [
            "Pradeep Dasigi",
            "Kyle Lo",
            "Iz Beltagy",
            "Arman Cohan",
            "Noah A Smith",
            "Matt Gardner"
        ],
        "dcterms:description": "A multi-perspective scientific machine reading comprehension dataset that includes perspectives from beginners, students, and experts, constructed from 741 scientific papers and 6,057 question-answer pairs.",
        "dcterms:title": "SciMRC",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Scientific papers",
            "Question-answer pairs",
            "Multi-perspective",
            "Machine comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Rui Meng",
            "Khushboo Thaker",
            "Lei Zhang",
            "Yue Dong",
            "Xingdi Yuan",
            "Tong Wang",
            "Daqing He"
        ],
        "dcterms:description": "A faceted summarization dataset for long scientific documents that brings structure into summaries.",
        "dcterms:title": "FacetSum",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Summarization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Faceted summarization",
            "Scientific documents",
            "Long documents"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Kyle Lo",
            "Lucy Lu Wang",
            "Mark Neumann",
            "Rodney Michael Kinney",
            "Daniel S. Weld"
        ],
        "dcterms:description": "The Semantic Scholar Open Research Corpus, a large-scale dataset of scholarly papers.",
        "dcterms:title": "S2orc",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Research Corpus",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Scholarly papers",
            "Research corpus",
            "Semantic Scholar"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Qiao Jin",
            "Bhuwan Dhingra",
            "Zhengping Liu",
            "William Cohen",
            "Xinghua Lu"
        ],
        "dcterms:description": "A dataset for biomedical research question answering, focusing on questions derived from PubMed articles.",
        "dcterms:title": "PubmedQA",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Biomedical research",
            "Question answering",
            "PubMed"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pradeep Dasigi",
            "Kyle Lo",
            "Iz Beltagy",
            "Arman Cohan",
            "Noah A Smith",
            "Matt Gardner"
        ],
        "dcterms:description": "A dataset of information-seeking questions and answers anchored in research papers.",
        "dcterms:title": "QASPER",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Information-seeking",
            "Research papers",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing over 100,000 questions for machine comprehension of text.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "Question answering",
            "SQuAD"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mandar Joshi",
            "Eunsol Choi",
            "Daniel S Weld",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "A large-scale distantly supervised challenge dataset for reading comprehension.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Challenge dataset",
            "TriviaQA"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D Manning"
        ],
        "dcterms:description": "A dataset for diverse, explainable multi-hop question answering.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-hop Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-hop QA",
            "Explainable AI",
            "HotpotQA"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dimitris Pappas",
            "Petros Stavropoulos",
            "Ion Androutsopoulos",
            "Ryan McDonald"
        ],
        "dcterms:description": "A dataset for biomedical machine reading comprehension.",
        "dcterms:title": "BioMRC",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Biomedical MRC",
            "Machine reading comprehension",
            "BioMRC"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur P. Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee",
            "Kristina Toutanova",
            "Llion Jones",
            "Matthew Kelcey",
            "Ming-Wei Chang",
            "Andrew M. Dai",
            "Jakob Uszkoreit",
            "Quoc V. Le",
            "Slav Petrov"
        ],
        "dcterms:description": "A benchmark for question answering research, providing a dataset of natural questions.",
        "dcterms:title": "Natural Questions",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Natural questions",
            "Benchmark",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]