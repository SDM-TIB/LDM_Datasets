[
    {
        "dcterms:creator": [
            "Yevgeni Berzak",
            "Chie Nakamura",
            "Amelia Smith",
            "Emily Weng",
            "Boris Katz",
            "Suzanne Flynn",
            "Roger Levy"
        ],
        "dcterms:description": "CELER is a corpus of eye movements in L1 and L2 English reading, containing eye-tracking recordings collected from 69 native speakers of English during natural reading of 5,456 sentences.",
        "dcterms:title": "CELER",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Eye Tracking",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Eye movements",
            "L1 English",
            "L2 English",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Abhijit Mishra",
            "Diptesh Kanojia",
            "Pushpak Bhattacharyya"
        ],
        "dcterms:description": "ETSA contains task-specific gaze recordings for sentiment classification of 7 subjects who each read 383 positive and 611 negative sentences, including sarcastic quotes, short movie reviews, and tweets.",
        "dcterms:title": "ETSA",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis",
            "Eye Tracking"
        ],
        "dcat:keyword": [
            "Gaze recordings",
            "Sentiment classification",
            "Sarcasm detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel Bowman"
        ],
        "dcterms:description": "GLUE is a multi-task benchmark and analysis platform for natural language understanding, including various tasks such as sentiment analysis, linguistic acceptability, similarity and paraphrase tasks, and natural language inference tasks.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multi-task learning",
            "Natural language understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    }
]