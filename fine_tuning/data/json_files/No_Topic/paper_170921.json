[
    {
        "dcterms:creator": [
            "F. Hill",
            "A. Bordes",
            "S. Chopra",
            "J. Weston"
        ],
        "dcterms:description": "The Children’s Book Test (CBT) dataset is built from children’s books and contains 669,343 questions for training, 8,000 for validation, and 10,000 for testing.",
        "dcterms:title": "Children’s Book Test (CBT)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Children's books",
            "Question answering",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "R. Kadlec",
            "M. Schmid",
            "O. Bajgar",
            "J. Kleindienst"
        ],
        "dcterms:description": "The Who Did What (WDW) dataset is used for reading comprehension tasks and includes various question types.",
        "dcterms:title": "Who Did What",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Question answering",
            "Text understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "J. Zhang",
            "K. Lopyrev",
            "P. Liang"
        ],
        "dcterms:description": "The Stanford Question Answering Dataset (SQuAD) contains 23,215 paragraphs from 536 Wikipedia articles, with questions that require answers as spans of text.",
        "dcterms:title": "SQuAD (Stanford Question Answering Dataset)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Question answering",
            "Machine comprehension",
            "Text understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "B. Dhingra",
            "Z. Zhou",
            "D. Fitzpatrick",
            "M. Muehl",
            "W. W. Cohen"
        ],
        "dcterms:description": "The Twitter dataset consists of English tweets with at least one hashtag, used for social media tag prediction.",
        "dcterms:title": "Twitter dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Social Media",
            "Text Classification"
        ],
        "dcat:keyword": [
            "Twitter",
            "Social media",
            "Tag prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Tag Prediction"
        ]
    }
]