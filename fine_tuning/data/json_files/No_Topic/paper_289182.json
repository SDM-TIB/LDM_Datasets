[
    {
        "dcterms:creator": [
            "J. Engel",
            "C. Resnick",
            "A. Roberts",
            "S. Dieleman",
            "D. Eck",
            "K. Simonyan",
            "M. Norouzi"
        ],
        "dcterms:description": "The NSynth dataset offers about 300,000 audio samples of musical notes, each with a unique pitch, timbre, and envelope recorded from 1,006 different instruments. The recordings, sampled at 16kHz, are 4 seconds long and can be used for 3 downstream classification tasks: predicting the instrument itself (1,006 classes), the instrument family (11 classes), and predicting the pitch of the note (128 values).",
        "dcterms:title": "NSynth",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio",
            "Music"
        ],
        "dcat:keyword": [
            "Audio dataset",
            "Musical notes",
            "Instrument classification",
            "Pitch estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Instrument classification",
            "Pitch estimation"
        ]
    }
]