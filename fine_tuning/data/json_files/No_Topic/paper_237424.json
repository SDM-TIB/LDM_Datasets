[
    {
        "dcterms:creator": [
            "Peter Anderson",
            "Qi Wu",
            "Damien Teney",
            "Jake Bruce",
            "Mark Johnson",
            "Niko Sünderhauf",
            "Ian Reid",
            "Stephen Gould",
            "Anton van den Hengel"
        ],
        "dcterms:description": "The R2R dataset consists of 10,800 panoramic views (each panoramic view has 36 images) and 7,189 trajectories. Each trajectory is paired with three natural language instructions. The challenge of R2R is to test the agent’s generalization ability in unseen environments.",
        "dcterms:title": "Room-to-Room (R2R)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-and-Language Navigation"
        ],
        "dcat:keyword": [
            "Navigation",
            "Panoramic Views",
            "Natural Language Instructions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Angel Chang",
            "Angela Dai",
            "Thomas Funkhouser",
            "Maciej Halber",
            "Matthias Nießner",
            "Manolis Savva",
            "Shuran Song",
            "Andy Zeng",
            "Yinda Zhang"
        ],
        "dcterms:description": "Matterport3D is a dataset that provides RGB-D data in indoor environments, allowing for the development of intelligent agents in photorealistic settings.",
        "dcterms:title": "Matterport3D",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Vision",
            "Indoor Navigation"
        ],
        "dcat:keyword": [
            "RGB-D Data",
            "Indoor Environments",
            "3D Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "Navigation",
            "3D Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "Jesse Thomason",
            "Michael Murray",
            "Maya Cakmak",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "CVDN is a dataset for vision-and-dialog navigation, where the agent navigates based on dialog history that consists of multiple turns of question-answering interactions.",
        "dcterms:title": "CVDN (Cooperative Vision-and-Dialogue Navigation)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-and-Language Navigation"
        ],
        "dcat:keyword": [
            "Dialog History",
            "Navigation",
            "Cooperative Tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Dialog-based Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Khanh Nguyen",
            "Hal Daumé III"
        ],
        "dcterms:description": "HANNA is a dataset that simulates a scenario where a human requester asks an agent via language to find an object in an indoor environment, providing subtasks in the form of natural language instructions.",
        "dcterms:title": "HANNA (Help, Anna!)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-and-Language Navigation"
        ],
        "dcat:keyword": [
            "Interactive Learning",
            "Natural Language Instructions",
            "Object Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Interactive Assistance"
        ]
    }
]