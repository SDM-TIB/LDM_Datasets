To extract datasets from the research paper titled "4D Panoptic Segmentation as Invariant and Equivariant Field Prediction" by Minghan Zhu et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by examining the **abstract** and **introduction** sections of the paper. The abstract mentions the use of **SemanticKITTI** as a benchmark for 4D panoptic segmentation, which indicates that this dataset is likely central to the research.

Next, I will look for a dedicated **datasets section** or any mention of datasets in the **experiments** section. In this paper, the authors discuss their experiments primarily on the **SemanticKITTI dataset**, which is a large-scale dataset for LiDAR-based semantic segmentation and panoptic segmentation. 

In the **experiments section**, the authors provide details about the dataset, including its structure and the number of sequences used for training and validation. They mention that the dataset consists of 22 sequences from the KITTI dataset, with 10 sequences for training, 1 for validation, and 11 for testing, totaling 43,552 frames.

Now, I will check the **References section** to find the full citation for the **SemanticKITTI dataset**. The citation provided in the references is:

- **SemanticKITTI Dataset**:
  > Jens Behley, Martin Garbade, Andres Milioto, Jan Quenzel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. *SemanticKITTI: A dataset for semantic scene understanding of lidar sequences*. In Proceedings of the IEEE/CVF International Conference on Computer Vision, pages 9297â€“9307, 2019.

Since the paper primarily focuses on the **SemanticKITTI dataset**, I will compile this information into a structured format, ensuring that I include the full citation for the dataset as required.

After gathering all necessary details, I will prepare the dataset entry for **SemanticKITTI** and ensure it is ready for review or further processing.