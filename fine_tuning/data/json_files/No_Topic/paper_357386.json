[
    {
        "dcterms:creator": [
            "Patrick T. Komiske",
            "Eric M. Metodiev",
            "Jesse Thaler"
        ],
        "dcterms:description": "The Energy Mover’s Distance (EMD) is a metric for the space of collider events, defined based on the Wasserstein metric, which quantifies the work required to rearrange the radiation pattern of one event into another.",
        "dcterms:title": "Energy Mover’s Distance (EMD)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.1103/physrevlett.123.041801",
        "dcat:theme": [
            "High-Energy Physics",
            "Metric Space"
        ],
        "dcat:keyword": [
            "Wasserstein metric",
            "collider events",
            "energy distribution"
        ],
        "dcat:landingPage": "https://doi.org/10.1103%2Fphysrevlett.123.041801",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Rikab Gambhir",
            "Akshunna Dogra",
            "Jesse Thaler",
            "Demba Ba",
            "Abiy Tasissa"
        ],
        "dcterms:description": "The SHAPER tool is used for developing geometric collider observables, leveraging the Energy Mover’s Distance for clustering particles into jets.",
        "dcterms:title": "SHAPER Tool",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "High-Energy Physics",
            "Jet Clustering"
        ],
        "dcat:keyword": [
            "geometric observables",
            "jet shape",
            "collider physics"
        ],
        "dcat:landingPage": "https://indi.to/rbQ5j",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ouail Kitouni",
            "Niklas Nolte",
            "Mike Williams"
        ],
        "dcterms:description": "Lipschitz Networks are neural networks that enforce an upper bound on the Lipschitz constant, enhancing expressiveness and robustness in modeling.",
        "dcterms:title": "Lipschitz Networks",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2112.00038",
        "dcat:theme": [
            "Machine Learning",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Lipschitz continuity",
            "neural architecture",
            "robustness"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2112.00038",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Cem Anil",
            "James Lucas",
            "Roger Grosse"
        ],
        "dcterms:description": "This dataset focuses on the approximation of Lipschitz functions, providing insights into the sorting and optimization of such functions.",
        "dcterms:title": "Sorting out Lipschitz function approximation",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://proceedings.mlr.press/v97/anil19a.html",
        "dcat:theme": [
            "Machine Learning",
            "Function Approximation"
        ],
        "dcat:keyword": [
            "Lipschitz functions",
            "function approximation",
            "optimization"
        ],
        "dcat:landingPage": "http://proceedings.mlr.press/v97/anil19a.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jean Feydy",
            "Thibault Séjourné",
            "François-Xavier Vialard",
            "Shun-ichi Amari",
            "Alain Trouvé",
            "Gabriel Peyré"
        ],
        "dcterms:description": "Sinkhorn Divergences provide a method for interpolating between optimal transport and maximum mean discrepancy (MMD), enhancing the comparison of probability distributions.",
        "dcterms:title": "Sinkhorn Divergences",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1810.08278",
        "dcat:theme": [
            "Optimal Transport",
            "Statistics"
        ],
        "dcat:keyword": [
            "optimal transport",
            "maximum mean discrepancy",
            "probability distributions"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1810.08278",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Miguel Arratia",
            "Yiannis Makris",
            "Duff Neill",
            "Felix Ringer",
            "Nobuo Sato"
        ],
        "dcterms:description": "Asymmetric jet clustering is a method used in deep-inelastic scattering to analyze the structure of jets in high-energy particle collisions.",
        "dcterms:title": "Asymmetric jet clustering",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "10.1103/PhysRevD.104.034005",
        "dcat:theme": [
            "High-Energy Physics",
            "Jet Analysis"
        ],
        "dcat:keyword": [
            "jet clustering",
            "deep-inelastic scattering",
            "high-energy collisions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Henry Gouk",
            "Eibe Frank",
            "Bernhard Pfahringer",
            "Michael J. Cree"
        ],
        "dcterms:description": "This dataset focuses on the regularization of neural networks by enforcing Lipschitz continuity, enhancing the stability and performance of neural models.",
        "dcterms:title": "Regularisation of neural networks",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "regularization",
            "Lipschitz continuity",
            "neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Takeru Miyato",
            "Toshiki Kataoka",
            "Masanori Koyama",
            "Yuichi Yoshida"
        ],
        "dcterms:description": "Spectral Normalization for GANs is a technique that stabilizes the training of Generative Adversarial Networks by controlling the Lipschitz constant of the discriminator.",
        "dcterms:title": "Spectral Normalization for GANs",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1802.05957",
        "dcat:theme": [
            "Machine Learning",
            "Generative Models"
        ],
        "dcat:keyword": [
            "GANs",
            "spectral normalization",
            "training stability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]