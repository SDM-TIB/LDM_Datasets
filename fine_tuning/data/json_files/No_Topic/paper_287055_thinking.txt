To extract datasets from the research paper titled "Towards Continual, Online, Self-Supervised Depth" by Muhammad Umar Karim Khan, I will follow a systematic approach to identify and document the datasets mentioned throughout the paper.

First, I will read through the **abstract, introduction, and experimental results sections** to locate any references to datasets. The abstract mentions that the method is evaluated on "diverse public datasets that include outdoor, indoor and synthetic scenes," which indicates that datasets are involved.

Next, I will focus on the **experiments section** where the author explicitly lists the datasets used for evaluation. In the section labeled **VIII. Experimental Results**, the author states that three datasets are used: **KITTI**, **Virtual KITTI**, and **rectified New York University (NYU) v2** datasets. This is a clear indication that these datasets are central to the experiments conducted.

I will then look for detailed descriptions of each dataset within the text. The author provides specific information about the datasets in the **A. Datasets** subsection, which includes:

1. **KITTI Dataset**: This dataset is divided into training and testing frames, with specific scenes used for pre-training and online training. The author notes the number of frames and the categories of scenes included.

2. **Virtual KITTI Dataset**: Similar to the KITTI dataset, this dataset is also divided into training and testing frames, with details on the scenes used for both pre-training and online training.

3. **NYU v2 Dataset**: This dataset is described in terms of the number of training and testing frames, along with the scenes used for pre-training and online training.

After identifying these datasets, I will consult the **References section** to find the full citations for each dataset. The citations are crucial for proper attribution and to allow others to access the datasets used in the research.

The full citations for the datasets are as follows:

- **KITTI Dataset**: 
  > Andreas Geiger, Philip Lenz, and Raquel Urtasun. *Are We Ready for Autonomous Driving? The KITTI Vision Benchmark Suite*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 3354–3361, 2012.

- **Virtual KITTI Dataset**: 
  > Y. Cabon, N. Murray, and M. Humenberger. *Virtual Kitti 2*. 2020.

- **NYU v2 Dataset**: 
  > Nathan Silberman, Derek Hoiem, Pushmeet Kohli, and Rob Fergus. *Indoor Segmentation and Support Inference from RGBD Images*. In European Conference on Computer Vision (ECCV), pages 746–760, 2012.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.