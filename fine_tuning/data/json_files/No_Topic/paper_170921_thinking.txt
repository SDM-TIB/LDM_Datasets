To extract datasets from the research paper titled "Fine-Grained Gating for Reading Comprehension" by Zhilin Yang et al., I will follow a systematic approach to identify and document each dataset mentioned in the paper.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets that are explicitly mentioned. The abstract indicates that the authors achieved state-of-the-art results on several reading comprehension tasks, which suggests that datasets are involved.

In the **introduction**, the authors mention improved performance on the **Children’s Book Test** and **Who Did What** datasets. This is a strong indication that these datasets are central to their experiments.

Next, I will look into **section 4 (Experiments)**, where the authors provide detailed descriptions of the datasets used. Here, they mention:

1. **Children’s Book Test (CBT)**: This dataset is derived from children's books and contains 669,343 questions for training, 8,000 for validation, and 10,000 for testing. The authors follow the experimental settings from a previous work to evaluate their model.

2. **Who Did What (WDW)**: The authors also evaluate their model on this dataset, although specific details about the dataset size or structure are not provided in the text.

3. **Stanford Question Answering Dataset (SQuAD)**: This dataset contains 23,215 paragraphs from Wikipedia articles, with a focus on span-based answers rather than single-word answers. The dataset is partitioned into training, development, and test sets.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **Children’s Book Test (CBT)**, the citation is:
  > Hill, F., Bordes, A., Chopra, S., & Weston, J. (2016). The goldilocks principle: Reading children’s books with explicit memory representations. In ICLR.

- For the **Who Did What (WDW)** dataset, the citation is:
  > Kadlec, R., Schmid, M., Bajgar, O., & Kleindienst, J. (2016). Text understanding with the attention sum reader network. In ACL.

- For the **Stanford Question Answering Dataset (SQuAD)**, the citation is:
  > Rajpurkar, P., Zhang, J., Lopyrev, K., & Liang, P. (2016). SQuAD: 100,000+ questions for machine comprehension of text. In EMNLP.

After gathering this information, I will compile the dataset entries into a structured format that includes the dataset names, descriptions, and full citations, ensuring that each dataset is accurately represented and properly cited.