[
    {
        "dcterms:creator": [
            "Vlad Hosu",
            "Franz Hahn",
            "Mohsen Jenadeleh",
            "Hanhe Lin",
            "Hui Men",
            "Tamás Szirányi",
            "Shujun Li",
            "Dietmar Saupe"
        ],
        "dcterms:description": "The KoNViD-1k dataset provides video frames that demonstrate a correlation between content/motion patterns and video quality, with 1,200 videos and an average of 114 votes for each video to obtain a reliable Mean Opinion Score (MOS).",
        "dcterms:title": "KoNViD-1k",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Quality Assessment"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Quality assessment",
            "Mean Opinion Score",
            "Perceptual quality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Quality Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Zeina Sinno",
            "Alan Conrad Bovik"
        ],
        "dcterms:description": "LIVE-VQC consists of 585 videos with complex authentic distortions captured by 80 different users using 101 different devices, with 240 annotations for each video.",
        "dcterms:title": "LIVE-VQC",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Quality Assessment"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Quality assessment",
            "Authentic distortions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Quality Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Yilin Wang",
            "Sasi Inguva",
            "Balu Adsumilli"
        ],
        "dcterms:description": "YouTube-UGC contains 1,380 user-generated content videos sampled from YouTube, with a duration of 20 seconds and resolutions ranging from 360P to 4K, with 123 annotations for each video.",
        "dcterms:title": "YouTube-UGC",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Quality Assessment"
        ],
        "dcat:keyword": [
            "Video dataset",
            "User-generated content",
            "Quality assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Quality Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Zhenqiang Ying",
            "Maniratnam Mandal",
            "Deepti Ghadiyaram",
            "Alan C. Bovik"
        ],
        "dcterms:description": "LSVQ is the largest VQA dataset currently, proposed in 2021, containing 39,076 videos.",
        "dcterms:title": "LSVQ",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Quality Assessment"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Quality assessment",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Quality Assessment"
        ]
    }
]