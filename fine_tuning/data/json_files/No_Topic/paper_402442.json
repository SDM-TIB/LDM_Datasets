[
    {
        "dcterms:creator": [
            "Kexin Yi",
            "Chuang Gan",
            "Yunzhu Li",
            "Pushmeet Kohli",
            "Jiajun Wu",
            "Antonio Torralba",
            "Joshua B. Tenenbaum"
        ],
        "dcterms:description": "CLEVRER is a dataset designed for video representation and reasoning, focusing on collision events and their causal relationships.",
        "dcterms:title": "CLEVRER",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Reasoning",
            "Causal Reasoning"
        ],
        "dcat:keyword": [
            "Collision events",
            "Video dataset",
            "Causal relationships"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Representation",
            "Causal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Rohit Girdhar",
            "Deva Ramanan"
        ],
        "dcterms:description": "CATER is a diagnostic dataset for evaluating compositional actions and temporal reasoning in videos.",
        "dcterms:title": "CATER",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Temporal Reasoning",
            "Compositional Actions"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Temporal reasoning",
            "Compositional actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Temporal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Ronan Alexandre Riochet",
            "Mario Ynocente Castro",
            "Mathieu Bermard",
            "Adam Lerer",
            "Rob Fergus",
            "VÃ©ronique Izard",
            "Emmanuel Dupoux"
        ],
        "dcterms:description": "IntPhys is a benchmark for visual intuitive physics reasoning, focusing on understanding physical interactions.",
        "dcterms:title": "IntPhys",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Intuitive Physics",
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Physics reasoning",
            "Visual dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Physics Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Jiajun Wu",
            "Ilker Yildirim",
            "Joseph J Lim",
            "Bill Freeman",
            "Josh Tenenbaum"
        ],
        "dcterms:description": "Galileo integrates a physics engine with deep learning to perceive physical object properties.",
        "dcterms:title": "Galileo",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Physical Properties",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Object properties"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Physical Property Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Anton Bakhtin",
            "Laurens van der Maaten",
            "Justin Johnson",
            "Laura Gustafson",
            "Ross Girshick"
        ],
        "dcterms:description": "PHYRE is a benchmark for physical reasoning, focusing on generating initial conditions leading to specific goal states.",
        "dcterms:title": "PHYRE",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Physical Reasoning"
        ],
        "dcat:keyword": [
            "Physics reasoning",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Physical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Fabien Baradel",
            "Natalia Neverova",
            "Julien Mille",
            "Greg Mori",
            "Christian Wolf"
        ],
        "dcterms:description": "CoPhy focuses on counterfactual learning of physical dynamics, allowing for reasoning about physical interactions.",
        "dcterms:title": "CoPhy",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Counterfactual Learning",
            "Physical Dynamics"
        ],
        "dcat:keyword": [
            "Counterfactual reasoning",
            "Physical dynamics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Counterfactual Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Tayfun Ates",
            "Muhammed Samil Atesoglu",
            "Cagatay Yigit",
            "Ilker Kesen",
            "Mert Kobas",
            "Erkut Erdem",
            "Aykut Erdem",
            "Tilbe Goksun",
            "Deniz Yuret"
        ],
        "dcterms:description": "CRAFT is a benchmark for causal reasoning about forces and interactions in physical scenes.",
        "dcterms:title": "CRAFT",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Causal Reasoning",
            "Forces and Interactions"
        ],
        "dcat:keyword": [
            "Causal reasoning",
            "Forces",
            "Interactions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Causal Reasoning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "CLEVRER-Humans is a video reasoning dataset for causal judgment of physical events with human labels.",
        "dcterms:title": "CLEVRER-Humans",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Causal Reasoning",
            "Video Reasoning"
        ],
        "dcat:keyword": [
            "Causal judgment",
            "Human-annotated",
            "Video dataset"
        ],
        "dcat:landingPage": "https://sites.google.com/stanford.edu/clevrer-humans/home",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Causal Reasoning",
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Makarand Tapaswi",
            "Yukun Zhu",
            "Rainer Stiefelhagen",
            "Antonio Torralba",
            "Raquel Urtasun",
            "Sanja Fidler"
        ],
        "dcterms:description": "MovieQA is a dataset for understanding stories in movies through question-answering.",
        "dcterms:title": "MovieQA",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Story Understanding"
        ],
        "dcat:keyword": [
            "Movies",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yunseok Jang",
            "Yale Song",
            "Youngjae Yu",
            "Youngjin Kim",
            "Gunhee Kim"
        ],
        "dcterms:description": "TGIF-QA is a dataset aimed at spatio-temporal reasoning in visual question answering.",
        "dcterms:title": "TGIF-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Spatio-Temporal Reasoning"
        ],
        "dcat:keyword": [
            "Spatio-temporal reasoning",
            "Visual question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Jie Lei",
            "Licheng Yu",
            "Tamara L Berg",
            "Mohit Bansal"
        ],
        "dcterms:description": "TVQA+ is a dataset for spatio-temporal grounding in video question answering.",
        "dcterms:title": "TVQA+",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Spatio-Temporal Grounding"
        ],
        "dcat:keyword": [
            "Video QA",
            "Spatio-temporal grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Madeleine Grunde-McLaughlin",
            "Ranjay Krishna",
            "Maneesh Agrawala"
        ],
        "dcterms:description": "AGQA is a benchmark for compositional spatio-temporal reasoning.",
        "dcterms:title": "AGQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Spatio-Temporal Reasoning",
            "Compositional Reasoning"
        ],
        "dcat:keyword": [
            "Spatio-temporal reasoning",
            "Compositional reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Spatio-Temporal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Zhenfang Chen",
            "Kexin Yi",
            "Yunzhu Li",
            "Mingyu Ding",
            "Antonio Torralba",
            "Joshua B. Tenenbaum",
            "Chuang Gan"
        ],
        "dcterms:description": "ComPhy is a dataset for compositional physical reasoning of objects and events from videos.",
        "dcterms:title": "ComPhy",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Compositional Reasoning",
            "Physical Reasoning"
        ],
        "dcat:keyword": [
            "Compositional reasoning",
            "Physical reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Physical Reasoning"
        ]
    }
]