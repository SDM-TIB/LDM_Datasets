[
    {
        "dcterms:creator": [
            "M. Junczys-Dowmunt",
            "R. Grundkiewicz",
            "T. Dwojak",
            "H. Hoang",
            "K. Heafield",
            "T. Neckermann",
            "F. Seide",
            "U. Germann",
            "A. F. Aji",
            "N. Bogoychev",
            "A. F. T. Martins",
            "A. Birch"
        ],
        "dcterms:description": "The WMT-14 dataset is used for training and evaluating machine translation models, specifically in the context of adversarial attacks.",
        "dcterms:title": "wmt-14 dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/P18-4020",
        "dcat:theme": [
            "Machine Translation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Machine Translation",
            "Adversarial Attacks",
            "Neural Networks"
        ],
        "dcat:landingPage": "https://aclanthology.org/P18-4020",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "M. PopoviÄ‡"
        ],
        "dcterms:description": "chrF is a metric for automatic evaluation of machine translation that calculates an F-score based on character n-grams.",
        "dcterms:title": "chrF",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/W15-3049",
        "dcat:theme": [
            "Machine Translation Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation Metric",
            "Character n-grams",
            "Machine Translation"
        ],
        "dcat:landingPage": "https://aclanthology.org/W15-3049",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "T. Zhang",
            "V. Kishore",
            "F. Wu",
            "K. Q. Weinberger",
            "Y. Artzi"
        ],
        "dcterms:description": "BertScore is a metric for evaluating text generation that leverages BERT embeddings to compute precision, recall, and F1 scores.",
        "dcterms:title": "BertScore",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Generation Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation Metric",
            "BERT",
            "Text Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Text Generation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "P. Michel",
            "X. Li",
            "G. Neubig",
            "J. Pino"
        ],
        "dcterms:description": "BLEU is a widely used metric for evaluating the quality of machine translation by comparing n-grams of the candidate translation with those of reference translations.",
        "dcterms:title": "BLEU",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation Metric",
            "Machine Translation",
            "n-grams"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    }
]