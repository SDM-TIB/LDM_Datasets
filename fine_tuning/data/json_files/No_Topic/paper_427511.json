[
    {
        "dcterms:creator": [
            "R. Krishna",
            "Y. Zhu",
            "O. Groth",
            "J. Johnson",
            "K. Hata",
            "J. Kravitz",
            "S. Chen",
            "Y. Kalantidis",
            "L. J. Li",
            "D. A. Shamma"
        ],
        "dcterms:description": "The Visual Genome dataset provides dense annotations of images, connecting language and vision through crowd-sourced image descriptions.",
        "dcterms:title": "Visual Genome",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Annotation"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Dense annotations",
            "Language and vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Dense Captioning",
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "T. Y. Lin",
            "M. Maire",
            "S. Belongie",
            "J. Hays",
            "P. Perona",
            "D. Ramanan",
            "P. Doll√°r",
            "C. L. Zitnick"
        ],
        "dcterms:description": "COCO is a large-scale dataset designed for object detection, segmentation, and captioning, featuring images with complex scenes and multiple objects.",
        "dcterms:title": "COCO (Common Objects in Context)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Object detection",
            "Segmentation",
            "Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "B. Thomee",
            "D. A. Shamma",
            "G. Friedland",
            "B. Elizalde",
            "K. Ni",
            "D. Poland",
            "D. Borth",
            "L. J. Li"
        ],
        "dcterms:description": "YFCC100M is a dataset containing 100 million photos and videos from Flickr, providing a rich resource for multimedia research.",
        "dcterms:title": "YFCC100M",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1145/2812802",
        "dcat:theme": [
            "Multimedia",
            "Image and Video Research"
        ],
        "dcat:keyword": [
            "Multimedia dataset",
            "Flickr",
            "Image and video research"
        ],
        "dcat:landingPage": "https://doi.org/10.1145/2812802",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Video",
        "mls:task": [
            "Image Captioning",
            "Video Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "M. Minderer",
            "A. Gritsenko",
            "N. Houlsby"
        ],
        "dcterms:description": "WebLI is a dataset designed for open-vocabulary object detection, containing a large number of image-text pairs collected from the web.",
        "dcterms:title": "WebLI",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Open-vocabulary detection",
            "Image-text pairs",
            "Web dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    }
]