To extract datasets from the research paper titled "Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate" by Michela Lorandi and Anya Belz, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and data sections** of the paper to identify any datasets mentioned. The abstract indicates that the authors evaluated their methods on data for under-resourced languages, which suggests that specific datasets are involved.

In **section 2 (Data and Task)**, the authors mention the **WebNLG’23 dataset**. They provide details about the dataset, including the number of items available for each language. Specifically, they state that there are 1,778 development items for each language, 1,399 test items for Breton, and 1,665 for Welsh, Irish, and Maltese. They also mention that 13,211 training items were automatically translated from English.

Next, I will look for the **full citation** of the WebNLG’23 dataset in the **References section**. The citation provided is:
> Enrico Aquilina, Anya Belz, Claudia Borg, Liam Cripwell, Claire Gardent, Albert Gatt, John Judge, Michela Lorandi, Anna Nikiforoskaya, William Soto-Martinez, and Craig Thomson. 2023. The 2023 webnlg shared task on low resource languages overview and evaluation results (webnlg 2023). In Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge, Prague, Czech Republic.

Since the paper primarily discusses the WebNLG’23 dataset, I will focus on this dataset for extraction.

Now, I will compile the dataset entry with the necessary details, including the full citation, ensuring that it is ready for downstream processing or review.