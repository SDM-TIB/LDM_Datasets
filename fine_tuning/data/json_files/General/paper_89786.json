[
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding, which includes various NLP tasks.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "NLP tasks",
            "Benchmark",
            "Multi-task learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing over 100,000 questions for machine comprehension of text, designed for evaluating reading comprehension systems.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question answering",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel Bowman"
        ],
        "dcterms:description": "A dataset for multi-genre natural language inference, part of the GLUE benchmark.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Inference"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel Bowman"
        ],
        "dcterms:description": "A dataset for paraphrase identification, part of the GLUE benchmark.",
        "dcterms:title": "QQP",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Detection"
        ],
        "dcat:keyword": [
            "Paraphrase identification",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel Bowman"
        ],
        "dcterms:description": "A sentiment analysis dataset, part of the GLUE benchmark.",
        "dcterms:title": "SST-2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment analysis",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A version of the SQuAD dataset for machine comprehension, specifically version 1.1.",
        "dcterms:title": "SQuAD v1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Question answering",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Reading Comprehension"
        ]
    }
]