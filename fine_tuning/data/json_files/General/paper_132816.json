[
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano"
        ],
        "dcterms:description": "A dataset for training models to solve math word problems, focusing on mathematical reasoning.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2110.14168",
        "dcat:theme": [
            "Mathematical Reasoning"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Mathematical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2110.14168",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical problem solving"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Saurav Kadavath",
            "Akul Arora",
            "Steven Basart",
            "Eric Tang",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A dataset designed to measure mathematical problem solving capabilities.",
        "dcterms:title": "MATH",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2103.03874",
        "dcat:theme": [
            "Mathematical Reasoning"
        ],
        "dcat:keyword": [
            "Mathematics",
            "Problem solving",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2103.03874",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical problem solving"
        ]
    },
    {
        "dcterms:creator": [
            "Mark Chen",
            "Jerry Tworek",
            "Heewoo Jun",
            "Qiming Yuan",
            "Henrique Ponde de Oliveira Pinto",
            "Jared Kaplan",
            "Harri Edwards",
            "Yuri Burda",
            "Nicholas Joseph",
            "Greg Brockman",
            "Alex Ray",
            "Raul Puri",
            "Gretchen Krueger",
            "Michael Petrov",
            "Heidy Khlaaf",
            "Girish Sastry",
            "Pamela Mishkin",
            "Brooke Chan",
            "Scott Gray",
            "Nick Ryder",
            "Mikhail Pavlov",
            "Alethea Power",
            "Lukasz Kaiser",
            "Mohammad Bavarian",
            "Clemens Winter",
            "Philippe Tillet",
            "Felipe Petroski Such",
            "Dave Cummings",
            "Matthias Plappert",
            "Fotios Chantzis",
            "Elizabeth Barnes",
            "Ariel Herbert-Voss",
            "William Hebgen Guss",
            "Alex Nichol",
            "Alex Paino",
            "Nikolas Tezak",
            "Jie Tang",
            "Igor Babuschkin",
            "Suchir Balaji",
            "Shantanu Jain",
            "William Saunders",
            "Christopher Hesse",
            "Andrew N. Carr",
            "Jan Leike",
            "Josh Achiam",
            "Vedant Misra",
            "Evan Morikawa",
            "Alec Radford",
            "Matthew Knight",
            "Miles Brundage",
            "Mira Murati",
            "Katie Mayer",
            "Peter Welinder",
            "Bob McGrew",
            "Dario Amodei",
            "Sam McCandlish",
            "Ilya Sutskever",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "A dataset for evaluating large language models trained on code.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2106.10454",
        "dcat:theme": [
            "Code Generation"
        ],
        "dcat:keyword": [
            "Code generation",
            "Programming",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2106.10454",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code generation"
        ]
    },
    {
        "dcterms:creator": [
            "Mirac Suzgun",
            "Nathan Scales",
            "Nathanael Schärli",
            "Sebastian Gehrmann",
            "Yi Tay",
            "Hyung Won Chung",
            "Aakanksha Chowdhery",
            "Quoc V Le",
            "Ed H Chi",
            "Denny Zhou",
            "Jason Wei"
        ],
        "dcterms:description": "A dataset for evaluating logical reasoning tasks.",
        "dcterms:title": "Logical Deductions",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2210.09261",
        "dcat:theme": [
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Logical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2210.09261",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Mirac Suzgun",
            "Nathan Scales",
            "Nathanael Schärli",
            "Sebastian Gehrmann",
            "Yi Tay",
            "Hyung Won Chung",
            "Aakanksha Chowdhery",
            "Quoc V Le",
            "Ed H Chi",
            "Denny Zhou",
            "Jason Wei"
        ],
        "dcterms:description": "A dataset for evaluating reasoning tasks involving penguins.",
        "dcterms:title": "Penguins",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2210.09261",
        "dcat:theme": [
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Logical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2210.09261",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Di Jin",
            "Eileen Pan",
            "Nassim Oufattole",
            "Wei-Hung Weng",
            "Hanyi Fang",
            "Peter Szolovits"
        ],
        "dcterms:description": "A large-scale open domain question answering dataset from medical exams.",
        "dcterms:title": "MedQA",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2009.13081",
        "dcat:theme": [
            "Medical Question Answering"
        ],
        "dcat:keyword": [
            "Medical exams",
            "Question answering",
            "Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2009.13081",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Md Tanvirul Alam",
            "Dipkamal Bhusal",
            "Youngja Park",
            "Nidhi Rastogi"
        ],
        "dcterms:description": "A Python library for cybersecurity named entity recognition.",
        "dcterms:title": "CyNER",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cybersecurity"
        ],
        "dcat:keyword": [
            "Named entity recognition",
            "Cybersecurity",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Named entity recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Rami Aly",
            "Zhijiang Guo",
            "Michael Sejr Schlichtkrull",
            "James Thorne",
            "Andreas Vlachos",
            "Christos Christodoulopoulos",
            "Oana Cocarascu",
            "Arpit Mittal"
        ],
        "dcterms:description": "A dataset for fact extraction and verification over unstructured and structured information.",
        "dcterms:title": "FEVER",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Fact Verification"
        ],
        "dcat:keyword": [
            "Fact extraction",
            "Verification",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Fact verification"
        ]
    },
    {
        "dcterms:creator": [
            "Mor Geva",
            "Daniel Khashabi",
            "Elad Segal",
            "Tushar Khot",
            "Dan Roth",
            "Jonathan Berant"
        ],
        "dcterms:description": "A question answering benchmark with implicit reasoning strategies.",
        "dcterms:title": "StrategyQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zi Lin",
            "Zihan Wang",
            "Yongqi Tong",
            "Yangkun Wang",
            "Yuxin Guo",
            "Yujia Wang",
            "Jingbo Shang"
        ],
        "dcterms:description": "A dataset unveiling hidden challenges of toxicity detection in real-world user-AI conversation.",
        "dcterms:title": "ToxicChats",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Detection"
        ],
        "dcat:keyword": [
            "Toxicity detection",
            "User-AI conversation",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity detection"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Saurav Kadavath",
            "Akul Arora",
            "Steven Basart",
            "Eric Tang",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A dataset measuring mathematical problem solving capabilities.",
        "dcterms:title": "MMLU (PM)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematical Reasoning"
        ],
        "dcat:keyword": [
            "Mathematics",
            "Problem solving",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical problem solving"
        ]
    },
    {
        "dcterms:creator": [
            "Mirac Suzgun",
            "Nathan Scales",
            "Nathanael Schärli",
            "Sebastian Gehrmann",
            "Yi Tay",
            "Hyung Won Chung",
            "Aakanksha Chowdhery",
            "Quoc V Le",
            "Ed H Chi",
            "Denny Zhou",
            "Jason Wei"
        ],
        "dcterms:description": "A dataset for evaluating visual reasoning tasks.",
        "dcterms:title": "Geometric Shapes",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Visual reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Takeshi Kojima",
            "Shixiang Shane Gu",
            "Machel Reid",
            "Yutaka Matsuo",
            "Yusuke Iwasawa"
        ],
        "dcterms:description": "A dataset for symbolic reasoning tasks.",
        "dcterms:title": "LastLetterConcat",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Symbolic Reasoning"
        ],
        "dcat:keyword": [
            "Symbolic reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Symbolic reasoning"
        ]
    }
]