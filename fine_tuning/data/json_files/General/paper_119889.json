[
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur P. Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee",
            "Kristina Toutanova",
            "Llion Jones",
            "Matthew Kelcey",
            "Ming-Wei Chang",
            "Andrew M. Dai",
            "Jakob Uszkoreit",
            "Quoc Le",
            "Slav Petrov"
        ],
        "dcterms:description": "A dataset used for training and evaluating open-domain question answering systems, consisting of questions and corresponding answers derived from Wikipedia.",
        "dcterms:title": "Natural Questions dataset (NQ)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Open-domain QA",
            "Wikipedia",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Nandan Thakur",
            "Nils Reimers",
            "Andreas Rücklé",
            "Abhishek Srivastava",
            "Iryna Gurevych"
        ],
        "dcterms:description": "A heterogeneous benchmark for zero-shot evaluation of information retrieval models, covering diverse domains and tasks.",
        "dcterms:title": "BEIR benchmark datasets",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Retrieval"
        ],
        "dcat:keyword": [
            "Zero-shot evaluation",
            "Information retrieval",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Information Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "George Tsatsaronis",
            "Georgios Balikas",
            "Prodromos Malakasiotis",
            "Ioannis Partalas",
            "Matthias Zschunke",
            "Michael R. Alvers",
            "Dirk Weissenborn",
            "Anastasia Krithara",
            "Sergios Petridis",
            "Dimitris Polychronopoulos",
            "Yannis Almirantis",
            "John Pavlopoulos",
            "Nicolas Baskiotis",
            "Patrick Gallinari",
            "Thierry Artières",
            "Axel-Cyrille Ngonga Ngomo",
            "Norman Heino",
            "Éric Gaussier",
            "Liliana Barrio-Alvers",
            "Michael Schroeder",
            "Ion Androutsopoulos",
            "Georgios Paliouras"
        ],
        "dcterms:description": "A large-scale biomedical semantic indexing and question answering competition dataset, focusing on biomedical literature.",
        "dcterms:title": "BioASQ",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical Question Answering"
        ],
        "dcat:keyword": [
            "Biomedical",
            "Semantic indexing",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Macedo Maia",
            "Siegfried Handschuh",
            "André Freitas",
            "Brian Davis",
            "Ross McDermott",
            "Manel Zarrouk",
            "Alexandra Balahur"
        ],
        "dcterms:description": "A dataset for financial opinion mining and question answering, used in a challenge at the WWW 2018 conference.",
        "dcterms:title": "FiQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Financial Question Answering"
        ],
        "dcat:keyword": [
            "Finance",
            "Opinion mining",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "Li Deng"
        ],
        "dcterms:description": "A human-generated machine reading comprehension dataset designed for training and evaluating reading comprehension models.",
        "dcterms:title": "MS MARCO",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Dataset",
            "Human-generated"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Doris Hoogeveen",
            "Karin M. Verspoor",
            "Timothy Baldwin"
        ],
        "dcterms:description": "A benchmark dataset for community question-answering research, focusing on duplicate question retrieval.",
        "dcterms:title": "CQADupStack",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Community Question Answering"
        ],
        "dcat:keyword": [
            "Duplicate questions",
            "Question answering",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Ellen M. Voorhees",
            "Tasmeer Alam",
            "Steven Bedrick",
            "Dina Demner-Fushman",
            "William R. Hersh",
            "Kyle Lo",
            "Kirk Roberts",
            "Ian Soboroff",
            "Lucy Lu Wang"
        ],
        "dcterms:description": "A test collection constructed for pandemic information retrieval, focusing on COVID-19 related information.",
        "dcterms:title": "TREC-COVID",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Retrieval"
        ],
        "dcat:keyword": [
            "COVID-19",
            "Information retrieval",
            "Test collection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Information Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Arman Cohan",
            "Sergey Feldman",
            "Iz Beltagy",
            "Doug Downey",
            "Daniel S. Weld"
        ],
        "dcterms:description": "A dataset for citation prediction, focusing on scientific documents and their citations.",
        "dcterms:title": "SCIDOCS",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Citation Prediction"
        ],
        "dcat:keyword": [
            "Citations",
            "Scientific documents",
            "Prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Citation Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "David Wadden",
            "Shanchuan Lin",
            "Kyle Lo",
            "Lucy Lu Wang",
            "Madeleine van Zuylen",
            "Arman Cohan",
            "Hannaneh Hajishirzi"
        ],
        "dcterms:description": "A dataset for fact-checking, focusing on verifying scientific claims.",
        "dcterms:title": "SciFact",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Fact Checking"
        ],
        "dcat:keyword": [
            "Scientific claims",
            "Verification",
            "Fact checking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Fact Checking"
        ]
    }
]