[
    {
        "dcterms:creator": [
            "Hanmeng Liu",
            "Jian Liu",
            "Leyang Cui",
            "Nan Duan",
            "Ming Zhou",
            "Yue Zhang"
        ],
        "dcterms:description": "LogiQA-v2 is a dataset designed for logical reasoning in machine reading comprehension (MRC) and natural language inference (NLI) tasks, providing a challenging benchmark for evaluating reasoning capabilities of models.",
        "dcterms:title": "LogiQA-v2",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Logical Reasoning",
            "Machine Reading Comprehension"
        ],
        "dcat:keyword": [
            "Logical reasoning",
            "Natural language inference",
            "Machine reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Logical reasoning",
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Weihao Yu",
            "Zihang Jiang",
            "Yanfei Dong",
            "Jiashi Feng"
        ],
        "dcterms:description": "ReClor is a reading comprehension dataset that requires logical reasoning, designed to evaluate the reasoning capabilities of models through multiple-choice questions.",
        "dcterms:title": "ReClor",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Logical Reasoning",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Logical reasoning",
            "Multiple choice questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading comprehension",
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano",
            "Christopher Hesse",
            "John Schulman"
        ],
        "dcterms:description": "GSM8K is a dataset for training models to solve math word problems, providing a benchmark for evaluating mathematical reasoning capabilities.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "abs/2110.14168",
        "dcat:theme": [
            "Mathematical Reasoning",
            "Word Problems"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Mathematical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical reasoning",
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Saurav Kadavath",
            "Akul Arora",
            "Steven Basart",
            "Eric Tang",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "MATH is a dataset designed to measure mathematical problem solving, providing a benchmark for evaluating models' mathematical reasoning capabilities.",
        "dcterms:title": "MATH",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematical Reasoning",
            "Problem Solving"
        ],
        "dcat:keyword": [
            "Mathematical problem solving",
            "Dataset",
            "Mathematics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical reasoning",
            "Problem solving"
        ]
    }
]