[
    {
        "dcterms:creator": [
            "Ramon Sanabria",
            "Ozan Caglayan",
            "Shruti Palaskar",
            "Desmond Elliott",
            "Lo√Øc Barrault",
            "Lucia Specia",
            "Florian Metze"
        ],
        "dcterms:description": "The dataset consists of 300 hours of instructional videos from the YouTube platform, depicting people showcasing particular skills with high variation in video/audio quality, camera angles, and duration. Transcriptions are mined from YouTube subtitles, containing a mix of automatically generated and human-annotated transcriptions.",
        "dcterms:title": "How2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Language Understanding",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Instructional videos",
            "Audio-visual speech recognition",
            "Transcriptions",
            "Multimodal grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Automatic Speech Recognition",
            "Multimodal Learning"
        ]
    }
]