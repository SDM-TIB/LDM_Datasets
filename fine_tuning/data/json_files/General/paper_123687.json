[
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "A 2D maze-like environment where the agent can take discrete steps and needs to navigate from the start to the goal position. It includes variations of the input space: global visibility and goal-conditioned observation.",
        "dcterms:title": "Discrete Grid World",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Grid world",
            "Navigation",
            "Reinforcement learning",
            "Discrete steps"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Navigation",
            "Pathfinding"
        ]
    },
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "An environment that replaces tabular states with image-based inputs, adding complexity and making the setup more reflective of real-world conditions. It is particularly useful for evaluating image-based navigation policies.",
        "dcterms:title": "Visual Grid World",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Image-based navigation",
            "Visual inputs",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Navigation",
            "Image processing"
        ]
    },
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "A high-fidelity simulated outdoor environment that closely replicates real-world navigation scenarios, including various types of trees and buildings.",
        "dcterms:title": "Simulated Outdoor Environment",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Outdoor simulation",
            "Navigation",
            "Robotics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Navigation",
            "Pathfinding"
        ]
    },
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "A dataset for real-world indoor navigation tasks, where the robot must navigate through various obstacles and spaces.",
        "dcterms:title": "Real-World Indoor Navigation",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Indoor navigation",
            "Robotics",
            "Obstacle avoidance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Real-world data",
        "mls:task": [
            "Navigation",
            "Pathfinding"
        ]
    },
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "A collection of expert demonstration trajectories used to train the behavioral policy for navigation tasks.",
        "dcterms:title": "Expert Demonstration Data (D)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Expert demonstrations",
            "Imitation learning",
            "Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Demonstration data",
        "mls:task": [
            "Imitation learning",
            "Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Chakraborty",
            "K. Weerakoon",
            "P. Poddar",
            "P. Tokekar",
            "A. S. Bedi",
            "D. Manocha"
        ],
        "dcterms:description": "Simulated data used for training and testing navigation policies in various environments.",
        "dcterms:title": "Dsim (Simulated Data)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotic Navigation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Simulated data",
            "Navigation",
            "Robotics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Navigation",
            "Pathfinding"
        ]
    }
]