[
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Kenton Lee",
            "Ming-Wei Chang",
            "Tom Kwiatkowski",
            "Michael Collins",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset for exploring the difficulty of natural yes/no questions.",
        "dcterms:title": "BoolQ",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1905.10044",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Yes/No questions",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Marie-Catherine De Marneffe",
            "Mandy Simons",
            "Judith Tonhauser"
        ],
        "dcterms:description": "A dataset for investigating projection in naturally occurring discourse.",
        "dcterms:title": "CB",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Discourse Analysis"
        ],
        "dcat:keyword": [
            "Projection",
            "Discourse"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Discourse Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Melissa Roemmele",
            "Cosmin Adrian Bejan",
            "Andrew S Gordon"
        ],
        "dcterms:description": "A dataset for evaluating commonsense causal reasoning.",
        "dcterms:title": "COPA",
        "dcterms:issued": "2011",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Causal reasoning",
            "Commonsense knowledge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Causal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Khashabi",
            "Snigdha Chaturvedi",
            "Michael Roth",
            "Shyam Upadhyay",
            "Dan Roth"
        ],
        "dcterms:description": "A challenge set for reading comprehension over multiple sentences.",
        "dcterms:title": "MultiRC",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Multi-sentence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Sheng Zhang",
            "Xiaodong Liu",
            "Jingjing Liu",
            "Jianfeng Gao",
            "Kevin Duh",
            "Benjamin Van Durme"
        ],
        "dcterms:description": "A dataset bridging the gap between human and machine commonsense reading comprehension.",
        "dcterms:title": "ReCoRD",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1810.12885",
        "dcat:theme": [
            "Natural Language Processing",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Danilo Giampiccolo",
            "Bernardo Magnini",
            "Ido Dagan",
            "William B Dolan"
        ],
        "dcterms:description": "A dataset for recognizing textual entailment.",
        "dcterms:title": "RTE",
        "dcterms:issued": "2007",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Textual Entailment"
        ],
        "dcat:keyword": [
            "Textual entailment",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Textual Entailment"
        ]
    },
    {
        "dcterms:creator": [
            "Mohammad Taher Pilehvar",
            "Jose Camacho-Collados"
        ],
        "dcterms:description": "A dataset for evaluating context-sensitive meaning representations.",
        "dcterms:title": "WiC",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1808.09121",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Sense Disambiguation"
        ],
        "dcat:keyword": [
            "Word in context",
            "Contextual meaning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Sense Disambiguation"
        ]
    },
    {
        "dcterms:creator": [
            "Hector Levesque",
            "Ernest Davis",
            "Leora Morgenstern"
        ],
        "dcterms:description": "A challenge for evaluating commonsense reasoning.",
        "dcterms:title": "WSC",
        "dcterms:issued": "2012",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Schema challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Kenton Lee",
            "Ming-Wei Chang",
            "Tom Kwiatkowski",
            "Michael Collins",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset for evaluating question answering.",
        "dcterms:title": "Arc-C",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1803.05457",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "AI2 reasoning challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Kenton Lee",
            "Ming-Wei Chang",
            "Tom Kwiatkowski",
            "Michael Collins",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset for evaluating question answering.",
        "dcterms:title": "Arc-E",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1803.05457",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "AI2 reasoning challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Rowan Zellers",
            "Ari Holtzman",
            "Yonatan Bisk",
            "Ali Farhadi",
            "Yejin Choi"
        ],
        "dcterms:description": "A dataset for evaluating the ability of machines to finish sentences.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1905.07830",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentence Completion"
        ],
        "dcat:keyword": [
            "Sentence completion",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Completion"
        ]
    },
    {
        "dcterms:creator": [
            "Yonatan Bisk",
            "Rowan Zellers",
            "Jianfeng Gao",
            "Yejin Choi"
        ],
        "dcterms:description": "A dataset for reasoning about physical commonsense in natural language.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Physical commonsense",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Keisuke Sakaguchi",
            "Ronan Le Bras",
            "Chandra Bhagavatula",
            "Yejin Choi"
        ],
        "dcterms:description": "An adversarial Winograd schema challenge at scale.",
        "dcterms:title": "WinoGrande",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Adversarial challenge",
            "Commonsense reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    }
]