[
    {
        "dcterms:creator": [
            "Yejin Bang",
            "Samuel Cahyawijaya",
            "Nayeon Lee",
            "Wenliang Dai",
            "Dan Su",
            "Bryan Wilie",
            "Holy Lovenia",
            "Ziwei Ji",
            "Tiezheng Yu",
            "Willy Chung",
            "Quyet V. Do",
            "Yan Xu",
            "Pascale Fung"
        ],
        "dcterms:description": "LogiQA is a dataset specifically designed for multi-choice question-answering tasks that involve logical reasoning, adopted from the Chinese Civil Service Examination, translated into English, and released in both Chinese and English versions.",
        "dcterms:title": "LogiQA 2.0",
        "dcterms:issued": "2023",
        "dcterms:language": "English, Chinese",
        "dcterms:identifier": "https://github.com/csitfun/LogiQA2.0",
        "dcat:theme": [
            "Logical Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-choice question-answering",
            "Logical reasoning",
            "Chinese Civil Service Examination"
        ],
        "dcat:landingPage": "https://github.com/csitfun/LogiQA2.0",
        "dcterms:hasVersion": "2.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-choice reading comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Tom B. Brown",
            "Benjamin Mann",
            "Nick Ryder",
            "Melanie Subbiah",
            "Jared Kaplan",
            "Prafulla Dhariwal",
            "Arvind Neelakantan",
            "Pranav Shyam",
            "Girish Sastry",
            "Amanda Askell",
            "Sandhini Agarwal",
            "Ariel Herbert-Voss",
            "Gretchen Krueger",
            "Tom Henighan",
            "Rewon Child",
            "Aditya Ramesh",
            "Daniel M. Ziegler",
            "Jeffrey Wu",
            "Clemens Winter",
            "Christopher Hesse",
            "Mark Chen",
            "Eric Sigler",
            "Mateusz Litwin",
            "Scott Gray",
            "Benjamin Chess",
            "Jack Clark",
            "Christopher Berner",
            "Sam McCandlish",
            "Alec Radford",
            "Ilya Sutskever",
            "Dario Amodei"
        ],
        "dcterms:description": "ReClor is a logical reasoning dataset designed for reading comprehension tasks requiring logical reasoning, collecting question-answering examples from LSAT exams.",
        "dcterms:title": "ReClor",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Logical Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Logical reasoning",
            "LSAT"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Siyuan Wang",
            "Zhongkun Liu",
            "Wanjun Zhong",
            "Ming Zhou",
            "Zhongyu Wei",
            "Zhumin Chen",
            "Nan Duan"
        ],
        "dcterms:description": "AR-LSAT is a new dataset of analytical reasoning questions from the Law School Admission Test, featuring various reasoning games.",
        "dcterms:title": "AR-LSAT",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Logical Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Analytical reasoning",
            "Law School Admission Test"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Analytical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Hanmeng Liu",
            "Leyang Cui",
            "Jian Liu",
            "Yue Zhang"
        ],
        "dcterms:description": "ConTRoL is an NLI dataset that investigates contextual reasoning under the NLI framework, with a focus on logical reasoning.",
        "dcterms:title": "ConTRoL",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Contextual reasoning",
            "Natural Language Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Hitomi Yanaka",
            "Koji Mineshima",
            "Daisuke Bekki",
            "Kentaro Inui",
            "Satoshi Sekine",
            "Johan Bos"
        ],
        "dcterms:description": "MED is an NLI dataset focusing on monotonicity reasoning, generated through monotonicity rules.",
        "dcterms:title": "MED",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Monotonicity reasoning",
            "Natural Language Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Hitomi Yanaka",
            "Koji Mineshima",
            "Daisuke Bekki",
            "Kentaro Inui",
            "Satoshi Sekine",
            "Johan Bos"
        ],
        "dcterms:description": "HELP is an NLI dataset for identifying shortcomings of neural models in monotonicity reasoning.",
        "dcterms:title": "HELP",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Monotonicity reasoning",
            "Natural Language Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Pratik Joshi",
            "Somak Aditya",
            "Aalok Sathe",
            "Monojit Choudhury"
        ],
        "dcterms:description": "TaxiNLI is an NLI dataset re-annotated on the MNLI dataset with fine-grained category labels.",
        "dcterms:title": "TaxiNLI",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Fine-grained categories"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel Bowman"
        ],
        "dcterms:description": "MNLI is a broad-coverage challenge corpus for sentence understanding through inference.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Sentence understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Swarnadeep Saha",
            "Yixin Nie",
            "Mohit Bansal"
        ],
        "dcterms:description": "ConjNLI is a challenging stress test for NLI over conjunctive sentences.",
        "dcterms:title": "ConjNLI",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Conjunctive sentences",
            "Natural Language Inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    }
]