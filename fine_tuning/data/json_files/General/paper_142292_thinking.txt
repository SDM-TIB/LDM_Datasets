To extract datasets from the research paper titled "DLoRA-TrOCR: Mixed Text Mode Optical Character Recognition Based On Transformer" by Da Chang and Yu Li, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions the challenges in OCR and hints at the use of various datasets for evaluation, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section 4 (Experiments)**, particularly **subsection 4.1 (Experiment Setup)**, where the authors describe the datasets used for their experiments. Here, they explicitly mention three types of datasets:

1. **Handwritten dataset**: They specify that this dataset is derived from the **IAM dataset**, which is widely recognized in the field of handwritten text recognition. The authors provide details about the partitioning of the dataset, including the number of lines in the training, validation, and test sets.

2. **Printed dataset**: This dataset is sourced from the **SROIE dataset**, specifically task 2, which focuses on text recognition in receipt images. The authors detail the number of images and lines of text in both the training and test datasets.

3. **Street View Text datasets**: The authors mention that this dataset is compiled from multiple public benchmarks, including IIIT5K-Words, Street View Text, ICDAR 2013, ICDAR 2015, Street View Text-Perspective, and CUTE80. They provide information about the number of lines of text in the training and test sets.

After identifying these datasets, I will refer to the **References section** to find the full citations for each dataset:

- For the **IAM dataset**, the citation is:
  > J. Puigcerver, D. Martin-Albo, and M. Villegas. *Laia: A deep learning toolkit for htr*. GitHub repository, 2016. URL: https://github.com/jpuigcerver/Laia.

- For the **SROIE dataset**, the citation is:
  > Z. Huang, K. Chen, J. He, X. Bai, D. Karatzas, S. Lu, and C. V. Jawahar. *ICDAR2019 competition on scanned receipt ocr and information extraction*. In Proceedings of the International Conference on Document Analysis and Recognition (ICDAR), pages 1516–1520, 2019. URL: https://api.semanticscholar.org/CorpusID:211026630.

- For the **Street View Text datasets**, the citation is:
  > K. Wang, B. Babenko, and S. J. Belongie. *End-to-end scene text recognition*. In Proceedings of the International Conference on Computer Vision (ICCV), pages 1457–1464, 2011. URL: https://api.semanticscholar.org/CorpusID:14136313.

Now that I have gathered the necessary information about the datasets and their citations, I will compile this into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding citations.