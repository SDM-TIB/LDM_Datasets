[
    {
        "dcterms:creator": [
            "Fei Xia",
            "Amir R Zamir",
            "Zhiyang He",
            "Alexander Sax",
            "Jitendra Malik",
            "Silvio Savarese"
        ],
        "dcterms:description": "The Gibson dataset provides real-world perception data for embodied agents, facilitating the training and evaluation of navigation algorithms in realistic environments.",
        "dcterms:title": "Gibson dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Embodied AI"
        ],
        "dcat:keyword": [
            "Real-world perception",
            "Embodied agents",
            "Navigation",
            "3D environments"
        ],
        "dcat:landingPage": "https://storage.googleapis.com/gibson_material/Agreement%20GDS%2006-04-18.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "PointGoal Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Erik Wijmans",
            "Abhishek Kadian",
            "Ari Morcos",
            "Stefan Lee",
            "Irfan Essa",
            "Devi Parikh",
            "Manolis Savva",
            "Dhruv Batra"
        ],
        "dcterms:description": "The 2020 Habitat Challenge dataset is designed for evaluating navigation agents in realistic environments, focusing on PointGoal navigation without access to idealized localization.",
        "dcterms:title": "2020 Habitat Challenge",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Navigation"
        ],
        "dcat:keyword": [
            "PointGoal navigation",
            "Embodied AI",
            "Realistic environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "PointGoal Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Samyak Datta",
            "Oleksandr Maksymets",
            "Judy Hoffman",
            "Stefan Lee",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "The Egomotion dataset is utilized for training agents to estimate their own motion based on consecutive RGB-D observations, enhancing their ability to navigate in environments.",
        "dcterms:title": "Egomotion dataset (used by Datta et al.)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2009.03231",
        "dcat:theme": [
            "Computer Vision",
            "Navigation"
        ],
        "dcat:keyword": [
            "Egomotion",
            "Localization",
            "RGB-D observations"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2009.03231",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Egomotion Estimation"
        ]
    }
]