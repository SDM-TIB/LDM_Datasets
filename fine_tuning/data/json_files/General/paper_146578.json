[
    {
        "dcterms:creator": [
            "Qingyue Wang",
            "Liang Ding",
            "Yanan Cao",
            "Zhiliang Tian",
            "Shi Wang",
            "Dacheng Tao",
            "Li Guo"
        ],
        "dcterms:description": "A dataset containing multi-session dialogue data with summaries of each speaker's persona and aggregated summary information after multiple sessions.",
        "dcterms:title": "Multi-Session Chat (MSC)",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-session dialogue",
            "Dialogue summarization",
            "Speaker persona"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Management",
            "Memory Management"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Negative samples generated for training the Direct Preference Optimization (DPO) algorithm, created by modifying entities in sentences to reflect causal relationships.",
        "dcterms:title": "DPO negative sample",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Negative samples",
            "Direct Preference Optimization",
            "Causal information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reinforcement Learning",
            "Preference Learning"
        ]
    }
]