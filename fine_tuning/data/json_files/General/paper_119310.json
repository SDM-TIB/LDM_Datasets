[
    {
        "dcterms:creator": [
            "Junichi Yamagishi"
        ],
        "dcterms:description": "The VCTK dataset contains around 44 hours of speech from 110 speakers, sampled at 48 kHz. The training and test setup omits speakers p280 and p315, using recordings from mic1, with the first 100 speakers for training and the remaining 8 speakers for testing.",
        "dcterms:title": "VCTK",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Multi-speaker corpus",
            "Voice cloning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Super Resolution",
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Zafar Rafii"
        ],
        "dcterms:description": "The MusDB dataset contains 150 songs (10 hours) of musical mixtures, along with isolated stems, sampled at 44.1 kHz. The provided train/test setup uses only the mixture tracks to test the model and baselines.",
        "dcterms:title": "MusDB",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Music Processing"
        ],
        "dcat:keyword": [
            "Music dataset",
            "Musical mixtures",
            "Isolated stems"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio Super Resolution",
            "Music Source Separation"
        ]
    }
]