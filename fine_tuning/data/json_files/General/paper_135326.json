[
    {
        "dcterms:creator": [
            "S. Changpinyo",
            "P. Sharma",
            "N. Ding",
            "R. Soricut"
        ],
        "dcterms:description": "A dataset containing image-text pairs designed to enhance the recognition of long-tail visual concepts.",
        "dcterms:title": "CC3M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Image-Text Understanding"
        ],
        "dcat:keyword": [
            "Image-text pairs",
            "Long-tail visual concepts",
            "Multimodal datasets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Concept Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "X. Chen",
            "H. Fang",
            "T.-Y. Lin",
            "R. Vedantam",
            "S. Gupta",
            "P. Doll√°r",
            "C. L. Zitnick"
        ],
        "dcterms:description": "A dataset for image captioning that includes a large number of images with corresponding captions.",
        "dcterms:title": "COCO Captioning",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1504.00325",
        "dcat:theme": [
            "Image Captioning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Image captions",
            "Image-text pairs",
            "Dataset for evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "B. A. Plummer",
            "L. Wang",
            "C. M. Cervantes",
            "J. C. Caicedo",
            "J. Hockenmaier",
            "S. Lazebnik"
        ],
        "dcterms:description": "A dataset that collects region-to-phrase correspondences for richer image-to-sentence models.",
        "dcterms:title": "Flick-30k",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image-Text Correspondence",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Region-to-phrase correspondences",
            "Image-to-sentence models",
            "Image-text pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Image Captioning",
            "Image-Text Correspondence"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Basart",
            "A. Zou",
            "M. Mazeika",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "A benchmark for measuring massive multitask language understanding.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Understanding",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask learning",
            "Language understanding",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bisk",
            "R. Zellers",
            "R. L. Bras",
            "J. Gao",
            "Y. Choi"
        ],
        "dcterms:description": "A dataset for reasoning about physical commonsense in natural language.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Physical commonsense",
            "Reasoning",
            "Natural language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Talmor",
            "J. Herzig",
            "N. Lourie",
            "J. Berant"
        ],
        "dcterms:description": "A question answering challenge targeting commonsense knowledge.",
        "dcterms:title": "Commonsense QA (CSQA)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense knowledge",
            "Question answering",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "T. Mihaylov",
            "P. Clark",
            "T. Khot",
            "A. Sabharwal"
        ],
        "dcterms:description": "A dataset for open book question answering requiring multi-step reasoning.",
        "dcterms:title": "OpenBook QA (OBQA)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Open book",
            "Multi-step reasoning",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "B. Y. Lin",
            "Z. Wu",
            "Y. Yang",
            "D.-H. Lee",
            "X. Ren"
        ],
        "dcterms:description": "A dataset for reasoning about riddle questions featuring linguistic creativity and commonsense knowledge.",
        "dcterms:title": "RiddleSense (RS)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2101.00376",
        "dcat:theme": [
            "Commonsense Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Riddles",
            "Commonsense knowledge",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Sap",
            "H. Rashkin",
            "D. Chen",
            "R. LeBras",
            "Y. Choi"
        ],
        "dcterms:description": "A dataset for commonsense reasoning about social interactions.",
        "dcterms:title": "Social IQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1904.09728",
        "dcat:theme": [
            "Social Reasoning",
            "Commonsense Knowledge"
        ],
        "dcat:keyword": [
            "Social interactions",
            "Commonsense reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Geva",
            "D. Khashabi",
            "E. Segal",
            "T. Khot",
            "D. Roth",
            "J. Berant"
        ],
        "dcterms:description": "A question answering benchmark that requires implicit reasoning strategies.",
        "dcterms:title": "StrategyQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Implicit reasoning",
            "Question answering",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Antol",
            "A. Agrawal",
            "J. Lu",
            "M. Mitchell",
            "D. Batra",
            "C. L. Zitnick",
            "D. V. Parikh"
        ],
        "dcterms:description": "A visual question answering dataset that includes a variety of images and questions.",
        "dcterms:title": "VQAv2",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Visual questions",
            "Image understanding",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "K. Marino",
            "M. Rastegari",
            "A. Farhadi",
            "R. Mottaghi"
        ],
        "dcterms:description": "A visual question answering benchmark that requires external knowledge.",
        "dcterms:title": "OK-VQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Knowledge-based Reasoning"
        ],
        "dcat:keyword": [
            "External knowledge",
            "Visual questions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. F. Biten",
            "R. Tito",
            "A. Mafla",
            "L. Gomez",
            "M. Rusinol",
            "E. Valveny",
            "C. Jawahar",
            "D. Karatzas"
        ],
        "dcterms:description": "A dataset for scene text visual question answering.",
        "dcterms:title": "ST-VQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Text Recognition"
        ],
        "dcat:keyword": [
            "Scene text",
            "Visual questions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Mishra",
            "S. Shekhar",
            "A. K. Singh",
            "A. Chakraborty"
        ],
        "dcterms:description": "A dataset for visual question answering by reading text in images.",
        "dcterms:title": "OCR-VQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Text Recognition"
        ],
        "dcat:keyword": [
            "OCR",
            "Visual questions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Singh",
            "V. Natarjan",
            "M. Shah",
            "Y. Jiang",
            "X. Chen",
            "D. Batra",
            "D. Parikh",
            "M. Rohrbach"
        ],
        "dcterms:description": "A dataset aimed at developing VQA models that can read text.",
        "dcterms:title": "TextVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Text Recognition"
        ],
        "dcat:keyword": [
            "Text reading",
            "Visual questions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Mathew",
            "D. Karatzas",
            "C. Jawahar"
        ],
        "dcterms:description": "A dataset for visual question answering on document images.",
        "dcterms:title": "DocVQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Document Understanding"
        ],
        "dcat:keyword": [
            "Document images",
            "Visual questions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]