[
    {
        "dcterms:creator": [
            "A. Wang",
            "A. Singh",
            "J. Michael",
            "F. Hill",
            "O. Levy",
            "S. R. Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding, including various tasks such as sentence similarity, sentiment classification, and textual entailment.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/s17-2001",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multi-task learning",
            "Natural language understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence similarity",
            "Sentiment classification",
            "Textual entailment"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "R. Jia",
            "P. Liang"
        ],
        "dcterms:description": "A dataset for question answering that includes unanswerable questions, extending the original SQuAD dataset.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/s17-2001",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Unanswerable questions",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "J. Zhang",
            "K. Lopyrev",
            "P. Liang"
        ],
        "dcterms:description": "A dataset containing over 100,000 questions for machine comprehension of text.",
        "dcterms:title": "SQuAD1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Machine comprehension",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "R. Jia",
            "P. Liang"
        ],
        "dcterms:description": "An extension of SQuAD1.1 that includes unanswerable questions.",
        "dcterms:title": "SQuAD2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Unanswerable questions",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    }
]