To extract datasets from the research paper titled "Regionalized models for Spanish language variations based on Twitter" by Eric S. Tellez et al., I will follow a systematic approach to identify and document the datasets mentioned throughout the paper.

First, I will read through the **abstract** and **introduction** sections to get an overview of the datasets discussed. The abstract mentions the creation of regionalized resources based on Twitter messages from 26 Spanish-speaking countries, which indicates that there are datasets related to Twitter data.

Next, I will focus on **section 2 (Twitter corpora of the Spanish language)**, where the authors describe the collection of tweets. They mention that they collected geotagged tweets from 2016 to 2019, which is a significant dataset. I will look for specific details about the dataset, such as the number of tweets collected from each country and any relevant statistics.

In **Table 1**, the authors provide a detailed breakdown of the datasets, including the number of tweets and users from each country. This table is crucial for extracting the dataset information. The countries listed include Argentina, Bolivia, Chile, Colombia, and others, along with their respective statistics.

I will also check the **References section** to find full citations for any datasets mentioned. The authors may reference other works that describe the datasets or methodologies used to collect the data.

The key datasets identified in the paper are:

1. **Twitter Spanish Corpora (TSC)**: This dataset consists of tweets collected from 26 Spanish-speaking countries, with a total of approximately 800 million messages after filtering. The dataset is characterized by the number of tweets, users, and tokens from each country.

2. **Regional Word Embeddings**: The authors created FastText models for each country based on the Twitter data, which serve as semantic representations of the regional vocabularies.

3. **BILMA Language Models**: These are pre-trained BERT-like models developed using the Twitter data from specific countries, aimed at understanding regional language variations.

Now, I will compile the full citations for the datasets mentioned:

- For the **Twitter Spanish Corpora (TSC)**, the citation is:
  > Tellez, E. S., Moctezuma, D., Miranda, S., Graff, M., & Ruiz, G. (2021). Regionalized models for Spanish language variations based on Twitter. *Linguistic Resources*.

- For the **FastText models**, the citation is:
  > Grave, E., Bojanowski, P., Gupta, P., Joulin, A., & Mikolov, T. (2018). Learning Word Vectors for 157 Languages. Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018).

- For the **BILMA models**, the citation is:
  > Tellez, E. S., Moctezuma, D., Miranda, S., Graff, M., & Ruiz, G. (2021). BILMA: Bert In Latin America. *Linguistic Resources*.

After gathering this information, I will summarize the datasets and their citations in a structured format for easy reference and further analysis.