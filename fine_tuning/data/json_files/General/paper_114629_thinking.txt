To extract datasets from the research paper titled "HyperNST: Hyper-Networks for Neural Style Transfer" by Dan Ruta et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, methodology, and evaluation sections** of the paper. The abstract mentions a technique for artistic stylization based on a dataset of artistic portraits, which suggests that datasets are involved.

Next, I will focus on **section 4 (Evaluation)**, where the authors explicitly discuss the datasets used for their experiments. In this section, they mention creating a test dataset for evaluation, which consists of images from two specific datasets:

1. **FFHQ (Flickr-Faces-HQ)**: The authors state that they extracted 100 random content images from this dataset. This indicates that FFHQ is a significant dataset used in their evaluation.

2. **AAHQ (Artstation Artistic HQ)**: Similarly, they mention extracting 100 random style images from this dataset, which is also crucial for their experiments.

The authors further explain that these two datasets combined result in 10,000 evaluation images when all combinations are used for stylization. This confirms the importance of both datasets in their research.

Now, I will check the **References section** to find the full citations for these datasets:

- For **FFHQ**, the citation is:
  > Tero Karras, Samuli Laine, and Timo Aila. *A style-based generator architecture for generative adversarial networks*. In Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV), pages 4401â€“4410, 2019.

- For **AAHQ**, the citation is:
  > Mingcong Liu, Qiang Li, Zekui Qin, Guoxin Zhang, Pengfei Wan, and Wen Zheng. *Blendgan: Implicitly GAN blending for arbitrary stylized face generation*. CoRR, abs/2110.11728, 2021.

Having gathered this information, I will now summarize the datasets and their citations clearly, ensuring that I maintain the integrity of the information for future reference or processing.