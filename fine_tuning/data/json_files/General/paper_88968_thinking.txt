To extract datasets from the research paper titled "Gesticulator: A framework for semantically-aware speech-driven gesture generation" by Taras Kucherenko et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract provides a brief overview of the research, and the introduction often highlights the datasets used for the experiments.

In the **introduction**, the authors mention the importance of gesture generation and refer to a publicly available corpus of 3D co-speech gestures, specifically the **Trinity College dataset**. This indicates that this dataset is likely central to their research.

Next, I will look into **section 3 (Training and Test Data)**, where the authors provide detailed information about the dataset used for training their model. Here, they explicitly state that they used the **Trinity Gesture Dataset**, which consists of 244 minutes of audio and motion capture recordings of a male actor speaking freely on various topics. They also mention that they removed lower-body data and retained 15 upper-body joints.

Additionally, I will check the **References section** to find the full citation for the Trinity Gesture Dataset. The authors reference the dataset as follows:

- **Trinity Gesture Dataset**:
  > Ylva Ferstl and Rachel McDonnell. *Investigating the use of recurrent motion modelling for speech gesture generation*. In Proceedings of the International Conference on Intelligent Virtual Agents, 2018.

Now that I have identified the dataset and its citation, I will compile this information into a structured format for clarity.

In summary, the key steps I took were:
1. Read the abstract and introduction to identify potential datasets.
2. Examine the methodology section for explicit mentions of datasets.
3. Retrieve full citations from the references section.

This systematic approach ensures that I accurately capture the datasets used in the research and provide proper citations for each.