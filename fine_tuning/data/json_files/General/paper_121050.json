[
    {
        "dcterms:creator": [
            "W. Yu",
            "Z. Jiang",
            "Y. Dong",
            "J. Feng"
        ],
        "dcterms:description": "ReClor is a reading comprehension dataset requiring logical reasoning, consisting of 6,138 examples with 17 reasoning types, designed to evaluate the reasoning capabilities of models.",
        "dcterms:title": "ReClor",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Logical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading comprehension",
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Liu",
            "L. Cui",
            "H. Liu",
            "D. Huang",
            "Y. Wang",
            "Y. Zhang"
        ],
        "dcterms:description": "LogiQA is a challenge dataset for machine reading comprehension with logical reasoning, containing 8,678 samples sourced from National Civil Servants Examinations of China.",
        "dcterms:title": "LogiQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Machine reading comprehension",
            "Logical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading comprehension",
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "F. Pourpanah",
            "M. Abdar",
            "Y. Luo",
            "X. Zhou",
            "R. Wang",
            "C. P. Lim",
            "X.-Z. Wang",
            "Q. J. Wu"
        ],
        "dcterms:description": "ZsLR is a benchmark for generalized zero-shot logical reasoning, designed to evaluate models on unseen reasoning types through various sampling strategies.",
        "dcterms:title": "ZsLR (Generalized Zero-shot Logical Reasoning)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Logical Reasoning"
        ],
        "dcat:keyword": [
            "Zero-shot learning",
            "Logical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "https://github.com/xufangzhi/TaCo",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Logical reasoning",
            "Zero-shot learning"
        ]
    }
]