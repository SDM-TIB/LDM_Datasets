To extract datasets from the research paper titled "Hitachi at SemEval-2020 Task 12: Offensive Language Identification with Noisy Labels using Statistical Sampling and Post-Processing" by Manikandan Ravikiran et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and dataset sections** to identify any datasets mentioned. The abstract indicates participation in SemEval-2020 Task-12, which suggests that a specific dataset is used for the task.

Next, I will focus on **section 3 (Dataset)**, where the authors provide detailed information about the dataset used for the task. They mention that the dataset consists of **9,275,847 noisy labeled tweets** and is divided into three subtasks. The specifics of each subtask are crucial for understanding the dataset's structure:

1. **Subtask-A**: Offensive language detection (1,88,728 tweets).
2. **Subtask-B**: Categorizing offensive language targeting a specific entity (9,087,119 tweets).
3. **Subtask-C**: Identifying whether the target of an offensive post is an individual, group, or unknown (1,13,803 tweets).

The authors also mention that the dataset is based on the work of Rosenthal et al. (2020), which is essential for citation purposes.

I will then check the **References section** to find the full citation for the dataset. The relevant citation for the dataset is:

- For the SemEval-2020 Task-12 dataset:
  > Sara Rosenthal, Pepa Atanasova, Georgi Karadzhov, Marcos Zampieri, and Preslav Nakov. *A Large-Scale Semi-Supervised Dataset for Offensive Language Identification*. In arXiv, 2020.

After gathering this information, I will compile the dataset details, ensuring to include the full citation for the dataset as required. This will provide a comprehensive overview of the datasets used in the research paper.