[
    {
        "dcterms:creator": [
            "Y. Jiao",
            "A. GabryÂ´s",
            "G. Tinchev",
            "B. Putrycz",
            "D. Korzekwa",
            "V. Klimkov"
        ],
        "dcterms:description": "An internal dataset of 200 speech hours recorded by 116 native speakers of English, across a variety of expressive speaking styles such as happiness, sadness, anger, etc.",
        "dcterms:title": "Internal dataset of 200 speech hours",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Text-to-Speech",
            "Expressive speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Synthesis",
            "Prosody Modelling",
            "Acoustic Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "C. Miao",
            "S. Liang",
            "M. Chen",
            "J. Ma",
            "S. Wang",
            "J. Xiao"
        ],
        "dcterms:description": "A non-autoregressive network for text to speech based on flow, used for acoustic modelling.",
        "dcterms:title": "Flow-TTS model",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Flow-based model",
            "Text-to-Speech",
            "Acoustic modelling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis",
            "Acoustic Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "V. Popov",
            "I. Vovk",
            "V. Gogoryan",
            "T. Sadekova",
            "M. Kudinov"
        ],
        "dcterms:description": "A diffusion probabilistic model for text-to-speech, used for acoustic modelling.",
        "dcterms:title": "Diffusion models",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Diffusion model",
            "Text-to-Speech",
            "Acoustic modelling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis",
            "Acoustic Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ren",
            "C. Hu",
            "X. Tan",
            "T. Qin",
            "S. Zhao",
            "Z. Zhao",
            "T.-Y. Liu"
        ],
        "dcterms:description": "A model trained with L2 loss for prosody prediction, used in the context of text-to-speech synthesis.",
        "dcterms:title": "L2 loss-based model",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "L2 loss",
            "Prosody prediction",
            "Text-to-Speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis",
            "Prosody Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Hodari",
            "O. Watts",
            "S. King"
        ],
        "dcterms:description": "A generative modelling approach to produce varied intonation for speech synthesis.",
        "dcterms:title": "Mixture Density Network (MDN)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Generative modelling",
            "Intonation",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis",
            "Prosody Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "O. Ronneberger",
            "P. Fischer",
            "T. Brox"
        ],
        "dcterms:description": "A convolutional network architecture used for biomedical image segmentation, applied here in the context of speech synthesis.",
        "dcterms:title": "U-Net architecture",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Processing",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "U-Net",
            "Convolutional network",
            "Biomedical segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Wan",
            "Q. Wang",
            "A. Papir",
            "I. L. Moreno"
        ],
        "dcterms:description": "A generalized end-to-end loss model for speaker verification, used for speaker embedding in the context of TTS.",
        "dcterms:title": "Speaker embedding",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Verification",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "Speaker embedding",
            "End-to-end loss",
            "Speaker verification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Shah",
            "K. Pokora",
            "A. Ezzerg",
            "V. Klimkov",
            "G. Huybrechts",
            "B. Putrycz",
            "D. Korzekwa",
            "T. Merritt"
        ],
        "dcterms:description": "Oracle prosodic features extracted from target speech, used for training prosody models.",
        "dcterms:title": "Oracle prosody features",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Oracle features",
            "Prosody",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Synthesis",
            "Prosody Modelling"
        ]
    },
    {
        "dcterms:creator": [
            "A. Abbas",
            "T. Merritt",
            "A. Moinet",
            "S. Karlapati",
            "E. Muszynska",
            "S. Slangen",
            "E. Gatti",
            "T. Drugman"
        ],
        "dcterms:description": "A method for expressive, variable, and controllable duration modelling in TTS, using Jensen-Shannon divergence.",
        "dcterms:title": "Jensen-Shannon divergence (JSD)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Jensen-Shannon divergence",
            "Duration modelling",
            "Expressive speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]