[
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "MMLU comprises 4-option multiple-choice questions across a wide range of tasks from fields including STEM, humanities, social science, and others, covering 57 subjects.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multiple-Choice Questions",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "MCQ",
            "Benchmark",
            "Language Models",
            "Multitask Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Alon Talmor",
            "Jonathan Herzig",
            "Nicholas Lourie",
            "Jonathan Berant"
        ],
        "dcterms:description": "CSQA contains 5-option multiple-choice questions that draw upon ConceptNet concepts, enabling a variety and integration of worldly knowledge within the queries.",
        "dcterms:title": "CSQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Knowledge",
            "Question Answering"
        ],
        "dcat:keyword": [
            "CommonsenseQA",
            "MCQ",
            "Knowledge Integration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple Choice Question Answering"
        ]
    }
]