To extract the datasets from the research paper titled "CapsNet comparative performance evaluation for image classification" by Rinat Mukhometzianov and Juan Carrillo, I will follow a systematic approach.

First, I will read through the **abstract** and **introduction** to get an overview of the research focus and any datasets mentioned. The abstract indicates that the authors evaluated the CapsNet algorithm on four datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will navigate to the **Datasets section** (Section 2) where the authors explicitly describe the datasets used for their experiments. Here, I will find the following datasets mentioned:

1. **Yale Face Database B**: This dataset contains 5,850 grayscale images across 38 classes, with varying illumination conditions and viewpoints. The authors reference this dataset as suitable for evaluating the performance of capsule networks.

2. **MIT CBCL Dataset**: This dataset includes 5,240 images with different illumination and pose conditions. The characteristics are noted to be similar to those of the Yale Face Database B.

3. **Belgium TS Dataset**: Comprising 7,000 images of 62 types of traffic signs from urban areas in Belgium, this dataset presents challenges due to occlusions and varying conditions.

4. **CIFAR-100 Dataset**: This dataset contains 60,000 images of 100 types of everyday objects, which poses a significant challenge for image classification due to variations in illumination, pose, and size.

After identifying the datasets, I will check the **References section** to find the full citations for each dataset. The citations are as follows:

- For **Yale Face Database B**:
  > Georghiades, A.S., Belhumeur, P.N., Kriegman, D.J. (2001). From few to many: illumination cone models for face recognition under variable lighting and pose. IEEE Trans. Pattern Anal. Mach. Intell., 23, 643–660.

- For **MIT CBCL Dataset**:
  > Weyrauch, B., Heisele, B., Huang, J., Blanz, V. (2004). Component-Based Face Recognition with 3D Morphable Models. In: 2004 Conference on Computer Vision and Pattern Recognition Workshop. pp. 85–85. IEEE.

- For **Belgium TS Dataset**:
  > Timofte, R., Zimmermann, K., Gool, L. Van. Multi-view traffic sign detection, recognition, and 3D localisation.

- For **CIFAR-100 Dataset**:
  > Krizhevsky, A. (2009). Learning Multiple Layers of Features from Tiny Images.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This systematic approach ensures that I accurately capture the datasets and their relevant citations from the research paper.