[
    {
        "dcterms:creator": [
            "Alexander R. Fabbri",
            "Wojciech Kryściński",
            "Bryan McCann",
            "Caiming Xiong",
            "Richard Socher",
            "Dragomir Radev"
        ],
        "dcterms:description": "SummEval is an evaluation benchmark for summarization that assigns human ratings on four key dimensions of every summary: fluency, coherence, consistency, and relevance.",
        "dcterms:title": "SummEval",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Summarization evaluation",
            "Human ratings",
            "Fluency",
            "Coherence",
            "Consistency",
            "Relevance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Moritz Hermann",
            "Tomáš Kočiský",
            "Edward Grefenstette",
            "Lasse Espeholt",
            "Will Kay",
            "Mustafa Suleyman",
            "Phil Blunsom"
        ],
        "dcterms:description": "CNN/DailyMail is a dataset used for training models to read and comprehend text, particularly in the context of summarization.",
        "dcterms:title": "CNN/DailyMail",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Text summarization",
            "News articles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Markus Freitag",
            "Ricardo Rei",
            "Nitika Mathur",
            "Chi-kiu Lo",
            "Craig Stewart",
            "Eleftherios Avramidis",
            "Tom Kocmi",
            "George Foster",
            "Alon Lavie",
            "André F. T. Martins"
        ],
        "dcterms:description": "WMT22 Metrics is a shared task that evaluates the performance of various metrics for machine translation, emphasizing the effectiveness of neural metrics over traditional ones like BLEU.",
        "dcterms:title": "WMT22 Metrics",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Evaluation Metrics"
        ],
        "dcat:keyword": [
            "Machine translation evaluation",
            "Neural metrics",
            "BLEU"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    }
]