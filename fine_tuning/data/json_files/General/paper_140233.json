[
    {
        "dcterms:creator": [
            "Harsh Agrawal",
            "Peter Anderson",
            "Karan Desai",
            "Yufei Wang",
            "Xinlei Chen",
            "Rishabh Jain",
            "Mark Johnson",
            "Dhruv Batra",
            "Devi Parikh",
            "Stefan Lee"
        ],
        "dcterms:description": "A dataset for novel object captioning that includes images and corresponding captions, focusing on the ability to describe novel objects in images.",
        "dcterms:title": "Nocaps",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Novel object captioning",
            "Image captions",
            "Computer vision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Bryan A Plummer",
            "Liwei Wang",
            "Chris M Cervantes",
            "Juan C Caicedo",
            "Julia Hockenmaier",
            "Svetlana Lazebnik"
        ],
        "dcterms:description": "A dataset that collects region-to-phrase correspondences for richer image-to-sentence models, providing a large set of images with annotated entities.",
        "dcterms:title": "Flickr30K",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image annotations",
            "Region-to-phrase correspondences",
            "Image captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Dustin Schwenk",
            "Apoorv Khandelwal",
            "Christopher Clark",
            "Kenneth Marino",
            "Roozbeh Mottaghi"
        ],
        "dcterms:description": "A benchmark for visual question answering that incorporates world knowledge, designed to evaluate models on their ability to answer questions based on images.",
        "dcterms:title": "A-OKVQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "World knowledge",
            "Image understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Xiang Yue",
            "Yuansheng Ni",
            "Kai Zhang",
            "Tianyu Zheng",
            "Ruoqi Liu",
            "Ge Zhang",
            "Samuel Stevens",
            "Dongfu Jiang",
            "Weiming Ren",
            "Yuxuan Sun",
            "Cong Wei",
            "Botao Yu",
            "Ruibin Yuan",
            "Renliang Sun",
            "Ming Yin",
            "Boyuan Zheng",
            "Zhenzhu Yang",
            "Yibo Liu",
            "Wenhao Huang",
            "Huan Sun",
            "Yu Su",
            "Wenhu Chen"
        ],
        "dcterms:description": "A massive multi-discipline multimodal understanding and reasoning benchmark designed for expert AGI, covering a wide range of tasks.",
        "dcterms:title": "MMMU",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2311.16502",
        "dcat:theme": [
            "Multimodal Understanding",
            "Reasoning"
        ],
        "dcat:keyword": [
            "Multimodal reasoning",
            "Expert AGI",
            "Understanding tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multimodal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Liang Chen",
            "Yichi Zhang",
            "Shuhuai Ren",
            "Haozhe Zhao",
            "Zefan Cai",
            "Yuchi Wang",
            "Peiyi Wang",
            "Tianyu Liu",
            "Baobao Chang"
        ],
        "dcterms:description": "A benchmark for evaluating multimodal large language models in the perception-cognition-action chain, focusing on their ability to perform tasks across these domains.",
        "dcterms:title": "PCA-Bench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Evaluation",
            "Cognition"
        ],
        "dcat:keyword": [
            "Perception",
            "Cognition",
            "Action",
            "Multimodal models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multimodal Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Anand Mishra",
            "Shashank Shekhar",
            "Ajeet Kumar Singh",
            "Anirban Chakraborty"
        ],
        "dcterms:description": "A dataset for visual question answering that focuses on reading text in images to answer questions, integrating OCR capabilities.",
        "dcterms:title": "OCR-VQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "OCR"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "OCR",
            "Text in images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yunseok Jang",
            "Yale Song",
            "Youngjae Yu",
            "Youngjin Kim",
            "Gunhee Kim"
        ],
        "dcterms:description": "A dataset aimed at spatio-temporal reasoning in visual question answering, focusing on understanding video content.",
        "dcterms:title": "TGIF-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Spatio-temporal Reasoning"
        ],
        "dcat:keyword": [
            "Video QA",
            "Spatio-temporal reasoning",
            "Visual understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dejing Xu",
            "Zhou Zhao",
            "Jun Xiao",
            "Fei Wu",
            "Hanwang Zhang",
            "Xiangnan He",
            "Yueting Zhuang"
        ],
        "dcterms:description": "A dataset for video question answering that utilizes gradually refined attention over appearance and motion to answer questions about videos.",
        "dcterms:title": "MSVD-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Attention Mechanisms"
        ],
        "dcat:keyword": [
            "Video QA",
            "Attention",
            "Visual understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dejing Xu",
            "Zhou Zhao",
            "Jun Xiao",
            "Fei Wu",
            "Hanwang Zhang",
            "Xiangnan He",
            "Yueting Zhuang"
        ],
        "dcterms:description": "A dataset for video question answering that focuses on gradually refined attention over appearance and motion, similar to MSVD-QA.",
        "dcterms:title": "MSRVTT-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Attention Mechanisms"
        ],
        "dcat:keyword": [
            "Video QA",
            "Attention",
            "Visual understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Video Question Answering"
        ]
    }
]