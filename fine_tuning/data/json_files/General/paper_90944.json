[
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A large corpus of books used for pre-training language models, containing 800 million words.",
        "dcterms:title": "BooksCorpus",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Pre-training",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A large corpus of Wikipedia articles used for pre-training language models, containing 2.5 billion words.",
        "dcterms:title": "Wikipedia",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Pre-training",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A large corpus of news articles used for pre-training language models, containing 2 billion words.",
        "dcterms:title": "NewsCorpus",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Pre-training",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Richard Socher",
            "Alex Perelygin",
            "Jean Wu",
            "Jason Chuang",
            "Christopher D Manning",
            "Andrew Ng",
            "Christopher Potts"
        ],
        "dcterms:description": "A dataset for sentiment analysis containing movie reviews with binary sentiment labels.",
        "dcterms:title": "SST-2 (Stanford Sentiment Treebank 2)",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment analysis",
            "Text classification",
            "Movie reviews"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Shankar Iyer",
            "Nikhil Dandekar",
            "Kornél Csernai"
        ],
        "dcterms:description": "A dataset containing pairs of questions from Quora, labeled as duplicates or not.",
        "dcterms:title": "QQP (Quora Question Pairs)",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Duplicate detection",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Duplicate Question Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Zi-Rong Zhang",
            "Min Chu",
            "Eric Chang"
        ],
        "dcterms:description": "A dataset for polyphone disambiguation in Chinese, containing sentences with polyphonic characters.",
        "dcterms:title": "PolyDis (Polyphone Disambiguation)",
        "dcterms:issued": "2002",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Polyphone disambiguation",
            "Chinese language",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Polyphone Disambiguation"
        ]
    },
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A dataset for language modeling tasks, containing a collection of text from various sources.",
        "dcterms:title": "WikiText-2",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Tomas Mikolov",
            "Martin Karafiát",
            "Luks Burget",
            "Jan Cernock",
            "Sanjeev Khudanpur"
        ],
        "dcterms:description": "A dataset for language modeling tasks, containing a collection of text from the Penn Treebank.",
        "dcterms:title": "PTB (Penn Treebank)",
        "dcterms:issued": "2010",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A larger version of the WikiText dataset for language modeling tasks.",
        "dcterms:title": "WikiText-103",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Kaitao Song",
            "Xu Tan",
            "Tao Qin",
            "Jianfeng Lu",
            "Tie-Yan Liu"
        ],
        "dcterms:description": "A dataset for machine translation tasks, specifically for Chinese-English translation.",
        "dcterms:title": "WMT17 (Chinese-English)",
        "dcterms:issued": "2019",
        "dcterms:language": "Chinese, English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Machine translation",
            "Chinese-English",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Kaitao Song",
            "Xu Tan",
            "Tao Qin",
            "Jianfeng Lu",
            "Tie-Yan Liu"
        ],
        "dcterms:description": "A dataset for machine translation tasks, specifically for English-French translation.",
        "dcterms:title": "WMT14 (English-French)",
        "dcterms:issued": "2019",
        "dcterms:language": "English, French",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Machine translation",
            "English-French",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Kaitao Song",
            "Xu Tan",
            "Tao Qin",
            "Jianfeng Lu",
            "Tie-Yan Liu"
        ],
        "dcterms:description": "A dataset for machine translation tasks, specifically for English-German translation.",
        "dcterms:title": "WMT16 (English-German)",
        "dcterms:issued": "2019",
        "dcterms:language": "English, German",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Machine translation",
            "English-German",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    }
]