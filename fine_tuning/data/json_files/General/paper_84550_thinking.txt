To extract datasets from the research paper titled "Robust Neural Machine Translation with Doubly Adversarial Inputs" by Yong Cheng, Lu Jiang, and Wolfgang Macherey, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses experimental results on Chinese-English and English-German translation tasks, which suggests that datasets are involved, but I need to find their specific names.

Next, I will examine **section 4 (Experiments)**, where the authors describe their experimental setup. In this section, they mention using the **LDC corpus** for the Chinese-English translation task, which consists of 1.2 million sentence pairs. They also refer to the **WMT’14 corpus** for the English-German translation task, which contains 4.5 million sentence pairs. These are the primary datasets used for their experiments.

I will also check the **References section** to find full citations for these datasets. The LDC corpus is typically cited as follows:
- For the LDC corpus, the citation is:
  > Linguistic Data Consortium. *LDC Chinese-English Parallel Corpus*. Linguistic Data Consortium, 2016.

And for the WMT’14 corpus, the citation is:
- For the WMT’14 corpus, the citation is:
  > Bojar, Ondřej, et al. *Findings of the 2014 Workshop on Statistical Machine Translation*. In Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 1-12, 2014.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further use.

In summary, the datasets extracted from the paper are:
1. **LDC corpus** for Chinese-English translation.
2. **WMT’14 corpus** for English-German translation.

I will ensure to include the full citations for both datasets in my final output.