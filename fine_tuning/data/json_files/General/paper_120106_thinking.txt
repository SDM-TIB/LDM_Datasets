To extract datasets from the research paper titled "Framewise WaveGAN: High Speed Adversarial Vocoder in Time Domain with Very Low Computational Complexity" by Ahmed Mustafa et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract discusses the performance of the proposed vocoder and mentions the use of a training speech corpus, which suggests that there may be specific datasets referenced.

Next, I will focus on **section 4 (Experiments and Results)**, particularly **subsection 4.1 (Experimental Setup)**, where the authors describe the training data. They mention using a training speech corpus of **205 hours sampled at 16 kHz**, obtained from a combination of TTS datasets. This indicates that multiple datasets were used, and I need to identify them.

In the same subsection, the authors list several TTS datasets used for training, specifically mentioning datasets from references [26] to [34]. I will need to extract the names of these datasets and their details.

Now, I will consult the **References section** to find the full citations for each dataset mentioned. The references include:

1. **TTS datasets**:
   - Reference [26]: 
     > I. Demirsahin, O. Kjartansson, A. Gutkin, and C. Rivera, “Open-source Multi-speaker Corpora of the English Accents in the British Isles,” in Proc. LREC, 2020.
   - Reference [27]: 
     > O. Kjartansson, A. Gutkin, A. Butryna, I. Demirsahin, and C. Rivera, “Open-Source High Quality Speech Datasets for Basque, Catalan and Galician,” in Proc. SLTU and CCURL, 2020.
   - Reference [28]: 
     > A. Guevara-Rukoz, I. Demirsahin, F. He, S.-H. C. Chu, S. Sarin, K. Pipatsrisawat, A. Gutkin, A. Butryna, and O. Kjartansson, “Crowdsourcing Latin American Spanish for Low-Resource Text-to-Speech,” in Proc. LREC, 2020.
   - Reference [29]: 
     > F. He, S.-H. C. Chu, O. Kjartansson, C. Rivera, A. Katanova, A. Gutkin, I. Demirsahin, C. Johny, M. Jansche, S. Sarin, and K. Pipatsrisawat, “Open-source Multi-speaker Speech Corpora for Building Gujarati, Kannada, Malayalam, Marathi, Tamil and Telugu Speech Synthesis Systems,” in Proc. LREC, 2020.
   - Reference [30]: 
     > K. Sodimana, K. Pipatsrisawat, L. Ha, M. Jansche, O. Kjartansson, P. De Silva, and S. Sarin, “A Step-by-Step Process for Building TTS Voices Using Open Source Data and Framework for Bangla, Javanese, Khmer, Nepali, Sinhala, and Sundanese,” in Proc. SLTU, 2018.
   - Reference [31]: 
     > Y. M. Oo, T. Wattanavekin, C. Li, P. De Silva, S. Sarin, K. Pipatsrisawat, M. Jansche, O. Kjartansson, and A. Gutkin, “Burmese Speech Corpus, Finite-State Text Normalization and Pronunciation Grammars with an Application to Text-to-Speech,” in Proc. LREC, 2020.
   - Reference [32]: 
     > D. van Niekerk, C. van Heerden, M. Davel, N. Kleynhans, O. Kjartansson, M. Jansche, and L. Ha, “Rapid development of TTS corpora for four South African languages,” in Proc. INTERSPEECH, 2017.
   - Reference [33]: 
     > A. Gutkin, I. Demirsahin, O. Kjartansson, C. Rivera, and K. Túbò. sún, “Developing an Open-Source Corpus of Yoruba Speech,” in Proc. INTERSPEECH, 2020.
   - Reference [34]: 
     > E. Bakhturina, V. Lavrukhin, B. Ginsburg, and Y. Zhang, “Hi-Fi Multi-Speaker English TTS Dataset,” arXiv preprint arXiv:2104.01497, 2021.

After gathering this information, I will compile the dataset entries, ensuring to include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets utilized in the research paper.