[
    {
        "dcterms:creator": [
            "Peter Bailey",
            "Alistair Moffat",
            "Falk Scholer",
            "Paul Thomas"
        ],
        "dcterms:description": "A test collection with query variability, where crowd workers created multiple unique queries for a given information need.",
        "dcterms:title": "UQV100",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Retrieval",
            "Query Variability"
        ],
        "dcat:keyword": [
            "Query Variability",
            "Test Collection",
            "User Queries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Query Variation Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Nick Craswell",
            "Bhaskar Mitra",
            "Emine Yilmaz",
            "Daniel Campos",
            "Ellen M Voorhees"
        ],
        "dcterms:description": "A dataset for the passage retrieval task, part of the TREC 2019 Deep Learning Track, containing queries and relevance judgments.",
        "dcterms:title": "TREC-DL-2019",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2003.07820",
        "dcat:theme": [
            "Information Retrieval",
            "Passage Retrieval"
        ],
        "dcat:keyword": [
            "Passage Retrieval",
            "TREC",
            "Deep Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Passage Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Helia Hashemi",
            "Mohammad Aliannejadi",
            "Hamed Zamani",
            "W Bruce Croft"
        ],
        "dcterms:description": "A non-factoid question answering benchmark that includes a set of questions and their corresponding answers.",
        "dcterms:title": "ANTIQU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Retrieval",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question Answering",
            "Benchmark",
            "Non-factoid Questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]