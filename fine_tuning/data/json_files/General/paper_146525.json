[
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark",
            "Gretchen Krueger",
            "Ilya Sutskever"
        ],
        "dcterms:description": "A multimodal model that learns transferable visual representations from natural language supervision, enabling zero-shot performance in various visual tasks.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Vision-Language Model",
            "Zero-shot Learning",
            "Transfer Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Alexander Kirillov",
            "Eric Mintun",
            "Nikhila Ravi",
            "Hanzi Mao",
            "Chloe Rolland",
            "Laura Gustafson",
            "Tete Xiao",
            "Spencer Whitehead",
            "Alexander C. Berg",
            "Wan-Yen Lo",
            "Piotr Dollar",
            "Ross Girshick"
        ],
        "dcterms:description": "A model designed for segmentation tasks that enhances visual comprehension capabilities by providing fine-grained visual prompts.",
        "dcterms:title": "SAM",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Segmentation"
        ],
        "dcat:keyword": [
            "Segmentation Model",
            "Visual Prompting",
            "Multimodal Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Licheng Yu",
            "Zhe Lin",
            "Xiaohui Shen",
            "Jimei Yang",
            "Xin Lu",
            "Mohit Bansal",
            "Tamara L. Berg"
        ],
        "dcterms:description": "A model that utilizes modular attention mechanisms for understanding referring expressions in images.",
        "dcterms:title": "MAttNet",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Referring Expression Comprehension"
        ],
        "dcat:keyword": [
            "Attention Mechanism",
            "Referring Expressions",
            "Image Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Sanjay Subramanian",
            "William Merrill",
            "Trevor Darrell",
            "Matt Gardner",
            "Sameer Singh",
            "Anna Rohrbach"
        ],
        "dcterms:description": "A baseline model for referring expression comprehension that demonstrates strong zero-shot performance.",
        "dcterms:title": "ReCLIP",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Referring Expression Comprehension"
        ],
        "dcat:keyword": [
            "Zero-shot Learning",
            "Referring Expressions",
            "Baseline Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Aishwarya Kamath",
            "Mannat Singh",
            "Yann LeCun",
            "Gabriel Synnaeve",
            "Ishan Misra",
            "Nicolas Carion"
        ],
        "dcterms:description": "A model designed for end-to-end multi-modal understanding, integrating visual and textual data for improved comprehension.",
        "dcterms:title": "MDETR",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "End-to-End Model",
            "Multi-Modal Understanding",
            "Visual Grounding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Model",
        "mls:task": [
            "Referring Expression Comprehension"
        ]
    }
]