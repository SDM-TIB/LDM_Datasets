[
    {
        "dcterms:creator": [
            "T. Kwiatkowski",
            "J. Palomaki",
            "O. Redfield",
            "M. Collins",
            "A. P. Parikh",
            "C. Alberti",
            "D. Epstein",
            "I. Polosukhin"
        ],
        "dcterms:description": "Natural Questions (NQ) is developed from Google Search and contains questions coupled with human-annotated answers extracted from Wikipedia. It has three versions: NQ-10, NQ-20, and NQ-30, with total document numbers of 10, 20, and 30, respectively.",
        "dcterms:title": "Natural Questions (NQ)",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Wikipedia",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Yang",
            "P. Qi",
            "S. Zhang",
            "Y. Bengio",
            "W. W. Cohen",
            "R. Salakhutdinov",
            "C. D. Manning"
        ],
        "dcterms:description": "HotpotQA is a well-known multi-hop question answering dataset based on Wikipedia, involving questions requiring finding and reasoning over multiple supporting facts from 10 documents.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop reasoning",
            "Wikipedia",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "H. Trivedi",
            "N. Balasubramanian",
            "T. Khot",
            "A. Sabharwal"
        ],
        "dcterms:description": "MuSiQue consists of questions that involve 2-4 hops and six types of reasoning chains, constructed through a bottom-up process by carefully selecting and composing single-hop questions.",
        "dcterms:title": "MuSiQue",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop reasoning",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "X. Ho",
            "A.-K. D. Nguyen",
            "S. Sugawara",
            "A. Aizawa"
        ],
        "dcterms:description": "2WikiMultiHopQA (2Wiki) consists of up to 5-hop questions, each associated with 10 documents, and evaluates the interpretability of models not only with supporting evidence but also with entity-relation tuples.",
        "dcterms:title": "2WikiMultiHopQA (2Wiki)",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop reasoning",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "W. He",
            "K. Liu",
            "J. Liu",
            "Y. Lyu",
            "S. Zhao",
            "X. Xiao",
            "Y. Liu",
            "Y. Wang",
            "H. Wu",
            "Q. She",
            "X. Liu",
            "T. Wu",
            "H. Wang"
        ],
        "dcterms:description": "DuReader is a Chinese dataset developed based on Baidu Search and Baidu Zhidao, adapted for assessing long context ability, associating each question with 20 candidate documents.",
        "dcterms:title": "DuReader",
        "dcterms:issued": "2018",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Chinese",
            "Question answering",
            "Machine reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]