[
    {
        "dcterms:creator": [
            "Aljoscha Burchardt",
            "Vivien Macketanz",
            "Jon Dehdari",
            "Georg Heigold",
            "Jan-Thorsten Peter",
            "Philip Williams"
        ],
        "dcterms:description": "A grammatical test suite for evaluating German to English machine translation systems, focusing on 107 phenomena organized in 14 categories.",
        "dcterms:title": "DFKI Test Suite for German→English MT",
        "dcterms:issued": "2017",
        "dcterms:language": "German, English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Linguistic Evaluation"
        ],
        "dcat:keyword": [
            "Test Suite",
            "Machine Translation Evaluation",
            "German-English Translation",
            "Linguistic Phenomena"
        ],
        "dcat:landingPage": "https://github.com/DFKI-NLP/TQ_AutoTest",
        "dcterms:hasVersion": "latest",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Matthew Snover",
            "Nitin Madnani",
            "Bonnie J Dorr",
            "Richard Schwartz"
        ],
        "dcterms:description": "HTER is a metric for evaluating machine translation output based on human judgments of fluency and adequacy.",
        "dcterms:title": "HTER",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Evaluation Metrics"
        ],
        "dcat:keyword": [
            "Human Evaluation",
            "Translation Quality",
            "MT Metrics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Maja Popović"
        ],
        "dcterms:description": "Hjerson is an open-source tool designed for the automatic classification of errors in machine translation output.",
        "dcterms:title": "Hjerson",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Error Classification"
        ],
        "dcat:keyword": [
            "Error Analysis",
            "Machine Translation",
            "Automatic Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Error Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Arle Lommel",
            "Aljoscha Burchardt",
            "Maja Popović",
            "Kim Harris",
            "Eleftherios Avramidis",
            "Hans Uszkoreit"
        ],
        "dcterms:description": "MQM is a new analytic measure for the annotation and analysis of machine translation errors on real data.",
        "dcterms:title": "MQM",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Error Analysis"
        ],
        "dcat:keyword": [
            "Error Annotation",
            "Machine Translation Quality",
            "Analytic Measures"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Error Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Franck Burlot",
            "Yves Scherrer",
            "Vinit Ravishankar",
            "Ondřej Bojar",
            "Stig-Arne Grönroos",
            "Maarit Koponen",
            "Tommi Nieminen",
            "François Yvon"
        ],
        "dcterms:description": "The WMT’18 Morpheval test suites are designed for evaluating morphological analysis in machine translation across multiple language pairs.",
        "dcterms:title": "Morpheval test suites",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Morphological Evaluation"
        ],
        "dcat:keyword": [
            "Morphological Analysis",
            "Machine Translation Evaluation",
            "Language Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Morphological Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Ondřej Bojar",
            "Jiří Mírovský",
            "Kateřina Rysová",
            "Magdaléna Rysová"
        ],
        "dcterms:description": "EvalD is a reference-less discourse evaluation method for machine translation outputs.",
        "dcterms:title": "EvalD Reference-Less Discourse Evaluation",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Discourse Evaluation"
        ],
        "dcat:keyword": [
            "Discourse Analysis",
            "Machine Translation Evaluation",
            "Reference-Less Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Discourse Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Annette Rios",
            "Mathias Müller",
            "Rico Sennrich"
        ],
        "dcterms:description": "The Word Sense Disambiguation Test Suite is designed to evaluate the ability of machine translation systems to handle word sense disambiguation.",
        "dcterms:title": "Word Sense Disambiguation Test Suite",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Word Sense Disambiguation"
        ],
        "dcat:keyword": [
            "Word Sense Disambiguation",
            "Machine Translation Evaluation",
            "Evaluation Metrics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Word Sense Disambiguation"
        ]
    }
]