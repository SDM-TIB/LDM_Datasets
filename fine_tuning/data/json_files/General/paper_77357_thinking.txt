To extract datasets from the research paper titled "Classification of sparsely labeled spatio-temporal data through semi-supervised adversarial learning" by Atanas Mirchev and Seyed-Ahmad Ahmadi, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract indicates that the authors aim to model spatio-temporal sensor data, which suggests that a dataset is likely involved.

Next, I will focus on **section 5 (Data Set)**, where the authors explicitly describe the dataset used for their experiments. Here, they mention the **NTU RGB+D dataset**, which is a large-scale action recognition dataset. The authors provide details about how they utilized the dataset, including the number of samples in the training and test sets, and the preprocessing steps they applied.

The authors specify that they used only the joints modality of the NTU RGB+D dataset, which consists of 3D coordinates of 25 skeleton joints at each time step. They also detail how they split the dataset into training and test sets, which is crucial for understanding the dataset's structure.

Now, I will check the **References section** to find the full citation for the NTU RGB+D dataset. The citation provided in the paper is:

> Amir Shahroudy, Jun Liu, Tian-Tsong Ng, and Gang Wang. *NTU RGB+D: A large scale dataset for 3D human activity analysis*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1010â€“1019, 2016.

With this information, I can summarize the dataset as follows:

1. **NTU RGB+D Dataset**: A large-scale dataset for action recognition, containing 3D coordinates of 25 skeleton joints for various actions. The dataset is split into a training set with 40,320 samples and a test set with 16,560 samples.

Finally, I will compile this information into a structured format for further processing, ensuring that the full citation for the dataset is included.