[
    {
        "dcterms:creator": [
            "C. Guo",
            "X. Zuo",
            "S. Wang",
            "S. Zou",
            "Q. Sun",
            "A. Deng",
            "M. Gong",
            "L. Cheng"
        ],
        "dcterms:description": "This dataset consists of 1191 motion clips and 90099 frames in total, with action labels for 12 actions. Each action label has at least 47 and at most 218 samples, and the sequence lengths range from 8 to 470.",
        "dcterms:title": "HumanAct12",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Motion Generation",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "3D human motions",
            "motion clips",
            "action labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Motion Generation",
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Liu",
            "A. Shahroudy",
            "M. Perez",
            "G. Wang",
            "L. Y. Duan",
            "A. C. Kot"
        ],
        "dcterms:description": "The NTU-RGBD dataset originally contains pose annotations from a MS Kinect sensor and label annotations for 120 actions. A refined subset of 13 actions has been created with a state-of-the-art pose estimation method.",
        "dcterms:title": "NTU-RGBD",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Understanding",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "RGB-D data",
            "pose annotations",
            "human activity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Activity Recognition",
            "Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ji",
            "F. Xu",
            "Y. Yang",
            "F. Shen",
            "H. T. Shen",
            "W. S. Zheng"
        ],
        "dcterms:description": "This dataset includes 40 action classes, 40 subjects, and 25K samples, making it the largest dataset used in the experiments. It features a train/test split and sequences are rotated to a frontal view.",
        "dcterms:title": "UESTC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "RGB-D Data"
        ],
        "dcat:keyword": [
            "RGB-D database",
            "human action recognition",
            "large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Action Recognition"
        ]
    }
]