[
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "MMLU contains a series of benchmarks across diverse domains to evaluate the modelâ€™s language understanding, specifically focusing on high school physics and chemistry.",
        "dcterms:title": "MMLU (Massive Multitask Language Understanding)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [
            "Language Understanding",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask",
            "Language Models",
            "Physics",
            "Chemistry"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "GSM8K is a dataset for evaluating models on mathematical reasoning tasks, particularly focusing on word problems.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematics",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Mathematical Reasoning",
            "Word Problems"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical Reasoning",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Wenhu Chen",
            "Xinyi Wang",
            "William Yang Wang"
        ],
        "dcterms:description": "TimeQA is a dataset designed for answering time-sensitive questions that require reasoning about temporal information.",
        "dcterms:title": "TimeQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2108.06314",
        "dcat:theme": [
            "Question Answering",
            "Temporal Reasoning"
        ],
        "dcat:keyword": [
            "Time-sensitive Questions",
            "Temporal Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Michael Zhang",
            "Eunsol Choi"
        ],
        "dcterms:description": "SituatedQA incorporates extra-linguistic contexts into question answering, requiring models to consider temporal or geographical contexts.",
        "dcterms:title": "SituatedQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Contextual Reasoning"
        ],
        "dcat:keyword": [
            "Contextual Questions",
            "Geographical Context"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Harsh Trivedi",
            "Niranjan Balasubramanian",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "MuSiQue is a dataset for multi-hop reasoning, created via composable pairs of single-hop questions.",
        "dcterms:title": "MuSiQue",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Hop Reasoning",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop Questions",
            "Compositional Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mor Geva",
            "Daniel Khashabi",
            "Elad Segal",
            "Tushar Khot",
            "Dan Roth",
            "Jonathan Berant"
        ],
        "dcterms:description": "StrategyQA is a question answering benchmark that requires implicit reasoning strategies to solve open-domain questions.",
        "dcterms:title": "StrategyQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Reasoning Strategies"
        ],
        "dcat:keyword": [
            "Implicit Reasoning",
            "Open-Domain Questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]