[
    {
        "dcterms:creator": [
            "Fan Yu",
            "Shiliang Zhang",
            "Yihui Fu",
            "Lei Xie",
            "Siqi Zheng",
            "Zhihao Du",
            "Weilong Huang",
            "Pengcheng Guo",
            "Zhijie Yan",
            "Bin Ma"
        ],
        "dcterms:description": "The AliMeeting Corpus is used for training and evaluating speaker diarization and automatic speech recognition systems, particularly in multi-channel multi-party meeting scenarios.",
        "dcterms:title": "AliMeeting Corpus",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.07393",
        "dcat:theme": [
            "Speech Recognition",
            "Speaker Diarization"
        ],
        "dcat:keyword": [
            "Multi-channel",
            "Meeting transcription",
            "Speaker diarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Diarization",
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Yue Fan",
            "Jiawen Kang",
            "Lantian Li",
            "Kaicheng Li",
            "Haolin Chen",
            "Sitong Cheng",
            "Pengyuan Zhang",
            "Ziya Zhou",
            "Yunqi Cai",
            "Dong Wang"
        ],
        "dcterms:description": "CN-Celeb is utilized as a training set for speaker embedding extraction, focusing on Chinese speaker recognition.",
        "dcterms:title": "CN-Celeb",
        "dcterms:issued": "2019",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Recognition"
        ],
        "dcat:keyword": [
            "Chinese speakers",
            "Speaker recognition",
            "Training dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Lantian Li",
            "Ruiqi Liu",
            "Jiawen Kang",
            "Yue Fan",
            "Hao Cui",
            "Yunqi Cai",
            "Ravichander Vipperla",
            "Thomas Fang Zheng",
            "Dong Wang"
        ],
        "dcterms:description": "CN-Celeb is also referenced for multi-genre speaker recognition, providing a diverse dataset for training speaker recognition systems.",
        "dcterms:title": "CN-Celeb",
        "dcterms:issued": "2020",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2012.12468",
        "dcat:theme": [
            "Speaker Recognition"
        ],
        "dcat:keyword": [
            "Multi-genre",
            "Speaker recognition",
            "Chinese speakers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Yihui Fu",
            "Luyao Cheng",
            "Shubo Lv",
            "Yukai Jv",
            "Yuxiang Kong",
            "Zhuo Chen",
            "Yanxin Hu",
            "Lei Xie",
            "Jian Wu",
            "Hui Bu",
            "Xin Xu",
            "Jun Du",
            "Jingdong Chen"
        ],
        "dcterms:description": "AISHELL-4 is an open-source dataset designed for various speech processing tasks, including speech enhancement, separation, recognition, and speaker diarization in conference scenarios.",
        "dcterms:title": "AISHELL-4",
        "dcterms:issued": "2021",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2104.03603",
        "dcat:theme": [
            "Speech Enhancement",
            "Speech Recognition",
            "Speaker Diarization"
        ],
        "dcat:keyword": [
            "Conference scenario",
            "Speech processing",
            "Open-source dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Enhancement",
            "Speech Recognition",
            "Speaker Diarization"
        ]
    },
    {
        "dcterms:creator": [
            "David Snyder",
            "Guoguo Chen",
            "Daniel Povey"
        ],
        "dcterms:description": "MUSAN is a corpus that includes music, speech, and noise, used for data augmentation in training speaker embedding extractors.",
        "dcterms:title": "MUSAN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1510.08484",
        "dcat:theme": [
            "Data Augmentation"
        ],
        "dcat:keyword": [
            "Music",
            "Speech",
            "Noise",
            "Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Data Augmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Tom Ko",
            "Vijayaditya Peddinti",
            "Daniel Povey",
            "Michael L. Seltzer",
            "Sanjeev Khudanpur"
        ],
        "dcterms:description": "RIRs (Room Impulse Responses) are used for simulating reverberant conditions in speech recognition tasks, aiding in the training of robust models.",
        "dcterms:title": "RIRs (Room Impulse Responses)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Augmentation"
        ],
        "dcat:keyword": [
            "Reverberation",
            "Speech recognition",
            "Data augmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Data Augmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A simulated dataset generated from the near-field recordings in the AliMeeting Corpus, used for training and improving the robustness of ASR systems.",
        "dcterms:title": "Simulated dataset (D4)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Simulated data",
            "ASR training",
            "Multi-speaker"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    }
]