[
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset recorded in a voice production studio by a professional voice talent, containing 40,244 utterances, approximately 40 hours of training data.",
        "dcterms:title": "Voice production studio dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Voice production",
            "Speech synthesis",
            "Training data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Hideki Kawahara"
        ],
        "dcterms:description": "A vocoder that exploits perceptually isomorphic decomposition of speech sounds.",
        "dcterms:title": "STRAIGHT vocoder",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Vocoder",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Masanori Morise",
            "Fumiya Yokomori",
            "Kenji Ozawa"
        ],
        "dcterms:description": "A vocoder-based high-quality speech synthesis system for real-time applications.",
        "dcterms:title": "WORLD vocoder",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Vocoder",
            "Speech synthesis",
            "Real-time applications"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yuxuan Wang",
            "RJ Skerry-Ryan",
            "Daisy Stanton",
            "Yonghui Wu",
            "Ron J Weiss",
            "Navdeep Jaitly",
            "Zongheng Yang",
            "Ying Xiao",
            "Zhifeng Chen",
            "Samy Bengio"
        ],
        "dcterms:description": "An end-to-end speech synthesis model that generates mel-spectrograms from text.",
        "dcterms:title": "Tacotron",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1703.10135",
        "dcat:theme": [],
        "dcat:keyword": [
            "Speech synthesis",
            "End-to-end model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Aaron van den Oord",
            "Sander Dieleman",
            "Heiga Zen",
            "Karen Simonyan",
            "Oriol Vinyals",
            "Alex Graves",
            "Nal Kalchbrenner",
            "Andrew Senior",
            "Koray Kavukcuoglu"
        ],
        "dcterms:description": "A generative model for raw audio that uses a deep neural network architecture.",
        "dcterms:title": "WaveNet",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1609.03499",
        "dcat:theme": [],
        "dcat:keyword": [
            "Audio generation",
            "Neural network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ryan Prenger",
            "Rafael Valle",
            "Bryan Catanzaro"
        ],
        "dcterms:description": "A flow-based generative network for speech synthesis that allows for efficient audio generation.",
        "dcterms:title": "WaveGlow",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Speech synthesis",
            "Generative model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Bohan Zhai",
            "Tianren Gao",
            "Flora Xue",
            "Daniel Rothchild",
            "Bichen Wu",
            "Joseph E Gonzalez",
            "Kurt Keutzer"
        ],
        "dcterms:description": "Lightweight vocoders designed for on-device speech synthesis.",
        "dcterms:title": "SqueezeWave",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2001.05685",
        "dcat:theme": [],
        "dcat:keyword": [
            "Vocoder",
            "On-device synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yi Ren",
            "Yangjun Ruan",
            "Xu Tan",
            "Tao Qin",
            "Sheng Zhao",
            "Zhou Zhao",
            "Tie-Yan Liu"
        ],
        "dcterms:description": "A fast, robust, and controllable text-to-speech model.",
        "dcterms:title": "FastSpeech",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Text-to-Speech",
            "Speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Kundan Kumar",
            "Rithesh Kumar",
            "Thibault de Boissiere",
            "Lucas Gestin",
            "Wei Zhen Teoh",
            "Jose Sotelo",
            "Alexandre de BrÂ´ebisson",
            "Yoshua Bengio",
            "Aaron C Courville"
        ],
        "dcterms:description": "Generative adversarial networks for conditional waveform synthesis.",
        "dcterms:title": "MelGAN",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "GAN",
            "Waveform synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Geng Yang",
            "Shan Yang",
            "Kai Liu",
            "Peng Fang",
            "Wei Chen",
            "Lei Xie"
        ],
        "dcterms:description": "A faster waveform generation model for high-quality text-to-speech.",
        "dcterms:title": "Multi-band MelGAN",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2005.05106",
        "dcat:theme": [],
        "dcat:keyword": [
            "Waveform generation",
            "Text-to-Speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    }
]