[
    {
        "dcterms:creator": [
            "E. Costello",
            "J.C. Holland",
            "C. Kirwan"
        ],
        "dcterms:description": "A dataset containing multiple-choice questions (MCQs) from MOOCs in the domains of Computer Science, Humanities, and Healthcare, evaluated for common item writing flaws.",
        "dcterms:title": "MCQs in Computer Science, Humanities, and Healthcare",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1186/s13104-018-3959-4",
        "dcat:theme": [
            "Education",
            "Assessment"
        ],
        "dcat:keyword": [
            "Multiple-Choice Questions",
            "MOOCs",
            "Item Writing Flaws"
        ],
        "dcat:landingPage": "https://doi.org/10.1186/s13104-018-3959-4",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Moore",
            "H.A. Nguyen",
            "T. Chen",
            "J. Stamper"
        ],
        "dcterms:description": "A dataset of student-generated multiple-choice questions (MCQs) from Chemistry and Statistics courses, assessed for quality using GPT-4 and rule-based methods.",
        "dcterms:title": "Student-generated MCQs from Chemistry and Statistics courses",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Education",
            "Assessment"
        ],
        "dcat:keyword": [
            "Multiple-Choice Questions",
            "Student-generated",
            "Quality Assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Evaluation"
        ]
    }
]