[
    {
        "dcterms:creator": [
            "Z. Wang",
            "Y. Dong",
            "J. Zeng",
            "V. Adams",
            "M. N. Sreedhar",
            "D. Egert",
            "O. Delalleau",
            "J. P. Scowcroft",
            "N. Kant",
            "A. Swope"
        ],
        "dcterms:description": "HelpSteer is a multi-attribute helpfulness dataset designed for evaluating the performance of language models across various dimensions such as Helpfulness, Correctness, Coherence, Complexity, and Verbosity.",
        "dcterms:title": "HelpSteer",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2311.09528",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Helpfulness",
            "Evaluation",
            "Language Models"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2311.09528",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation of Language Models"
        ]
    },
    {
        "dcterms:creator": [
            "H. Lightman",
            "V. Kosaraju",
            "Y. Burda",
            "H. Edwards",
            "B. Baker",
            "T. Lee",
            "J. Leike",
            "J. Schulman",
            "I. Sutskever",
            "K. Cobbe"
        ],
        "dcterms:description": "PRM800K is a dataset used for verifying the correctness of model outputs through a step-by-step evaluation process.",
        "dcterms:title": "PRM800K",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://openreview.net/forum?id=v8L0pN6EOi",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Verification",
            "Evaluation",
            "Language Models"
        ],
        "dcat:landingPage": "https://openreview.net/forum?id=v8L0pN6EOi",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Verification of Model Outputs"
        ]
    },
    {
        "dcterms:creator": [
            "N. Muennighoff",
            "Q. Liu",
            "A. Zebaze",
            "Q. Zheng",
            "B. Hui",
            "T. Y. Zhuo",
            "S. Singh",
            "X. Tang",
            "L. Von Werra",
            "S. Longpre"
        ],
        "dcterms:description": "CommitPack is a dataset designed for instruction tuning of code generation models, focusing on the evaluation of model outputs in coding tasks.",
        "dcterms:title": "CommitPack",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2308.07124",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Code Generation",
            "Instruction Tuning",
            "Evaluation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2308.07124",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan"
        ],
        "dcterms:description": "HH RLHF Harmlessness is a dataset focused on training models to be helpful and harmless through reinforcement learning from human feedback.",
        "dcterms:title": "HH RLHF Harmlessness",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2204.05862",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Human Feedback",
            "Safety"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2204.05862",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Safety Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Zhou",
            "P. Liu",
            "P. Xu",
            "S. Iyer",
            "J. Sun",
            "Y. Mao",
            "X. Ma",
            "A. Efrat",
            "P. Yu",
            "L. YU"
        ],
        "dcterms:description": "LIMA is a dataset that emphasizes the principle of 'less is more' for alignment in language models, focusing on instruction tuning.",
        "dcterms:title": "LIMA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Alignment",
            "Instruction Tuning",
            "Evaluation"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper_files/paper/2023/file/ac662d74829e4407ce1d126477f4a03a-Paper-Conference.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Tuning"
        ]
    },
    {
        "dcterms:creator": [
            "R. Nakano",
            "J. Hilton",
            "S. Balaji",
            "J. Wu",
            "L. Ouyang",
            "C. Kim",
            "C. Hesse",
            "S. Jain",
            "V. Kosaraju",
            "W. Saunders"
        ],
        "dcterms:description": "WebGPT is a dataset that enables browser-assisted question-answering with human feedback, focusing on improving the quality of responses.",
        "dcterms:title": "WebGPT",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2112.09332",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Question Answering",
            "Human Feedback",
            "Web Interaction"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2112.09332",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Ji",
            "M. Liu",
            "J. Dai",
            "X. Pan",
            "C. Zhang",
            "C. Bian",
            "B. Chen",
            "R. Sun",
            "Y. Wang",
            "Y. Yang"
        ],
        "dcterms:description": "BeaverTails Helpfulness is a dataset aimed at improving the safety alignment of language models through human-preference evaluations.",
        "dcterms:title": "BeaverTails Helpfulness",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4dbb61cb68671edc4ca3712d70083b9f-Paper-Datasets_and_Benchmarks.pdf",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Safety Alignment",
            "Human Preference",
            "Evaluation"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper_files/paper/2023/file/4dbb61cb68671edc4ca3712d70083b9f-Paper-Datasets_and_Benchmarks.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Safety Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Min",
            "K. Krishna",
            "X. Lyu",
            "M. Lewis",
            "W.-t. Yih",
            "P. Koh",
            "M. Iyyer",
            "L. Zettlemoyer",
            "H. Hajishirzi"
        ],
        "dcterms:description": "FActScore is a dataset designed for fine-grained atomic evaluation of factual precision in long-form text generation.",
        "dcterms:title": "FActScore",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2023.emnlp-main.741",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Factual Precision",
            "Text Generation",
            "Evaluation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.emnlp-main.741",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factual Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Maynez",
            "S. Narayan",
            "B. Bohnet",
            "R. McDonald"
        ],
        "dcterms:description": "XSum Hallucination is a dataset that evaluates the faithfulness and factuality of abstractive summarization.",
        "dcterms:title": "XSum Hallucination",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2020.acl-main.173",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Summarization",
            "Factuality",
            "Evaluation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2020.acl-main.173",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Li",
            "D. Choi",
            "J. Chung",
            "N. Kushman",
            "J. Schrittwieser",
            "R. Leblond",
            "T. Eccles",
            "J. Keeling",
            "F. Gimeno",
            "A. D. Lago"
        ],
        "dcterms:description": "HaluEval is a large-scale hallucination evaluation benchmark for large language models, focusing on the accuracy of generated outputs.",
        "dcterms:title": "HaluEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2023.emnlp-main.397",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Hallucination",
            "Evaluation",
            "Language Models"
        ],
        "dcat:landingPage": "https://aclanthology.org/2023.emnlp-main.397",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation of Generated Outputs"
        ]
    },
    {
        "dcterms:creator": [
            "A. Williams",
            "N. Nangia",
            "S. Bowman"
        ],
        "dcterms:description": "MNLI is a broad-coverage challenge corpus for sentence understanding through inference, used for evaluating model performance on natural language inference tasks.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/N18-1101",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Natural Language Inference",
            "Evaluation",
            "Sentence Understanding"
        ],
        "dcat:landingPage": "https://aclanthology.org/N18-1101",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    }
]