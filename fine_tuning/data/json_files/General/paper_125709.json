[
    {
        "dcterms:creator": [
            "Nathan Silberman",
            "Derek Hoiem",
            "Pushmeet Kohli",
            "Rob Fergus"
        ],
        "dcterms:description": "The NYU-v2 dataset includes pairs of RGB images and depth maps on 464 indoor scenes, which are separated into 120K training samples from 249 scenes and 654 testing samples from 215 scenes. The range of depth labels is up to 10 meters.",
        "dcterms:title": "NYU-v2",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "RGB-D dataset",
            "Indoor scenes",
            "Depth estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Monocular Depth Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Christoph Stiller",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI dataset consists of paired RGB images and corresponding depth maps obtained by a 3D laser scanner on 61 outdoor scenes while driving. The range of depth annotations is up to 80 meters.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "RGB-D dataset",
            "Outdoor scenes",
            "Depth estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Monocular Depth Estimation"
        ]
    }
]