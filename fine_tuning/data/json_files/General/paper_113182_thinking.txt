To extract the datasets mentioned in the research paper titled "Open-world Semantic Segmentation for LIDAR Point Clouds" by Jun Cen et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned. In the abstract, the authors state that their method achieves state-of-the-art performance on the **SemanticKITTI** and **nuScenes** datasets. This indicates that these datasets are crucial for their research.

Next, I will look for specific mentions of these datasets in the **experiments section**. The authors describe their evaluation protocols and confirm that they used both **SemanticKITTI** and **nuScenes** for their experiments. This reinforces the importance of these datasets in their work.

I will then check the **References section** to find the full citations for these datasets. The citations are essential for proper attribution and to guide readers to the original sources of the datasets.

1. **SemanticKITTI Dataset**: The citation is:
   > Behley, J., Garbade, M., Milioto, A., Quenzel, J., Behnke, S., Stachniss, C., & Gall, J. (2019). *SemanticKITTI: A Dataset for Semantic Scene Understanding of LiDAR Sequences*. In Proceedings of the IEEE International Conference on Computer Vision (ICCV).

2. **nuScenes Dataset**: The citation is:
   > Caesar, H., Bankiti, V., Lang, A.H., Vora, S., Liong, V.E., Xu, Q., Krishnan, A., Pan, Y., Baldan, G., & Beijbom, O. (2020). *nuscenes: A multimodal dataset for autonomous driving*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

After gathering this information, I will compile the dataset entries, ensuring that each dataset is described accurately and includes its full citation. This will provide a comprehensive overview of the datasets used in the research paper, ready for any further processing or review.