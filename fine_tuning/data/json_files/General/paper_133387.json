[
    {
        "dcterms:creator": [
            "T. Yu",
            "Z. Yu",
            "C. Schmid"
        ],
        "dcterms:description": "RefCOCO is a dataset for referring expressions that helps in the comprehension of objects and scenes.",
        "dcterms:title": "RefCOCO",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Referring expressions",
            "Object comprehension",
            "Scene understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object localization",
            "Text understanding"
        ]
    },
    {
        "dcterms:creator": [
            "O. Sidorov",
            "R. Hu",
            "A. Rohrbach",
            "A. Singh"
        ],
        "dcterms:description": "TextCaps is a dataset designed for image captioning that incorporates reading comprehension.",
        "dcterms:title": "TextCaps",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Image captioning",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image captioning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Singh",
            "V. Natarajan",
            "M. Shah",
            "Y. Jiang",
            "X. Chen",
            "D. Batra",
            "D. Parikh",
            "A. Rohrbach"
        ],
        "dcterms:description": "TextVQA is a dataset aimed at visual question answering that requires reading text in images.",
        "dcterms:title": "TextVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Text reading"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual question answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. F. Biten",
            "R. Tito",
            "A. Mafla",
            "L. Gomez",
            "C. V. Jawahar",
            "D. Karatzas"
        ],
        "dcterms:description": "STVQA is a dataset for scene text visual question answering.",
        "dcterms:title": "STVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Scene text",
            "Visual question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual question answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Mishra",
            "S. Shekhar",
            "A. K. Singh",
            "A. Chakraborty"
        ],
        "dcterms:description": "OCRVQA is a dataset for visual question answering that focuses on reading text in images.",
        "dcterms:title": "OCRVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "OCR"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual question answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Mathew",
            "D. Karatzas",
            "C. V. Jawahar"
        ],
        "dcterms:description": "InfographicVQA is a dataset for visual question answering on infographics.",
        "dcterms:title": "InfographicVQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Infographics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual question answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Mathew",
            "V. Bagal",
            "R. Tito",
            "D. Karatzas",
            "E. Valveny",
            "C. V. Jawahar"
        ],
        "dcterms:description": "DocVQA is a dataset for visual question answering on document images.",
        "dcterms:title": "DocVQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Document images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual question answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Masry",
            "D. Long",
            "J. Q. Tan",
            "S. Joty",
            "E. Hoque"
        ],
        "dcterms:description": "ChartQA is a benchmark for question answering about charts that requires visual and logical reasoning.",
        "dcterms:title": "ChartQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Charts"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xu",
            "T. Mei",
            "T. Yao",
            "Y. Rui"
        ],
        "dcterms:description": "MSR-VTT is a large video description dataset for bridging video and language.",
        "dcterms:title": "MSR-VTT",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Video description",
            "Video and language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video description"
        ]
    },
    {
        "dcterms:creator": [
            "X. Wang",
            "J. Wu",
            "Z. Chen",
            "Y. Wang"
        ],
        "dcterms:description": "VATEX is a large-scale, high-quality multilingual dataset for video-and-language research.",
        "dcterms:title": "VATEX",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Video and language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video and language research"
        ]
    },
    {
        "dcterms:creator": [
            "A. Monfort",
            "S. Jin",
            "A. Liu",
            "D. Harwath",
            "R. Feris",
            "J. Glass",
            "A. Oliva"
        ],
        "dcterms:description": "Spoken Moments in Time is a dataset for learning joint audio-visual representations from video descriptions.",
        "dcterms:title": "Spoken Moments in Time",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Audio-Visual Learning"
        ],
        "dcat:keyword": [
            "Audio-visual representations",
            "Video descriptions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Audio-visual learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xiao",
            "X. Shang",
            "A. Yao",
            "T.-S. Chua"
        ],
        "dcterms:description": "NExT-QA is a dataset for question-answering that explains temporal actions.",
        "dcterms:title": "NExT-QA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Temporal actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xu",
            "T. Mei"
        ],
        "dcterms:description": "MSR-VTT-QA is a large video question answering benchmark requiring external knowledge.",
        "dcterms:title": "MSR-VTT-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Video question answering",
            "External knowledge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Video question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Yu",
            "J. Xu",
            "Y. Zhuang"
        ],
        "dcterms:description": "ActivityNet-QA is a dataset for understanding complex web videos via question answering.",
        "dcterms:title": "ActivityNet-QA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Web videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "K. Karkkainen",
            "J. Joo"
        ],
        "dcterms:description": "FairFace is a face attribute dataset for balanced race, gender, and age for bias measurement and mitigation.",
        "dcterms:title": "FairFace",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Fairness"
        ],
        "dcat:keyword": [
            "Face attributes",
            "Bias measurement"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Bias measurement"
        ]
    },
    {
        "dcterms:creator": [
            "C. Schumann",
            "S. Ricco",
            "U. Prabhu",
            "V. Ferrari",
            "C. R. Pantofaru"
        ],
        "dcterms:description": "MIAP is a dataset aimed at creating more inclusive people annotations for fairness.",
        "dcterms:title": "MIAP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Fairness"
        ],
        "dcat:keyword": [
            "Inclusive annotations",
            "Fairness"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Fairness"
        ]
    }
]