[
    {
        "dcterms:creator": [
            "Chengyue Wu",
            "Yixiao Ge",
            "Qiushan Guo",
            "Jiahao Wang",
            "Zhixuan Liang",
            "Zeyu Lu",
            "Ying Shan",
            "Ping Luo"
        ],
        "dcterms:description": "Plot2Code is a comprehensive visual coding benchmark designed for a fair and in-depth assessment of Multi-modal Large Language Models (MLLMs). It includes 132 manually selected high-quality matplotlib plots across six plot types, each paired with its source code and a descriptive instruction generated by GPT-4.",
        "dcterms:title": "Plot2Code",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/datasets/TencentARC/Plot2Code",
        "dcat:theme": [
            "Multi-modal Code Generation",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Visual Coding",
            "MLLM Evaluation",
            "Matplotlib",
            "Code Generation"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/TencentARC/Plot2Code",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation",
            "Visual Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Mark Chen",
            "Jerry Tworek",
            "Heewoo Jun",
            "Qiming Yuan",
            "Henrique Ponde de Oliveira Pinto",
            "Jared Kaplan",
            "Harri Edwards",
            "Yuri Burda",
            "Nicholas Joseph",
            "Greg Brockman"
        ],
        "dcterms:description": "HumanEval is a dataset designed to evaluate large language models trained on code, focusing on programming tasks.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Evaluation"
        ],
        "dcat:keyword": [
            "Programming",
            "Code Generation",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Austin",
            "Augustus Odena",
            "Maxwell Nye",
            "Maarten Bosma",
            "Henryk Michalewski",
            "David Dohan",
            "Ellen Jiang",
            "Carrie Cai",
            "Michael Terry",
            "Quoc Le"
        ],
        "dcterms:description": "MBPP is a dataset for program synthesis with large language models, focusing on generating code from natural language descriptions.",
        "dcterms:title": "MBPP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Synthesis"
        ],
        "dcat:keyword": [
            "Natural Language Processing",
            "Code Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Chenglei Si",
            "Yanzhe Zhang",
            "Zhengyuan Yang",
            "Ruibo Liu",
            "Diyi Yang"
        ],
        "dcterms:description": "Design2Code is a dataset aimed at evaluating the automation of front-end engineering, particularly in generating HTML files from design inputs.",
        "dcterms:title": "Design2Code",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Front-end Engineering",
            "Automation"
        ],
        "dcat:keyword": [
            "HTML Generation",
            "Design Automation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Kaixin Li",
            "Yuchen Tian",
            "Qisheng Hu",
            "Ziyang Luo",
            "Jing Ma"
        ],
        "dcterms:description": "MMCode is a dataset for evaluating multi-modal code generation tasks, focusing on visually rich programming problems.",
        "dcterms:title": "MMCode",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-modal Code Generation"
        ],
        "dcat:keyword": [
            "Visual Programming",
            "Code Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Kunato Nishina",
            "Yusuke Matsui"
        ],
        "dcterms:description": "SVGEditBench is a benchmark dataset for assessing the SVG editing capabilities of large language models.",
        "dcterms:title": "SVGEditBench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "SVG Editing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "SVG",
            "Editing",
            "Large Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Evaluation"
        ]
    }
]