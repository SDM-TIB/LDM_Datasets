[
    {
        "dcterms:creator": [
            "Mingxing Tan",
            "Quoc Le"
        ],
        "dcterms:description": "EfficientNet is an image classification model that uses depth-wise separable convolutions, which has been shown to achieve state-of-the-art performance while being computationally efficient.",
        "dcterms:title": "EfficientNet",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image classification",
            "Convolutional Neural Networks",
            "EfficientNet"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "BERT is a language model that uses the attention mechanism for natural language understanding, achieving state-of-the-art results on various NLP tasks.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1810.04805",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Language model",
            "Transformers",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding",
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Kaiming He",
            "Xiangyu Zhang",
            "Shaoqing Ren",
            "Jian Sun"
        ],
        "dcterms:description": "ResNet-50 is a deep residual learning framework for image recognition that utilizes skip connections to facilitate training of very deep networks.",
        "dcterms:title": "ResNet-50",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1512.03385",
        "dcat:theme": [
            "Computer Vision",
            "Image Recognition"
        ],
        "dcat:keyword": [
            "Deep Learning",
            "Residual Networks",
            "Image Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Siyang Qin",
            "Alessandro Bissacco",
            "Michalis Raptis",
            "Yasuhisa Fujii",
            "Ying Xiao"
        ],
        "dcterms:description": "OCR workloads refer to tasks related to optical character recognition, specifically in the context of end-to-end text spotting in images.",
        "dcterms:title": "OCR workloads",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Optical Character Recognition"
        ],
        "dcat:keyword": [
            "Text Spotting",
            "OCR",
            "Image Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Text Recognition",
            "Image Analysis"
        ]
    }
]