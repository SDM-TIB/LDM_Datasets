To extract datasets from the research paper titled "A Factorized Recurrent Neural Network based architecture for medium to large vocabulary Language Modelling" by Anantharaman Palacode Narayana Iyer, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experimental results sections** to identify any datasets that are mentioned or utilized in the research. The abstract provides a general overview, but the introduction often contains specific references to datasets used for training or evaluation.

In the **introduction**, the author discusses the need for training language models on large vocabularies and mentions that the architecture is designed to support vocabularies ranging from 10,000 to 50,000 words. However, I need to look for specific datasets that were used in the experiments.

Next, I will focus on the **experiments section**. Here, the author mentions that the language model was evaluated on two corpora: the **Brown corpus** and a **custom corpus** consisting of product reviews for mobile devices. This indicates that both datasets are crucial for the evaluation of the proposed model.

Now, I will check the **References section** to find full citations for these datasets:

1. For the **Brown corpus**, the citation is:
   > Natural Language Tool Kit, http://nltk.org

2. For the **custom corpus**, since it is described as a dataset of product reviews, it may not have a formal citation in the references. However, I can note that it is a custom dataset created for the purpose of this research.

After gathering this information, I will summarize the datasets as follows:

- **Brown Corpus**: A well-known corpus used for language modeling, consisting of 57,340 sentences and 88,829 word tokens. It is widely used in natural language processing research and is available through the Natural Language Toolkit (NLTK).

- **Custom Corpus**: A dataset created specifically for this research, consisting of product reviews for mobile devices. The exact details of this dataset, such as size and structure, are not provided in the references.

Finally, I will compile the dataset entries into a structured format for further processing or review.