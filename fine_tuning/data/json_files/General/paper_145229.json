[
    {
        "dcterms:creator": [
            "Chenyu Zhou",
            "Mengdan Zhang",
            "Peixian Chen",
            "Chaoyou Fu",
            "Yunhang Shen",
            "Xiawu Zheng",
            "Xing Sun",
            "Rongrong Ji"
        ],
        "dcterms:description": "A new dataset developed for the Interleaved Image-Text Comprehension (IITC) task, designed to enhance the capabilities of multi-modal large language models in understanding complex scientific literature with interleaved image-text content.",
        "dcterms:title": "VEGA Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://zhourax.github.io/VEGA/",
        "dcat:theme": [
            "Multi-modal Learning",
            "Natural Language Processing",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image-Text Comprehension",
            "Scientific Literature",
            "Multi-modal Dataset"
        ],
        "dcat:landingPage": "https://zhourax.github.io/VEGA/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Interleaved Image-Text Comprehension",
            "Image-Text Association"
        ]
    },
    {
        "dcterms:creator": [
            "Shengzhi Li",
            "Nima Tajbakhsh"
        ],
        "dcterms:description": "A large-scale synthetic multi-turn question-answering dataset for scientific graphs, containing 295k high-quality, multi-turn data entries.",
        "dcterms:title": "SciGraphQA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Scientific Research"
        ],
        "dcat:keyword": [
            "Synthetic Dataset",
            "Multi-turn QA",
            "Scientific Graphs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yuchen Zeng",
            "Wonjun Kang",
            "Yicong Chen",
            "Hyung Il Koo",
            "Kangwook Lee"
        ],
        "dcterms:description": "A dataset containing video clips with 13 joints annotated in all frames, focusing on human action recognition.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video Dataset",
            "Human Action",
            "Joint Estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Junnan Li",
            "Dongxu Li",
            "Silvio Savarese",
            "Steven Hoi"
        ],
        "dcterms:description": "A dataset designed for human action recognition, focusing on video clips with annotated actions.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video Dataset",
            "Human Action",
            "Joint Estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]