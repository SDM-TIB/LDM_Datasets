[
    {
        "dcterms:creator": [
            "A. Milan",
            "L. Leal-Taixé",
            "I. Reid",
            "S. Roth",
            "K. Schindler"
        ],
        "dcterms:description": "Contains 7 training sequences and test sequences, with 5316 and 5919 images in the training and test sets, respectively. The training set includes 112K bounding boxes and 0.5K IDs for training.",
        "dcterms:title": "MOT16",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1603.00831",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Pedestrian tracking",
            "Video analysis",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "A. Milan",
            "L. Leal-Taixé",
            "I. Reid",
            "S. Roth",
            "K. Schindler"
        ],
        "dcterms:description": "The sequences are identical to MOT16, but MOT17 provides pedestrian detection results from three public detectors, allowing tracking models to directly reuse these detection results, eliminating the impact of object detection on the overall tracking results for fair comparison in public competitions. Additionally, MOT17 has updated some annotations in the dataset.",
        "dcterms:title": "MOT17",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1603.00831",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Pedestrian tracking",
            "Video analysis",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "P. Dendorfer",
            "H. Rezatofighi",
            "A. Milan",
            "J. Shi",
            "D. Cremers",
            "I. Reid",
            "S. Roth",
            "K. Schindler",
            "L. Leal-Taixé"
        ],
        "dcterms:description": "Consists of 8 video segments from three different scenes, with 8931 frames in the training set and 4479 frames in the test set. It includes videos with higher crowd density captured in unrestricted environments, some shot at night with significant occlusions between pedestrians, posing high challenges.",
        "dcterms:title": "MOT20",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2003.09003",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Pedestrian tracking",
            "Crowded scenes",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    }
]