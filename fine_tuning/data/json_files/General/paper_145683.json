[
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee"
        ],
        "dcterms:description": "Natural Questions is designed for end-to-end question answering. The questions are mined from real Google search queries and the answers were spans in Wikipedia articles identified by annotators.",
        "dcterms:title": "NQ (Natural Questions)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "End-to-end QA",
            "Natural language processing",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William W Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D Manning"
        ],
        "dcterms:description": "HotpotQA consists of two-hop questions over diverse topics, requiring two Wikipedia passages to answer the questions.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop QA",
            "Wikipedia",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pradeep Dasigi",
            "Kyle Lo",
            "Iz Beltagy",
            "Arman Cohan",
            "Noah A Smith",
            "Matt Gardner"
        ],
        "dcterms:description": "Qasper is an information-seeking question answering dataset over academic research papers, where each question is written as a followup to the title and abstract of a particular paper.",
        "dcterms:title": "Qasper",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Academic QA",
            "Research papers",
            "Information seeking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yushi Bai",
            "Xin Lv",
            "Jiajie Zhang",
            "Hongchang Lyu",
            "Jiankai Tang",
            "Zhidian Huang",
            "Zhengxiao Du",
            "Xiao Liu",
            "Aohan Zeng",
            "Lei Hou"
        ],
        "dcterms:description": "MultiFieldQA-en is a question-answering dataset based on long documents from diverse sources, including legal documents, government reports, encyclopedias, and academic papers.",
        "dcterms:title": "MultiFieldQA-en",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Long documents",
            "Diverse sources",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]