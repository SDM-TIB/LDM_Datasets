To extract datasets from the research paper titled "Unifying Regularisation Methods for Continual Learning" by Frederik Benzing, I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract provides a brief overview of the research, and the introduction often outlines the context and significance of the datasets used.

Next, I will focus on the **experiments section** where datasets are typically described in detail. In this paper, the author discusses continual learning and mentions that experiments were conducted on standard continual learning benchmarks. I will look for specific names of datasets in this section.

Upon reviewing the paper, I find that the author mentions using the following datasets:

1. **Permuted MNIST**: This dataset consists of random pixel permutations of the MNIST dataset, used for domain-incremental learning tasks.

2. **Split CIFAR**: This dataset is derived from CIFAR-10 and CIFAR-100, where the network is trained on groups of classes incrementally.

Now, I will check the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution and to provide readers with sources for further exploration.

- For **Permuted MNIST**, the citation is:
  > Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. *An empirical investigation of catastrophic forgetting in gradient-based neural networks*. arXiv preprint arXiv:1312.6211, 2013.

- For **CIFAR-10 and CIFAR-100**, the citation is:
  > Alex Krizhevsky. *Learning Multiple Layers of Features from Tiny Images*. Technical Report, 2009.

With these citations in hand, I will summarize the datasets as follows:

1. **Permuted MNIST**: A dataset consisting of random pixel permutations of the MNIST dataset, used for domain-incremental learning tasks.
   - Citation: Ian J. Goodfellow, Mehdi Mirza, Da Xiao, Aaron Courville, and Yoshua Bengio. *An empirical investigation of catastrophic forgetting in gradient-based neural networks*. arXiv preprint arXiv:1312.6211, 2013.

2. **Split CIFAR**: A dataset derived from CIFAR-10 and CIFAR-100, where the network is trained on groups of classes incrementally.
   - Citation: Alex Krizhevsky. *Learning Multiple Layers of Features from Tiny Images*. Technical Report, 2009.

Finally, I will compile this information into a structured format for easy reference and use in future analyses or applications.