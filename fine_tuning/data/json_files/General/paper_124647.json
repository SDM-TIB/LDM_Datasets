[
    {
        "dcterms:creator": [],
        "dcterms:description": "The Edinburgh International Accents of English Corpus (EdAcc) is designed to represent the diversity of English, encompassing almost 40 hours of dyadic video call conversations between speakers with various first and second-language varieties of English.",
        "dcterms:title": "The Edinburgh International Accents of English Corpus (EdAcc)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Linguistic Diversity"
        ],
        "dcat:keyword": [
            "English accents",
            "dyadic conversations",
            "ASR challenges",
            "linguistic background"
        ],
        "dcat:landingPage": "https://groups.inf.ed.ac.uk/edacc/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video",
        "mls:task": [
            "Speech Recognition",
            "Bias Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "J. J. Godfrey",
            "E. C. Holliman",
            "J. McDaniel"
        ],
        "dcterms:description": "Switchboard is a telephone speech corpus that contains conversations among speakers from various dialect regions of American English.",
        "dcterms:title": "Switchboard",
        "dcterms:issued": "1992",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Conversational Speech"
        ],
        "dcat:keyword": [
            "telephone conversations",
            "American English",
            "ASR benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "V. Panayotov",
            "G. Chen",
            "D. Povey",
            "S. Khudanpur"
        ],
        "dcterms:description": "Librispeech is an ASR corpus based on public domain audiobooks, designed to provide a large amount of training data for speech recognition systems.",
        "dcterms:title": "Librispeech",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Read Speech"
        ],
        "dcat:keyword": [
            "public domain audiobooks",
            "ASR training data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. S. Garofolo",
            "L. F. Lamel",
            "W. M. Fisher",
            "J. G. Fiscus",
            "D. S. Pallett"
        ],
        "dcterms:description": "TIMIT is a DARPA-sponsored acoustic-phonetic continuous speech corpus that provides a standard for evaluating speech recognition systems.",
        "dcterms:title": "TIMIT",
        "dcterms:issued": "1993",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Phonetic Analysis"
        ],
        "dcat:keyword": [
            "acoustic-phonetic corpus",
            "speech recognition benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "D. B. Paul",
            "J. Baker"
        ],
        "dcterms:description": "The Wall Street Journal corpus is designed for continuous speech recognition research, based on read speech from the Wall Street Journal.",
        "dcterms:title": "Wall Street Journal",
        "dcterms:issued": "1992",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Read Speech"
        ],
        "dcat:keyword": [
            "read speech corpus",
            "CSR research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Ardila",
            "M. Branson",
            "K. Davis",
            "M. Kohler",
            "J. Meyer",
            "M. Henretty",
            "R. Morais",
            "L. Saunders",
            "F. Tyers",
            "G. Weber"
        ],
        "dcterms:description": "Mozilla Common Voice is a massively multilingual speech corpus aimed at improving voice recognition technologies across various languages.",
        "dcterms:title": "Mozilla Common Voice (MCV)",
        "dcterms:issued": "2019",
        "dcterms:language": "Multiple",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Multilingual Speech"
        ],
        "dcat:keyword": [
            "multilingual corpus",
            "voice recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "X. Shi",
            "F. Yu",
            "Y. Lu",
            "Y. Liang",
            "Q. Feng",
            "D. Wang",
            "Y. Qian",
            "L. Xie"
        ],
        "dcterms:description": "The Accented English Speech Recognition Challenge (AESRC2020) provides datasets and benchmarks for evaluating ASR systems on accented English.",
        "dcterms:title": "The Accented English Speech Recognition Challenge (AESRC2020)",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Accent Recognition"
        ],
        "dcat:keyword": [
            "accented English",
            "ASR challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "I. McCowan",
            "J. Carletta",
            "W. Kraaij",
            "S. Ashby",
            "S. Bourban",
            "M. Flynn",
            "M. Guillemot",
            "T. Hain",
            "J. Kadlec",
            "V. Karaiskos"
        ],
        "dcterms:description": "The AMI Meeting Corpus is designed for research in meeting transcription and understanding, containing recordings of meetings.",
        "dcterms:title": "AMI",
        "dcterms:issued": "2005",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Meeting Transcription"
        ],
        "dcat:keyword": [
            "meeting corpus",
            "transcription research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "P. Bell",
            "M. J. Gales",
            "T. Hain",
            "J. Kilgour",
            "P. Lanchantin",
            "X. Liu",
            "A. McParland",
            "S. Renals",
            "O. Saz",
            "M. Wester"
        ],
        "dcterms:description": "The MGB Challenge dataset evaluates multi-genre broadcast media recognition, providing a benchmark for ASR systems.",
        "dcterms:title": "MGB",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Broadcast Media"
        ],
        "dcat:keyword": [
            "multi-genre broadcast",
            "ASR evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Kahn",
            "M. Rivi`ere",
            "W. Zheng",
            "E. Kharitonov",
            "Q. Xu",
            "P.-E. MazarÂ´e",
            "J. Karadayi",
            "V. Liptchinsky",
            "R. Collobert",
            "C. Fuegen"
        ],
        "dcterms:description": "Libri-light is a benchmark for ASR with limited or no supervision, providing a dataset for training speech recognition systems.",
        "dcterms:title": "Libri-light",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automatic Speech Recognition",
            "Limited Supervision"
        ],
        "dcat:keyword": [
            "ASR benchmark",
            "limited supervision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]