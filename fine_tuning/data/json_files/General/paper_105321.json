[
    {
        "dcterms:creator": [
            "Z. Liu",
            "P. Luo",
            "X. Wang",
            "T. Tang"
        ],
        "dcterms:description": "A dataset containing celebrity images with rich annotations for facial attributes, used for training and evaluating face attribute recognition models.",
        "dcterms:title": "CelebA-HQ Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Face Recognition"
        ],
        "dcat:keyword": [
            "Facial attributes",
            "Celebrity images",
            "Face recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Face Attribute Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "T. Karras",
            "S. Laine",
            "T. Aila"
        ],
        "dcterms:description": "A dataset of high-quality images used for training generative models, particularly for face generation.",
        "dcterms:title": "FFHQ Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Generative Models"
        ],
        "dcat:keyword": [
            "High-quality images",
            "Face generation",
            "Generative adversarial networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "O. Patashnik",
            "Z. Wu",
            "E. Shechtman",
            "D. Cohen-Or",
            "D. Lischinski"
        ],
        "dcterms:description": "A method that enables text-driven manipulation of images generated by StyleGAN, allowing for semantic editing based on textual descriptions.",
        "dcterms:title": "StyleCLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Manipulation"
        ],
        "dcat:keyword": [
            "Text-driven manipulation",
            "StyleGAN",
            "Semantic editing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Editing"
        ]
    },
    {
        "dcterms:creator": [
            "M. Liu",
            "Q. Li",
            "Z. Qin",
            "G. Zhang",
            "P. Wan",
            "W. Zheng"
        ],
        "dcterms:description": "A method for blending GANs to generate stylized face images, allowing for arbitrary style transfer.",
        "dcterms:title": "BlendGAN",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Generation"
        ],
        "dcat:keyword": [
            "GAN blending",
            "Stylized face generation",
            "Image synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "P. Zhu",
            "R. Abdal",
            "J.C. Femiani",
            "P. Wonka"
        ],
        "dcterms:description": "A method for controlling domain gaps in single-shot domain adaptation for generative adversarial networks.",
        "dcterms:title": "Mind The Gap (MTG)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Domain Adaptation"
        ],
        "dcat:keyword": [
            "Domain adaptation",
            "Generative adversarial networks",
            "Single-shot adaptation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Domain Adaptation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Deng",
            "J. Guo",
            "S. Zafeiriou"
        ],
        "dcterms:description": "A face recognition model that uses additive angular margin loss to improve recognition accuracy.",
        "dcterms:title": "ArcFace",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Face Recognition"
        ],
        "dcat:keyword": [
            "Face recognition",
            "Angular margin loss",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Face Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Li",
            "D. Li",
            "C. Xiong",
            "S. Hoi"
        ],
        "dcterms:description": "A framework for unified vision-language understanding and generation through bootstrapping language-image pre-training.",
        "dcterms:title": "BLIP",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Vision-Language"
        ],
        "dcat:keyword": [
            "Vision-language understanding",
            "Image generation",
            "Pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Vision-Language Tasks"
        ]
    },
    {
        "dcterms:creator": [
            "T. Karras",
            "S. Laine",
            "M. Aittala",
            "J. Hellsten",
            "J. Lehtinen",
            "T. Aila"
        ],
        "dcterms:description": "A generative adversarial network architecture that focuses on style-based image generation.",
        "dcterms:title": "StyleGAN",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Generative adversarial networks",
            "Image generation",
            "Style-based generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Generation"
        ]
    },
    {
        "dcterms:creator": [
            "O. Tov",
            "Y. Alaluf",
            "Y. Nitzan",
            "O. Patashnik",
            "D. Cohen-Or"
        ],
        "dcterms:description": "An encoder designed for manipulating images generated by StyleGAN, allowing for effective image editing.",
        "dcterms:title": "e4e Encoder",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Manipulation"
        ],
        "dcat:keyword": [
            "Image manipulation",
            "StyleGAN",
            "Encoder"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Editing"
        ]
    }
]