[
    {
        "dcterms:creator": [
            "S. Gehman",
            "S. Gururangan",
            "M. Sap",
            "Y. Choi",
            "N. A. Smith"
        ],
        "dcterms:description": "A dataset containing half-sentence prompts sourced from the OpenWebText dataset, used to evaluate the toxicity of language model generations.",
        "dcterms:title": "RealToxicityPrompts",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "toxicity",
            "language models",
            "prompts"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Gehman",
            "S. Gururangan",
            "M. Sap",
            "Y. Choi",
            "N. A. Smith"
        ],
        "dcterms:description": "A dataset sourced from comments pages of Wikipedia, used to classify toxic comments.",
        "dcterms:title": "Toxic Comment Classification Challenge (TCCC)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "toxic comments",
            "classification",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Classification"
        ]
    },
    {
        "dcterms:creator": [
            "M. Nadeem",
            "A. Bethke",
            "S. Reddy"
        ],
        "dcterms:description": "A dataset measuring stereotypical bias in pretrained language models, covering racial, national, gender, and professional stereotypes.",
        "dcterms:title": "Stereoset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "stereotypical bias",
            "language models",
            "social bias"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Zhao",
            "T. Wang",
            "M. Yatskar",
            "V. Ordonez",
            "K.-W. Chang"
        ],
        "dcterms:description": "The largest manually labelled gender bias dataset, used to measure gender bias in coreference resolution.",
        "dcterms:title": "WinoBias",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "gender bias",
            "coreference resolution",
            "manual labeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    }
]