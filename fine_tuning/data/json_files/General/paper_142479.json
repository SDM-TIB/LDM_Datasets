[
    {
        "dcterms:creator": [
            "Greg Kamradt"
        ],
        "dcterms:description": "A test designed to evaluate the ability of language models to retrieve specific information from a long context, where a short sentence (the needle) is embedded within a larger body of text (the haystack).",
        "dcterms:title": "Needle-in-a-Haystack",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/gkamradt/LLMTest_NeedleInAHaystack",
        "dcat:theme": [
            "Information Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Long-context models",
            "Information retrieval",
            "Language models"
        ],
        "dcat:landingPage": "https://github.com/gkamradt/LLMTest_NeedleInAHaystack",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Information Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A benchmark for evaluating the performance of language models across multiple tasks, focusing on their understanding and reasoning capabilities.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask learning",
            "Language understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Language Understanding",
            "Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano",
            "Christopher Hesse",
            "John Schulman"
        ],
        "dcterms:description": "A dataset for training models to solve mathematical word problems, focusing on the extraction and reasoning required to arrive at the correct answers.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematics",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Reasoning",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Mathematical Reasoning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset synthesized from up-to-date news articles, used for extractive question answering tasks.",
        "dcterms:title": "Extractive QA Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Extractive QA",
            "News articles",
            "Information retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Young",
            "Bei Chen",
            "Chao Li",
            "Chengen Huang",
            "Ge Zhang",
            "Guanwei Zhang",
            "Heng Li",
            "Jiangcheng Zhu",
            "Jianqun Chen",
            "Jing Chang"
        ],
        "dcterms:description": "A dataset related to open foundation models, focusing on various model architectures and their capabilities.",
        "dcterms:title": "Yi",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2403.04652",
        "dcat:theme": [
            "Machine Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Foundation models",
            "Open models",
            "AI research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Albert Q Jiang",
            "Alexandre Sablayrolles",
            "Antoine Roux",
            "Arthur Mensch",
            "Blanche Savary",
            "Chris Bamford",
            "Devendra Singh Chaplot",
            "Diego de las Casas",
            "Emma Bou Hanna",
            "Florian Bressand"
        ],
        "dcterms:description": "A dataset focusing on a mixture of experts model architecture, exploring the capabilities and performance of such models.",
        "dcterms:title": "Mixtral",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2401.04088",
        "dcat:theme": [
            "Machine Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Mixture of experts",
            "Model architecture",
            "AI research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Albert Q Jiang",
            "Alexandre Sablayrolles",
            "Arthur Mensch",
            "Chris Bamford",
            "Devendra Singh Chaplot",
            "Diego de las Casas",
            "Florian Bressand",
            "Gianna Lengyel",
            "Guillaume Lample",
            "Lucile Saulnier"
        ],
        "dcterms:description": "A dataset related to the Mistral model, focusing on its architecture and performance in various tasks.",
        "dcterms:title": "Mistral",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2310.06825",
        "dcat:theme": [
            "Machine Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Mistral model",
            "AI research",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]