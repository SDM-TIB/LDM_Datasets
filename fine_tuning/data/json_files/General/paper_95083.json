[
    {
        "dcterms:creator": [
            "R. Speer",
            "Catherine Havasi"
        ],
        "dcterms:description": "ConceptNet is designed to test for general conceptual knowledge by masking single token objects from randomly sampled sentences.",
        "dcterms:title": "ConceptNet",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Knowledge Base",
            "Conceptual Knowledge"
        ],
        "dcat:keyword": [
            "Conceptual knowledge",
            "Cloze tasks",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Knowledge probing"
        ]
    },
    {
        "dcterms:creator": [
            "Hady ElSahar",
            "Pavlos Vougiouklis",
            "Arslen Remaci",
            "Christophe Gravier",
            "Jonathon S. Hare",
            "Frédérique Laforest",
            "Elena Simperl"
        ],
        "dcterms:description": "T-REx consists of hundreds of sentences for 41 specific relationship types, designed to align natural language with knowledge base triples.",
        "dcterms:title": "T-REx",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Knowledge Base",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Knowledge base triples",
            "Natural language alignment",
            "Relation extraction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Knowledge probing"
        ]
    },
    {
        "dcterms:creator": [
            "Dave Orr"
        ],
        "dcterms:description": "Google-RE tests for 3 specific types of factual knowledge related to people, including place-of-birth, date-of-birth, and place-of-death.",
        "dcterms:title": "Google-RE",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Factual Knowledge",
            "Relation Extraction"
        ],
        "dcat:keyword": [
            "Factual knowledge",
            "Relation extraction",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Knowledge probing"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD is a dataset containing over 100,000 questions for machine comprehension of text, designed for question answering tasks.",
        "dcterms:title": "SQuAD 1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Machine comprehension",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD 2.0 combines the original SQuAD dataset with unanswerable questions, providing a more challenging question answering task.",
        "dcterms:title": "SQuAD 2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Unanswerable questions",
            "Question answering",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tri Nguyen",
            "Mir Rosenberg",
            "Xia Song",
            "Jianfeng Gao",
            "Saurabh Tiwary",
            "Rangan Majumder",
            "Li Deng"
        ],
        "dcterms:description": "MSMARCO is a human-generated machine reading comprehension dataset designed for passage reranking and question answering.",
        "dcterms:title": "MSMARCO",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Comprehension",
            "Passage Reranking"
        ],
        "dcat:keyword": [
            "Passage reranking",
            "Machine reading comprehension",
            "Natural language processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Passage reranking",
            "Question answering"
        ]
    }
]