[
    {
        "dcterms:creator": [
            "A. Radford",
            "J. Wu",
            "R. Child",
            "D. Luan",
            "D. Amodei",
            "I. Sutskever"
        ],
        "dcterms:description": "A dataset containing a large collection of books used for training language models.",
        "dcterms:title": "BookCorpus",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Books",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. Wu",
            "R. Child",
            "D. Luan",
            "D. Amodei",
            "I. Sutskever"
        ],
        "dcterms:description": "A dataset consisting of articles from Wikipedia used for training language models.",
        "dcterms:title": "English Wikipedia",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Wikipedia",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "M. E. Peters",
            "M. Neumann",
            "M. Iyyer",
            "M. Gardner",
            "C. Clark",
            "K. Lee",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "A benchmark for evaluating the performance of models on various natural language understanding tasks.",
        "dcterms:title": "GLUE benchmark",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Natural Language Understanding",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "R. Jia",
            "P. Liang"
        ],
        "dcterms:description": "A dataset for machine comprehension of text, containing over 100,000 questions based on a set of Wikipedia articles.",
        "dcterms:title": "SQuAD v1.1",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question Answering",
            "Machine Comprehension",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "1.1",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "J. Zhang",
            "K. Lopyrev",
            "P. Liang"
        ],
        "dcterms:description": "An extension of SQuAD v1.1 that includes unanswerable questions to test the model's ability to recognize when no answer is available.",
        "dcterms:title": "SQuAD v2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question Answering",
            "Unanswerable Questions",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "2.0",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]