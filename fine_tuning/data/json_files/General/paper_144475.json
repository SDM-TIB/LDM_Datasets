[
    {
        "dcterms:creator": [
            "Alina Kuznetsova",
            "Hassan Rom",
            "Neil Alldrin",
            "Jasper Uijlings",
            "Ivan Krasin",
            "Jordi Pont-Tuset",
            "Shahab Kamali",
            "Stefan Popov",
            "Matteo Malloci",
            "Alexander Kolesnikov"
        ],
        "dcterms:description": "The Open Spatial Dataset (OSD) is created from images in the OpenImages dataset, which contains a total of 1.7 million images. The dataset includes 1 million unique images and 5 million open-vocabulary regions, each associated with a bounding box and segmentation mask.",
        "dcterms:title": "Open Spatial Dataset (OSD)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Segmentation"
        ],
        "dcat:keyword": [
            "OpenImages",
            "Image dataset",
            "Segmentation",
            "Bounding box"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Segmentation",
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "SpatialRGPT-Bench is a comprehensive benchmark based on ground-truth 3D annotations that span indoor, outdoor, and simulated environments, for evaluating 3D spatial cognition in VLMs.",
        "dcterms:title": "SpatialRGPT-Bench",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Benchmarking",
            "Spatial Cognition"
        ],
        "dcat:keyword": [
            "3D annotations",
            "Benchmark",
            "Spatial reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Spatial Reasoning Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Christoph Stiller",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI dataset is a benchmark for various tasks in the field of computer vision, particularly for autonomous driving, providing stereo, optical flow, visual odometry, and 3D object detection data.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Stereo Vision",
            "Optical Flow",
            "3D Object Detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Visual Odometry"
        ]
    },
    {
        "dcterms:creator": [
            "Pushmeet Kohli",
            "Nathan Silberman",
            "Derek Hoiem",
            "Rob Fergus"
        ],
        "dcterms:description": "The NYU dataset provides RGB-D images for indoor scene understanding, including semantic segmentation and object recognition tasks.",
        "dcterms:title": "NYU",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Indoor Scene Understanding",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "RGB-D",
            "Indoor Dataset",
            "Semantic Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Semantic Segmentation",
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Holger Caesar",
            "Varun Bankiti",
            "Alex H Lang",
            "Sourabh Vora",
            "Venice Erin Liong",
            "Qiang Xu",
            "Anush Krishnan",
            "Yu Pan",
            "Giancarlo Baldan",
            "Oscar Beijbom"
        ],
        "dcterms:description": "nuScenes is a multimodal dataset for autonomous driving, providing data from various sensors including cameras, LiDAR, and radar, along with annotations for object detection and tracking.",
        "dcterms:title": "nuScenes",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "LiDAR",
            "Radar",
            "Object Detection",
            "Tracking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Shuran Song",
            "Samuel P Lichtenberg",
            "Jianxiong Xiao"
        ],
        "dcterms:description": "SUNRGBD is a RGB-D scene understanding benchmark suite that provides a large dataset of indoor scenes with depth information for various tasks including object detection and scene segmentation.",
        "dcterms:title": "SUNRGBD",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Indoor Scene Understanding",
            "RGB-D Data"
        ],
        "dcat:keyword": [
            "RGB-D",
            "Indoor Dataset",
            "Scene Segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection",
            "Scene Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Mike Roberts",
            "Jason Ramapuram",
            "Anurag Ranjan",
            "Atulit Kumar",
            "Miguel Angel Bautista",
            "Nathan Paczan",
            "Russ Webb",
            "Joshua M Susskind"
        ],
        "dcterms:description": "Hypersim is a photorealistic synthetic dataset designed for holistic indoor scene understanding, providing high-quality images and annotations for various tasks.",
        "dcterms:title": "Hypersim",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data",
            "Indoor Scene Understanding"
        ],
        "dcat:keyword": [
            "Synthetic Dataset",
            "Photorealistic",
            "Scene Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Scene Understanding",
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Mu Hu",
            "Wei Yin",
            "Chi Zhang",
            "Zhipeng Cai",
            "Xiaoxiao Long",
            "Hao Chen",
            "Kaixuan Wang",
            "Gang Yu",
            "Chunhua Shen",
            "Shaojie Shen"
        ],
        "dcterms:description": "Metric3Dv2 is a versatile monocular geometric foundation model for zero-shot metric depth and surface normal estimation, trained on diverse indoor and outdoor scenes.",
        "dcterms:title": "Metric3Dv2",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Monocular Depth Estimation",
            "Geometric Modeling"
        ],
        "dcat:keyword": [
            "Depth Estimation",
            "Surface Normals",
            "Monocular"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Depth Estimation",
            "Surface Normal Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Shengjie Zhu",
            "Abhinav Kumar",
            "Masa Hu",
            "Xiaoming Liu"
        ],
        "dcterms:description": "WildCamera is a dataset focused on in-the-wild monocular camera calibration, providing data and methods for improving camera calibration in real-world scenarios.",
        "dcterms:title": "WildCamera",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Camera Calibration",
            "Monocular Data"
        ],
        "dcat:keyword": [
            "Camera Calibration",
            "Monocular",
            "Wild Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Camera Calibration"
        ]
    }
]