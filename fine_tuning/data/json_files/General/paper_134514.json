[
    {
        "dcterms:creator": [
            "Haotian Liu",
            "Chunyuan Li",
            "Qingyang Wu",
            "Yong Jae Lee"
        ],
        "dcterms:description": "CC595K was filtered by LLaVA, extracting noun phrases from captions in the CC3M dataset, resulting in approximately 595k image-text pairs used for pretraining the model.",
        "dcterms:title": "CC595K",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Image-Text Pairs"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Text dataset",
            "Pretraining"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image-Text Pair",
        "mls:task": [
            "Pretraining"
        ]
    },
    {
        "dcterms:creator": [
            "Pan Lu",
            "Swaroop Mishra",
            "Tony Xia",
            "Liang Qiu",
            "Kai-Wei Chang",
            "Song-Chun Zhu",
            "Oyvind Tafjord",
            "Peter Clark",
            "Ashwin Kalyan"
        ],
        "dcterms:description": "ScienceQA consists of 21,000 data samples, including multiple-choice questions with multimodal content, covering various subjects and topics. The training split includes 12,726 samples for model optimization.",
        "dcterms:title": "ScienceQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Reasoning",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Science questions",
            "Multimodal content",
            "Multiple-choice"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]