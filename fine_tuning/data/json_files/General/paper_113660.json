[
    {
        "dcterms:creator": [
            "Dima Damen",
            "Hazel Doughty",
            "Giovanni Maria Farinella",
            "Sanja Fidler",
            "Antonino Furnari",
            "Evangelos Kazakos",
            "Davide Moltisanti",
            "Jonathan Munro",
            "Toby Perrett",
            "Will Price"
        ],
        "dcterms:description": "A large-scale egocentric benchmark with densely annotated actions and object interactions in kitchen environments.",
        "dcterms:title": "EPIC-KITCHENS",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Egocentric Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric video",
            "Action recognition",
            "Object interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Guillermo Garcia-Hernando",
            "Shanxin Yuan",
            "Seungryul Baek",
            "Tae-Kyun Kim"
        ],
        "dcterms:description": "A benchmark dataset for first-person hand actions with RGB-D videos and 3D hand pose annotations.",
        "dcterms:title": "FPHA (First Person Hand Action)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Hand Action Recognition"
        ],
        "dcat:keyword": [
            "RGB-D videos",
            "Hand pose",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A new dataset comprising more than 500K synchronized RGBD frames and gravity directions for studying egocentric scene understanding.",
        "dcterms:title": "EDINA (Egocentric Depth on everyday INdoor Activities)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Egocentric Scene Understanding"
        ],
        "dcat:keyword": [
            "RGBD dataset",
            "Indoor activities",
            "Depth estimation",
            "Surface normals"
        ],
        "dcat:landingPage": "https://github.com/tien-d/EgoDepthNormal",
        "dcterms:hasVersion": "",
        "dcterms:format": "RGBD",
        "mls:task": [
            "Depth Estimation",
            "Surface Normal Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Angela Dai",
            "Angel X. Chang",
            "Manolis Savva",
            "Maciej Halber",
            "Thomas Funkhouser",
            "Matthias Nie√üner"
        ],
        "dcterms:description": "A richly annotated dataset of 3D reconstructions of indoor scenes.",
        "dcterms:title": "ScanNet",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "3D Scene Reconstruction"
        ],
        "dcat:keyword": [
            "3D reconstruction",
            "Indoor scenes",
            "RGBD"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "Scene Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Pushmeet Kohli",
            "Nathan Silberman",
            "Derek Hoiem",
            "Rob Fergus"
        ],
        "dcterms:description": "A dataset for indoor segmentation and support inference from RGB-D images.",
        "dcterms:title": "NYUv2",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Indoor Scene Understanding"
        ],
        "dcat:keyword": [
            "RGBD images",
            "Indoor segmentation",
            "Support inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "RGBD",
        "mls:task": [
            "Scene Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Santhosh K. Ramakrishnan",
            "Aaron Gokaslan",
            "Erik Wijmans",
            "Oleksandr Maksymets",
            "Alex Clegg",
            "John Turner",
            "Eric Undersander",
            "Wojciech Galuba",
            "Andrew Westbury",
            "Angel X. Chang",
            "Manolis Savva",
            "Yili Zhao",
            "Dhruv Batra"
        ],
        "dcterms:description": "A dataset containing 1,000 large-scale 3D environments for embodied AI.",
        "dcterms:title": "HM3D",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "3D Environments"
        ],
        "dcat:keyword": [
            "3D environments",
            "Embodied AI",
            "Large-scale"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yansong Tang",
            "Zian Wang",
            "Jiwen Lu",
            "Jianjiang Feng",
            "Jie Zhou"
        ],
        "dcterms:description": "A dataset for action recognition in RGB-D egocentric videos.",
        "dcterms:title": "THU-READ",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "RGB-D videos",
            "Egocentric action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]