[
    {
        "dcterms:creator": [
            "Chung-Chi Chen",
            "Hen-Hsen Huang",
            "Hiroya Takamura",
            "Hsin-Hsi Chen"
        ],
        "dcterms:description": "A dataset used for evaluating the numeracy learning ability of models, specifically in the context of detecting exaggerated information in market comments.",
        "dcterms:title": "Numeracy600K",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Numeracy",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Numeracy learning",
            "Market comments",
            "Text-to-text transfer model"
        ],
        "dcat:landingPage": "https://github.com/kuntalkumarpal/T5Numeracy",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Magnitude Order Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A reading comprehension benchmark requiring discrete reasoning over paragraphs, used for evaluating models' ability to answer questions based on provided text.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Machine comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dheeru Dua",
            "Yizhong Wang",
            "Pradeep Dasigi",
            "Gabriel Stanovsky",
            "Sameer Singh",
            "Matt Gardner"
        ],
        "dcterms:description": "A benchmark dataset for reading comprehension that requires discrete reasoning over paragraphs, utilized in evaluating numerical reasoning tasks.",
        "dcterms:title": "DROP",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Discrete reasoning",
            "Reading comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Swaroop Mishra",
            "Arindam Mitra",
            "Neeraj Varshney",
            "Bhavdeep Sachdeva",
            "Chitta Baral"
        ],
        "dcterms:description": "A dataset aimed at developing question format independent numerical reasoning skills through a set of prerequisite tasks.",
        "dcterms:title": "NUMBERGAME",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Numerical Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Numerical reasoning",
            "Question format independence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Numerical Reasoning"
        ]
    }
]