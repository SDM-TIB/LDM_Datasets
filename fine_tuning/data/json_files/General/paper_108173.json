[
    {
        "dcterms:creator": [
            "OndË‡rej Bojar",
            "Christian Buck",
            "Christian Federmann",
            "Barry Haddow",
            "Philipp Koehn",
            "Johannes Leveling",
            "Christof Monz",
            "Pavel Pecina",
            "Matt Post",
            "Herve Saint-Amand"
        ],
        "dcterms:description": "A dataset commonly used as a benchmark for neural machine translation, consisting of 4.5 million sentence pairs for training.",
        "dcterms:title": "WMT14",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Neural Machine Translation",
            "Benchmark Dataset",
            "Sentence Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A dataset used for language modeling tasks, consisting of a large corpus of text.",
        "dcterms:title": "Wikitext-103",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1609.07843",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text Dataset",
            "Language Modeling",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel Bowman"
        ],
        "dcterms:description": "A broad-coverage challenge corpus for sentence understanding through inference.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Sentence Understanding",
            "Inference",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Eugene Bagdasaryan",
            "Andreas Veit",
            "Yiqing Hua",
            "Deborah Estrin",
            "Vitaly Shmatikov"
        ],
        "dcterms:description": "A dataset used for training models in conversational response generation.",
        "dcterms:title": "Reddit",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Conversational AI"
        ],
        "dcat:keyword": [
            "Text Dataset",
            "Conversational Response Generation",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Generation"
        ]
    }
]