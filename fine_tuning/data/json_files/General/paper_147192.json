[
    {
        "dcterms:creator": [
            "Gemma Team"
        ],
        "dcterms:description": "Gemma 2 9B activations were used to evaluate the performance of JumpReLU Sparse Autoencoders, focusing on reconstruction fidelity.",
        "dcterms:title": "Gemma 2 9B",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf",
        "dcat:theme": [
            "Language Models",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Language model activations",
            "Reconstruction fidelity",
            "Sparse autoencoders"
        ],
        "dcat:landingPage": "https://storage.googleapis.com/deepmind-media/gemma/gemma-2-report.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "S. Biderman",
            "H. Schoelkopf",
            "Q. G. Anthony",
            "H. Bradley",
            "K. Oâ€™Brien",
            "E. Hallahan",
            "M. A. Khan",
            "S. Purohit",
            "U. S. Prashanth",
            "E. Raff"
        ],
        "dcterms:description": "The Pythia suite of models was referenced for comparison of the sparsity-fidelity trade-off between architectures and interpretability.",
        "dcterms:title": "Pythia",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Models",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Model analysis",
            "Training",
            "Scaling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Gemini Team"
        ],
        "dcterms:description": "Gemini 1.5 was mentioned in the context of generating explanations and simulating activations for features learned by sparse autoencoders.",
        "dcterms:title": "Gemini",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2403.05530",
        "dcat:theme": [
            "Language Models",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Multimodal understanding",
            "Feature explanation",
            "Activation simulation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2403.05530",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]