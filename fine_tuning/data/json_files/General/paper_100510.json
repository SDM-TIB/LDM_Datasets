[
    {
        "dcterms:creator": [
            "N. Silberman",
            "D. Hoiem",
            "P. Kohli",
            "R. Fergus"
        ],
        "dcterms:description": "The NYUv2-Depth dataset is comprised of a variety of indoor scenes, captured by Microsoft Kinect as RGB-D video sequences. The color images and depth maps are provided at a resolution of 640 Ã— 480.",
        "dcterms:title": "NYUv2-Depth",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "RGB-D dataset",
            "Indoor scenes",
            "Depth maps"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Monocular Depth Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "David Eigen",
            "Christian Puhrsch",
            "Rob Fergus"
        ],
        "dcterms:description": "The NYU-Depth v2 dataset contains depth map predictions from a single image using a multi-scale deep network. It includes a training set with 120K samples.",
        "dcterms:title": "NYU-Depth v2",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "Depth map prediction",
            "Single image",
            "Multi-scale deep network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Monocular Depth Estimation"
        ]
    }
]