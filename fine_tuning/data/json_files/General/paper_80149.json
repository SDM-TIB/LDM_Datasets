[
    {
        "dcterms:creator": [
            "H. Tseng",
            "P. Chang",
            "G. Andrew"
        ],
        "dcterms:description": "A dataset used for training a Conditional Random Field Word Segmenter, specifically for the Sighan Bakeoff 2005 competition.",
        "dcterms:title": "Backoff 2005",
        "dcterms:issued": "2005",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese text",
            "word segmentation",
            "conditional random fields"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An internet lexicon containing high-frequency words used in social media contexts.",
        "dcterms:title": "Sougou lab internet lexicon",
        "dcterms:issued": "2006",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Lexicon"
        ],
        "dcat:keyword": [
            "internet terms",
            "high-frequency words",
            "social media"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "F. Peng",
            "F. Feng",
            "A. McCallum"
        ],
        "dcterms:description": "A dataset used for Chinese segmentation and new word detection, providing a standard for evaluating segmentation models.",
        "dcterms:title": "MSR",
        "dcterms:issued": "2010",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese segmentation",
            "new word detection",
            "conditional random fields"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation",
            "New Word Detection"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset used for training and evaluating word segmentation models, primarily from newspaper text.",
        "dcterms:title": "PKU",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese text",
            "word segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset crawled from Sina Weibo, annotated manually for word segmentation tasks.",
        "dcterms:title": "Sina Weibo",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Segmentation"
        ],
        "dcat:keyword": [
            "social media",
            "Chinese text",
            "manual annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A lexicon file used in the mmseg4j project for word segmentation.",
        "dcterms:title": "mmseg4j project lexicon file",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Lexicon"
        ],
        "dcat:keyword": [
            "word segmentation",
            "Chinese text"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    }
]