[
    {
        "dcterms:creator": [
            "Joao Carreira",
            "Andrew Zisserman"
        ],
        "dcterms:description": "Kinetics-400 (K400) contains videos with variable number of people. Some K400 actions cannot be distinguished by only using skeletons, thus we use a subset of K400, named Posetics, as the main benchmark for action classification.",
        "dcterms:title": "Kinetics-400 (K400)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action classification",
            "Skeleton-based action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Di Yang",
            "Yaohui Wang",
            "Antitza Dantcheva",
            "Lorenzo Garattoni",
            "Gianpiero Francesca",
            "François Brémond"
        ],
        "dcterms:description": "Posetics merges together classes featuring identical skeletons, resulting in 320 total classes (e.g., ‘eating burger’ and ‘eating hotdog’ are merged into ‘eating something’).",
        "dcterms:title": "Posetics",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Skeleton-based Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "Action classification",
            "Merged classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Yunsheng Pang",
            "Qiuhong Ke",
            "Hossein Rahmani",
            "James Bailey",
            "Jun Liu"
        ],
        "dcterms:description": "NTU-Inter is a commonly used benchmark for two-person interaction recognition. It’s a subset of the in-lab collected NTURGB+D, containing only mutual action classes (with two subjects).",
        "dcterms:title": "NTU-Inter",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Interaction Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "Two-person interaction",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Skeleton",
        "mls:task": [
            "Interaction Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Chunhui Gu",
            "Chen Sun",
            "David A Ross",
            "Carl Vondrick",
            "Caroline Pantofaru",
            "Yeqing Li",
            "Sudheendra Vijayanarasimhan",
            "George Toderici",
            "Susanna Ricco",
            "Rahul Sukthankar"
        ],
        "dcterms:description": "AVA 2.2 is a spatio-temporal action detection benchmark. It’s a multi-label dataset with 80 action classes, falling into three major categories: person movement, object manipulation, and person interaction.",
        "dcterms:title": "AVA 2.2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Detection",
            "Multi-label Classification"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Spatio-temporal actions",
            "Multi-label"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Mostafa S Ibrahim",
            "Srikanth Muralidharan",
            "Zhiwei Deng",
            "Arash Vahdat",
            "Greg Mori"
        ],
        "dcterms:description": "Volleyball is a group activity recognition dataset with 8 volleyball group activities. Each clip has up to 13 persons, with the center frame annotated with GT person boxes.",
        "dcterms:title": "Volleyball",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Group Activity Recognition",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Group activity dataset",
            "Volleyball actions",
            "Multi-person"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Group Activity Recognition"
        ]
    }
]