[
    {
        "dcterms:creator": [
            "N. Li",
            "A. Pan",
            "A. Gopal",
            "S. Yue",
            "D. Berrios",
            "A. Gatti",
            "J. D. Li",
            "A.-K. Dombrowski",
            "S. Goel",
            "L. Phan"
        ],
        "dcterms:description": "The WMDP benchmark serves as a proxy measurement of hazardous knowledge in biology, chemistry, and cybersecurity, containing questions that are not explicitly dangerous but are precursors to information useful for bioterrorism, chemical weapons, or cybercrime.",
        "dcterms:title": "WMDP",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2403.03218",
        "dcat:theme": [
            "Benchmarking",
            "Safety Evaluation"
        ],
        "dcat:keyword": [
            "Hazardous knowledge",
            "Bioterrorism",
            "Cybersecurity",
            "Chemical weapons"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Capability evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Basart",
            "A. Zou",
            "M. Mazeika",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "MMLU tests knowledge across a variety of topics, measuring massive multitask language understanding.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [
            "Benchmarking",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Multitask evaluation",
            "Language understanding",
            "Knowledge assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding"
        ]
    },
    {
        "dcterms:creator": [
            "A. Talmor",
            "J. Herzig",
            "N. Lourie",
            "J. Berant"
        ],
        "dcterms:description": "CommonsenseQA is a question answering challenge that targets commonsense knowledge, assessing the ability of models to answer questions that require understanding of everyday situations.",
        "dcterms:title": "CSQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1811.00937",
        "dcat:theme": [
            "Benchmarking",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Question answering",
            "Commonsense knowledge",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    }
]