[
    {
        "dcterms:creator": [
            "Gabriel Preda"
        ],
        "dcterms:description": "A small subset of annotated Covid-19 tweets containing 6000 tweets with sentiments classified as positive, negative, and neutral. The dataset is highly imbalanced with 3680 neutral tweets, 1900 positive tweets, and 420 negative tweets.",
        "dcterms:title": "Covid-19 tweets (annotated for positive, negative, and neutral sentiments)",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "https://www.kaggle.com/gpreda/all-covid19-vaccines-tweets",
        "dcat:theme": [
            "Sentiment Analysis",
            "Social Media"
        ],
        "dcat:keyword": [
            "Covid-19",
            "Vaccines",
            "Sentiment",
            "Twitter",
            "Annotated Tweets"
        ],
        "dcat:landingPage": "https://www.kaggle.com/gpreda/all-covid19-vaccines-tweets",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "M. Müller",
            "M. Salathé",
            "P. Kummervold"
        ],
        "dcterms:description": "A domain-specific transformer-based model pre-trained on 160 million Twitter messages related to Covid-19, aimed at understanding social media content regarding the pandemic.",
        "dcterms:title": "COVID-Twitter-BERT or CT-BERT (Covid-19 tweets)",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Covid-19",
            "Twitter",
            "Sentiment Analysis",
            "Transformer Model"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "D. Nguyen",
            "T. Vu",
            "A. Nguyen"
        ],
        "dcterms:description": "A large-scale pre-trained language model for English Tweets, designed to outperform strong baselines in various NLP tasks.",
        "dcterms:title": "BERTweet (English Tweets)",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "English Tweets",
            "Pre-trained Model",
            "NLP",
            "Sentiment Analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "N. V. Chawla",
            "K. W. Bowyer",
            "L. O. Hall",
            "W. P. Kegelmeyer"
        ],
        "dcterms:description": "A technique for generating synthetic samples to address class imbalance in datasets, particularly useful in machine learning tasks.",
        "dcterms:title": "SMOTE (Synthetic Minority Over-sampling Technique)",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Augmentation",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Synthetic Data",
            "Class Imbalance",
            "Oversampling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Leekha",
            "M. Goswami",
            "M. Jain"
        ],
        "dcterms:description": "A language modeling based synthetic data generation approach for tackling class imbalance in natural language processing tasks.",
        "dcterms:title": "Language Model-based Oversampling Technique (LMOTE)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Augmentation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Synthetic Data",
            "Language Model",
            "Oversampling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]