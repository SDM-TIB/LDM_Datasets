[
    {
        "dcterms:creator": [
            "Shengpeng Ji",
            "Jialong Zuo",
            "Minghui Fang",
            "Ziyue Jiang",
            "Feiyang Chen",
            "Xinyu Duan",
            "Baoxing Huai",
            "Zhou Zhao"
        ],
        "dcterms:description": "TextrolSpeech is a large-scale speech emotion dataset annotated with rich text attributes, comprising 236,220 pairs of style prompts in natural text descriptions with five style factors and corresponding speech samples.",
        "dcterms:title": "TextrolSpeech",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Emotion",
            "Text style prompts",
            "Controllable TTS"
        ],
        "dcat:landingPage": "https://sall-e.github.io/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech",
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Heiga Zen",
            "Viet Dang",
            "Rob Clark",
            "Yu Zhang",
            "Ron J Weiss",
            "Ye Jia",
            "Zhifeng Chen",
            "Yonghui Wu"
        ],
        "dcterms:description": "LibriTTS is a corpus derived from LibriSpeech for text-to-speech synthesis, providing a large amount of high-quality speech data.",
        "dcterms:title": "LibriTTS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "Speech synthesis",
            "TTS dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech"
        ]
    },
    {
        "dcterms:creator": [
            "Christophe Veaux",
            "Junichi Yamagishi",
            "Kirsten MacDonald"
        ],
        "dcterms:description": "VCTK is an English multi-speaker corpus designed for voice cloning, providing diverse speech samples from multiple speakers.",
        "dcterms:title": "VCTK",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Voice Cloning"
        ],
        "dcat:keyword": [
            "Multi-speaker dataset",
            "Voice cloning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Cloning"
        ]
    },
    {
        "dcterms:creator": [
            "Kun Zhou",
            "Berrak Sisman",
            "Rui Liu",
            "Haizhou Li"
        ],
        "dcterms:description": "ESD is an emotional speech dataset designed for voice conversion, focusing on seen and unseen emotional style transfer.",
        "dcterms:title": "ESD",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Voice Conversion",
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "Voice conversion dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Conversion"
        ]
    },
    {
        "dcterms:creator": [
            "Kate Dupuis",
            "M Kathleen Pichora-Fuller"
        ],
        "dcterms:description": "TESS is a set of emotional speech recordings designed for research in emotion recognition, featuring various emotional expressions.",
        "dcterms:title": "TESS",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech dataset",
            "Emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Kaisiyuan Wang",
            "Qianyi Wu",
            "Linsen Song",
            "Zhuoqian Yang",
            "Wayne Wu",
            "Chen Qian",
            "Ran He",
            "Yu Qiao",
            "Chen Change Loy"
        ],
        "dcterms:description": "MEAD is a large-scale audio-visual dataset for generating emotional talking faces, combining audio and visual data for research.",
        "dcterms:title": "MEAD",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Generation"
        ],
        "dcat:keyword": [
            "Emotional talking faces",
            "Audio-visual dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video",
        "mls:task": [
            "Emotion Recognition",
            "Audio-Visual Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Shae D Morgan"
        ],
        "dcterms:description": "SAVEE is a dataset containing categorical and dimensional ratings of emotional speech, providing insights into emotional expression in speech.",
        "dcterms:title": "SAVEE",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech dataset",
            "Emotion ratings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "MESS is a dataset mentioned in the context of the paper but not explicitly cited, focusing on emotional speech.",
        "dcterms:title": "MESS",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]