[
    {
        "dcterms:creator": [
            "Dan Stowell",
            "Tereza Petrusková",
            "Martin Šálek",
            "Pavel Linhart"
        ],
        "dcterms:description": "Audio data collected to accompany the work on automatic acoustic identification of individual animals. It contains labelled recordings of individuals from three different bird species: Little owl, Chiffchaff, and Tree pipit. The data was augmented by mixing foreground recordings of each individual with background recordings of other individuals, and the labels were re-structured to follow a 3 level hierarchical taxonomy.",
        "dcterms:title": "3 Bird Species",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bioacoustics",
            "Animal Identification"
        ],
        "dcat:keyword": [
            "Bird species",
            "Audio recordings",
            "Acoustic identification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Species identification",
            "Audio classification"
        ]
    },
    {
        "dcterms:creator": [
            "Jesse Engel",
            "Cinjon Resnick",
            "Adam Roberts",
            "Sander Dieleman",
            "Douglas Eck",
            "Karen Simonyan",
            "Mohammad Norouzi"
        ],
        "dcterms:description": "A large-scale dataset of annotated musical notes containing 4-second audio snippets of notes played with different instruments. A small selection of the dataset was created to address the task of instrument recognition, organized into a 2-level hierarchical taxonomy using instrument family labels as the highest level classes.",
        "dcterms:title": "Nsynth",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Music",
            "Instrument Recognition"
        ],
        "dcat:keyword": [
            "Musical notes",
            "Audio snippets",
            "Instrument classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Instrument recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Annamaria Mesaros",
            "Toni Heittola",
            "Tuomas Virtanen"
        ],
        "dcterms:description": "Dataset of 30-second audio segments from 15 acoustic scenes, organized into 3 groups: indoor, outdoor, and vehicles according to the environment where they were captured. The selected data consists of recordings balanced across the 3 groups.",
        "dcterms:title": "TUTasc2016",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Acoustic Scenes",
            "Environmental Sound Classification"
        ],
        "dcat:keyword": [
            "Acoustic scenes",
            "Audio segments",
            "Environmental classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Scene classification"
        ]
    }
]