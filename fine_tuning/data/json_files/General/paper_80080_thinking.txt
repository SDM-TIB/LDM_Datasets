To extract datasets from the research paper titled "Learning Depth from Single Monocular Images Using Deep Convolutional Neural Fields" by Fayao Liu et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the proposed method is evaluated on both indoor and outdoor scene datasets, which indicates that there are datasets to be identified.

Next, I will focus on the **introduction section** to look for specific mentions of datasets. The authors discuss the challenges of depth estimation and reference the use of RGBD images, which suggests that they might be using specific datasets for their experiments.

In the **experiments section**, I will look for a subsection dedicated to datasets, which is often labeled as "Datasets" or something similar. This section typically provides detailed descriptions of the datasets used in the experiments. 

Upon reviewing the paper, I find the following datasets mentioned:

1. **NYU v2 Dataset**: This dataset consists of 1449 RGBD images of indoor scenes, with 795 used for training and 654 for testing. It is a well-known benchmark for depth estimation tasks.

2. **Make3D Dataset**: This dataset contains 534 images depicting outdoor scenes, with 400 images for training and 134 for testing. It is commonly used for evaluating depth estimation methods in outdoor environments.

3. **KITTI Dataset**: This dataset includes images taken from a driving vehicle with depth information captured by a LiDAR sensor. The authors mention using a specific test set of 697 images from 28 scenes.

Next, I will check the **References section** of the paper to find the full citations for these datasets. The citations are crucial for proper attribution and to allow others to access the datasets.

The full citations I find are:

- For the **NYU v2 Dataset**:
  > Nathan Silberman, Derek Hoiem, and Rob Fergus. "Indoor segmentation and support inference from RGBD images." In Proceedings of the European Conference on Computer Vision (ECCV), 2012.

- For the **Make3D Dataset**:
  > A. Saxena, M. Sun, and A. Y. Ng. "Make3D: Learning 3D scene structure from a single still image." IEEE Transactions on Pattern Analysis and Machine Intelligence, 2009.

- For the **KITTI Dataset**:
  > Andreas Geiger, Philip Lenz, Christoph Stiller, and Raquel Urtasun. "Vision meets robotics: The KITTI dataset." International Journal of Robotics Research, 2013.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This includes ensuring that each dataset is clearly described along with its citation for proper attribution.