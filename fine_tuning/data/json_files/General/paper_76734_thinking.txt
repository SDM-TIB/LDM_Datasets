To extract datasets from the research paper titled "SparseNet: A Sparse DenseNet for Image Classification" by Wenqi Liu and Kun Zeng, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. In the abstract, the authors state that they evaluate their method on datasets of CIFAR (including CIFAR10 and CIFAR100) and SVHN. This indicates that these datasets are relevant to their research.

Next, I will focus on **section 4.1 (Datasets)**, where the authors provide detailed descriptions of the datasets used in their experiments:

1. **CIFAR-10**: This dataset consists of colored images with three channels, each sized 32 × 32 pixels. It includes 50,000 training images and 10,000 test images, categorized into 10 classes.

2. **CIFAR-100**: Similar to CIFAR-10, this dataset also contains colored images of the same size (32 × 32 pixels) but is divided into 100 classes, with the same number of training and test images as CIFAR-10.

3. **SVHN (Street View House Numbers)**: This dataset consists of colored images with three channels, also sized 32 × 32 pixels. It includes 73,257 training images, 531,131 additional training images, and 26,032 test images.

In the **References section**, I will look for full citations for these datasets. The citations are as follows:

- For **CIFAR-10 and CIFAR-100**, the citation is:
  > Krizhevsky, A., Hinton, G. (2009). *Learning multiple layers of features from tiny images*. 

- For **SVHN**, the citation is:
  > Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y. (2011). *Reading digits in natural images with unsupervised feature learning*. In NIPS workshop on deep learning and unsupervised feature learning.

Now, I will compile the dataset entries with their full citations, ensuring that each dataset is accurately represented and properly cited. This will provide a clear and comprehensive overview of the datasets used in the research.