[
    {
        "dcterms:creator": [
            "Guillermo Garcia-Hernando",
            "Shanxin Yuan",
            "Seungryul Baek",
            "Tae-Kyun Kim"
        ],
        "dcterms:description": "The STB dataset has real hand images sequentially captured in 18,000 frames with 6 different lighting conditions and backgrounds. Each frame image is labeled with 3D annotations of 21 joints.",
        "dcterms:title": "STB dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Hand Pose Estimation"
        ],
        "dcat:keyword": [
            "Hand images",
            "3D annotations",
            "Gesture recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Hand Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Hanbyul Joo",
            "Hao Liu",
            "Lei Tan",
            "Lin Gui",
            "Bart Nabbe",
            "Iain Matthews",
            "Takeo Kanade",
            "Shohei Nobuhara",
            "Yaser Sheikh"
        ],
        "dcterms:description": "The PANOPTIC dataset is re-engineered from data from multiple views of Panoptic studio. The dataset is made of 14,847 image samples along with 2D joint annotations, and provides general views of hands and skin tones.",
        "dcterms:title": "PANOPTIC dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Hand Pose Estimation"
        ],
        "dcat:keyword": [
            "Multi-view data",
            "2D joint annotations",
            "Hand tracking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Hand Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Guillermo Garcia-Hernando",
            "Shanxin Yuan",
            "Seungryul Baek",
            "Tae-Kyun Kim"
        ],
        "dcterms:description": "The FPHA dataset consists of RGB video sequences of 6 subjects performing 45 types of hand activities with daily objects in egocentric views (e.g., pouring a bottle, charging a phone) that follow with heavy (self-)occlusions. Each sample is annotated with 2D and 3D labels both of which are used for training.",
        "dcterms:title": "FPHA dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Hand Pose Estimation"
        ],
        "dcat:keyword": [
            "RGB video sequences",
            "Hand activities",
            "Egocentric views"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Hand Pose Estimation"
        ]
    }
]