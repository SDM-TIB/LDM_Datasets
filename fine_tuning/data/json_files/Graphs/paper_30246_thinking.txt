To extract datasets from the research paper titled "SRFeat: Learning Locally Accurate and Globally Consistent Non-Rigid Shape Correspondence" by Lei Li et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the work, and the introduction often highlights the datasets used for evaluation. 

In the **introduction**, the authors mention that they demonstrate their approach through experiments on a wide range of challenging matching benchmarks, including 3D non-rigid shape correspondence and 2D image keypoint matching. This suggests that multiple datasets are involved, but I need to find specific names.

Next, I will focus on **section 4 (Experiments)**, where the authors detail the datasets used for their experiments. Here, they explicitly mention several datasets:

1. **FAUST Dataset**: This dataset is used for evaluating human shape matching performance. It contains 100 shapes labeled with ground-truth correspondences, and the authors specify that they use the unaligned remeshed versions of the dataset.

2. **SCAPE Dataset**: Another dataset for human shape matching, containing 71 labeled shapes. The authors mention a specific training/testing split of 51/20 shapes.

3. **SHREC’19 Dataset**: This dataset is used as a more challenging benchmark for human shape matching, containing 44 labeled shapes and 430 shape pairs in total.

4. **SMAL Dataset**: A dataset for four-legged animal shapes, which includes five categories (cats, dogs, cows, horses, and hippos). The authors specify that they use the first three categories for training and the last two for testing.

In addition to these datasets, I will also check the **References section** to find the full citations for each dataset mentioned:

- For the **FAUST Dataset**, the citation is:
  > Federica Bogo, Javier Romero, Matthew Loper, and Michael J. Black. *FAUST: Dataset and evaluation for 3D mesh registration*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2014.

- For the **SCAPE Dataset**, the citation is:
  > Dragomir Anguelov, Praveen Srinivasan, Daphne Koller, Sebastian Thrun, Jim Rodgers, and James Davis. *SCAPE: Shape completion and animation of people*. In SIGGRAPH, pages 408–416, 2005.

- For the **SHREC’19 Dataset**, the citation is:
  > Simone Melzi, Riccardo Marin, Emanuele Rodolà, Umberto Castellani, Jing Ren, Adrien Poulenard, Peter Wonka, and Maks Ovsjanikov. *Matching humans with different connectivity*. In 3DOR, pages 121–128, 2019.

- For the **SMAL Dataset**, the citation is:
  > Silvia Zuffi, Angjoo Kanazawa, David W. Jacobs, and Michael J. Black. *3D Menagerie: Modeling the 3D shape and pose of animals*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.