[
    {
        "dcterms:creator": [
            "Jun Xu",
            "Tao Mei",
            "Ting Yao",
            "Yong Rui"
        ],
        "dcterms:description": "MSR-VTT dataset is an open-domain dataset and consists of more than 7K videos and 10K clips of approximately 20 seconds duration sourced from YouTube. The dataset contains 200K clip-caption pairs with each clip being annotated with 20 captions using Amazon Mechanical Turk (AMT).",
        "dcterms:title": "MSR-VTT",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Captioning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Captioning",
            "Open-domain",
            "YouTube"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "David Chen",
            "William B Dolan"
        ],
        "dcterms:description": "MSVD is sourced from YouTube and contains 1970 clips with an average duration of around 10 seconds. Each clip has been annotated with one caption using Amazon Mechanical Turks (AMT).",
        "dcterms:title": "MSVD",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Captioning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Captioning",
            "YouTube"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Captioning"
        ]
    }
]