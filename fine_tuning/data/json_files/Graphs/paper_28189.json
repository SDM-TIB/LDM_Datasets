[
    {
        "dcterms:creator": [
            "Alex Krizhevsky"
        ],
        "dcterms:description": "CIFAR10 dataset contains 60,000 colour images from 10 object categories. In particular, the dataset contains 50,000 training images and 10,000 testing images. The size of each image is 32 × 32.",
        "dcterms:title": "CIFAR10",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Color images",
            "Object categories"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Adam Coates",
            "Andrew Ng",
            "Honglak Lee"
        ],
        "dcterms:description": "STL10 dataset contains 13,000 labeled colour images from 10 classes. Specifically, the dataset is divided into 5,000 training images and 8,000 testing images. The size of each image is 96 × 96.",
        "dcterms:title": "STL10",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Color images",
            "Labeled images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Tiny-ImageNet dataset contains 100,000 training images and 10,000 testing images from 200 classes. Each class has 500 training images and 50 testing images. Each image has size 64 × 64.",
        "dcterms:title": "Tiny-ImageNet",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.kaggle.com/c/tiny-imagenet/overview",
        "dcat:theme": [
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Small-scale ImageNet",
            "Color images"
        ],
        "dcat:landingPage": "https://www.kaggle.com/c/tiny-imagenet/overview",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark"
        ],
        "dcterms:description": "CLIP is a model that learns transferable visual representations from natural language supervision, trained on 400 million (image, text) pairs collected from the Internet.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2103.00020",
        "dcat:theme": [
            "Image and Text Representation"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Text dataset",
            "Natural language supervision"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2103.00020",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image and Text",
        "mls:task": [
            "Image Classification",
            "Text Classification"
        ]
    }
]