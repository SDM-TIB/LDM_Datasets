[
    {
        "dcterms:creator": [
            "A. Shahroudy",
            "J. Liu",
            "T.-T. Ng",
            "G. Wang"
        ],
        "dcterms:description": "A large-scale and multi-modality dataset for skeleton-based action recognition, consisting of 56,880 video clips in 60 action classes performed by 40 subjects, captured by three Microsoft Kinect v2 sensors.",
        "dcterms:title": "NTU RGB+D",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "3D human activity",
            "Action classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "W. Kay",
            "et al."
        ],
        "dcterms:description": "A large-scale dataset for skeleton-based action recognition derived from the original Kinetics dataset, which contains about 300,000 video clips in 400 classes, with joint information estimated using the OpenPose toolbox.",
        "dcterms:title": "Kinetics-Skeleton",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "Action recognition",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]