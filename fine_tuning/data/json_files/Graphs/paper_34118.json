[
    {
        "dcterms:creator": [
            "Yang Yang",
            "Ran Bao",
            "Weili Guo",
            "De-Chuan Zhan",
            "Yilong Yin",
            "Jian Yang"
        ],
        "dcterms:description": "A dataset comprised of social media comments in several Indian languages, annotated with precision by expert judges to capture the nuanced implications for offline context harm.",
        "dcterms:title": "TRAC-2024 Offline Harm Potential Identification Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "Indian languages",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Social Media Analysis",
            "Harm Prediction"
        ],
        "dcat:keyword": [
            "Social Media",
            "Harm Potential",
            "Multilingual",
            "Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Simran Khanuja",
            "Diksha Bansal",
            "Sarvesh Mehtani",
            "Savya Khosla",
            "Atreyee Dey",
            "Balaji Gopalan",
            "Dilip Kumar Margam",
            "Pooja Aggarwal",
            "Rajiv Teja Nagipogu",
            "Shachi Dave"
        ],
        "dcterms:description": "A cutting-edge language model built on the transformer architecture, designed to enhance natural language understanding for Indian languages, pre-trained on a vast corpus covering 17 Indian languages.",
        "dcterms:title": "MuRILBERT",
        "dcterms:issued": "2021",
        "dcterms:language": "Indian languages",
        "dcterms:identifier": "arXiv:2103.10730",
        "dcat:theme": [
            "Natural Language Processing",
            "Multilingual Representation"
        ],
        "dcat:keyword": [
            "Language Model",
            "Indian Languages",
            "Transformer",
            "Pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Sagor Sarker"
        ],
        "dcterms:description": "A specialized transformer-based model meticulously honed for the Bengali language, pre-trained with a masked language model objective on a large corpus of Bengali text.",
        "dcterms:title": "BanglaBERT",
        "dcterms:issued": "2022",
        "dcterms:language": "Bengali",
        "dcterms:identifier": "https://github.com/sagorbrur/bangla-bert",
        "dcat:theme": [
            "Natural Language Processing",
            "Bengali Language Processing"
        ],
        "dcat:keyword": [
            "Bengali",
            "Language Model",
            "Transformer",
            "NLP Tasks"
        ],
        "dcat:landingPage": "https://github.com/sagorbrur/bangla-bert",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "NLP Tasks"
        ]
    },
    {
        "dcterms:creator": [
            "Divyanshu Kakwani",
            "Anoop Kunchukuttan",
            "Satish Golla",
            "NC Gokul",
            "Avik Bhattacharyya",
            "Mitesh M Khapra",
            "Pratyush Kumar"
        ],
        "dcterms:description": "A suite providing monolingual corpora, evaluation benchmarks, and pre-trained multilingual models for Indian languages.",
        "dcterms:title": "IndicBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "Indian languages",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Multilingual Representation"
        ],
        "dcat:keyword": [
            "Indian Languages",
            "Pre-trained Models",
            "Evaluation Benchmarks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Md Saroar Jahan",
            "Mainul Haque",
            "Nabil Arhab",
            "Mourad Oussalah"
        ],
        "dcterms:description": "A BERT-based model for abusive language detection in Bengali, designed to identify harmful content.",
        "dcterms:title": "BanglaHateBert",
        "dcterms:issued": "2022",
        "dcterms:language": "Bengali",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Abusive Language Detection"
        ],
        "dcat:keyword": [
            "Bengali",
            "Abusive Language",
            "BERT",
            "Hate Speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Abusive Language Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Alexis Conneau",
            "Kartikay Khandelwal",
            "Naman Goyal",
            "Vishrav Chaudhary",
            "Guillaume Wenzek",
            "Francisco Guzm√°n",
            "Edouard Grave",
            "Myle Ott",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "A transformer-based language model trained with the multilingual masked language modeling objective on 100 languages, designed for cross-lingual representation learning.",
        "dcterms:title": "XLM-R",
        "dcterms:issued": "2019",
        "dcterms:language": "Multilingual",
        "dcterms:identifier": "arXiv:1911.02116",
        "dcat:theme": [
            "Natural Language Processing",
            "Cross-lingual Representation"
        ],
        "dcat:keyword": [
            "Multilingual",
            "Language Model",
            "Cross-lingual Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding"
        ]
    }
]