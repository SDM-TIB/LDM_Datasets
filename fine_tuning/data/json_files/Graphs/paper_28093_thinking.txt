To extract datasets from the research paper titled "Video Contrastive Learning with Global Context" by Haofei Kuang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any mentions of datasets. The abstract states that the proposed method outperforms previous state-of-the-art methods on five video datasets for various tasks, which indicates that datasets are involved.

Next, I will focus on **section 4.1 (Datasets)**, where the authors explicitly list the datasets used in their experiments. Here, they mention:

1. **Kinetics400**: This dataset consists of approximately 240,000 training and 20,000 validation videos trimmed to 10 seconds from 400 human action categories.
2. **UCF101**: This dataset contains 13,320 videos spread across 101 categories of human actions.
3. **HMDB51**: This dataset includes 6,849 videos divided into 51 action categories.
4. **Something-Something-v2**: This dataset consists of 174 action classes and a total of 220,847 videos.
5. **ActivityNet**: This dataset contains 200 human daily living actions, with 10,024 training and 4,926 validation videos.

I will also check the **References section** to find the full citations for these datasets. The citations are as follows:

- For **Kinetics400**, the citation is:
  > Will Kay, Joao Carreira, Karen Simonyan, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, Paul Natsev, Mustafa Suleyman, and Andrew Zisserman. *The Kinetics Human Action Video Dataset*. arXiv preprint arXiv:1705.06950, 2017.

- For **UCF101**, the citation is:
  > Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. *UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild*. arXiv preprint arXiv:1212.0402, 2012.

- For **HMDB51**, the citation is:
  > Hildegard Kuehne, Hueihan Jhuang, Est´ıbaliz Garrote, Tomaso Poggio, and Thomas Serre. *HMDB: A Large Video Database for Human Motion Recognition*. In ICCV, 2011.

- For **Something-Something-v2**, the citation is:
  > Raghav Goyal, Samira Ebrahimi Kahou, Vincent Michalski, Joanna Materzynska, Susanne Westphal, Heuna Kim, Valentin Haenel, Ingo Fruend, Peter Yianilos, Moritz Mueller-Freitag, et al. *The “Something Something” Video Database for Learning and Evaluating Visual Common Sense*. In ICCV, 2017.

- For **ActivityNet**, the citation is:
  > Fabian Caba Heilbron, Victor Escorcia, Bernard Ghanem, and Juan Carlos Niebles. *ActivityNet: A Large-Scale Video Benchmark for Human Activity Understanding*. In CVPR, 2015.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured all necessary details regarding the datasets used in the research.