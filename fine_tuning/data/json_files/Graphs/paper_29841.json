[
    {
        "dcterms:creator": [
            "Jun Liu",
            "Gang Wang",
            "Ping Hu",
            "Ling-Yu Duan",
            "Alex C. Kot"
        ],
        "dcterms:description": "This dataset is the most widely used dataset for skeleton-based action recognition. It contains 56,880 skeleton sequence samples that involve 60 action categories performed by 40 subjects. Each human skeleton is represented by 25 joints with 3D coordinates captured by 3 cameras from different horizontal angles.",
        "dcterms:title": "NTU-RGB+D 60",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "Action recognition",
            "3D human activity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jun Liu",
            "Amir Shahroudy",
            "Mauricio Perez",
            "Gang Wang",
            "Ling-Yu Duan",
            "Alex C. Kot"
        ],
        "dcterms:description": "This dataset is an extended version of NTU-RGB+D 60 dataset. It contains 114,480 skeleton sequence samples and involves 120 action classes performed by 106 subjects in 155 viewpoints and 3 different camera perspectives.",
        "dcterms:title": "NTU-RGB+D 120",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton dataset",
            "Action recognition",
            "3D human activity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Tianjiao Li",
            "Jun Liu",
            "Wei Zhang",
            "Yun Ni",
            "Wenqian Wang",
            "Zhiheng Li"
        ],
        "dcterms:description": "This dataset is recently released for human behavior understanding with unmanned aerial vehicles, including 22,476x3 multi-modal video sequences. It involves 155 different activity categories performed by 119 distinct subjects in 45 different environment sites.",
        "dcterms:title": "UAV-Human",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Behavior Understanding"
        ],
        "dcat:keyword": [
            "UAV dataset",
            "Human behavior",
            "Multi-modal video"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Behavior Recognition"
        ]
    }
]