To extract datasets from the research paper titled "RedCore: Relative Advantage Aware Cross-modal Representation Learning for Missing Modalities with Imbalanced Missing Rates" by Jun Sun et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract states that the authors evaluate their method on three commonly used multimodal datasets: **IEMOCAP**, **CMU-MOSEI**, and **MSP-IMPROV**. This indicates that these datasets are crucial for the experiments conducted in the paper.

Next, I will look for a dedicated **Datasets section** or any mention of these datasets in the **experiments section**. In the methods section, the authors describe the datasets in detail, including their characteristics and the modalities involved. 

1. **IEMOCAP**: This dataset consists of conversation videos where two actors perform scenarios designed to evoke emotional expressions. It is annotated into categorical emotion labels. The reference for this dataset is:
   > Busso, C., Bulut, M., Lee, C.-C., Kazemzadeh, A., Mower, E., Kim, S., Chang, J. N., Lee, S., & Narayanan, S. S. (2008). IEMOCAP: Interactive emotional dyadic motion capture database. *Language Resources and Evaluation*, 42, 335–359.

2. **CMU-MOSEI**: This dataset includes over 23,500 sentence utterance videos from more than 1000 online YouTube speakers, annotated with sentiment labels (positive, negative, neutral). The reference for this dataset is:
   > Zadeh, A. B., Liang, P. P., Poria, S., Cambria, E., & Morency, L.-P. (2018). Multimodal language analysis in the wild: CMU-MOSEI dataset and interpretable dynamic fusion graph. In *Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, 2236–2246.

3. **MSP-IMPROV**: This dataset consists of data from six dyadic conversations involving 12 actors, used for studying emotion perception. The reference for this dataset is:
   > Busso, C., Parthasarathy, S., Burmania, A., AbdelWahab, M., Sadoughi, N., & Provost, E. M. (2016). MSP-IMPROV: An acted corpus of dyadic interactions to study emotion perception. *IEEE Transactions on Affective Computing*, 8(1), 67–80.

After identifying the datasets and their references, I will ensure to note down the full citations for each dataset as they are crucial for proper attribution in any subsequent analysis or application of the research findings.

Finally, I will compile the dataset information into a structured format for easy reference and use in future work.