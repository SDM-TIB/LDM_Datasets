[
    {
        "dcterms:creator": [
            "R.K.E. Bellamy",
            "K. Dey",
            "M. Hind",
            "S.C. Hoffman",
            "S. Houde",
            "K. Kannan",
            "P. Lohia",
            "J. Martino",
            "S. Mehta",
            "A. Mojsilovic",
            "S. Nagar",
            "K.N. Ramamurthy",
            "J. Richards",
            "D. Saha",
            "P. Sattigeri",
            "M. Singh",
            "K.R. Varshney",
            "Y. Zhang"
        ],
        "dcterms:description": "A comprehensive Python open-source package developed at IBM that contains over 70 fairness metrics and 10 bias mitigation algorithms, designed to translate algorithmic research into practical applications across various domains.",
        "dcterms:title": "AI Fairness 360",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv 1810.01943",
        "dcat:theme": [
            "Fairness",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Fairness metrics",
            "Bias mitigation",
            "Open-source toolkit"
        ],
        "dcat:landingPage": "https://github.com/ibm/aif360",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Bias detection",
            "Fairness assessment"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A popular perturbation-based interpretability technique that provides local explanations to black-box models by training a linear classifier that approximates the behavior of the model.",
        "dcterms:title": "LIME",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/",
        "dcat:theme": [
            "Interpretability",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Local explanations",
            "Black-box models",
            "Interpretability technique"
        ],
        "dcat:landingPage": "https://www.oreilly.com/content/introduction-to-local-interpretable-model-agnostic-explanations-lime/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Model interpretation",
            "Bias detection"
        ]
    },
    {
        "dcterms:creator": [
            "James Wexler",
            "M. Pushkarna",
            "T. Bolukbasi",
            "M. Wattenberg",
            "F. Viegas",
            "J. Wilson"
        ],
        "dcterms:description": "An interactive visualization platform that allows users to probe, visualize, and analyze their data against different classifiers, facilitating the identification of bias using hypothetical scenarios.",
        "dcterms:title": "What-If Tool",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visualization",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Interactive visualization",
            "Data analysis",
            "Bias detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Model auditing",
            "Bias detection"
        ]
    },
    {
        "dcterms:creator": [
            "M. Zehlike",
            "T. Sühr",
            "C. Castillo",
            "I. Kitanovski"
        ],
        "dcterms:description": "An open-source search API designed to apply fairness in ranked search results, ensuring that the proportion of protected candidates in every prefix of the top-k ranking remains statistically above a given minimum.",
        "dcterms:title": "FairSearch",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "http://dx.doi.org/10.1145/3366424.3383534",
        "dcat:theme": [
            "Fairness",
            "Search Algorithms"
        ],
        "dcat:keyword": [
            "Ranked search",
            "Fairness API",
            "Search results"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1145/3366424.3383534",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Fairness assessment",
            "Search result evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "l. Tramer",
            "V. Atlidakis",
            "R. Geambasu",
            "D. Hsu",
            "J.P. Hubaux",
            "M. Humbert",
            "A. Juels",
            "H. Lin"
        ],
        "dcterms:description": "A tool that helps identify unwanted associations, unfair, discriminatory, or offensive user treatment in data-driven applications, addressing disparate impact and uneven rates of algorithmic error.",
        "dcterms:title": "FairTest",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv 1510.02377",
        "dcat:theme": [
            "Fairness",
            "Data Analysis"
        ],
        "dcat:keyword": [
            "Discrimination detection",
            "Bias identification",
            "Data-driven applications"
        ],
        "dcat:landingPage": "https://github.com/columbia/fairtest",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Bias detection",
            "Fairness assessment"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An open-source Python library with many fairness metrics to detect bias, allowing users to upload their data and generate bias reports based on configured metrics.",
        "dcterms:title": "Aequitas",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/pdf/1811.05577.pdf",
        "dcat:theme": [
            "Fairness",
            "Data Analysis"
        ],
        "dcat:keyword": [
            "Bias detection",
            "Fairness metrics",
            "Data auditing"
        ],
        "dcat:landingPage": "https://arxiv.org/pdf/1811.05577.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Bias detection",
            "Fairness assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Niels Bantilan"
        ],
        "dcterms:description": "A fairness-aware machine learning interface for end-to-end discrimination discovery and mitigation, focusing on model-agnostic predictions.",
        "dcterms:title": "Themis-ML",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://dx.doi.org/10.1080/15228835.2017.1416512",
        "dcat:theme": [
            "Fairness",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Discrimination discovery",
            "Bias mitigation",
            "Machine learning interface"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1080/15228835.2017.1416512",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Discrimination discovery",
            "Bias mitigation"
        ]
    },
    {
        "dcterms:creator": [
            "S.A. Friedler",
            "C. Scheidegger",
            "S. Venkatasubramanian",
            "S. Choudhary",
            "E.P. Hamilton",
            "D. Roth"
        ],
        "dcterms:description": "An open-source framework that facilitates a direct comparison of multiple algorithms, focusing on fairness-enhancing interventions in machine learning.",
        "dcterms:title": "Fairness Test-Bed",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://dx.doi.org/10.1145/3287560.3287589",
        "dcat:theme": [
            "Fairness",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Algorithm comparison",
            "Fairness assessment",
            "Intervention evaluation"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1145/3287560.3287589",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Fairness assessment",
            "Algorithm evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D’Amour, Alexander",
            "Srinivasan, Hansa",
            "Atwood, James",
            "Baljekar, Pallavi",
            "Sculley, D.",
            "Halpern, Yoni"
        ],
        "dcterms:description": "A dynamic tool implemented in the OpenAI Gym environment that builds simulations to explore the long-term impacts of deploying machine learning-based decision systems in social environments.",
        "dcterms:title": "ML-Fairness Gym",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1145/3351095.3372878",
        "dcat:theme": [
            "Fairness",
            "Simulation"
        ],
        "dcat:keyword": [
            "Simulation studies",
            "Decision systems",
            "Long-term fairness"
        ],
        "dcat:landingPage": "https://doi.org/10.1145/3351095.3372878",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Simulation",
            "Fairness assessment"
        ]
    },
    {
        "dcterms:creator": [
            "E. Choi",
            "T. Bahadori",
            "A. Schuetz",
            "W. Stewart",
            "J. Sun"
        ],
        "dcterms:description": "An interpretable predictive model in healthcare using a reverse time attention mechanism, designed to explain how each medical code contributes to predictions.",
        "dcterms:title": "RETAIN",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1608.05745",
        "dcat:theme": [
            "Healthcare",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Interpretable model",
            "Healthcare predictions",
            "Attention mechanism"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1608.05745",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Healthcare prediction",
            "Model interpretation"
        ]
    }
]