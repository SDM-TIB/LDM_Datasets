To extract datasets from the research paper titled "Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations" by Umberto Michieli and Pietro Zanuttigh, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and method sections** to identify any datasets mentioned. In the abstract, the authors mention evaluating their approach on **Pascal VOC2012** and **ADE20K** datasets, indicating that these are the datasets used for their experiments.

Next, I will look for more detailed descriptions of these datasets in the **method section**. In section 5 (Training Procedure), the authors provide specific information about both datasets:

1. **Pascal VOC2012**: This dataset contains 10,582 images in the training split and 1,449 in the validation split. Each pixel is assigned to one of 21 different classes (20 object classes plus background).

2. **ADE20K**: This is a large-scale dataset with 22,210 images, of which 2,000 form the validation split. It includes 150 classes, representing both stuff (e.g., sky, building) and object classes (e.g., bottle, chair).

I will also check the **References section** to find the full citations for these datasets:

- For **Pascal VOC2012**, the citation is:
  > M. Everingham, L. Van Gool, C. K. I. Williams, J. Winn, and A. Zisserman. *The PASCAL Visual Object Classes Challenge 2012 Results*. 2012.

- For **ADE20K**, the citation is:
  > Bolei Zhou, Hang Zhao, Xavier Puig, Sanja Fidler, Adela Barriuso, and Antonio Torralba. *ADE20K: A Large-scale Dataset for Semantic Segmentation and Scene Parsing*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 633â€“641, 2017.

Now that I have identified the datasets and their citations, I will prepare to compile this information into a structured format for further use.