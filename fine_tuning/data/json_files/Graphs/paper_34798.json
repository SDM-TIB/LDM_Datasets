[
    {
        "dcterms:creator": [
            "W.-L. Zheng",
            "B.-L. Lu"
        ],
        "dcterms:description": "The SEED dataset encompasses data from 15 native Chinese subjects, with the objective of eliciting negative, positive, and neutral emotions using 15 Chinese film clips. Each film clip has a duration of approximately 4 minutes. Subsequently, the participants are tasked with providing self-evaluations regarding their emotional responses, considering dimensions such as valence and arousal after viewing these film clips. To record brain activity, EEG signals are acquired using a 62-channel electrode setup arranged in the 10-20 system, at a high sampling rate of 1000 Hz.",
        "dcterms:title": "Shanghai Jiao Tong University emotion EEG dataset (SEED)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "EEG Data"
        ],
        "dcat:keyword": [
            "EEG",
            "Emotion",
            "Classification",
            "Chinese Film Clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "EEG",
        "mls:task": [
            "Emotion Classification"
        ]
    },
    {
        "dcterms:creator": [
            "X. Hu",
            "F. Wang",
            "D. Zhang"
        ],
        "dcterms:description": "The THU-EP dataset comprises data from 80 subjects, involving the use of 28 video clips as stimuli to elicit negative, positive, and neutral emotions. Each video clip has an average duration of approximately 67 seconds. These video clips are associated with a range of emotion items, including anger, disgust, fear, sadness, amusement, joy, inspiration, tenderness, arousal, valence, familiarity, and liking.",
        "dcterms:title": "TsingHua University emotional profile dataset (THU-EP)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "EEG Data"
        ],
        "dcat:keyword": [
            "EEG",
            "Emotion",
            "Video Clips",
            "Self-report Emotional Scores"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "EEG",
        "mls:task": [
            "Emotion Classification"
        ]
    },
    {
        "dcterms:creator": [
            "J. Chen",
            "X. Wang",
            "C. Huang",
            "X. Hu",
            "X. Shen",
            "D. Zhang"
        ],
        "dcterms:description": "The FACED dataset is an extended version of the THU-EP dataset, comprising data from 123 subjects. The experimental protocol remains the same as THU-EP, with the addition of 43 subjects, making it a relatively larger dataset for studying emotions using EEG.",
        "dcterms:title": "Finer-grained affective computing EEG dataset (FACED)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1038/s41597-023-02650-w",
        "dcat:theme": [
            "Emotion Recognition",
            "EEG Data"
        ],
        "dcat:keyword": [
            "EEG",
            "Emotion",
            "Classification",
            "Larger Dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.1038/s41597-023-02650-w",
        "dcterms:hasVersion": "",
        "dcterms:format": "EEG",
        "mls:task": [
            "Emotion Classification"
        ]
    },
    {
        "dcterms:creator": [
            "M. Soleymani",
            "S. Asghari-Esfeden",
            "Y. Fu",
            "M. Pantic"
        ],
        "dcterms:description": "MAHNOB-HCI is a comprehensive multi-modal dataset designed for the investigation of human emotional responses and the implicit tagging of emotions. This dataset involves the participation of 30 subjects in data collection experiments.",
        "dcterms:title": "Multimodal database for affect recognition and implicit tagging dataset (MAHNOB-HCI)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multi-modal Data"
        ],
        "dcat:keyword": [
            "EEG",
            "Emotion",
            "Multi-modal",
            "Film Clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "EEG",
        "mls:task": [
            "Emotion Regression"
        ]
    }
]