[
    {
        "dcterms:creator": [
            "Peter Anderson",
            "Xiaodong He",
            "Chris Buehler",
            "Damien Teney",
            "Mark Johnson",
            "Stephen Gould",
            "Lei Zhang"
        ],
        "dcterms:description": "A popular dataset containing images and their corresponding human-generated captions, used for training and evaluating image captioning models.",
        "dcterms:title": "MSCOCO",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Captioning",
            "Human annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Jiuniu Wang",
            "Wenjia Xu",
            "Qingzhong Wang",
            "Antoni B Chan"
        ],
        "dcterms:description": "A dataset designed to evaluate distinctive image captioning by comparing generated captions with ground truth captions from similar image sets.",
        "dcterms:title": "CIDErBtw",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Distinctive Captioning"
        ],
        "dcat:keyword": [
            "Distinctive captions",
            "Image sets",
            "Evaluation metric"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Ruotian Luo",
            "Brian Price",
            "Scott Cohen",
            "Gregory Shakhnarovich"
        ],
        "dcterms:description": "A dataset focused on training descriptive captions with a discriminability objective, enhancing the distinctiveness of generated captions.",
        "dcterms:title": "DiscCap",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Descriptive Captions"
        ],
        "dcat:keyword": [
            "Discriminability",
            "Descriptive captions",
            "Image dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Marcella Cornia",
            "Matteo Stefanini",
            "Lorenzo Baraldi",
            "Rita Cucchiara"
        ],
        "dcterms:description": "A dataset used for image captioning that employs a meshed-memory transformer architecture to enhance the generation of captions.",
        "dcterms:title": "M2Transformer",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Transformer Models"
        ],
        "dcat:keyword": [
            "Transformer",
            "Image captioning",
            "Memory attention"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning"
        ]
    }
]