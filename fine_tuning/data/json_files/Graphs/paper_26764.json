[
    {
        "dcterms:creator": [
            "O. Vinyals",
            "T. Ewalds",
            "S. Bartunov",
            "P. Georgiev",
            "A. S. Vezhnevets",
            "M. Yeo",
            "A. Makhzani",
            "H. Küttler",
            "J. Agapiou",
            "J. Schrittwieser",
            "J. Quan",
            "S. Gaffney",
            "S. Petersen",
            "K. Simonyan",
            "T. Schaul",
            "H. van Hasselt",
            "D. Silver",
            "T. P. Lillicrap",
            "K. Calderone",
            "P. Keet",
            "A. Brunasso",
            "D. Lawrence",
            "A. Ekermo",
            "J. Repp",
            "R. Tsing"
        ],
        "dcterms:description": "The SMAC benchmark is designed for evaluating multi-agent reinforcement learning algorithms, focusing on unit micromanagement tasks in the StarCraft II environment.",
        "dcterms:title": "SMAC benchmark",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1708.04782",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "StarCraft II",
            "Multi-Agent Reinforcement Learning",
            "Micromanagement Tasks"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1708.04782",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Agent Coordination"
        ]
    },
    {
        "dcterms:creator": [
            "O. Vinyals",
            "T. Ewalds",
            "S. Bartunov",
            "P. Georgiev",
            "A. S. Vezhnevets",
            "M. Yeo",
            "A. Makhzani",
            "H. Küttler",
            "J. Agapiou",
            "J. Schrittwieser",
            "J. Quan",
            "S. Gaffney",
            "S. Petersen",
            "K. Simonyan",
            "T. Schaul",
            "H. van Hasselt",
            "D. Silver",
            "T. P. Lillicrap",
            "K. Calderone",
            "P. Keet",
            "A. Brunasso",
            "D. Lawrence",
            "A. Ekermo",
            "J. Repp",
            "R. Tsing"
        ],
        "dcterms:description": "StarCraft II is a real-time strategy game that serves as a challenging environment for testing reinforcement learning algorithms, particularly in multi-agent settings.",
        "dcterms:title": "StarCraft II",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1708.04782",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Real-Time Strategy",
            "Multi-Agent Systems",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1708.04782",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Multi-Agent Coordination"
        ]
    },
    {
        "dcterms:creator": [
            "L. V. D. M. Laurens",
            "G. Hinton"
        ],
        "dcterms:description": "The t-SNE method is a technique for visualizing high-dimensional data by reducing it to two or three dimensions while preserving the local structure of the data.",
        "dcterms:title": "t-SNE method",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Visualization",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Dimensionality Reduction",
            "Visualization",
            "t-SNE"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Data Visualization"
        ]
    }
]