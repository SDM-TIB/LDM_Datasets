To extract datasets from the research paper titled "HAN: An Efficient Hierarchical Self-Attention Network for Skeleton-Based Gesture Recognition" by Jianbo Liu et al., I will follow a systematic approach to ensure I capture all relevant details, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors evaluate their method on three gesture recognition datasets, which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on **section IV (Experiments)**, where the authors explicitly introduce the datasets used for their experiments. Here, they mention three datasets:

1. **SHREC’17 Track**: This dataset contains 14 gestures performed by 28 individuals, resulting in 2800 sequences. It includes both depth images and skeleton data, with 22 hand joints annotated.

2. **DHG-14/28**: Similar to SHREC’17 Track, this dataset also contains 2800 sequences of 22 hand joints, but it is performed by 20 individuals with each gesture performed exactly 5 times. The authors note that this dataset uses a leave-one-subject-out experimental protocol.

3. **FPHA**: This dataset consists of 45 different daily hand actions performed by 6 individuals, with a total of 1175 action videos. It captures skeleton sequences along with RGB-D data, providing 21 hand joints (excluding the palm joint).

After identifying the datasets, I will check the **References section** to find the full citations for each dataset:

- For **SHREC’17 Track**, the citation is:
  > Q. De Smedt, H. Wannous, J.-P. Vandeborre, J. Guerry, B. Le Saux, and D. Filliat. *SHREC’17 Track: 3D Hand Gesture Recognition Using a Depth and Skeletal Dataset*. In Proceedings of the Eurographics Workshop on 3D Object Retrieval (3DOR), Lyon, France, Apr. 2017, pp. 33–38.

- For **DHG-14/28**, the citation is:
  > Q. De Smedt, H. Wannous, and J.-P. Vandeborre. *Skeleton-Based Dynamic Hand Gesture Recognition*. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), Las Vegas, NV, United States, Jun. 2016, pp. 1206–1214.

- For **FPHA**, the citation is:
  > G. Garcia-Hernando, S. Yuan, S. Baek, and T.-K. Kim. *First-Person Hand Action Benchmark with RGB-D Videos and 3D Hand Pose Annotations*. In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), Salt Lake City, UT, United States, Jun. 2018, pp. 409–419.

Now that I have gathered the necessary information about the datasets and their citations, I will compile this into a structured format for further processing or review. This ensures that I have accurately captured the datasets and their full citations as required.