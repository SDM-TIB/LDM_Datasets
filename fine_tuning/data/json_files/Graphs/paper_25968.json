[
    {
        "dcterms:creator": [
            "Amir Shahroudy",
            "Jun Liu",
            "Tian-Tsong Ng",
            "Gang Wang"
        ],
        "dcterms:description": "This dataset was captured from 40 human subjects by 3 Microsoft Kinect v2 cameras. It consists of 56880 action sequences with 60 classes. Actions 1-49 were performed by one actor, and actions 50-60 were performed by the other two actors. Each body skeleton was recorded with 25 joints.",
        "dcterms:title": "NTU RGB+D Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "3D human activity",
            "skeleton data",
            "action sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Lorenzo Seidenari",
            "Vincenzo Varano",
            "Stefano Berretti",
            "Alberto Bimbo",
            "Pietro Pala"
        ],
        "dcterms:description": "This dataset contains 215 action sequences of 10 actors with 9 classes. Each body skeleton was collected from Kinect, and recorded with 15 joints. The standard experimental settings follow a leave-one-actor-out validation protocol.",
        "dcterms:title": "Florence 3D Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "depth camera",
            "action sequences",
            "skeleton data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Lu Xia",
            "Chia-Chih Chen",
            "Jake K Aggarwal"
        ],
        "dcterms:description": "This dataset was captured using a single stationary Kinect. It consists of 200 sequences with 10 classes, and each skeleton includes 20 joints. The dataset was recorded by three channels: RGB, depth, and skeleton joint locations.",
        "dcterms:title": "UT-Kinect Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Kinect",
            "skeleton data",
            "action sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jian-Fang Hu",
            "Wei-Shi Zheng",
            "Jianhuang Lai",
            "Jianguo Zhang"
        ],
        "dcterms:description": "On this dataset, 40 actors were asked to perform 12 different activities, resulting in a total of 480 action videos. The corresponding RGB, depth, and skeleton information were captured by a Kinect.",
        "dcterms:title": "SYSU 3D Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "RGB data",
            "depth data",
            "skeleton data",
            "action sequences"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Action Recognition"
        ]
    }
]