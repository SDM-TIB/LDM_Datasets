[
    {
        "dcterms:creator": [
            "Jiyang Gao",
            "Chen Sun",
            "Zhenheng Yang",
            "Ram Nevatia"
        ],
        "dcterms:description": "Charades-STA is a benchmark for video grounding, generated based on the Charades dataset, mainly for indoor activities, with moment annotations for training and testing.",
        "dcterms:title": "Charades-STA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Grounding",
            "Activity Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Temporal activity localization",
            "Indoor activities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Marcus Rohrbach",
            "Michaela Regneri",
            "Mykhaylo Andriluka",
            "Sikandar Amin",
            "Manfred Pinkal",
            "Bernt Schiele"
        ],
        "dcterms:description": "TACoS is constructed from the MPII Cooking Composite Activities dataset, providing a set of videos with corresponding queries for activity recognition.",
        "dcterms:title": "TACoS",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Activity Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Cooking activities",
            "Composite activities",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Fabian Caba Heilbron",
            "Victor Escorcia",
            "Bernard Ghanem",
            "Juan Carlos Niebles"
        ],
        "dcterms:description": "ActivityNet Caption involves a large-scale video dataset with queries for human activity understanding, providing annotations for various moments.",
        "dcterms:title": "ActivityNet Caption",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Understanding",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Activity recognition",
            "Moment annotations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Activity Recognition"
        ]
    }
]