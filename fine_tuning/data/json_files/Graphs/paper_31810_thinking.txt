To extract datasets from the research paper titled "Weighted Point Cloud Normal Estimation" by Weijia Wang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by examining the **abstract** and **introduction** sections of the paper. The abstract mentions that the method achieves state-of-the-art performance on both synthetic and real-world datasets, which indicates that there are datasets involved, but I need to identify their names and details.

Next, I will look for a dedicated **datasets section** or any mention of datasets in the **experiments** section. In the experiments section, the authors refer to using datasets for evaluating their method. I will pay close attention to any specific names or descriptions of datasets used in their experiments.

Upon reviewing the paper, I find that the authors mention two types of datasets:

1. **Synthetic Dataset**: The authors refer to a synthetic dataset used for testing their method, which includes 19 shapes from the PCPNet dataset, corrupted with various levels of Gaussian noise. However, they do not provide a specific citation for this dataset in the text.

2. **Real-world Scanned Dataset**: The authors mention using the **Kinect Fusion dataset** for evaluating their method on real-world point clouds. This dataset is known for containing raw point clouds that are often corrupted with noise during scanning.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **PCPNet dataset**, the citation is:
  > P. Guerrero, Y. Kleiman, M. Ovsjanikov, and N. J. Mitra. "PCPNet: Learning Local Shape Properties from Raw Point Clouds." *Computer Graphics Forum*, vol. 37, no. 2, pp. 75–85, 2018.

- For the **Kinect Fusion dataset**, the citation is:
  > S. Izadi, D. Kim, O. Hilliges, D. Molyneaux, R. Newcombe, P. Kohli, J. Shotton, S. Hodges, D. Freeman, A. Davison, and A. Fitzgibbon. "KinectFusion: Real-time 3D Reconstruction and Interaction Using a Moving Depth Camera." In *UIST '11 Proceedings of the 24th annual ACM symposium on User interface software and technology*, ACM, Oct. 2011, pp. 559–568.

With these citations in hand, I will summarize the datasets as follows:

1. **Synthetic Dataset**: This dataset consists of 19 shapes from the PCPNet dataset, used for testing the robustness of the proposed method against Gaussian noise.

2. **Kinect Fusion Dataset**: This dataset contains real-world scanned point clouds, which are often noisy due to the scanning process, and is used to evaluate the performance of the proposed method in practical scenarios.

Finally, I will compile this information into a structured format for further processing or review.