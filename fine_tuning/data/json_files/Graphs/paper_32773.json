[
    {
        "dcterms:creator": [
            "Michael Laskin",
            "Denis Yarats",
            "Hao Liu",
            "Kimin Lee",
            "Albert Zhan",
            "Kevin Lu",
            "Catherine Cang",
            "Lerrel Pinto",
            "Pieter Abbeel"
        ],
        "dcterms:description": "URLB is an unsupervised reinforcement learning benchmark designed to evaluate the performance of various reinforcement learning algorithms in a standardized manner.",
        "dcterms:title": "URLB",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2110.15191",
        "dcat:theme": [
            "Reinforcement Learning",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Unsupervised Learning",
            "Reinforcement Learning",
            "Benchmark",
            "Skill Discovery"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2110.15191",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Skill Discovery",
            "Behavioral Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Yuval Tassa",
            "Yotam Doron",
            "Alistair Muldal",
            "Tom Erez",
            "Yazhe Li",
            "Diego de Las Casas",
            "David Budden",
            "Abbas Abdolmaleki",
            "Josh Merel",
            "Andrew Lefrancq"
        ],
        "dcterms:description": "DMC is a suite of continuous control tasks designed for reinforcement learning research, providing a variety of environments for evaluating algorithms.",
        "dcterms:title": "DMC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1801.00690",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Tasks"
        ],
        "dcat:keyword": [
            "Continuous Control",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1801.00690",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Skill Discovery",
            "Behavioral Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms, providing a variety of environments.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Toolkit"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Benchmark",
            "Toolkit"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1606.01540",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Skill Discovery",
            "Behavioral Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Marc G Bellemare",
            "Yavar Naddaf",
            "Joel Veness",
            "Michael Bowling"
        ],
        "dcterms:description": "The Arcade Learning Environment is a platform for evaluating general agents in a variety of arcade games, providing a rich set of environments for reinforcement learning.",
        "dcterms:title": "Arcade Learning Environment",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Environment"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Game Environment",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Skill Discovery",
            "Behavioral Evaluation"
        ]
    }
]