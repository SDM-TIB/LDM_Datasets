[
    {
        "dcterms:creator": [
            "Y. Huang",
            "T. Z. Shabestary",
            "A. Gruenstein"
        ],
        "dcterms:description": "Multi-talker noise datasets used to evaluate the performance of speech enhancement algorithms in noisy environments.",
        "dcterms:title": "Multi-talker noise datasets",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Noise Cancellation"
        ],
        "dcat:keyword": [
            "Multi-talker",
            "Noise datasets",
            "Speech enhancement"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Huang",
            "T. Z. Shabestary",
            "A. Gruenstein",
            "L. Wan"
        ],
        "dcterms:description": "Multi-talker data sets utilized for robust hotword detection and evaluation of adaptive noise cancellation techniques.",
        "dcterms:title": "Multi-talker data sets",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Noise Cancellation"
        ],
        "dcat:keyword": [
            "Hotword detection",
            "Adaptive noise cancellation",
            "Multi-talker"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Hotword Detection"
        ]
    },
    {
        "dcterms:creator": [
            "J. Barker",
            "R. Marxer",
            "E. Vincent",
            "S. Watanabe"
        ],
        "dcterms:description": "The third CHiME speech separation and recognition challenge dataset, which provides a benchmark for evaluating speech separation and recognition systems in noisy environments.",
        "dcterms:title": "CHiME speech separation and recognition challenge",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "CHiME",
            "Speech separation",
            "Recognition challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Separation",
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Barker",
            "S. Watanabe",
            "E. Vincent",
            "J. Trmal"
        ],
        "dcterms:description": "The fifth CHiME speech separation and recognition challenge dataset, which includes tasks and baselines for evaluating speech separation and recognition systems.",
        "dcterms:title": "CHiME speech separation and recognition challenge (fifth)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "CHiME",
            "Speech separation",
            "Recognition challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Separation",
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "T. N. Sainath",
            "Y. He",
            "B. Li",
            "A. Narayanan",
            "R. Pang",
            "A. Bruguier",
            "S. Chang",
            "W. Li",
            "R. Alvarez",
            "Z. Chen"
        ],
        "dcterms:description": "A dataset comprising anonymized, hand-transcribed English utterances from various domains, used to train a state-of-the-art end-to-end recurrent neural transducer model for speech recognition.",
        "dcterms:title": "VoiceSearch, Farfield, Telephony, and YouTube",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Speech recognition",
            "End-to-end model",
            "Anonymized data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]