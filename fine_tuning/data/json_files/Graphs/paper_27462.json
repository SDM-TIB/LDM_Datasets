[
    {
        "dcterms:creator": [
            "Thomas Sch\"ops",
            "Torsten Sattler",
            "Marc Pollefeys"
        ],
        "dcterms:description": "The ETH3D SLAM Benchmark includes image sequences captured with a camera experiencing severe motion blur due to rapid shaking. It is used to evaluate visual odometry methods under challenging conditions.",
        "dcterms:title": "ETH3D SLAM Benchmark",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Odometry",
            "SLAM"
        ],
        "dcat:keyword": [
            "Motion blur",
            "Camera shake",
            "Visual odometry evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Odometry Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Jurgen Sturm",
            "Nikolas Engelhard",
            "Felix Endres",
            "Wolfram Burgard",
            "Daniel Cremers"
        ],
        "dcterms:description": "The TUM RGB-D dataset contains hand-held SLAM sequences collected with a Kinect sensor, featuring motion blurred images. It is primarily used for evaluating RGB-D SLAM systems.",
        "dcterms:title": "TUM RGB-D",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Odometry",
            "SLAM"
        ],
        "dcat:keyword": [
            "RGB-D",
            "Motion blur",
            "Hand-held SLAM"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Odometry Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Proposed Motion Blur Benchmarking Dataset is a new dataset specifically designed to evaluate visual odometry methods under varying levels of motion blur. It includes sequences with synchronized ground truth trajectories.",
        "dcterms:title": "Proposed Motion Blur Benchmarking Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Odometry",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Motion blur",
            "Visual odometry",
            "Benchmarking dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Odometry Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Peidong Liu",
            "Zhaopeng Cui",
            "Viktor Larsson",
            "Marc Pollefeys"
        ],
        "dcterms:description": "The ArchVizInterior dataset is a synthetic dataset created using the Unreal game engine, featuring camera motions from the ETH3D Benchmark. It provides perfect ground truth sharp images paired with motion blurred images.",
        "dcterms:title": "ArchVizInterior",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Odometry",
            "Synthetic Dataset"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Motion blur",
            "Visual odometry evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Odometry Evaluation"
        ]
    }
]