To extract datasets from the research paper titled "Explicitly Modeling the Discriminability for Instance-Aware Visual Object Tracking" by Mengmeng Wang, Xiaoqian Yang, and Yong Liu, I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to identify any datasets mentioned. The abstract mentions "extensive experimental evaluations on 8 benchmark datasets," which indicates that multiple datasets are involved.

Next, I will focus on the **experiments section** where the authors typically describe the datasets used for evaluation. In this section, they state that they conducted experiments on **8 benchmark datasets**. I will look for a dedicated subsection or mention of these datasets.

Upon reviewing the paper, I find that the authors explicitly list the datasets in **section 4 (Experiments)**. They mention the following datasets:

1. **OTB50**: A dataset containing 50 challenging videos for evaluating visual tracking algorithms.
2. **OTB100**: An extension of OTB50, containing an additional 50 challenging videos.
3. **GOT-10k**: A large dataset with over 10,000 video segments designed for generic object tracking.
4. **LaSOT**: A large-scale dataset with high-quality dense annotations, consisting of 1,400 videos.
5. **Need for Speed (NFS)**: A dataset focused on fast-moving objects, containing challenging videos.
6. **UAV123**: A dataset with 123 sequences captured from low-altitude UAVs.
7. **TrackingNet**: A large-scale dataset consisting of real-world videos sampled from YouTube.
8. **VOT2019**: A dataset consisting of 60 videos that challenge reinitialized trackers.

Next, I will check the **References section** to find the full citations for these datasets. The citations are as follows:

- **OTB50**: Wu, Y., Lim, J., & Yang, M.-H. (2013). Online object tracking: A benchmark. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2411-2418.
  
- **OTB100**: Wu, Y., Lim, J., & Yang, M.-H. (2013). Online object tracking: A benchmark. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2411-2418.
  
- **GOT-10k**: Huang, L., Zhao, X., & Huang, K. (2019). GOT-10k: A large high-diversity benchmark for generic object tracking in the wild. IEEE Transactions on Pattern Analysis and Machine Intelligence.
  
- **LaSOT**: Fan, H., Lin, L., Yang, F., Chu, P., Deng, G., Yu, S., Bai, H., Xu, Y., & Ling, H. (2019). LaSOT: A high-quality benchmark for large-scale single object tracking. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 5374-5383.
  
- **Need for Speed (NFS)**: Kiani Galoogahi, H., Fagg, A., Huang, C., Ramanan, D., & Lucey, S. (2017). Need for speed: A benchmark for higher frame rate object tracking. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 1125-1134.
  
- **UAV123**: Mueller, M., Smith, N., & Ghanem, B. (2016). A benchmark and simulator for UAV tracking. In European Conference on Computer Vision (ECCV), 445-461.
  
- **TrackingNet**: Muller, M., Bibi, A., Giancola, S., Alsubaihi, S., & Ghanem, B. (2018). TrackingNet: A large-scale dataset and benchmark for object tracking in the wild. In Proceedings of the European Conference on Computer Vision (ECCV), 300-317.
  
- **VOT2019**: Kristan, M., Matas, J., Leonardis, A., Felsberg, M., Pflugfelder, R., Kamarainen, J.-K., Zajc, L. C., Drbohlav, O., & Lukezic, A. (2019). The seventh visual object tracking VOT2019 challenge results. In Proceedings of the IEEE International Conference on Computer Vision Workshops, 0-0.

Now that I have identified the datasets and their full citations, I will compile this information into a structured format for further processing or review.