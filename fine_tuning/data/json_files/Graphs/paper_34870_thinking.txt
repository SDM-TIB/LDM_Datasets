To extract datasets from the research paper titled "Resource-Efficient Speech Quality Prediction through Quantization Aware Training and Binary Activation Maps" by Mattias Nilsson et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by reviewing the **abstract and introduction** sections to identify any datasets mentioned. The abstract discusses the use of deep learning methods for speech quality prediction, but it does not specify any datasets. The introduction elaborates on the need for resource-efficient speech enhancement solutions and mentions various metrics but does not name any datasets either.

Next, I will examine the **Methods section**, particularly subsection 3.2 titled "Dataset." Here, the authors state that they trained and evaluated their models on the **DNS2020 dataset**. They describe this dataset as a synthetic dataset consisting of clean speech with added noise at various signal-to-noise ratios (SNRs). They also mention that they computed PESQ labels for segments derived from this dataset.

In this section, the authors provide details about how they generated their dataset, including the number of noisy-clean pairs and the total duration of audio. This information is crucial for understanding the dataset's structure and purpose.

Now, I will look at the **References section** to find the full citation for the DNS2020 dataset. The relevant citation is:

- For **DNS2020 dataset**:
  > C. K. A. Reddy, V. Gopal, R. Cutler, E. Beyrami, R. Cheng, H. Dubey, S. Matusevych, R. Aichner, A. Aazami, S. Braun, P. Rana, S. Srinivasan, and J. Gehrke. *The INTERSPEECH 2020 Deep Noise Suppression Challenge: Datasets, Subjective Testing Framework, and Challenge Results*. In Interspeech 2020, ISCA, Oct. 2020, pp. 2492â€“2496.

Having gathered this information, I will now summarize the dataset details:

1. **DNS2020 Dataset**: A synthetic dataset consisting of clean speech with added noise at various SNRs. It includes 6,000 noisy-clean pairs of 30 seconds each, totaling 50 hours of audio, which is framed into segments for training.

Finally, I will compile the dataset entry into a structured format that includes the dataset name, description, and full citation, ensuring that all necessary details are captured for future reference or processing.