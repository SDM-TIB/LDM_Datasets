To extract datasets from the research paper titled "What Makes Good Contrastive Learning on Small-Scale Wearable-based Tasks?" by Tian Tian et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract provides a brief overview of the research focus, and the introduction often highlights the datasets used for experiments.

In the **introduction**, the authors mention that they conducted empirical evaluations on three benchmark datasets: **UCIHAR**, **UniMiB SHAR (SHAR)**, and **Heterogeneity Dataset for Human Activity Recognition (HHAR)**. This indicates that these datasets are central to their research.

Next, I will look for a dedicated **datasets section** or any mention of datasets in the **experiments section**. In this paper, the datasets are described in the **B.1 Datasets** subsection, where the authors provide details about each dataset:

1. **UCIHAR Dataset**: This dataset records six activities of daily living, collected from 30 participants using smartphones. The data includes readings at a sampling rate of 50 Hz and consists of 9 dimensions.

2. **UniMiB SHAR Dataset**: This dataset is designed to include larger domain discrepancies and contains data from 30 participants performing 17 fine-grained activities, recorded at a sampling rate of 50 Hz.

3. **HHAR Dataset**: This dataset collects data from 9 participants performing six activities in real-world scenarios, using 8 smartphones and 4 smartwatches. The readings are recorded at varying frequencies between 50 to 200 Hz.

Now, I will check the **References section** to find the full citations for these datasets. The citations are as follows:

- For **UCIHAR Dataset**:
  > Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, and Jorge Luis Reyes-Ortiz. *Human Activity Recognition on Smartphones Using a Multiclass Hardware-Friendly Support Vector Machine*. In IWAAL. Springer, 216–223, 2012.

- For **UniMiB SHAR Dataset**:
  > Daniela Micucci, Marco Mobilio, and Paolo Napoletano. *UniMiB SHAR: a new dataset for human activity recognition using acceleration data from smartphones*. CoRR abs/1611.07688, 2016.

- For **HHAR Dataset**:
  > Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow, Mikkel Baun Kjærgaard, Anind K. Dey, Tobias Sonne, and Mads Møller Jensen. *Smart Devices are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity Recognition*. In SenSys. ACM, 127–140, 2015.

After gathering all this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will provide a comprehensive overview of the datasets used in the research paper, ready for further processing or review.