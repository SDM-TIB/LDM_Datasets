To extract datasets from the research paper titled "Adaptive Object Graphs for Better Instantaneous Mapping" by Avishkar Saha et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors set a new state-of-the-art in BEV estimation across three large-scale datasets, which indicates that datasets are likely discussed in detail later in the paper.

Next, I will focus on the **experiments section** (section 4), where the authors typically describe the datasets used for evaluation. In this section, they explicitly mention three datasets: **nuScenes**, **Argoverse**, and **Lyft**. I will take note of the details provided for each dataset, including their characteristics and any specific metrics or annotations mentioned.

1. **nuScenes**: The authors describe nuScenes as consisting of 1000 clips, each 20 seconds long, captured across different cities. Each scene is annotated with 3D bounding boxes for 10 object classes, along with vector maps for the road, sidewalk, and more.

2. **Argoverse**: This dataset is mentioned as containing rich maps for 3D tracking and forecasting, which is relevant for the authors' experiments.

3. **Lyft**: The Lyft dataset is referenced as another source of data for their experiments, although specific details may be less emphasized compared to nuScenes and Argoverse.

After identifying the datasets, I will check the **References section** to find the full citations for each dataset. This is crucial for proper attribution and to provide readers with the necessary information to locate the datasets.

- For **nuScenes**, the citation is:
  > Holger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. *nuscenes: A multi-modal dataset for autonomous driving*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 11621–11631, 2020.

- For **Argoverse**, the citation is:
  > Ming-Fang Chang, John Lambert, Patsorn Sangkloy, Jagjeet Singh, Slawomir Bak, Andrew Hartnett, De Wang, Peter Carr, Simon Lucey, Deva Ramanan, et al. *Argoverse: 3D tracking and forecasting with rich maps*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 8748–8757, 2019.

- For **Lyft**, the citation is:
  > R Kesten, M Usman, J Houston, T Pandya, K Nadhamuni, A Ferreira, M Yuan, B Low, A Jain, P Ondruska, et al. *Lyft level 5 av dataset 2019*. URL: https://level5.lyft.com/dataset.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their proper citations.