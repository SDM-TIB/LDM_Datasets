[
    {
        "dcterms:creator": [
            "Shuang Li",
            "Tong Xiao",
            "Hongsheng Li",
            "Bolei Zhou",
            "Dayu Yue",
            "Xiaogang Wang"
        ],
        "dcterms:description": "The CUHK-PEDES dataset is the only benchmark for text-based person search (TBPS), containing 40,206 images of 13,003 different people, with each image annotated with two descriptive sentences.",
        "dcterms:title": "CUHK-PEDES",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Text-Based Person Search"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Person search",
            "Text descriptions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Person Search"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "MSCOCO is a large-scale dataset containing images with corresponding captions, widely used for various vision and language tasks.",
        "dcterms:title": "MSCOCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image-Text Retrieval"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Captions",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Bryan A Plummer",
            "Liwei Wang",
            "Chris M Cervantes",
            "Juan C Caicedo",
            "Julia Hockenmaier",
            "Svetlana Lazebnik"
        ],
        "dcterms:description": "Flickr30k is a dataset that collects region-to-phrase correspondences for richer image-to-sentence models, containing images with multiple descriptive phrases.",
        "dcterms:title": "Flickr30k",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image-Text Retrieval"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Region-to-phrase correspondences",
            "Image captions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark"
        ],
        "dcterms:description": "WIT is a dataset designed for learning transferable visual models from natural language supervision, containing a large number of image-text pairs.",
        "dcterms:title": "WIT",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image-Text Retrieval"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Natural language supervision",
            "Image-text pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image-Text Retrieval"
        ]
    }
]