[
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A collection of over 100 million tokens extracted from the set of verified Good and Featured articles on Wikipedia.",
        "dcterms:title": "WikiText-103",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Wikipedia",
            "Language modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Chen et al."
        ],
        "dcterms:description": "A benchmark for evaluating large language models trained on code, consisting of 164 programming problems and their respective unit tests.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2107.03374",
        "dcat:theme": [
            "Code Generation",
            "Programming Language Evaluation"
        ],
        "dcat:keyword": [
            "Code dataset",
            "Programming problems",
            "Unit tests"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Completion",
            "Code Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Ruchir Puri",
            "David Kung",
            "Geert Janssen",
            "Wei Zhang",
            "Giacomo Domeniconi",
            "Vladimir Zolotov",
            "Julian T Dolby",
            "Jie Chen",
            "Mihir Choudhury",
            "Lindsey Decker",
            "Veronika Thost",
            "Luca Buratti",
            "Saurabh Pujar",
            "Shyam Ramji",
            "Ulrich Finkler",
            "Susan Malaika",
            "Frederick Reiss"
        ],
        "dcterms:description": "A large-scale AI for code dataset for learning a diversity of coding tasks.",
        "dcterms:title": "CodeNet",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Understanding",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Code dataset",
            "Diversity of coding tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Learning",
            "Code Representation"
        ]
    },
    {
        "dcterms:creator": [
            "Eneko Agirre",
            "Carmen Banea",
            "Daniel Cer",
            "Mona Diab",
            "Aitor Gonzalez-Agirre",
            "Rada Mihalcea",
            "German Rigau",
            "Janyce Wiebe"
        ],
        "dcterms:description": "A dataset for evaluating semantic textual similarity, consisting of pairs of sentences with similarity scores.",
        "dcterms:title": "STS (Semantic Textual Similarity)",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Textual similarity",
            "Semantic evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Marco Marelli",
            "Stefano Menini",
            "Marco Baroni",
            "Luisa Bentivogli",
            "Raffaella Bernardi",
            "Roberto Zamparini"
        ],
        "dcterms:description": "A dataset for evaluating compositional distributional semantic models, consisting of sentence pairs with similarity scores.",
        "dcterms:title": "SICK (Sentences Involving Compositional Knowledge)",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Semantic Evaluation"
        ],
        "dcat:keyword": [
            "Compositional knowledge",
            "Sentence similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Daya Guo",
            "Shuai Lu",
            "Nan Duan",
            "Yanlin Wang",
            "Ming Zhou",
            "Jian Yin"
        ],
        "dcterms:description": "A dataset for code representation, focusing on cross-modal pre-training for code tasks.",
        "dcterms:title": "CodeSearch Dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Representation",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Code dataset",
            "Cross-modal learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Search",
            "Code Representation Learning"
        ]
    }
]