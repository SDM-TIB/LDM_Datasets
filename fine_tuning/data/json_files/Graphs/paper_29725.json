[
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. Zufﬁ",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "The sub-JHMDB dataset is designed for action recognition and contains video clips with annotated actions, providing a benchmark for evaluating action recognition algorithms.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Annotated actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Dua, D.",
            "Graff, C."
        ],
        "dcterms:description": "The EEG eye dataset contains EEG recordings used to predict whether the eyes of the subject are open or closed, serving as a benchmark for classification tasks.",
        "dcterms:title": "EEG eye dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://archive.ics.uci.edu/ml",
        "dcat:theme": [
            "Biomedical Data",
            "Classification"
        ],
        "dcat:keyword": [
            "EEG data",
            "Classification",
            "Open/Closed eyes"
        ],
        "dcat:landingPage": "http://archive.ics.uci.edu/ml",
        "dcterms:hasVersion": "",
        "dcterms:format": "Time Series",
        "mls:task": [
            "Classification"
        ]
    },
    {
        "dcterms:creator": [
            "A. Hyvarinen",
            "H. Morioka"
        ],
        "dcterms:description": "Synthetic Data for Time Contrastive Learning (TCL) is generated to evaluate the performance of contrastive learning methods in identifying latent components over time.",
        "dcterms:title": "Synthetic Data for Time Contrastive Learning (TCL)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data",
            "Contrastive Learning"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Time contrastive learning",
            "Latent component identification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Synthetic",
        "mls:task": [
            "Latent Component Identification"
        ]
    },
    {
        "dcterms:creator": [
            "L. Gresele",
            "P. K. Rubenstein",
            "A. Mehrjou",
            "F. Locatello",
            "B. Schölkopf"
        ],
        "dcterms:description": "Synthetic Data for Multiview Contrastive Learning (MVCL) is created to study the identifiability of latent components from multiple views of data.",
        "dcterms:title": "Synthetic Data for Multiview Contrastive Learning (MVCL)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data",
            "Contrastive Learning"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Multiview learning",
            "Latent component identification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Synthetic",
        "mls:task": [
            "Latent Component Identification"
        ]
    }
]