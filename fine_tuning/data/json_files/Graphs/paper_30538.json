[
    {
        "dcterms:creator": [
            "T. Menne",
            "J. Heymann",
            "A. Alexandridis",
            "K. Irie",
            "A. Zeyer",
            "M. Kitza",
            "P. Golik",
            "I. Kulikov",
            "L. Drude",
            "R. Schl√ºter"
        ],
        "dcterms:description": "The CHiME-4 dataset contains real and artificially simulated noisy speech data collected by asking volunteers to read text from the Wall Street Journal (WSJ0) corpus using a six-channel distant microphone array and a close-by microphone.",
        "dcterms:title": "CHiME-4",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Noise Robustness"
        ],
        "dcat:keyword": [
            "Automatic Speech Recognition",
            "Noisy Speech Data",
            "Microphone Array"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "D. Snyder",
            "G. Chen",
            "D. Povey"
        ],
        "dcterms:description": "The MUSAN dataset contains 109 hours of data in total, including 60 hours of English speech data, 42 hours of music data, and 6 hours of noise data, used for constructing noise data in the pre-training stage.",
        "dcterms:title": "MUSAN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1510.08484",
        "dcat:theme": [
            "Speech Recognition",
            "Noise Data"
        ],
        "dcat:keyword": [
            "Music",
            "Speech",
            "Noise",
            "Audio Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": []
    }
]