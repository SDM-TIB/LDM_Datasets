To extract datasets from the research paper titled "TetraSphere: A Neural Descriptor for O(3)-Invariant Point Cloud Analysis" by Pavlo Melnyk et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that TetraSphere sets a new state-of-the-art performance classifying randomly rotated real-world object scans of the challenging subsets of ScanObjectNN. This indicates that datasets are involved, and I should look for their names and details.

Next, I will focus on **section 5 (Experiments)**, where the authors discuss the datasets used for evaluation. They mention using:

1. **ScanObjectNN**: This dataset consists of 2902 unique object instances belonging to 15 classes. The authors specifically refer to two subsets: the easiest (OBJ_BG) and the most challenging (PB_T50_RS), which contains approximately 15,000 point clouds with various perturbations.

2. **ModelNet40**: This dataset includes 12,311 CAD models randomly sampled as point clouds comprised of 1024 points.

3. **ShapeNet-part**: This dataset consists of 16,881 point clouds of 16 categories partitioned with 50 part labels in total.

The authors provide details about how they preprocess these datasets, which is important for understanding their application in the experiments.

Now, I will check the **References section** to find the full citations for these datasets:

- For **ScanObjectNN**, the citation is:
  > Mikaela Angelina Uy, Quang-Hieu Pham, Binh-Son Hua, Duc Thanh Nguyen, and Sai-Kit Yeung. *Revisiting point cloud classification: A new benchmark dataset and classification model on real-world data*. In International Conference on Computer Vision (ICCV), 2019.

- For **ModelNet40**, the citation is:
  > Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. *3D ShapeNets: A deep representation for volumetric shapes*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1912â€“1920, 2015.

- For **ShapeNet-part**, the citation is:
  > Angel X Chang, Thomas Funkhouser, Leonidas Guibas, Pat Hanrahan, Qixing Huang, Zimo Li, Silvio Savarese, Manolis Savva, Shuran Song, Hao Su, et al. *ShapeNet: An information-rich 3D model repository*. arXiv preprint arXiv:1512.03012, 2015.

After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will provide a comprehensive overview of the datasets used in the research paper, ready for further processing or review.