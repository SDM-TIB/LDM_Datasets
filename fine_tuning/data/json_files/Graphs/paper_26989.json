[
    {
        "dcterms:creator": [
            "Amir Shahroudy",
            "Jun Liu",
            "Tian-Tsong Ng",
            "Gang Wang"
        ],
        "dcterms:description": "The NTU RGB+D dataset is the largest indoor-captured action recognition dataset, widely used for evaluating skeleton-based human action recognition methods. It consists of 56,880 action video clips from 60 different human action classes, captured by 3 cameras from 3 different views. Each action clip is represented as a sequence of 300 skeletons, each with 3D coordinates of 25 body joints.",
        "dcterms:title": "NTU-RGB+D",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Action Recognition"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "Action recognition",
            "3D human activity",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Action Recognition"
        ]
    }
]