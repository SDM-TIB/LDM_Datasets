[
    {
        "dcterms:creator": [
            "Jiyang Gao",
            "Chen Sun",
            "Zhenheng Yang",
            "Ram Nevatia"
        ],
        "dcterms:description": "Charades-STA is a benchmark dataset for video moment retrieval, adapted from the Charades dataset, containing 6670 videos and 16124 queries, with an average video duration of 30.59 seconds and 2.41 annotated moments per video.",
        "dcterms:title": "Charades-STA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Moment Retrieval",
            "Activity Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Temporal activity localization",
            "Natural language queries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Moment Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Fabian Caba Heilbron",
            "Victor Escorcia",
            "Bernard Ghanem",
            "Juan Carlos Niebles"
        ],
        "dcterms:description": "ActivityNet-Captions is collected for the dense video captioning task, consisting of 19811 videos with 71957 queries, where each video has an average duration of around 117.75 seconds and contains 3.63 annotated moments.",
        "dcterms:title": "ActivityNet-Captions",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Captioning",
            "Activity Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Dense video captioning",
            "Natural language queries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Moment Retrieval"
        ]
    }
]