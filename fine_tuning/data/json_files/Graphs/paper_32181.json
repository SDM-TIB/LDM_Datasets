[
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Tao Xu",
            "Greg Brockman",
            "Christine McLeavey",
            "Ilya Sutskever"
        ],
        "dcterms:description": "OpenAI's Whisper ASR model is utilized to generate unique outputs at different compression levels, which serve as ASR hypotheses for training and validation of the referenceless quality metric.",
        "dcterms:title": "OpenAIâ€™s Whisper ASR model",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2212.04356",
        "dcat:theme": [
            "Speech Recognition",
            "Automatic Speech Recognition"
        ],
        "dcat:keyword": [
            "ASR",
            "Speech Quality",
            "Contrastive Learning"
        ],
        "dcat:landingPage": "https://github.com/aixplain/NoRefER",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "AmirAli Bagher Zadeh",
            "Paul Pu Liang",
            "Soujanya Poria",
            "Erik Cambria",
            "Louis-Philippe Morency"
        ],
        "dcterms:description": "CMU MOSEI dataset contains a total of 134 hours of speech from Youtube videos of 2,645 speakers, used for training the referenceless quality metric.",
        "dcterms:title": "CMU MOSEI",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Analysis",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Speech Dataset",
            "Multimodal",
            "Emotion Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Amir Zadeh",
            "Yan Sheng Cao",
            "Simon Hessner",
            "Paul Pu Liang",
            "Soujanya Poria",
            "Louis-Philippe Morency"
        ],
        "dcterms:description": "MOSEAS is a multimodal language dataset for Spanish, Portuguese, German, and French, used in conjunction with CMU MOSEI for training the referenceless quality metric.",
        "dcterms:title": "MOSEAS",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Analysis",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Multimodal Dataset",
            "Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Rosana Ardila",
            "Megan Branson",
            "Kelly Davis",
            "Michael Henretty",
            "Michael Kohler",
            "Josh Meyer",
            "Reuben Morais",
            "Lindsay Saunders",
            "Francis M Tyers",
            "Gregor Weber"
        ],
        "dcterms:description": "Common Voice is a massively-multilingual speech corpus used for testing the referenceless metric on various languages.",
        "dcterms:title": "Common Voice",
        "dcterms:issued": "2019",
        "dcterms:language": "Multilingual",
        "dcterms:identifier": "arXiv:1912.06670",
        "dcat:theme": [
            "Speech Recognition",
            "Multilingual Corpus"
        ],
        "dcat:keyword": [
            "Speech Dataset",
            "Multilingual",
            "Voice Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Vassil Panayotov",
            "Guoguo Chen",
            "Daniel Povey",
            "Sanjeev Khudanpur"
        ],
        "dcterms:description": "Libri-Speech is an ASR corpus based on public domain audio books, used for testing the referenceless metric on English language.",
        "dcterms:title": "Libri-Speech",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "ASR Corpus"
        ],
        "dcat:keyword": [
            "Speech Dataset",
            "Public Domain",
            "Audio Books"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Quality Estimation"
        ]
    }
]