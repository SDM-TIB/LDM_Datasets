To extract datasets from the research paper titled "Mix Dimension in Poincaré Geometry for 3D Skeleton-based Action Recognition" by Wei Peng et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that the authors evaluate their method on "two current largest scale 3D datasets," which indicates that datasets are indeed present.

Next, I will focus on the **experiments section**, where the authors explicitly mention the datasets used for evaluation. In this section, they refer to two datasets:

1. **NTU RGB+D**: The authors describe this dataset as one of the most widely used for action recognition, containing 56,880 video clips across 60 human action classes. They specify that the dataset includes various modalities, but their experiments focus solely on the skeleton data.

2. **NTU RGB+D 120**: This dataset is mentioned as an extended version of the NTU RGB+D dataset, featuring 114,480 samples covering 120 action classes. The authors note that it is more challenging due to a wider range of subjects and action categories.

To ensure I have the correct citations, I will refer to the **References section** of the paper to find the full citations for these datasets:

- For **NTU RGB+D**, the citation is:
  > Shahroudy, A., Liu, J., Ng, T.-T., & Wang, G. (2016). NTU RGB+D: A large scale dataset for 3D human activity analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1010–1019.

- For **NTU RGB+D 120**, the citation is:
  > Liu, J., Shahroudy, A., Wang, G., Duan, L.-Y., & Chichung, A. K. (2019). NTU RGB+D 120: A large-scale benchmark for 3D human activity understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the research and their corresponding references.