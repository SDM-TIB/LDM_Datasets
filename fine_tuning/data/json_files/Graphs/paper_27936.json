[
    {
        "dcterms:creator": [
            "Q. De Smedt",
            "H. Wannous",
            "J.-P. Vandeborre",
            "J. Guerry",
            "B. Le Saux",
            "D. Filliat"
        ],
        "dcterms:description": "The SHREC’17 Track dataset is a challenging hand gesture dataset which provides both depth images and skeleton data. It contains 14 gestures performed by 28 individuals, captured using an Intel RealSense short range depth camera.",
        "dcterms:title": "SHREC’17 Track",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Hand gestures",
            "Depth images",
            "Skeleton data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Depth and Skeleton Data",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Q. De Smedt",
            "H. Wannous",
            "J.-P. Vandeborre"
        ],
        "dcterms:description": "The DHG-14/28 dataset contains 2800 sequences of 22 hand joints, performed by 20 individuals. Each gesture is performed exactly 5 times, using a leave-one-subject-out experimental protocol.",
        "dcterms:title": "DHG-14/28",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Dynamic hand gestures",
            "Skeleton data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Skeleton Data",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "G. Garcia-Hernando",
            "S. Yuan",
            "S. Baek",
            "T.-K. Kim"
        ],
        "dcterms:description": "The FPHA dataset is collected from a first-person perspective, providing 1175 action videos categorized into 45 different daily hand actions involving 26 objects, with 3D hand pose annotations.",
        "dcterms:title": "FPHA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "First-person perspective",
            "Hand actions",
            "RGB-D videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "RGB-D Video and Skeleton Data",
        "mls:task": [
            "Action Recognition"
        ]
    }
]