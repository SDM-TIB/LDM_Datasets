[
    {
        "dcterms:creator": [
            "Carlos Busso",
            "Murtaza Bulut",
            "Chi-Chun Lee",
            "Abe Kazemzadeh",
            "Emily Mower",
            "Samuel Kim",
            "Jeannette N. Chang",
            "Sungbok Lee",
            "Shrikanth S. Narayanan"
        ],
        "dcterms:description": "IEMOCAP is a conversational dataset where each utterance was labeled with one of the six emotion categories (Anger, Excited, Sadness, Happiness, Frustrated, and Neutral).",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Analysis"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Conversational dataset",
            "Multimodal emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video, Text",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Soujanya Poria",
            "Devamanyu Hazarika",
            "Navonil Majumder",
            "Gautam Naik",
            "Erik Cambria",
            "Rada Mihalcea"
        ],
        "dcterms:description": "MELD is a multimodal multi-party dataset for emotion recognition in conversations, containing various emotional labels.",
        "dcterms:title": "MELD",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Analysis"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Multimodal dataset",
            "Conversation analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Text",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Amir Zadeh",
            "Paul Pu Liang",
            "Soujanya Poria",
            "Erik Cambria",
            "Louis-Philippe Morency"
        ],
        "dcterms:description": "MOSEI is a dataset for multimodal language analysis, containing annotated emotional labels for various video clips.",
        "dcterms:title": "MOSEI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Analysis"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Multimodal dataset",
            "Language analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio, Video, Text",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]