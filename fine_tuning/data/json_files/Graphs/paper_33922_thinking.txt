To extract datasets from the research paper titled "LoDisc: Learning Global-Local Discriminative Features for Self-Supervised Fine-Grained Visual Recognition" by Jialu Shi et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the research, and the introduction often outlines the context and significance of the datasets used.

In the **introduction**, the authors discuss the challenges of fine-grained visual recognition and mention the need for effective datasets. However, I need to look for specific dataset names.

Next, I will focus on the **experiments section**, particularly **section 4.1 (Experiments Setup)**, where the authors describe the datasets used for their evaluations. Here, they explicitly mention four datasets:

1. **FGVC-Aircraft**: This dataset consists of 10,200 images across 100 categories of aircraft, with a training split of 6,667 images and a testing split of 3,333 images.

2. **Stanford Cars**: This dataset includes 16,185 images from 196 categories of cars, with 8,144 training images and 8,041 testing images.

3. **CUB-200-2011**: This dataset contains 11,788 images from 200 categories of birds, with a training split of 5,994 images and a testing split of 5,794 images.

4. **Caltech-101**: This dataset comprises 9,145 images from 101 object categories, including a background category, with a training split of 6,822 images and a testing split of 2,323 images.

To ensure I have the correct citations for these datasets, I will refer to the **References section** of the paper. The citations for the datasets are as follows:

- For **FGVC-Aircraft**:
  > Subhransu Maji, Esa Rahtu, Juho Kannala, Matthew Blaschko, and Andrea Vedaldi. *Fine-grained visual classification of aircraft*. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops, pages 554–561, 2013.

- For **Stanford Cars**:
  > Jonathan Krause, Michael Stark, Jia Deng, and Li Fei-Fei. *3D object representations for fine-grained categorization*. In Proceedings of the IEEE International Conference on Computer Vision (ICCV) Workshops, pages 554–561, 2013.

- For **CUB-200-2011**:
  > Catherine Wah, Steve Branson, Peter Welinder, Pietro Perona, and Serge Belongie. *The Caltech-UCSD Birds-200-2011 dataset*. Technical report, California Institute of Technology, 2011.

- For **Caltech-101**:
  > Li Fei-Fei, Rob Fergus, and Pietro Perona. *Learning generative visual models from few training examples: An incremental bayesian approach tested on 101 object categories*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, pages 178–178, 2004.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.