[
    {
        "dcterms:creator": [
            "E. Vincent",
            "S. Watanabe",
            "A. A. Nugraha",
            "J. Barker",
            "R. Marxer"
        ],
        "dcterms:description": "The CHiME-4 corpus focuses on the commercially-motivated scenario in the real-world application: a person talking to a mobile tablet device in real, noisy public environments, including streets, pedestrian areas, cafeterias, and buses. The training data consists of 6-microphone recordings from the WSJ0 corpus spoken live in the environments or simulated by mixing with noise backgrounds.",
        "dcterms:title": "CHiME-4",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Robust ASR"
        ],
        "dcat:keyword": [
            "Noisy environments",
            "Speech recognition",
            "Microphone array"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S. Renals",
            "T. Hain",
            "H. Bourlard"
        ],
        "dcterms:description": "The AMI corpus contains approximately 78 hours of meeting recordings with three to five participants. The recording contains audio from independent headset microphones worn by each participant and multiple distant microphones.",
        "dcterms:title": "AMI",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Meeting Analysis"
        ],
        "dcat:keyword": [
            "Meeting recordings",
            "Multi-party conversations",
            "Speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "V. Panayotov",
            "G. Chen",
            "D. Povey",
            "S. Khudanpur"
        ],
        "dcterms:description": "Librispeech is one of the most popular ASR corpora for SSL. It contains 1000 hours of close distance reading speech.",
        "dcterms:title": "Librispeech",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Self-supervised Learning"
        ],
        "dcat:keyword": [
            "Audio books",
            "Speech recognition",
            "ASR corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "T. Ko",
            "V. Peddinti",
            "D. Povey",
            "M. L. Seltzer",
            "S. Khudanpur"
        ],
        "dcterms:description": "The dataset contains simulated RIRs and noises used to generate the simulated noisy and distant-talking speech.",
        "dcterms:title": "RIRs and Noises",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Augmentation",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Reverberation",
            "Noise recordings",
            "Data augmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    }
]