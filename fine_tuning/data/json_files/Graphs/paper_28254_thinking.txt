To extract datasets from the research paper titled "Supervised Contrastive Learning for Detecting Anomalous Driving Behaviours from Multimodal Videos" by Shehroz S. Khan et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract mentions a "driver anomaly detection dataset" that contains 783 minutes of video recordings, which indicates that a dataset is indeed present.

Next, I will focus on the **introduction** and **section III (Video-Based Driver Anomaly Detection Datasets)**, where the authors discuss various datasets related to driving behaviors. In section III, they specifically introduce the **Driver Anomaly Detection (DAD) dataset**, which is described in detail. The DAD dataset is collected from a driver simulator and includes video data from 31 drivers, with a training set of 650 minutes and a test set of 133 minutes.

The paper also references other datasets related to driving behaviors, such as:

1. **CVRR-HANDS 3D**: A hand-focused dataset correlated with driver ability.
2. **DriverMHG**: A multi-modal dataset for recognizing driver micro hand gestures.
3. **DrivFace**: A dataset providing information on drivers' faces and head pose annotations.
4. **DriveAHead**: A dataset for driver head pose estimation.
5. **DD-Pose**: A dataset for driver head pose benchmark.
6. **Drive&Act**: A dataset for distraction-related anomalous driving data.
7. **DMD**: A large-scale multi-modal driver monitoring dataset.
8. **Pandora**: Another driver monitoring dataset.

In the **References section**, I will look for full citations for the datasets mentioned, especially focusing on the DAD dataset since it is the primary dataset used in the experiments.

The citation for the **Driver Anomaly Detection (DAD) dataset** is:
> O. Köpüklü, J. Zheng, H. Xu, and G. Rigoll. *Driver Anomaly Detection: A Dataset and Contrastive Learning Approach*. In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision, 2021, pp. 91–100.

For the other datasets, I will also extract their citations from the references:

- **CVRR-HANDS 3D**:
> E. Ohn-Bar, S. Martin, and M. Trivedi. *Driver Hand Activity Analysis in Naturalistic Driving Studies: Challenges, Algorithms, and Experimental Studies*. Journal of Electronic Imaging, vol. 22, no. 4, p. 041119, 2013.

- **DriverMHG**:
> O. Köpüklü, T. Ledwon, Y. Rong, N. Kose, and G. Rigoll. *DriverMHG: A Multi-Modal Dataset for Dynamic Recognition of Driver Micro Hand Gestures and a Real-Time Recognition Framework*. In 2020 15th IEEE International Conference on Automatic Face and Gesture Recognition (FG 2020), pp. 77–84.

- **DrivFace**:
> K. Diaz-Chito, A. Hernández-Sabaté, and A. M. López. *A Reduced Feature Set for Driver Head Pose Estimation*. Applied Soft Computing, vol. 45, pp. 98–107, 2016.

- **DriveAHead**:
> A. Schwarz, M. Haurilet, M. Martinez, and R. Stiefelhagen. *DriveAhead-A Large-Scale Driver Head Pose Dataset*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, 2017, pp. 1–10.

- **DD-Pose**:
> M. Roth and D. M. Gavrila. *DD-Pose-A Large-Scale Driver Head Pose Benchmark*. In 2019 IEEE Intelligent Vehicles Symposium (IV), pp. 927–934.

- **Drive&Act**:
> M. Martin, A. Roitberg, M. Haurilet, M. Horne, S. Reiß, M. Voit, and R. Stiefelhagen. *Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles*. In Proceedings of the IEEE/CVF International Conference on Computer Vision, 2019, pp. 2801–2810.

- **DMD**:
> J. D. Ortega, N. Kose, P. Ca˜nas, M.-A. Chao, A. Unnervik, M. Nieto, O. Otaegui, and L. Salgado. *DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention and Alertness Analysis*. Lecture Notes in Computer Science, pp. 387–405, 2020.

- **Pandora**:
> G. Borghi, M. Venturelli, R. Vezzani, and R. Cucchiara. *Poseidon: Face-from-Depth for Driver Pose Estimation*. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5494–5503.

Now, I will compile the dataset entries, ensuring to include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets referenced in the paper.