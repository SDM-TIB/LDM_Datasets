To extract datasets from the research paper titled "Time-Equivariant Contrastive Video Representation Learning" by Simon Jenni and Hailin Jin, I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. In the abstract, the authors refer to achieving state-of-the-art results on benchmarks including **UCF101, HMDB51, and Diving48**. This indicates that these datasets are likely to be discussed in detail later in the paper.

Next, I will look specifically at **section 4 (Experiments)**, where the authors describe the datasets used for their experiments. Here, they explicitly mention:

1. **Kinetics-400**: This dataset contains around 240,000 training videos and is used for unsupervised pre-training. It is a large-scale dataset for action recognition.
   
2. **UCF101**: This dataset consists of 101 human action classes from videos in the wild and is used for evaluating the learned representation in transfer to action recognition.

3. **HMDB51**: This dataset includes 51 action categories and is also used for evaluating the learned representation.

4. **Diving48**: This dataset focuses on diving actions, where different classes are defined primarily by long-range motion patterns rather than static frame appearance.

In the **References section**, I will find the full citations for these datasets:

- For **Kinetics-400**, the citation is:
  > Andrew Zisserman, Joao Carreira, Karen Simonyan, Will Kay, Brian Zhang, Chloe Hillier, Sudheendra Vijayanarasimhan, Fabio Viola, Tim Green, Trevor Back, et al. *The kinetics human action video dataset*. ArXiv, 2017.

- For **UCF101**, the citation is:
  > Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. *UCF101: A dataset of 101 human actions classes from videos in the wild*. arXiv preprint arXiv:1212.0402, 2012.

- For **HMDB51**, the citation is:
  > H. Kuehne, H. Jhuang, E. Garrote, T. Poggio, and T. Serre. *HMDB: a large video database for human motion recognition*. In Proceedings of the International Conference on Computer Vision (ICCV), 2011.

- For **Diving48**, the citation is:
  > Yingwei Li, Yi Li, and Nuno Vasconcelos. *Resound: Towards action recognition without representation bias*. In Proceedings of the European Conference on Computer Vision (ECCV), pages 513â€“528, 2018.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further use. This ensures that I have accurately captured the datasets and their relevant details as presented in the paper.