[
    {
        "dcterms:creator": [
            "M. Tenorth",
            "J. Bandouch",
            "M. Beetz"
        ],
        "dcterms:description": "The TUM Kitchen dataset consists of nineteen videos of a sequence of kitchen activities recorded by four different monocular cameras. The activities include walking, picking up, and placing utensils to and from cabinets, drawers, and tables, with two-tier labels indicating motion verbs and locations or object manipulation modes.",
        "dcterms:title": "TUM Kitchen Dataset",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Kitchen activities",
            "Object manipulation",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Postural Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "B. Parsa",
            "E. U. Samani",
            "R. Hendrix",
            "C. Devine",
            "S. M. Singh",
            "S. Devasia",
            "A. G. Banerjee"
        ],
        "dcterms:description": "The UW-IOM dataset captures activities common in warehouses, consisting of videos that include object manipulation tasks such as picking up, placing, and carrying objects. It features a four-tier hierarchy of labels indicating object type, human motion, manipulation type, and relative height.",
        "dcterms:title": "UW-IOM Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Warehouse activities",
            "Object manipulation",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Postural Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "J. Carreira",
            "A. Zisserman"
        ],
        "dcterms:description": "The Kinetics dataset is a large-scale dataset for action recognition, containing video clips of various human actions. It serves as a benchmark for evaluating action recognition algorithms.",
        "dcterms:title": "Kinetics Dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Action recognition",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Kuehne",
            "H. Jhuang",
            "E. Garrote",
            "T. Poggio",
            "T. Serre"
        ],
        "dcterms:description": "The NTU-RGBD dataset is a large video database for human motion recognition, containing various actions performed by subjects in different settings. It is widely used for benchmarking action recognition algorithms.",
        "dcterms:title": "NTU-RGBD Dataset",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human motion recognition",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]