To extract datasets from the research paper titled "Detecting and Grounding Multi-Modal Media Manipulation" by Rui Shao et al., I will follow a systematic approach to identify and document the datasets mentioned in the text.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned. The abstract indicates that the authors constructed a new dataset for their research, which is a good starting point.

Next, I will focus on **section 3 (Multi-Modal Media Manipulation Dataset)**, where the authors describe the dataset in detail. Here, they introduce the **DGM4 dataset**, which is the primary dataset used in their study. The authors explain that this dataset consists of manipulated image-text pairs with rich annotations for various manipulation types.

In this section, the authors provide specific details about the dataset, including:
- The dataset is constructed from the **VisualNews dataset**, which collects image-text pairs from real-world news sources.
- The DGM4 dataset includes samples generated by two image manipulation approaches (Face Swap and Face Attribute) and two text manipulation approaches (Text Swap and Text Attribute).
- The dataset contains a total of **230,000 news samples**, including **77,426 pristine image-text pairs** and **152,574 manipulated pairs**.

Now, I will look for the **full citation** of the original dataset used to create the DGM4 dataset. The authors mention that they used the VisualNews dataset, so I will need to find its citation in the references section.

Upon reviewing the references, I find the citation for the VisualNews dataset:
- For the **VisualNews dataset**, the citation is:
  > Liu, F., Wang, Y., Wang, T., & Ordonez, V. (2021). *Visual news: Benchmark and challenges in news image captioning*. In Proceedings of the EMNLP, 2021.

Now that I have identified the DGM4 dataset and its source, I will compile the information into a structured format. 

The final entries for the datasets are:
1. **DGM4 Dataset**: A large-scale dataset for detecting and grounding multi-modal media manipulation, consisting of manipulated image-text pairs with rich annotations.
2. **VisualNews Dataset**: The original dataset from which the DGM4 dataset was derived, containing image-text pairs from real-world news sources.

I will ensure to include the full citations for both datasets in the final output.