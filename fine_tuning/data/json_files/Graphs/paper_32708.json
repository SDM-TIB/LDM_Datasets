[
    {
        "dcterms:creator": [
            "A. B. Abacha",
            "S. A. Hasan",
            "V. V. Datla",
            "J. Liu",
            "D. Demner-Fushman",
            "H. Müller"
        ],
        "dcterms:description": "The VQA-Med 2019 challenge dataset is the largest dataset currently available for the Med-VQA task, consisting of 4,200 images from the MedPix database, with 15,992 corresponding question and answer pairs. It features diversity in terms of question categories and image modalities.",
        "dcterms:title": "VQA-Med 2019",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Visual Question Answering"
        ],
        "dcat:keyword": [
            "Medical images",
            "Visual Question Answering",
            "Dataset",
            "ImageCLEF"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "O. Pelka",
            "S. Koitka",
            "J. Rückert",
            "F. Nensa",
            "C. M. Friedrich"
        ],
        "dcterms:description": "The Radiology Objects in Context (ROCO) dataset consists of over 81,000 radiology images in a wide variety of imaging modalities, making it suitable for self-supervised pretraining in the Med-VQA task.",
        "dcterms:title": "Radiology Objects in Context (ROCO)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Imaging",
            "Dataset"
        ],
        "dcat:keyword": [
            "Radiology images",
            "Multimodal dataset",
            "Self-supervised learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Self-supervised Pretraining"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhang",
            "Q. Chen",
            "Z. Yang",
            "H. Lin",
            "Z. Lu"
        ],
        "dcterms:description": "BioWordVec is a dataset that improves biomedical word embeddings with subword information and Medical Subject Headings (MeSH), used for encoding questions in the Med-VQA task.",
        "dcterms:title": "BioWordVec",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical NLP"
        ],
        "dcat:keyword": [
            "Biomedical embeddings",
            "Word embeddings",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Encoding"
        ]
    },
    {
        "dcterms:creator": [
            "J. Lee",
            "W. Yoon",
            "S. Kim",
            "D. Kim",
            "S. Kim",
            "C. H. So",
            "J. Kang"
        ],
        "dcterms:description": "The PubMed corpus comprises more than 35 million citations for biomedical literature from MEDLINE, life science journals, and online books, providing a rich resource for pretraining language models in the biomedical domain.",
        "dcterms:title": "PubMed corpus",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Biomedical Literature"
        ],
        "dcat:keyword": [
            "Biomedical text",
            "Language representation",
            "Text mining"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Representation"
        ]
    }
]