To extract datasets from the research paper titled "SCAT: Robust Self-supervised Contrastive Learning via Adversarial Training for Text Classification" by Junjie Wu and Dit-Yan Yeung, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract states that the authors evaluate their method on **two text classification datasets**, which indicates that datasets are involved.

Next, I will focus on **section 4.1 (Setup)**, where the authors explicitly mention the datasets used for evaluation. They state that they evaluate their method on:

1. **AG's News (AG)**: This dataset is described as a sentence-level classification task with four news-type categories: World, Sport, Business, and Science/Technology. The authors mention that they use 1,000 test examples collected by Jin et al. (2020).

2. **DBPedia**: This dataset is extracted from Wikipedia and is a sentence-level classification dataset containing 14 non-overlapping categories. The authors note that they randomly selected 1,000 samples from its original test set for experiments.

To confirm the details, I will check the **References section** for full citations of these datasets:

- For **AG's News**, the citation is:
  > Ziyu Jiang, Tianlong Chen, Ting Chen, and Zhangyang Wang. *Robust pre-training by adversarial contrastive learning*. In Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.

- For **DBPedia**, the citation is:
  > Xiang Zhang, Junbo Jake Zhao, and Yann LeCun. *Character-level convolutional networks for text classification*. In Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems 2015, December 7-12, 2015, Montreal, Quebec, Canada, pages 649â€“657.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.