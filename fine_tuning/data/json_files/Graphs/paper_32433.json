[
    {
        "dcterms:creator": [
            "Jiyang Gao",
            "Chen Sun",
            "Zhenheng Yang",
            "Ram Nevatia"
        ],
        "dcterms:description": "Charades-STA is built on the Charades dataset for temporal sentence grounding, containing 12,408 and 3,720 moment-sentence pairs for training and testing.",
        "dcterms:title": "Charades-STA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Temporal Sentence Grounding",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Temporal localization",
            "Video dataset",
            "Moment-sentence pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Temporal Sentence Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Marcus Rohrbach",
            "Michaela Regneri",
            "Mykhaylo Andriluka",
            "Sikandar Amin",
            "Manfred Pinkal",
            "Bernt Schiele"
        ],
        "dcterms:description": "TACoS consists of 127 videos selected from the MPII Cooking Composite Activities video corpus, containing 10,146, 4,589, and 4,083 moment-sentence pairs for training, validation, and testing, respectively.",
        "dcterms:title": "TACoS",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Temporal Sentence Grounding",
            "Cooking Activities"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Cooking",
            "Moment-sentence pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Temporal Sentence Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Ranjay Krishna",
            "Kenji Hata",
            "Frederic Ren",
            "Li Fei-Fei",
            "Juan Carlos Niebles"
        ],
        "dcterms:description": "ActivityNet Captions is originally designed for video captioning and recently introduced into temporal sentence grounding, containing 37,417, 17,505, and 17,031 moment-sentence pairs for training, validation, and testing, respectively.",
        "dcterms:title": "ActivityNet Captions",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Temporal Sentence Grounding",
            "Video Captioning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Captioning",
            "Moment-sentence pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Temporal Sentence Grounding"
        ]
    }
]