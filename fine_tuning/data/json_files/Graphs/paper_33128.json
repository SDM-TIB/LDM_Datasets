[
    {
        "dcterms:creator": [
            "Elisa Leonardelli",
            "Stefano Menini",
            "Alessio Palmero Aprosio",
            "Marco Guerini"
        ],
        "dcterms:description": "A dataset for the task of offensive language detection, consisting of 9,814 English tweets from three domains (Black Lives Matter movement, Election 2020, and COVID-19 pandemic), annotated for offensiveness by 5 annotators via Amazon Mechanical Turk.",
        "dcterms:title": "Multi-Domain Agreement dataset (DMDA)",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Offensive Language Detection"
        ],
        "dcat:keyword": [
            "Offensive language",
            "Toxicity",
            "Crowdsourced annotations",
            "Social media"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Offensive language detection"
        ]
    },
    {
        "dcterms:creator": [
            "Simona Frenda",
            "Alessandro Pedrani",
            "Valerio Basile",
            "Soda Marem Lo",
            "Alessandra Teresa Cignarella",
            "Raffaella Panizzon",
            "Cristina Marco",
            "Bianca Scarlini",
            "Viviana Patti",
            "Cristina Bosco",
            "Davide Bernardi"
        ],
        "dcterms:description": "An irony detection corpus encompassing 3,000 Post-Reply pairs extracted from social media, with annotations provided by 74 annotators balanced in terms of gender and nationality.",
        "dcterms:title": "English Perspectivist Irony Corpus (DI)",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Irony Detection"
        ],
        "dcat:keyword": [
            "Irony",
            "Social media",
            "Crowdsourced annotations",
            "Post-Reply pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Irony detection"
        ]
    },
    {
        "dcterms:creator": [
            "Maarten Sap",
            "Dallas Card",
            "Saadia Gabriel",
            "Yejin Choi",
            "Noah A. Smith"
        ],
        "dcterms:description": "A corpus that studies the effect of annotatorsâ€™ biases on their toxicity perceptions, gathering toxicity annotations for tweets to determine personal offensiveness.",
        "dcterms:title": "Racial Bias Toxicity Detection Corpus (DRB)",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Detection",
            "Bias in Annotation"
        ],
        "dcat:keyword": [
            "Toxicity",
            "Racial bias",
            "Crowdsourced annotations",
            "Social media"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity detection"
        ]
    }
]