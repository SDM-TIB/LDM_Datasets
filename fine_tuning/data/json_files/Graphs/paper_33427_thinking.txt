To extract datasets from the research paper titled "FAST: Feature Aware Similarity Thresholding for Weak Unlearning in Black-Box Generative Models" by Subhodip Panda and Prathosh AP, I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to identify any datasets mentioned. The abstract mentions the use of **MNIST** and **CelebA-HQ** datasets, indicating that these are likely the datasets used in the experiments.

Next, I will look for explicit mentions of these datasets in the **experiments section**. The authors describe two distinct unlearning settings:

1. **Class-level Filtering**: The **MNIST dataset** is used, which consists of 60,000 28 × 28 black and white images of handwritten digits. The authors specifically focus on filtering out two digit classes: 5 and 8.

2. **Feature-level Filtering**: The **CelebA-HQ dataset** is utilized, containing 30,000 high-quality RGB celebrity face images with dimensions of 256×256. The authors target subtle features such as Bangs and Hats for filtering.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **MNIST dataset**, the citation is:
  > Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. "Gradient-based learning applied to document recognition." *Proceedings of the IEEE*, vol. 86, no. 11, pp. 2278–2324, 1998.

- For the **CelebA-HQ dataset**, the citation is:
  > Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. "Deep learning face attributes in the wild." In *Proceedings of the International Conference on Computer Vision (ICCV)*, 2015.

Having identified the datasets and their citations, I will now compile the dataset entries into a structured format for further processing. This ensures that I have accurately captured the necessary information for each dataset used in the research.