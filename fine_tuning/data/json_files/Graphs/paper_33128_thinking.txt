To extract datasets from the research paper titled "Capturing Perspectives of Crowdsourced Annotators in Subjective Learning Tasks" by Negar Mokhberian et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any mentions of datasets. The abstract discusses the challenges of subjective tasks and mentions the use of multiple annotators, which suggests that datasets may be involved.

Next, I will focus on the **experiments section** (Section 4), specifically **subsection 4.1 (Datasets)**, where the authors explicitly list the datasets used in their experiments. Here, I will look for the names of the datasets, their descriptions, and any relevant details about their structure or purpose.

The paper mentions three datasets:

1. **Multi-Domain Agreement dataset (DMDA)**: This dataset is created for the task of offensive language detection and consists of 9,814 English tweets from three domains (Black Lives Matter movement, Election 2020, and COVID-19 pandemic). Each tweet was annotated for offensiveness by 5 annotators via Amazon Mechanical Turk.

2. **English Perspectivist Irony Corpus (DI)**: This irony detection corpus includes 3,000 Post-Reply pairs extracted from social media, evenly sourced from Twitter and Reddit across five English-speaking countries. The dataset features 74 annotators, balanced in terms of gender and nationality, with approximately 15 raters assigned to each nationality.

3. **Racial Bias Toxicity Detection Corpus (DRB)**: This dataset focuses on the effect of annotators' biases on their toxicity perceptions. It includes toxicity annotations for tweets, where annotators determine whether a tweet is offensive to them.

After identifying these datasets, I will check the **References section** for full citations. The citations for the datasets are as follows:

- For the **Multi-Domain Agreement dataset (DMDA)**, the citation is:
  > Elisa Leonardelli, Stefano Menini, Alessio Palmero Aprosio, Marco Guerini. *Agreeing to disagree: Annotating offensive language datasets with annotators’ disagreement*. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 10528–10539, 2021.

- For the **English Perspectivist Irony Corpus (DI)**, the citation is:
  > Simona Frenda, Alessandro Pedrani, Valerio Basile, Soda Marem Lo, Alessandra Teresa Cignarella, Raffaella Panizzon, Cristina Marco, Bianca Scarlini, Viviana Patti, Cristina Bosco, and Davide Bernardi. *EPIC: Multi-perspective annotation of a corpus of irony*. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13844–13857, 2023.

- For the **Racial Bias Toxicity Detection Corpus (DRB)**, the citation is:
  > Maarten Sap, Dallas Card, Saadia Gabriel, Yejin Choi, and Noah A. Smith. *The risk of racial bias in hate speech detection*. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, pages 1668–1678, 2019.

Now that I have gathered the necessary information about the datasets and their citations, I will compile this information into a structured format for further processing or review.