To extract datasets from the research paper titled "Multi-view Knowledge Graph Embedding for Entity Alignment" by Qingheng Zhang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by examining the **abstract** and **introduction** sections. The abstract mentions that the experiments were conducted on "real-world datasets," which indicates that datasets are indeed used. I will look for specific names or descriptions of these datasets.

Next, I will focus on the **experiments section** (Section 6), where the authors explicitly mention the datasets used. In this section, they state that they reused two datasets: **DBP-WD** and **DBP-YG**. I will note down the details provided about these datasets, including their origin and the number of aligned entity pairs.

After identifying the datasets, I will check the **references section** to find the full citations for the datasets mentioned. The authors reference a previous work by Sun et al. (2018) that introduced these datasets. I will locate this citation to ensure I have the complete reference.

The citation for the datasets is:
> Zequn Sun, Wei Hu, Qingheng Zhang, and Yuzhong Qu. *Bootstrapping entity alignment with knowledge graph embedding*. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI), pages 4396â€“4402, 2018.

Now, I will summarize the datasets as follows:

1. **DBP-WD**: A dataset sampled from DBpedia and Wikidata, containing 100,000 aligned entity pairs, with 30% of them provided as seed for training.
2. **DBP-YG**: A dataset sampled from DBpedia and YAGO, also containing 100,000 aligned entity pairs, with the same seed allocation as DBP-WD.

Finally, I will compile this information into a structured format that includes the dataset names, descriptions, and full citations, ready for further processing or review.