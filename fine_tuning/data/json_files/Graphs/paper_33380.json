[
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.-C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J. N. Chang",
            "S. Lee",
            "S. S. Narayanan"
        ],
        "dcterms:description": "IEMOCAP is an interactive emotional dyadic motion capture database that includes conversation videos where two actors perform improvised or scripted scenarios, specially selected to evoke emotional expressions.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Dyadic interactions",
            "Motion capture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A. B. Zadeh",
            "P. P. Liang",
            "S. Poria",
            "E. Cambria",
            "L.-P. Morency"
        ],
        "dcterms:description": "CMU-MOSEI is a collection of over 23,500 sentence utterance videos from more than 1000 online YouTube speakers, annotated with sentiment labels: positive, negative, and neutral.",
        "dcterms:title": "CMU-MOSEI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Sentiment dataset",
            "YouTube videos",
            "Multimodal analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "C. Busso",
            "S. Parthasarathy",
            "A. Burmania",
            "M. AbdelWahab",
            "N. Sadoughi",
            "E. M. Provost"
        ],
        "dcterms:description": "MSP-IMPROV is an acted corpus of dyadic interactions designed to study emotion perception, consisting of data from six dyadic conversations involving 12 actors.",
        "dcterms:title": "MSP-IMPROV",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Perception",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Dyadic interactions",
            "Acted corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]