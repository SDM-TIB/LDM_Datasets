[
    {
        "dcterms:creator": [
            "Max Bain",
            "Arsha Nagrani",
            "GÃ¼l Varol",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A large-scale dataset consisting of 2.5 million video-text pairs scraped from the web, demonstrating better alignments between text semantics and video content.",
        "dcterms:title": "WebVid2M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Text-video alignment",
            "Web-scraped data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video-Text Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Antoine Miech",
            "Dimitri Zhukov",
            "Jean-Baptiste Alayrac",
            "Makarand Tapaswi",
            "Ivan Laptev",
            "Josef Sivic"
        ],
        "dcterms:description": "A large dataset containing 100 million narrated video clips, designed for learning a text-video embedding.",
        "dcterms:title": "HowTo100M",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Narrated videos",
            "Text-video embedding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Text-Video Embedding Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Jun Xu",
            "Tao Mei",
            "Ting Yao",
            "Yong Rui"
        ],
        "dcterms:description": "A large video description dataset consisting of 10,000 videos, each associated with 20 text descriptions, aimed at bridging video and language.",
        "dcterms:title": "MSRVTT",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Text descriptions",
            "Video-language bridging"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Text-Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "David Chen",
            "William B Dolan"
        ],
        "dcterms:description": "A dataset consisting of 1,970 videos with approximately 40 text descriptions per video, used for evaluating paraphrase.",
        "dcterms:title": "MSVD",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Paraphrase evaluation",
            "Text descriptions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Text-Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Xin Wang",
            "Jiawei Wu",
            "Junkun Chen",
            "Lei Li",
            "Yuan-Fang Wang",
            "William Yang Wang"
        ],
        "dcterms:description": "A large-scale, high-quality multilingual dataset for video-and-language research, containing 34,991 videos.",
        "dcterms:title": "VATEX",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Video-language research",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Text-Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Lisa Anne Hendricks",
            "Oliver Wang",
            "Eli Shechtman",
            "Josef Sivic",
            "Trevor Darrell",
            "Bryan Russell"
        ],
        "dcterms:description": "A dataset containing 10,000 flickr videos with 40,000 localized text annotations for localizing moments in video.",
        "dcterms:title": "DiDeMo",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video and Language"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Localized text annotations",
            "Moment localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Paragraph-to-Video Retrieval"
        ]
    }
]