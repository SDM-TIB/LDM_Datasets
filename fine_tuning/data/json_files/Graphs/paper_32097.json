[
    {
        "dcterms:creator": [
            "Chen Qu",
            "Liu Yang",
            "Cen Chen",
            "Minghui Qiu",
            "W. Bruce Croft",
            "Mohit Iyyer"
        ],
        "dcterms:description": "OR-QuAC is the benchmark ODConvQA dataset, which extends a popular ConvQA dataset, namely QuAC, to the open-retrieval setting. This dataset consists of 35,526 conversational turns for training, 3,430 for validation, and 5,571 for testing.",
        "dcterms:title": "OR-QuAC",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Open-Domain Conversational Question Answering"
        ],
        "dcat:keyword": [
            "Conversational QA",
            "Open-retrieval",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Vaibhav Adlakha",
            "Shehzaad Dhuliawala",
            "Kaheer Suleman",
            "Harm de Vries",
            "Siva Reddy"
        ],
        "dcterms:description": "TopiOCQA is another ODConvQA dataset that considers the topic-switching problem across different conversational turns. This dataset contains 45,450 conversational turns and 2,514 turns for training and validation, respectively.",
        "dcterms:title": "TopiOCQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Open-Domain Conversational Question Answering"
        ],
        "dcat:keyword": [
            "Conversational QA",
            "Topic Switching",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]