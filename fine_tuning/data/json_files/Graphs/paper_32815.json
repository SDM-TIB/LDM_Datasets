[
    {
        "dcterms:creator": [
            "AmirAli Bagher Zadeh",
            "Paul Pu Liang",
            "Soujanya Poria",
            "Erik Cambria",
            "Louis-Philippe Morency"
        ],
        "dcterms:description": "A dataset used for multimodal language analysis, containing 23K annotated video clips with emotional content.",
        "dcterms:title": "CMU-MOSEI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Multimodal analysis",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Carlos Busso",
            "Murtaza Bulut",
            "Chi-Chun Lee",
            "Abe Kazemzadeh",
            "Emily Mower",
            "Samuel Kim",
            "Jeannette N Chang",
            "Sungbok Lee",
            "Shrikanth S Narayanan"
        ],
        "dcterms:description": "An interactive emotional dyadic motion capture database used for emotion recognition.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Dyadic interaction",
            "Motion capture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Soujanya Poria",
            "Devamanyu Hazarika",
            "Navonil Majumder",
            "Gautam Naik",
            "Erik Cambria",
            "Rada Mihalcea"
        ],
        "dcterms:description": "A multimodal multi-party dataset for emotion recognition in conversations.",
        "dcterms:title": "MELD",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1810.02508",
        "dcat:theme": [
            "Multimodal Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Multi-party conversations",
            "Emotion recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Houwei Cao",
            "David G Cooper",
            "Michael K Keutmann",
            "Ruben C Gur",
            "Ani Nenkova",
            "Ragini Verma"
        ],
        "dcterms:description": "A crowdsourced emotional multimodal actors dataset.",
        "dcterms:title": "CREMA-D",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Crowdsourced",
            "Multimodal actors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Steven R Livingstone",
            "Frank A Russo"
        ],
        "dcterms:description": "A dynamic, multimodal set of facial and vocal expressions in North American English.",
        "dcterms:title": "RAVDESS",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "10.1371/journal.pone.0196391",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Facial expressions",
            "Vocal expressions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "AmirAli Bagher Zadeh",
            "Paul Pu Liang",
            "Soujanya Poria",
            "Erik Cambria",
            "Louis-Philippe Morency"
        ],
        "dcterms:description": "A dataset used for multimodal language analysis, containing 2.2K annotated video clips with emotional content.",
        "dcterms:title": "CMU-MOSI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Multimodal analysis",
            "Video clips"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]