[
    {
        "dcterms:creator": [
            "Martin Cooke",
            "Jon Barker",
            "Stuart Cunningham",
            "Xu Shao"
        ],
        "dcterms:description": "The GRID corpus dataset is composed of sentences following fixed grammar from 33 speakers.",
        "dcterms:title": "GRID",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-visual corpus",
            "Speech perception",
            "Automatic speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Naomi Harte",
            "Eoin Gillen"
        ],
        "dcterms:description": "The TCD-TIMIT dataset is composed of uttering videos from 3 lip speakers and 59 volunteers.",
        "dcterms:title": "TCD-TIMIT",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-visual corpus",
            "Continuous speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Joon Son Chung",
            "Andrew Zisserman"
        ],
        "dcterms:description": "The LRW dataset is a word-level English audio-visual dataset derived from BBC news, composed of up to 1,000 training videos for each of 500 words.",
        "dcterms:title": "LRW",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-visual dataset",
            "Lip reading",
            "Word-level recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Synthesis"
        ]
    }
]