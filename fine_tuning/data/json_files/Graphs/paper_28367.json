[
    {
        "dcterms:creator": [
            "Roy Bar-Haim",
            "Lilach Eden",
            "Roni Friedman",
            "Yoav Kantor",
            "Dan Lahav",
            "Noam Slonim"
        ],
        "dcterms:description": "A collection of arguments mapped to manually-created key points, capturing the gist of the arguments.",
        "dcterms:title": "ArgsKP corpus",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Argumentation",
            "Summarization"
        ],
        "dcat:keyword": [
            "Argument summarization",
            "Key points",
            "Multi-document summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Argument summarization",
            "Key point extraction"
        ]
    },
    {
        "dcterms:creator": [
            "Roni Friedman",
            "Lena Dankin",
            "Yoav Katz",
            "Yufang Hou",
            "Noam Slonim"
        ],
        "dcterms:description": "A dataset containing 28 controversial topics, with 6515 arguments and a total of 243 key points, used for the KPA shared task.",
        "dcterms:title": "Dataset provided by the organizers (KPA shared task dataset)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Argumentation",
            "Summarization"
        ],
        "dcat:keyword": [
            "Key point analysis",
            "Argument-key point pairs",
            "Controversial topics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Key point matching",
            "Key point generation"
        ]
    },
    {
        "dcterms:creator": [
            "Assaf Toledo",
            "Shai Gretz",
            "Edo Cohen-Karlik",
            "Roni Friedman",
            "Elad Venezian",
            "Dan Lahav",
            "Michal Jacovi",
            "Ranit Aharonov",
            "Noam Slonim"
        ],
        "dcterms:description": "An API providing argument quality scores, used to assess the quality of arguments in the dataset.",
        "dcterms:title": "Project Debaterâ€™s API (for argument quality scores)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Argumentation",
            "Quality assessment"
        ],
        "dcat:keyword": [
            "Argument quality",
            "Quality scores",
            "Argument assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Argument quality assessment"
        ]
    }
]