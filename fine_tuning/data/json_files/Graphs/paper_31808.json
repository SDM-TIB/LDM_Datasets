[
    {
        "dcterms:creator": [
            "Junbin Xiao",
            "Xindi Shang",
            "Angela Yao",
            "Tat-Seng Chua"
        ],
        "dcterms:description": "A manually annotated multi-choice QA dataset targeting the explanation of video contents, especially causal and temporal reasoning. It contains 5,440 videos and 47,692 QA pairs, each QA pair comprises one question and five candidate answers.",
        "dcterms:title": "NExT-QA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Causal Reasoning",
            "Temporal Reasoning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Question answering",
            "Causal reasoning",
            "Temporal reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Jiangtong Li",
            "Li Niu",
            "Liqing Zhang"
        ],
        "dcterms:description": "A multi-choice QA benchmark emphasizing both evidence reasoning and commonsense reasoning in real-world actions. It contains 107,600 QA pairs and 26,900 video clips, with questions categorized into four types: description, explanatory, prediction, and counterfactual.",
        "dcterms:title": "Causal-VidQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Question answering",
            "Evidence reasoning",
            "Commonsense reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dejing Xu",
            "Zhou Zhao",
            "Jun Xiao",
            "Fei Wu",
            "Hanwang Zhang",
            "Xiangnan He",
            "Yueting Zhuang"
        ],
        "dcterms:description": "An open-ended QA benchmark focusing on the visual scene-sensing ability by asking descriptive questions. It contains 10,000 trimmed video clips and 243,680 QA pairs, with challenges including description and recognition capabilities.",
        "dcterms:title": "MSRVTT-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Visual Scene Sensing"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Question answering",
            "Descriptive questions",
            "Recognition capabilities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    }
]