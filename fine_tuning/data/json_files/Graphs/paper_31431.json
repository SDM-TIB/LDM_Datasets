[
    {
        "dcterms:creator": [
            "Yusuf Aytar",
            "Carl Vondrick",
            "Antonio Torralba"
        ],
        "dcterms:description": "Flickr-SoundNet contains 2 million unconstrained videos from Flickr, used for training audio-visual localization models.",
        "dcterms:title": "Flickr-SoundNet",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Learning",
            "Sound Source Localization"
        ],
        "dcat:keyword": [
            "Unconstrained videos",
            "Audio-visual pairs",
            "Localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Honglie Chen",
            "Weidi Xie",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "VGG-Sound includes 200k video clips from 309 classes, used for training and evaluating audio-visual localization models.",
        "dcterms:title": "VGG-Sound",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Learning",
            "Sound Source Localization"
        ],
        "dcat:keyword": [
            "Video clips",
            "Audio-visual pairs",
            "Localization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Jinxing Zhou",
            "Liang Zheng",
            "Yiran Zhong",
            "Shijie Hao",
            "Meng Wang"
        ],
        "dcterms:description": "AVSBench is a recently proposed audio-visual dataset with pixel-wise labels for fine-grained localization evaluation.",
        "dcterms:title": "AVSBench",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Learning",
            "Segmentation"
        ],
        "dcat:keyword": [
            "Pixel-wise labels",
            "Fine-grained localization",
            "Audio-visual segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Segmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Heard 110 is a subset of VGG-Sound used to test the open-set learning ability of models.",
        "dcterms:title": "Heard 110",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Open-set learning",
            "Audio-visual pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Open-set Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Unheard 110 is another subset of VGG-Sound used to evaluate models on unseen categories.",
        "dcterms:title": "Unheard 110",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Unseen categories",
            "Audio-visual pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Open-set Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Flickr 10k is a subset of Flickr-SoundNet used for training and evaluation.",
        "dcterms:title": "Flickr 10k",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Training set",
            "Audio-visual pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "VGG-SS is a subset of VGG-Sound used for evaluating audio-visual localization models.",
        "dcterms:title": "VGG-SS",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Evaluation set",
            "Audio-visual pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]