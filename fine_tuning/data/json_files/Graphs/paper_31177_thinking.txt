To extract the datasets mentioned in the research paper titled "HateProof: Are Hateful Meme Detection Systems really Robust?" by Piush Aggarwal et al., I will follow a systematic approach to ensure I capture all relevant details, including full citations for each dataset.

First, I will read through the **abstract, introduction, and datasets section** of the paper. The abstract provides a brief overview of the study's focus on vulnerabilities in hateful meme detection systems, which suggests that datasets are likely involved in the analysis.

Next, I will focus on **section 3 (Datasets)**, where the authors explicitly describe the datasets used in their experiments. Here, they mention three benchmark datasets:

1. **Fbhm Dataset**: This dataset, referenced as Kiela et al. [28], contains 10,000 memes collected from Getty images, annotated with various categories of hate and benign content. The dataset is split into training, development, and test sets.

2. **HarMeme Dataset**: Cited as Pramanick et al. [46], this dataset consists of COVID-related memes shared on US social media, with a total of 3,544 data points. It is categorized into hateful and non-hateful memes, with a similar split for training, validation, and testing.

3. **Mami Dataset**: Referenced as Fersini et al. [16], this dataset focuses on misogynistic content, containing 10,000 instances of memes collected from social media. The authors relabeled the memes as hateful or non-hateful based on their content.

After identifying these datasets, I will check the **References section** to gather the full citations for each dataset:

- For the **Fbhm Dataset**:
  > Kiela, D., Firooz, H., Mohan, A., Goswami, V., Singh, A., Ringshia, P., & Testuggine, D. (2020). The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes. https://doi.org/10.48550/ARXIV.2005.04790

- For the **HarMeme Dataset**:
  > Pramanick, S., Dimitrov, D., Mukherjee, R., Sharma, S., Akhtar, M. S., Nakov, P., & Chakraborty, T. (2021). Detecting Harmful Memes and Their Targets. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Association for Computational Linguistics, Online, 2783â€“2796. https://doi.org/10.18653/v1/2021.findings-acl.246

- For the **Mami Dataset**:
  > Fersini, E., Gasparini, F., Rizzi, G., Saibene, A., Chulvi, B., Rosso, P., Lees, A., & Sorensen, J. (2022). SemEval-2022 Task 5: Multimedia automatic misogyny identification. In Proceedings of the 16th International Workshop on Semantic Evaluation (SemEval-2022). Association for Computational Linguistics. 

Now that I have the datasets and their citations, I will compile this information into a structured format for further processing or review. This ensures that I have accurately captured the datasets used in the study along with their proper citations.