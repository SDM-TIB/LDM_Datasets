[
    {
        "dcterms:creator": [
            "Sewon Min",
            "Xinxi Lyu",
            "Ari Holtzman",
            "Mikel Artetxe",
            "Mike Lewis",
            "Hannaneh Hajishirzi",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "AmbigQA contains a subset of questions from the Natural Questions dataset, specifically those marked as ambiguous, allowing for multiple correct answers depending on interpretation.",
        "dcterms:title": "AmbigQA",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2004.10645",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Ambiguous questions",
            "Open-domain QA",
            "Natural Questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-answer Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel Joseph Amouyal",
            "Ohad Rubin",
            "Ori Yoran",
            "Tomer Wolfson",
            "Jonathan Herzig",
            "Jonathan Berant"
        ],
        "dcterms:description": "QAMPARI consists of questions whose correct answers span multiple paragraphs in the document from which they were retrieved, originally developed to evaluate retrieval methods.",
        "dcterms:title": "QAMPARI",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2205.12665",
        "dcat:theme": [
            "Question Answering",
            "Information Retrieval"
        ],
        "dcat:keyword": [
            "Open-domain QA",
            "Multi-paragraph answers",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-answer Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Chaitanya Malaviya",
            "Peter Shaw",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "QUEST is constructed by formulating queries that define implicit set operations over Wikipedia entities.",
        "dcterms:title": "QUEST",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.11694",
        "dcat:theme": [
            "Question Answering",
            "Information Retrieval"
        ],
        "dcat:keyword": [
            "Entity-seeking queries",
            "Set operations",
            "Open-domain QA"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-answer Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano",
            "Christopher Hesse",
            "John Schulman"
        ],
        "dcterms:description": "GSM8K is a dataset commonly used to assess the reasoning capabilities of language models through math word problems.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.14168",
        "dcat:theme": [
            "Mathematics",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Reasoning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Single-answer Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Ido Dagan",
            "Oren Glickman",
            "Bernardo Magnini"
        ],
        "dcterms:description": "RTE is a dataset used for recognizing textual entailment, providing a challenge for models to determine if a premise entails a hypothesis.",
        "dcterms:title": "RTE",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Textual entailment",
            "NLI",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "SNLI is a large annotated corpus for learning natural language inference, providing pairs of sentences labeled with entailment relations.",
        "dcterms:title": "SNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "NLI",
            "Textual entailment",
            "Annotated corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    }
]