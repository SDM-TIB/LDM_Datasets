[
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.-C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J. N. Chang",
            "S. Lee",
            "S. S. Narayanan"
        ],
        "dcterms:description": "The IEMOCAP dataset includes five sessions of utterances for 10 unique speakers, annotated with four basic emotions: anger, happiness, neutral, and sadness.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Speech emotion recognition",
            "Multi-modal data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Classification"
        ]
    },
    {
        "dcterms:creator": [
            "S. Tripathi",
            "H. Beigi"
        ],
        "dcterms:description": "The IEMOCAP dataset is utilized for multi-modal emotion recognition using deep learning techniques.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep learning",
            "Emotion recognition",
            "Multi-modal"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Emotion Classification"
        ]
    }
]