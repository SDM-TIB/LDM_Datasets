[
    {
        "dcterms:creator": [],
        "dcterms:description": "The TNO is a widely used dataset for infrared and visible image fusion. We adopt TNO as the benchmark to train our network for its high quality images with distinctive scenarios.",
        "dcterms:title": "TNO Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Fusion",
            "Infrared and Visible Imaging"
        ],
        "dcat:keyword": [
            "Image fusion",
            "Infrared images",
            "Visible images",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "https://figshare.com/articles/TNO_Image_Fusion_Dataset/1008029",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Fusion"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The RoadScene includes realistic driving scenes (e.g., vehicles, pedestrians and road symbol signs). It contains 221 representative image pairs with no uniform resolution, collected from authentic driving videos.",
        "dcterms:title": "RoadScene Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Driving Scenes",
            "Image Fusion"
        ],
        "dcat:keyword": [
            "Driving scenes",
            "Vehicles",
            "Pedestrians",
            "Road signs",
            "Image pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Fusion"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "2662 PET patches and 4114 SPECT patch images are selected from Atlas2 dataset. All images are cropped to size 64Ã—64 and normalized to [-1, 1] as training set.",
        "dcterms:title": "Atlas Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Imaging",
            "Image Fusion"
        ],
        "dcat:keyword": [
            "PET images",
            "SPECT images",
            "Medical image fusion",
            "Image patches"
        ],
        "dcat:landingPage": "http://www.med.harvard.edu/aanlib",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Medical Image Fusion"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "We conducted experiments on the latest M3FD dataset using the state-of-the-art detector YOLOv5.",
        "dcterms:title": "M3FD Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Image Fusion"
        ],
        "dcat:keyword": [
            "Object detection",
            "YOLOv5",
            "Multi-modal images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "We conducted experiments on the MFNet dataset using the state-of-the-art semantic segmentation model SegFormer.",
        "dcterms:title": "MFNet Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Segmentation",
            "Image Fusion"
        ],
        "dcat:keyword": [
            "Semantic segmentation",
            "SegFormer",
            "Image fusion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    }
]