[
    {
        "dcterms:creator": [
            "Stefano Menini",
            "Alessio Palmero Aprosio",
            "Sara Tonelli"
        ],
        "dcterms:description": "A contextual dataset of tweets where the toxicity of tweets was annotated in two phases: without context and with context from preceding tweets.",
        "dcterms:title": "FBK Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Detection",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Toxicity",
            "Contextual Annotation",
            "Tweets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Emily Dinan",
            "Samuel Humeau",
            "Bharath Chintagunta",
            "Jason Weston"
        ],
        "dcterms:description": "A dataset constructed by crowd-workers who produced offensive utterances in existing conversations to test the robustness of dialogue safety models.",
        "dcterms:title": "Build-It Break-It Fix-It (BBF) Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1908.06083",
        "dcat:theme": [
            "Dialogue Safety",
            "Robustness Testing"
        ],
        "dcat:keyword": [
            "Adversarial Attacks",
            "Dialogue",
            "Safety"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1908.06083",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Safety"
        ]
    },
    {
        "dcterms:creator": [
            "Jing Xu",
            "Da Ju",
            "Margaret Li",
            "Y-Lan Boureau",
            "Jason Weston",
            "Emily Dinan"
        ],
        "dcterms:description": "A dataset formed by collecting conversations between crowd-workers and dialogue models, where crowd-workers aimed to generate unsafe messages.",
        "dcterms:title": "Bot-Adversarial Dialogue (BAD) Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/2021.naacl-main.235",
        "dcat:theme": [
            "Conversational Agents",
            "Safety"
        ],
        "dcat:keyword": [
            "Adversarial Dialogue",
            "Toxicity",
            "Conversational Safety"
        ],
        "dcat:landingPage": "https://doi.org/10.18653/v1/2021.naacl-main.235",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Safety in Dialogue"
        ]
    },
    {
        "dcterms:creator": [
            "Jing Qian",
            "Anna Bethke",
            "Yinyin Liu",
            "Elizabeth M. Belding",
            "William Yang Wang"
        ],
        "dcterms:description": "A benchmark dataset for learning to intervene in online hate speech, constructed from Reddit comments.",
        "dcterms:title": "Hateful Qian Reddit (HQR) Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1909.04251",
        "dcat:theme": [
            "Hate Speech Detection",
            "Intervention Strategies"
        ],
        "dcat:keyword": [
            "Hate Speech",
            "Reddit",
            "Intervention"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1909.04251",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Hate Speech Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Jing Qian",
            "Anna Bethke",
            "Yinyin Liu",
            "Elizabeth M. Belding",
            "William Yang Wang"
        ],
        "dcterms:description": "A benchmark dataset for learning to intervene in online hate speech, constructed from Gab comments.",
        "dcterms:title": "Gab (HQG) Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1909.04251",
        "dcat:theme": [
            "Hate Speech Detection",
            "Intervention Strategies"
        ],
        "dcat:keyword": [
            "Hate Speech",
            "Gab",
            "Intervention"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1909.04251",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Hate Speech Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Bertie Vidgen",
            "Dong Nguyen",
            "Helen Margetts",
            "Patricia Rossini",
            "Rebekah Tromble"
        ],
        "dcterms:description": "A dataset built by sampling posts from Reddit, focusing on various types of abuse and the need for context in annotations.",
        "dcterms:title": "Contextual Abuse Dataset (CAD)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.18653/v1/2021.naacl-main.182",
        "dcat:theme": [
            "Abuse Detection",
            "Contextual Analysis"
        ],
        "dcat:keyword": [
            "Abuse",
            "Reddit",
            "Context"
        ],
        "dcat:landingPage": "https://doi.org/10.18653/v1/2021.naacl-main.182",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Abuse Detection"
        ]
    }
]