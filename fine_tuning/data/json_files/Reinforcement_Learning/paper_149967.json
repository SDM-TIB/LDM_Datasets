[
    {
        "dcterms:creator": [
            "W. Dabney",
            "M. Rowland",
            "M. G. Bellemare",
            "R. Munos"
        ],
        "dcterms:description": "A dataset used for distributional reinforcement learning that employs quantile regression to estimate the distribution of returns.",
        "dcterms:title": "C51",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Distributional RL",
            "Quantile Regression"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "W. Dabney",
            "R. Munos"
        ],
        "dcterms:description": "A dataset that provides a distributional perspective on reinforcement learning, focusing on quantile regression.",
        "dcterms:title": "QR-DQN",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Distributional RL",
            "Quantile Regression"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Li",
            "S. Bing",
            "S. Yang"
        ],
        "dcterms:description": "A dataset for distributional advantage actor-critic methods in reinforcement learning.",
        "dcterms:title": "QR-A2C",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "W. Dabney",
            "G. Ostrovski",
            "D. Silver",
            "R. Munos"
        ],
        "dcterms:description": "A dataset that introduces implicit quantile networks for distributional reinforcement learning.",
        "dcterms:title": "IQN",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Implicit Quantile Networks",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Rowland",
            "R. Dadashi",
            "S. Kumar",
            "R. Munos",
            "M. G. Bellemare",
            "W. Dabney"
        ],
        "dcterms:description": "A dataset that discusses statistics and samples in distributional reinforcement learning.",
        "dcterms:title": "ER-DQN",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Distributional RL",
            "Experience Replay"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Choi",
            "K. Lee",
            "S. Oh"
        ],
        "dcterms:description": "A dataset that explores distributional deep reinforcement learning using a mixture of Gaussians.",
        "dcterms:title": "MoG-DQN",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Mixture of Gaussians",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Yang",
            "L. Zhao",
            "Z. Lin",
            "T. Qin",
            "J. Bian",
            "T. Liu"
        ],
        "dcterms:description": "A dataset that presents a fully parameterized quantile function for distributional reinforcement learning.",
        "dcterms:title": "FQF",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Fully Parameterized Quantile Function",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. W. Nam",
            "Y. Kim",
            "C. Y. Park"
        ],
        "dcterms:description": "A dataset that provides a distributional perspective on the actor-critic framework.",
        "dcterms:title": "GMAC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "N. Nikolov",
            "J. Kirschner",
            "F. Berkenkamp",
            "A. Krause"
        ],
        "dcterms:description": "A dataset that focuses on information-directed exploration for deep reinforcement learning.",
        "dcterms:title": "IDS",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Information-Directed Exploration",
            "Deep RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "B. Mavrin",
            "H. Yao",
            "L. Kong",
            "K. Wu",
            "Y. Yu"
        ],
        "dcterms:description": "A dataset that discusses distributional reinforcement learning for efficient exploration.",
        "dcterms:title": "DLTV",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Efficient Exploration",
            "Distributional RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Keramati",
            "C. Dann",
            "A. Tamkin",
            "E. Brunskill"
        ],
        "dcterms:description": "A dataset that focuses on quickly learning a CVaR policy in reinforcement learning.",
        "dcterms:title": "CVaR-MDP",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "CVaR Policy",
            "Risk-Sensitive RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "F. Zhou",
            "Z. Zhu",
            "Q. Kuang",
            "L. Zhang"
        ],
        "dcterms:description": "A dataset that introduces a non-decreasing quantile function network for efficient exploration in distributional reinforcement learning.",
        "dcterms:title": "NDQFN",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Non-Decreasing Quantile Function",
            "Efficient Exploration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Kuznetsov",
            "P. Shvechikov",
            "A. Grishin",
            "D. P. Vetrov"
        ],
        "dcterms:description": "A dataset that addresses overestimation bias with truncated mixture of continuous distributional quantile critics.",
        "dcterms:title": "TQC",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Overestimation Bias",
            "Truncated Mixture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Duan",
            "Y. Guan",
            "S. E. Li",
            "Y. Ren",
            "Q. Sun",
            "B. Cheng"
        ],
        "dcterms:description": "A dataset that focuses on off-policy reinforcement learning for addressing value estimation errors.",
        "dcterms:title": "DSAC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Off-Policy Learning",
            "Value Estimation Errors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "N. Dorka",
            "J. Boedecker",
            "W. Burgard"
        ],
        "dcterms:description": "A dataset that discusses adaptively calibrated critic estimates for deep reinforcement learning.",
        "dcterms:title": "ACC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Calibrated Critic Estimates",
            "Deep RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "K. Ciosek",
            "Q. Vuong",
            "R. Loftin",
            "K. Hofmann"
        ],
        "dcterms:description": "A dataset that explores better exploration strategies with optimistic actor-critic methods.",
        "dcterms:title": "OAC",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Optimistic Actor-Critic",
            "Exploration Strategies"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Kalweit",
            "J. Boedecker"
        ],
        "dcterms:description": "A dataset that discusses uncertainty-driven imagination for continuous deep reinforcement learning.",
        "dcterms:title": "MA-BDDPG",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Uncertainty-Driven Imagination",
            "Continuous RL"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Zhang",
            "H. Yao"
        ],
        "dcterms:description": "A dataset that presents ACE, an actor ensemble algorithm for continuous control with tree search.",
        "dcterms:title": "ACE",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Actor Ensemble",
            "Continuous Control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]