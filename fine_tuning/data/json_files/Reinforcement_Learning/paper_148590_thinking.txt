To extract datasets from the research paper titled "BUT-FIT at SemEval-2020 Task 5: Automatic detection of counterfactual statements with deep pre-trained language representation models" by Martin Fajcik et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and experimental setup sections** to identify any datasets mentioned. The abstract provides a brief overview of the tasks and methods used, but I need to look for specific dataset names.

In the **introduction**, the authors discuss the SemEval-2020 Task 5, which involves detecting counterfactual statements. They mention that the challenge consists of two subtasks, but they do not specify datasets here. 

Next, I will focus on the **experimental setup section** (section 3), where the authors describe the datasets used for each subtask. They mention that for Subtask 1, they used a dataset with a train/validation/test split of 10,000/3,000/7,000 examples, and for Subtask 2, they used a dataset with a split of 3,196/355/1,950 examples. However, the specific names of these datasets are not provided in this section.

To find the dataset names, I will check the **related work section** (section 5) where the authors reference previous works. They mention a counterfactual tweet dataset created by Son et al. (2017) and a dataset for "what-if" question answering by Tandon et al. (2019). These references suggest that they may have used these datasets or similar ones for their experiments.

Now, I will look at the **References section** to gather full citations for the datasets mentioned:

1. For the **counterfactual tweet dataset** by Son et al. (2017), the citation is:
   > Youngseo Son, Anneke Buffone, Joe Raso, Allegra Larche, Anthony Janocko, Kevin Zembroski, H Andrew Schwartz, and Lyle Ungar. *Recognizing counterfactual thinking in social media texts*. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 654–658, 2017.

2. For the **WIQA dataset** by Tandon et al. (2019), the citation is:
   > Niket Tandon, Bhavana Dalvi Mishra, Keisuke Sakaguchi, Antoine Bosselut, and Peter Clark. *WIQA: A dataset for “what if...” reasoning over procedural text*. In EMNLP/IJCNLP, 2019.

After gathering the dataset names and their citations, I will compile this information into a structured format that highlights each dataset's purpose and citation.

Finally, I will ensure that the dataset entries are clear and ready for any further processing or review.