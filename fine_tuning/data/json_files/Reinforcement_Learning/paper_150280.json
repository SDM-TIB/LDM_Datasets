[
    {
        "dcterms:creator": [
            "Fred W. Buhl"
        ],
        "dcterms:description": "The EmoGator dataset consists of 32,130 vocal bursts from 357 speakers, classified into 30 distinct emotion categories, providing a total of 16.9654 hours of audio.",
        "dcterms:title": "EmoGator Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Vocal Bursts"
        ],
        "dcat:keyword": [
            "Vocal bursts",
            "Emotion categories",
            "Audio dataset",
            "Speech emotion recognition"
        ],
        "dcat:landingPage": "https://github.com/fredbuhl/EmoGator",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion classification"
        ]
    },
    {
        "dcterms:creator": [
            "Alice Baird",
            "Panagiotis Tzirakis",
            "Gauthier Gidel",
            "Marco Jiralerspong",
            "Eilif B. Muller",
            "Kory Mathewson",
            "Björn Schuller",
            "Erik Cambria",
            "Dacher Keltner",
            "Alan Cowen"
        ],
        "dcterms:description": "The Hume-VB dataset consists of 59,201 vocalizations from 1702 speakers, rated for 10 emotion categories with intensity scores for each sample.",
        "dcterms:title": "Hume-VB Dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2205.01780",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Vocal Bursts"
        ],
        "dcat:keyword": [
            "Vocalizations",
            "Emotion categories",
            "Intensity scores",
            "Audio dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Alice Baird",
            "Panagiotis Tzirakis",
            "Jeffrey A. Brooks",
            "Christopher B. Gregory",
            "Björn Schuller",
            "Anton Batliner",
            "Dacher Keltner",
            "Alan Cowen"
        ],
        "dcterms:description": "The Hume-VB dataset is also referenced in the context of the ACII 2022 Affective Vocal Bursts Workshop & Competition, focusing on understanding emotional expression through vocal bursts.",
        "dcterms:title": "Hume-VB Dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2207.03572",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Vocal Bursts"
        ],
        "dcat:keyword": [
            "Vocalizations",
            "Emotion categories",
            "Affective computing",
            "Audio dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Justin Salamon",
            "Christopher Jacoby",
            "Juan Pablo Bello"
        ],
        "dcterms:description": "The UrbanSound8k dataset is a collection of urban sound recordings, categorized into 10 classes, aimed at facilitating research in urban sound classification.",
        "dcterms:title": "UrbanSound8k Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sound Classification",
            "Urban Sound Research"
        ],
        "dcat:keyword": [
            "Urban sounds",
            "Audio dataset",
            "Sound classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Sound classification"
        ]
    }
]