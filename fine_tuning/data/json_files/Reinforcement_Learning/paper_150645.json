[
    {
        "dcterms:creator": [],
        "dcterms:description": "A benchmark for evaluating deep reinforcement learning methods, specifically in various Atari 2600 games, allowing for detailed analysis of agents' decision-making through attention visualization.",
        "dcterms:title": "Atari 2600",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Deep Reinforcement Learning",
            "Game tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Decision Making Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "M. Hessel",
            "J. Modayil",
            "H. Van Hasselt",
            "T. Schaul",
            "G. Ostrovski",
            "W. Dabney",
            "D. Horgan",
            "B. Piot",
            "M. Azar",
            "D. Silver"
        ],
        "dcterms:description": "A deep reinforcement learning algorithm that combines various improvements to achieve high performance on the Atari 2600 benchmark.",
        "dcterms:title": "Rainbow",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Network",
            "Reinforcement Learning",
            "Atari Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Performance Benchmarking"
        ]
    },
    {
        "dcterms:creator": [
            "L. Chen",
            "K. Lu",
            "A. Rajeswaran",
            "K. Lee",
            "A. Grover",
            "M. Laskin",
            "P. Abbeel",
            "A. Srinivas",
            "I. Mordatch"
        ],
        "dcterms:description": "A reinforcement learning method that utilizes sequence modeling to improve decision-making processes.",
        "dcterms:title": "Decision Transformer",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Sequence Modeling"
        ],
        "dcat:keyword": [
            "Transformer",
            "Reinforcement Learning",
            "Sequence Modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision Making",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "K.-H. Lee",
            "O. Nachum",
            "M. Yang",
            "L. Y. Lee",
            "D. Freeman",
            "W. Xu",
            "S. Guadarrama",
            "I. S. Fischer",
            "E. Jang",
            "H. Michalewski",
            "I. Mordatch"
        ],
        "dcterms:description": "A method that extends the Decision Transformer framework to multiple games, allowing for generalized learning across different environments.",
        "dcterms:title": "Multi-Game Decision Transformers",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Task Learning"
        ],
        "dcat:keyword": [
            "Multi-Game Learning",
            "Decision Transformer",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Task Learning",
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "A. P. Badia",
            "B. Piot",
            "S. Kapturowski",
            "P. Sprechmann",
            "A. Vitvitskyi",
            "D. Guo",
            "C. Blundell"
        ],
        "dcterms:description": "A method that outperforms human benchmarks on the Atari 2600, demonstrating advanced capabilities in reinforcement learning.",
        "dcterms:title": "Human-level Atari",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Human Benchmark",
            "Atari Games",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Performance Benchmarking"
        ]
    },
    {
        "dcterms:creator": [
            "T. Schaul",
            "J. Quan",
            "I. Antonoglou",
            "D. Silver"
        ],
        "dcterms:description": "A technique that enhances the learning efficiency of reinforcement learning agents by prioritizing important experiences.",
        "dcterms:title": "Prioritized Experience Replay",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Experience Replay"
        ],
        "dcat:keyword": [
            "Experience Replay",
            "Reinforcement Learning",
            "Prioritization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Experience Learning"
        ]
    },
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "W. Dabney",
            "R. Munos"
        ],
        "dcterms:description": "A perspective on reinforcement learning that focuses on the distribution of returns rather than just the expected value.",
        "dcterms:title": "Distributional RL",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Distributional Learning"
        ],
        "dcat:keyword": [
            "Distributional Learning",
            "Reinforcement Learning",
            "Returns Distribution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Value Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Fortunato",
            "M. G. Azar",
            "B. Piot",
            "J. Menick",
            "M. Hessel",
            "I. Osband",
            "A. Graves",
            "V. Mnih",
            "R. Munos",
            "D. Hassabis",
            "O. Pietquin",
            "C. Blundell",
            "S. Legg"
        ],
        "dcterms:description": "A method that introduces noise into the network to enhance exploration capabilities in reinforcement learning.",
        "dcterms:title": "Noisy Networks",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Exploration",
            "Noisy Networks",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Exploration",
            "Reinforcement Learning"
        ]
    }
]