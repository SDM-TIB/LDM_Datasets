[
    {
        "dcterms:creator": [
            "Yuntao Bai",
            "Andy Jones",
            "Kamal Ndousse",
            "Amanda Askell",
            "Anna Chen",
            "Nova DasSarma",
            "Dawn Drain",
            "Stanislav Fort",
            "Deep Ganguli",
            "Tom Henighan",
            "Nicholas Joseph",
            "Saurav Kadavath",
            "Jackson Kernion",
            "Tom Conerly",
            "Sheer El-Showk",
            "Nelson Elhage",
            "Zac Hatfield-Dodds",
            "Danny Hernandez",
            "Tristan Hume",
            "Scott Johnston",
            "Shauna Kravec",
            "Liane Lovitt",
            "Neel Nanda",
            "Catherine Olsson",
            "Dario Amodei",
            "Tom Brown",
            "Jack Clark",
            "Sam McCandlish",
            "Chris Olah",
            "Ben Mann",
            "Jared Kaplan"
        ],
        "dcterms:description": "A dataset consisting of attempts from individuals to elicit inappropriate responses from the model, such as seeking advice on engaging in illegal activities or using offensive language.",
        "dcterms:title": "red-team-attempts",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/2204.05862",
        "dcat:theme": [
            "AI Safety",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Adversarial examples",
            "Language model safety",
            "Human-AI interaction"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/2204.05862",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Adversarial Testing"
        ]
    },
    {
        "dcterms:creator": [
            "Yuntao Bai",
            "Andy Jones",
            "Kamal Ndousse",
            "Amanda Askell",
            "Anna Chen",
            "Nova DasSarma",
            "Dawn Drain",
            "Stanislav Fort",
            "Deep Ganguli",
            "Tom Henighan",
            "Nicholas Joseph",
            "Saurav Kadavath",
            "Jackson Kernion",
            "Tom Conerly",
            "Sheer El-Showk",
            "Nelson Elhage",
            "Zac Hatfield-Dodds",
            "Danny Hernandez",
            "Tristan Hume",
            "Scott Johnston",
            "Shauna Kravec",
            "Liane Lovitt",
            "Neel Nanda",
            "Catherine Olsson",
            "Dario Amodei",
            "Tom Brown",
            "Jack Clark",
            "Sam McCandlish",
            "Chris Olah",
            "Ben Mann",
            "Jared Kaplan"
        ],
        "dcterms:description": "A dataset designed to evaluate the harmlessness of AI responses, containing various prompts that may elicit harmful or inappropriate responses.",
        "dcterms:title": "harmless-base",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/2204.05862",
        "dcat:theme": [
            "AI Safety",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Harmlessness evaluation",
            "Language model safety",
            "Human-AI interaction"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/2204.05862",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Safety Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Yuntao Bai",
            "Andy Jones",
            "Kamal Ndousse",
            "Amanda Askell",
            "Anna Chen",
            "Nova DasSarma",
            "Dawn Drain",
            "Stanislav Fort",
            "Deep Ganguli",
            "Tom Henighan",
            "Nicholas Joseph",
            "Saurav Kadavath",
            "Jackson Kernion",
            "Tom Conerly",
            "Sheer El-Showk",
            "Nelson Elhage",
            "Zac Hatfield-Dodds",
            "Danny Hernandez",
            "Tristan Hume",
            "Scott Johnston",
            "Shauna Kravec",
            "Liane Lovitt",
            "Neel Nanda",
            "Catherine Olsson",
            "Dario Amodei",
            "Tom Brown",
            "Jack Clark",
            "Sam McCandlish",
            "Chris Olah",
            "Ben Mann",
            "Jared Kaplan"
        ],
        "dcterms:description": "A dataset that includes prompts designed to elicit helpful responses from AI, focusing on positive and constructive interactions.",
        "dcterms:title": "helpful-base",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/2204.05862",
        "dcat:theme": [
            "AI Safety",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Helpfulness evaluation",
            "Language model safety",
            "Human-AI interaction"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/2204.05862",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Helpfulness Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Reiichiro Nakano",
            "Jacob Hilton",
            "Suchir Balaji",
            "Jeff Wu",
            "Long Ouyang",
            "Christina Kim",
            "Christopher Hesse",
            "Shantanu Jain",
            "Vineet Kosaraju",
            "William Saunders",
            "Xu Jiang",
            "Karl Cobbe",
            "Tyna Eloundou",
            "Gretchen Krueger",
            "Kevin Button",
            "Matthew Knight",
            "Benjamin Chess",
            "John Schulman"
        ],
        "dcterms:description": "A dataset providing a distribution of non-adversarial general web queries collected from WebGPT users.",
        "dcterms:title": "openai/webgpt_comparisons",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Web Queries",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "WebGPT",
            "Question answering",
            "Human-AI interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yizhong Wang",
            "Yeganeh Kordi",
            "Swaroop Mishra",
            "Alisa Liu",
            "Noah A. Smith",
            "Daniel Khashabi",
            "Hannaneh Hajishirzi"
        ],
        "dcterms:description": "A large dataset of model-generated instructions aimed at aligning language models with self-generated instructions.",
        "dcterms:title": "yizhongw/self_instruct",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Instruction Generation",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Self-instruction",
            "Language model alignment",
            "Human-AI interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    }
]