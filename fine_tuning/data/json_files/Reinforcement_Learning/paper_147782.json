[
    {
        "dcterms:creator": [
            "Marcin Andrychowicz",
            "Filip Wolski",
            "Alex Ray",
            "Jonas Schneider",
            "Rachel Fong",
            "Peter Welinder",
            "Bob McGrew",
            "Josh Tobin",
            "Pieter Abbeel",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "The Hindsight Experience Replay (HER) method allows a neural network policy to generalize across sparse, goal-oriented rewards by augmenting the experience replay dataset with alternate goals.",
        "dcterms:title": "Hindsight Experience Replay (HER)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1707.01495",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-oriented Learning"
        ],
        "dcat:keyword": [
            "Experience Replay",
            "Goal Generalization",
            "Sparse Rewards"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1707.01495",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Goal Achievement",
            "Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Timothy P. Lillicrap",
            "Jonathan J. Hunt",
            "Alexander Pritzel",
            "Nicolas Heess",
            "Tom Erez",
            "Yuval Tassa",
            "David Silver",
            "Daan Wierstra"
        ],
        "dcterms:description": "DDPG is an off-policy policy-gradient algorithm for deterministic policies, used for continuous control tasks.",
        "dcterms:title": "DDPG (Deep Deterministic Policy Gradient)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1509.02971",
        "dcat:theme": [
            "Reinforcement Learning",
            "Continuous Control"
        ],
        "dcat:keyword": [
            "Policy Gradient",
            "Deterministic Policies",
            "Continuous Actions"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1509.02971",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A. Rusu",
            "Joel Veness",
            "Marc G. Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K. Fidjeland",
            "Georg Ostrovski",
            "Stig Petersen",
            "Charles Beattie",
            "Amir Sadik",
            "Ioannis Antonoglou",
            "Helen King",
            "Dharshan Kumaran",
            "Daan Wierstra",
            "Shane Legg",
            "Demis Hassabis"
        ],
        "dcterms:description": "DQN employs Q-learning with a replay dataset and other techniques to learn an optimal Q function for playing games.",
        "dcterms:title": "Deep Q-Networks (DQN)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Playing"
        ],
        "dcat:keyword": [
            "Q-Learning",
            "Deep Learning",
            "Game AI"
        ],
        "dcat:landingPage": "https://storage.googleapis.com/deepmind-media/dqn/DQNNaturePaper.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "A. Castelletti",
            "F. Pianosi",
            "M. Restelli"
        ],
        "dcterms:description": "Fitted Q-Iteration is a method for solving multi-objective Markov decision problems using tree-based approaches.",
        "dcterms:title": "Fitted Q-Iteration",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-objective Learning"
        ],
        "dcat:keyword": [
            "Q-Iteration",
            "Multi-objective Optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-objective Decision Making"
        ]
    },
    {
        "dcterms:creator": [
            "Hossam Mossalam",
            "Yannis M. Assael",
            "Diederik M. Roijers",
            "Shimon Whiteson"
        ],
        "dcterms:description": "Multi-objective Deep Reinforcement Learning focuses on learning policies that can optimize multiple objectives simultaneously.",
        "dcterms:title": "Multi-objective Deep Reinforcement Learning",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1610.02707",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-objective Learning"
        ],
        "dcat:keyword": [
            "Multi-objective Optimization",
            "Policy Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1610.02707",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-objective Decision Making"
        ]
    }
]