[
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI dataset consists of RGB images and lidar data collected from a moving vehicle in urban, rural, and highway environments, used for evaluating computer vision algorithms in autonomous driving.",
        "dcterms:title": "KITTI Dataset",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "RGB images",
            "Lidar data",
            "Autonomous vehicles",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Lidar",
        "mls:task": [
            "Object Detection",
            "Image Compression",
            "Lidar Compression"
        ]
    },
    {
        "dcterms:creator": [
            "Pei Sun",
            "Henrik Kretzschmar",
            "Xerxes Dotiwalla",
            "Aurelien Chouard",
            "Vijaysai Patnaik",
            "Paul Tsui",
            "James Guo",
            "Yin Zhou",
            "Yuning Chai",
            "Benjamin Caine"
        ],
        "dcterms:description": "The Waymo Open Perception Dataset provides a large-scale dataset for autonomous driving research, containing diverse sensor data including images and lidar point clouds.",
        "dcterms:title": "Waymo Open Perception Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Sensor data",
            "Lidar",
            "Images",
            "Autonomous vehicles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image, Lidar",
        "mls:task": [
            "Object Detection",
            "Image Compression",
            "Lidar Compression"
        ]
    },
    {
        "dcterms:creator": [
            "Alexey Dosovitskiy",
            "German Ros",
            "Felipe Codevilla",
            "Antonio Lopez",
            "Vladlen Koltun"
        ],
        "dcterms:description": "CARLA is an open urban driving simulator designed for the development, training, and validation of autonomous driving systems, providing a rich environment for testing algorithms.",
        "dcterms:title": "CARLA Simulator",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Simulation",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Driving simulator",
            "Urban environments",
            "Autonomous vehicles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Simulation",
            "Testing Algorithms"
        ]
    },
    {
        "dcterms:creator": [
            "Dengxin Dai",
            "Luc Van Gool"
        ],
        "dcterms:description": "The Nighttime Driving Dataset is designed for semantic image segmentation tasks, focusing on adapting models trained on daytime data to nighttime conditions.",
        "dcterms:title": "Nighttime Driving Dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Nighttime images",
            "Semantic segmentation",
            "Model adaptation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Blum",
            "PE. Sarlin",
            "J. Nieto"
        ],
        "dcterms:description": "The Fishyscapes Benchmark is a dataset for evaluating the robustness of semantic segmentation models, particularly in identifying blind spots in model performance.",
        "dcterms:title": "Fishyscapes Benchmark",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Semantic Segmentation"
        ],
        "dcat:keyword": [
            "Semantic segmentation",
            "Benchmark",
            "Robustness evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Semantic Segmentation"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C. Lawrence Zitnick"
        ],
        "dcterms:description": "The COCO dataset is a large-scale dataset for object detection, segmentation, and captioning, containing images with complex scenes and multiple objects.",
        "dcterms:title": "COCO Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Object detection",
            "Segmentation",
            "Image captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection",
            "Image Segmentation"
        ]
    }
]