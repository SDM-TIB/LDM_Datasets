[
    {
        "dcterms:creator": [
            "M. G Bellemare",
            "Y. Naddaf",
            "J. Veness",
            "M. Bowling"
        ],
        "dcterms:description": "The Arcade Learning Environment (ALE) is a benchmark for evaluating reinforcement learning algorithms, providing a variety of Atari 2600 games as environments for agents to learn and compete.",
        "dcterms:title": "Arcade Learning Environment (ALE)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement learning benchmark",
            "Game environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Reinforcement learning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Ernst",
            "P. Geurts",
            "L. Wehenkel"
        ],
        "dcterms:description": "Fitted Q-Iteration (FQI) is a batch reinforcement learning algorithm that approximates the Q-value function using regression techniques, allowing for learning from a fixed dataset of experiences.",
        "dcterms:title": "Fitted Q-Iteration (FQI)",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Batch Learning"
        ],
        "dcat:keyword": [
            "Batch reinforcement learning",
            "Q-learning",
            "Function approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value function approximation",
            "Policy improvement"
        ]
    },
    {
        "dcterms:creator": [
            "J. Langford",
            "T. Zhang"
        ],
        "dcterms:description": "Contextual Bandits is a framework for decision-making problems where the agent must choose actions based on context information, optimizing rewards in a sequential manner.",
        "dcterms:title": "Contextual Bandits",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Multi-armed bandits",
            "Contextual information",
            "Reward optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision making",
            "Reward maximization"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "K. Kavukcuoglu",
            "D. Silver",
            "A. Rusu",
            "J. Veness",
            "M. G Bellemare",
            "A. Graves",
            "M. Riedmiller",
            "A. K Fidjeland",
            "G. Ostrovski"
        ],
        "dcterms:description": "Deep Q-Network (DQN) is a reinforcement learning algorithm that combines Q-learning with deep neural networks, enabling agents to learn optimal policies directly from high-dimensional sensory inputs.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Neural networks",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Policy learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Chen",
            "N. Jiang"
        ],
        "dcterms:description": "Batch Reinforcement Learning refers to methods that learn from a fixed dataset of experiences, optimizing policies without direct interaction with the environment.",
        "dcterms:title": "Batch Reinforcement Learning",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Batch Learning"
        ],
        "dcat:keyword": [
            "Batch learning",
            "Policy optimization",
            "Data efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy improvement",
            "Value function approximation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Ross",
            "G. Gordon",
            "D. Bagnell"
        ],
        "dcterms:description": "Monte Carlo Tree Search (MCTS) is a heuristic search algorithm for decision processes, particularly in game playing, that uses random sampling of the search space to make decisions.",
        "dcterms:title": "Monte Carlo Tree Search (MCTS)",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Search Algorithms"
        ],
        "dcat:keyword": [
            "Tree search",
            "Game AI",
            "Sampling methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision making",
            "Game playing"
        ]
    }
]