[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "L. J. Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Ilya Sutskever"
        ],
        "dcterms:description": "OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms. It provides a variety of environments for testing and benchmarking.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Benchmarking",
            "Toolkit"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "MuJoCo environments include HalfCheetah, Hopper, Walker2d, Ant, and Humanoid, which are used for continuous control tasks in reinforcement learning.",
        "dcterms:title": "MuJoCo environments",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation"
        ],
        "dcat:keyword": [
            "Continuous control",
            "Robotics",
            "Simulation environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Scott Fujimoto",
            "Herke van Hoof",
            "David Meger"
        ],
        "dcterms:description": "TD3 is a reinforcement learning algorithm that improves upon DDPG by addressing function approximation error and introducing several heuristics.",
        "dcterms:title": "TD3",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithm"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Off-Policy",
            "Continuous control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Tuomas Haarnoja",
            "Aurick Zhou",
            "G. Edward Dahl",
            "Pieter Abbeel"
        ],
        "dcterms:description": "SAC is an off-policy reinforcement learning algorithm that incorporates maximum entropy to improve exploration and stability.",
        "dcterms:title": "SAC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithm"
        ],
        "dcat:keyword": [
            "Maximum entropy",
            "Off-Policy",
            "Continuous control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]