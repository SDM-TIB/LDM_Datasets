[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "The dense reward case of LunarLanderContinuous-v2 is the standard environment provided by OpenAI Gym library, where the state space consists of an eight-dimensional continuous vector with inertial states of the lander, and the action space consists of a two-dimensional continuous vector controlling main and side thrusters.",
        "dcterms:title": "LunarLanderContinuous-v2",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation"
        ],
        "dcat:keyword": [
            "OpenAI Gym",
            "Lunar Lander",
            "Continuous Control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "v2",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Shital Shah",
            "Debadeepta Dey",
            "Chris Lovett",
            "Ashish Kapoor"
        ],
        "dcterms:description": "Microsoft AirSim is a high-fidelity visual and physical simulation environment for autonomous vehicles, allowing for realistic training and testing of algorithms in a simulated setting.",
        "dcterms:title": "Microsoft AirSim",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1705.05065",
        "dcat:theme": [
            "Simulation",
            "Autonomous Vehicles"
        ],
        "dcat:keyword": [
            "High-Fidelity Simulation",
            "Autonomous Driving",
            "Robotics"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1705.05065",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Autonomous Vehicle Training"
        ]
    },
    {
        "dcterms:creator": [
            "Vinicius G. Goecks",
            "Gregory M. Gremillion",
            "Vernon J. Lawhern",
            "John Valasek",
            "Nicholas R. Waytowich"
        ],
        "dcterms:description": "Expert Demonstrations from Goecks et al. are used to provide human-provided exemplar behaviors for training autonomous systems, enhancing the learning process through demonstrations.",
        "dcterms:title": "Expert Demonstrations (from Goecks et al.)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1810.11545",
        "dcat:theme": [
            "Learning from Demonstrations",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "Human Demonstrations",
            "Safe Training",
            "Autonomous Systems"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1810.11545",
        "dcterms:hasVersion": "",
        "dcterms:format": "Demonstration Data",
        "mls:task": [
            "Behavior Cloning",
            "Reinforcement Learning"
        ]
    }
]