[
    {
        "dcterms:creator": [
            "N. Hansen",
            "X. Wang",
            "H. Su"
        ],
        "dcterms:description": "The TD-MPC framework combines model-free and model-based methods to achieve superior sample efficiency and improved performance on various tasks.",
        "dcterms:title": "Temporal Difference Learning for Model Predictive Control (TD-MPC)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Model Predictive Control"
        ],
        "dcat:keyword": [
            "Temporal Difference Learning",
            "Model Predictive Control",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Tassa",
            "Y. Doron",
            "A. Muldal",
            "T. Erez",
            "Y. Li",
            "D. de Las Casas",
            "D. Budden",
            "A. Abdolmaleki",
            "J. Merel",
            "A. Lefrancq",
            "T.P. Lillicrap",
            "M.A. Riedmiller"
        ],
        "dcterms:description": "The DeepMind Control Suite provides a set of continuous control tasks for reinforcement learning research.",
        "dcterms:title": "DeepMind Control suite (DMControl)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Tasks"
        ],
        "dcat:keyword": [
            "Control Suite",
            "Reinforcement Learning",
            "Continuous Control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Schrittwieser",
            "I. Antonoglou",
            "T. Hubert",
            "K. Simonyan",
            "L. Sifre",
            "S. Schmitt",
            "A. Guez",
            "E. Lockhart",
            "D. Hassabis",
            "T. Graepel"
        ],
        "dcterms:description": "MuZero is an algorithm that learns to play games by planning with a learned model, achieving state-of-the-art performance in various environments.",
        "dcterms:title": "MuZero",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Planning"
        ],
        "dcat:keyword": [
            "Planning",
            "Reinforcement Learning",
            "Game Playing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Hafner",
            "T. Lillicrap",
            "J. Ba",
            "M. Norouzi"
        ],
        "dcterms:description": "Dreamer is an algorithm that learns to control by imagining future states and rewards, enabling effective planning and decision-making.",
        "dcterms:title": "Dreamer",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Planning"
        ],
        "dcat:keyword": [
            "Imagination",
            "Planning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Hafner",
            "T.P. Lillicrap",
            "M. Norouzi",
            "J. Ba"
        ],
        "dcterms:description": "Dreamer-v2 is an improved version of Dreamer that focuses on mastering Atari games using discrete world models.",
        "dcterms:title": "Dreamer-v2",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Playing"
        ],
        "dcat:keyword": [
            "Atari Games",
            "World Models",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Hafner",
            "T. Lillicrap",
            "I. Fischer",
            "R. Villegas",
            "D. Ha",
            "H. Lee",
            "J. Davidson"
        ],
        "dcterms:description": "PlaNet is a model-based reinforcement learning algorithm that learns latent dynamics for planning from pixel observations.",
        "dcterms:title": "PlaNet",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Planning"
        ],
        "dcat:keyword": [
            "Latent Dynamics",
            "Planning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Haarnoja",
            "A. Zhou",
            "P. Abbeel",
            "S. Levine"
        ],
        "dcterms:description": "Soft Actor-Critic (SAC) is an off-policy maximum entropy deep reinforcement learning algorithm that utilizes a stochastic actor.",
        "dcterms:title": "Soft Actor-Critic (SAC)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Off-policy",
            "Maximum Entropy",
            "Deep Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "H. Sikchi",
            "W. Zhou",
            "D. Held"
        ],
        "dcterms:description": "LOOP is a framework for learning off-policy with online planning, enhancing the efficiency of reinforcement learning.",
        "dcterms:title": "LOOP",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Off-policy Learning",
            "Online Planning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]