[
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan"
        ],
        "dcterms:description": "A human-labeled dataset used to train models to be helpful and harmless, focusing on aligning language models with human preferences.",
        "dcterms:title": "Anthropic Helpfulness and Harmlessness dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2204.05862",
        "dcat:theme": [
            "Reinforcement Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Helpfulness",
            "Harmlessness",
            "Human Feedback",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Alignment",
            "Preference Learning"
        ]
    },
    {
        "dcterms:creator": [
            "E. Beeching",
            "Y. Belkada",
            "K. Rasul",
            "L. Tunstall",
            "L. von Werra",
            "N. Rajani",
            "N. Lambert"
        ],
        "dcterms:description": "A dataset containing questions and answers from the StackExchange platform, used for training models in question answering tasks.",
        "dcterms:title": "StackExchange dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/blog/stackllama",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "StackExchange",
            "Question Answering",
            "User-generated Content"
        ],
        "dcat:landingPage": "https://huggingface.co/blog/stackllama",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "E. Beeching",
            "Y. Belkada",
            "K. Rasul",
            "L. Tunstall",
            "L. von Werra",
            "N. Rajani",
            "N. Lambert"
        ],
        "dcterms:description": "A dataset used for summarization tasks, containing labeled responses for evaluating the performance of summarization models.",
        "dcterms:title": "TLDR dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/blog/stackllama",
        "dcat:theme": [
            "Summarization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Summarization",
            "Text Summarization",
            "User-generated Content"
        ],
        "dcat:landingPage": "https://huggingface.co/blog/stackllama",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "E. Beeching",
            "Y. Belkada",
            "K. Rasul",
            "L. Tunstall",
            "L. von Werra",
            "N. Rajani",
            "N. Lambert"
        ],
        "dcterms:description": "A dataset used for training models to evaluate helpfulness and harmlessness in responses, similar to the HH dataset.",
        "dcterms:title": "Dolly dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/blog/stackllama",
        "dcat:theme": [
            "Reinforcement Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Helpfulness",
            "Harmlessness",
            "Human Feedback",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "https://huggingface.co/blog/stackllama",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Alignment",
            "Preference Learning"
        ]
    }
]