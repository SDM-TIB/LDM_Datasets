To extract datasets from the research paper titled "Work in Progress: Temporally Extended Auxiliary Tasks" by Craig Sherstan et al., I will follow a systematic approach to identify and document the datasets mentioned in the text.

First, I will read through the **abstract, introduction, methods, and experiments sections** to look for any references to datasets. The abstract provides a brief overview of the research, and it may mention specific environments or datasets used for evaluation. 

Next, I will focus on the **introduction** to see if the authors discuss any datasets or environments relevant to their experiments. In this case, they mention using the **VizDoom environment**, which is a customizable 3D first-person environment for reinforcement learning. This indicates that VizDoom is a key dataset or environment for their research.

Moving on to the **methods section**, I will look for any specific datasets or configurations used in their experiments. The authors describe their experimental setup and mention that they evaluate their approach on multiple VizDoom scenarios, including **K-Item 2, Labyrinth 13, and Two Color Maze 5**. These scenarios are crucial as they represent the datasets used for testing the proposed methods.

In the **experiments section**, the authors provide further details about the scenarios and how they were utilized in their experiments. They confirm that the performance was evaluated across these specific VizDoom scenarios, which reinforces their significance as datasets.

Now, I will check the **references section** to find full citations for the VizDoom environment and the specific scenarios mentioned. The citation for the VizDoom environment is:

- **VizDoom**: 
  > Michał Kempka, Marek Wydmuch, Grzegorz Runc, Jakub Toczek, and Wojciech Jaśkowski. *ViZDoom: A Doom-based AI Research Platform for Visual Reinforcement Learning*. In IEEE Conference on Computational Intelligence and Games (CIG), pages 341–348, 2016.

For the specific scenarios, the authors reference the work by Beeching et al. (2019) for the descriptions of the scenarios used in their experiments. The citation is:

- **K-Item 2, Labyrinth 13, Two Color Maze 5**: 
  > Edward Beeching, Christian Wolf, Jilles Dibangoye, and Olivier Simonin. *Deep Reinforcement Learning on a Budget: 3D Control and Reasoning Without a Supercomputer*. arXiv 1904.01806, 2019.

After gathering this information, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets utilized in the research paper.