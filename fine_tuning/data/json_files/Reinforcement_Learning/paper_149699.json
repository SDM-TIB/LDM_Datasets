[
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "A continuous action-space variant of the classic CartPole environment where the agent needs to balance a pole on a moving cart while adapting to continuously varying gravitational force.",
        "dcterms:title": "NS CartPole",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "CartPole",
            "Continuous action space",
            "Non-stationary environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Balancing",
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "The Swing-Up Pendulum environment where the observation space is cluttered with bounded random noises to simulate real-world latency and noise.",
        "dcterms:title": "NS InvertedPendulum",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Inverted Pendulum",
            "Non-stationary environment",
            "Random noise"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Swing-up",
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Q. Gallouédec",
            "N. Cazin",
            "E. Dellandrèa",
            "L. Chen"
        ],
        "dcterms:description": "A high-dimensional robotics environment where a 7 DoFs robotic manipulator must execute optimal actions to reach a continuously moving target location.",
        "dcterms:title": "NS ReachTask",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic manipulation",
            "Dynamic target",
            "Non-stationary environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reaching",
            "Manipulation"
        ]
    },
    {
        "dcterms:creator": [
            "Q. Gallouédec",
            "N. Cazin",
            "E. Dellandrèa",
            "L. Chen"
        ],
        "dcterms:description": "An open-source goal-conditioned environment for robotic learning, providing various tasks for training robotic agents.",
        "dcterms:title": "Panda-Gym",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic learning",
            "Goal-conditioned",
            "Open-source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Goal reaching",
            "Robotic manipulation"
        ]
    }
]