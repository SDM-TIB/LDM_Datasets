[
    {
        "dcterms:creator": [
            "E. Todorov",
            "T. Erez",
            "Y. Tassa"
        ],
        "dcterms:description": "A physics engine for model-based control, used for continuous control tasks in reinforcement learning.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Physics Simulation"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Model-based control",
            "Continuous control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "C. Berner",
            "G. Brockman",
            "B. Chan",
            "V. Cheung",
            "P. Dkebiak",
            "C. Dennison",
            "D. Farhi",
            "Q. Fischer",
            "S. Hashme",
            "C. Hesse"
        ],
        "dcterms:description": "A large-scale deep reinforcement learning environment based on the Dota 2 game, used for training agents in complex strategic gameplay.",
        "dcterms:title": "Dota 2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1912.06680",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Playing"
        ],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Game AI",
            "Strategic gameplay"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "A. P. Badia",
            "M. Mirza",
            "A. Graves",
            "T. Lillicrap",
            "T. Harley",
            "D. Silver",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "A reinforcement learning algorithm that utilizes asynchronous methods to improve training efficiency and performance.",
        "dcterms:title": "A2C",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Asynchronous methods",
            "Deep reinforcement learning",
            "Policy optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "S. Levine",
            "P. Abbeel",
            "M. Jordan",
            "P. Moritz"
        ],
        "dcterms:description": "A method for estimating advantages in reinforcement learning that improves the stability and performance of policy gradient methods.",
        "dcterms:title": "Generalized Advantage Estimation (GAE)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1506.02438",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Advantage estimation",
            "Policy optimization",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "S. Levine",
            "P. Abbeel",
            "M. Jordan",
            "P. Moritz"
        ],
        "dcterms:description": "An optimization algorithm for policy gradient methods that enforces a trust region to ensure stable updates.",
        "dcterms:title": "TRPO",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Trust region optimization",
            "Policy optimization",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "A family of algorithms for policy optimization that improve upon previous methods by using a clipped objective function.",
        "dcterms:title": "PPO",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.06347",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Clipped objective",
            "Policy optimization",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    }
]