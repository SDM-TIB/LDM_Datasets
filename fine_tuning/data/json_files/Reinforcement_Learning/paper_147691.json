[
    {
        "dcterms:creator": [],
        "dcterms:description": "A collection of Atari2600 games used for evaluating deep reinforcement learning agents.",
        "dcterms:title": "Atari2600 games (Breakout, Pacman, Seaquest)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement learning",
            "Game environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A Rusu",
            "Joel Veness",
            "Marc G Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K Fidjeland",
            "Georg Ostrovski"
        ],
        "dcterms:description": "Experience tuples collected from the DQN algorithm, used for training and evaluating reinforcement learning agents.",
        "dcterms:title": "DQN (Deep Q Network) experience tuples",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Experience replay",
            "Reinforcement learning",
            "Deep Q Network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Laurens Van der Maaten",
            "Geoffrey Hinton"
        ],
        "dcterms:description": "t-SNE maps generated from neural activations to visualize the structure of the learned representations in deep reinforcement learning.",
        "dcterms:title": "t-SNE maps",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Dimensionality reduction",
            "Visualization",
            "t-SNE"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A Rusu",
            "Joel Veness",
            "Marc G Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K Fidjeland",
            "Georg Ostrovski"
        ],
        "dcterms:description": "Experience Replay (ER) mechanism used in DQN to store and sample experience tuples for training.",
        "dcterms:title": "Experience Replay (ER)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Experience replay",
            "Reinforcement learning",
            "Deep Q Network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Richard S Sutton",
            "Doina Precup",
            "Satinder Singh"
        ],
        "dcterms:description": "A framework for temporal abstraction in reinforcement learning, defining skills and options.",
        "dcterms:title": "Skills and Options in Reinforcement Learning",
        "dcterms:issued": "1999",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Temporal abstraction",
            "Reinforcement learning",
            "Skills",
            "Options"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "James MacQueen"
        ],
        "dcterms:description": "Clustering results obtained from K-means algorithm applied to the state representations.",
        "dcterms:title": "Clustering results from K-means",
        "dcterms:issued": "1967",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Clustering",
            "K-means",
            "Data analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Tom Zahavy",
            "Nir Ben Zrihem",
            "Shie Mannor"
        ],
        "dcterms:description": "Skills identified by Zahavy et al. (2016) that help in understanding the behavior of DQNs.",
        "dcterms:title": "Skills identified by Zahavy et al. (2016)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Skills",
            "Reinforcement learning",
            "DQN analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]