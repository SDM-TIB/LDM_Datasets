[
    {
        "dcterms:creator": [
            "K-F Lee",
            "H-W Hon"
        ],
        "dcterms:description": "The TIMIT dataset is used for speaker-independent phone recognition and contains 3696 training utterances, 400 validation utterances, and 182 test utterances. The audio waveforms were processed into frames of log mel filterbank spectrograms, resulting in a 123-dimensional input per frame. The targets for each utterance are the sequence of phonemes.",
        "dcterms:title": "TIMIT Dataset",
        "dcterms:issued": "1989",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Phoneme recognition",
            "Speech dataset",
            "Audio processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Phoneme Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Multi-TIMIT dataset is a generated dataset based on the TIMIT dataset, created by mixing male and female voices from TIMIT. It retains the same number of training, validation, and test utterances as the original TIMIT dataset and uses the same target phonemes.",
        "dcterms:title": "Multi-TIMIT Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Multi-speaker dataset",
            "Speech dataset",
            "Audio processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Phoneme Recognition"
        ]
    }
]