[
    {
        "dcterms:creator": [
            "R.A. Vincent",
            "J.R. Peirce"
        ],
        "dcterms:description": "MOVA is a traffic controller designed to reduce delay on isolated junctions by using induction loop detectors to estimate vehicle flow and compute a performance index based on delays.",
        "dcterms:title": "MOVA",
        "dcterms:issued": "1988",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Traffic Signal Control",
            "Intelligent Transportation Systems"
        ],
        "dcat:keyword": [
            "Traffic control",
            "Delay reduction",
            "Induction loop detectors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Traffic Signal Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "S.F. Smith",
            "G.J. Barlow"
        ],
        "dcterms:description": "SurTrac is a decentralized traffic control system where each intersection allocates green time independently based on incoming flows, allowing for the creation of 'green corridors'.",
        "dcterms:title": "SurTrac",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Traffic Signal Control",
            "Intelligent Transportation Systems"
        ],
        "dcat:keyword": [
            "Decentralized control",
            "Traffic management",
            "Green corridors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Traffic Signal Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "P.B. Hunt",
            "D.I. Robertson",
            "R.D. Bretherton",
            "M.C. Royle"
        ],
        "dcterms:description": "SCOOT is an online traffic signal optimization technique that adapts to real-time traffic conditions to improve traffic flow.",
        "dcterms:title": "SCOOT",
        "dcterms:issued": "1982",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Traffic Signal Control",
            "Intelligent Transportation Systems"
        ],
        "dcat:keyword": [
            "Traffic optimization",
            "Real-time control",
            "Traffic management"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Traffic Signal Optimization"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "PTV Vissim is a state-of-the-art commercial traffic simulator that produces a wide variety of traffic demands over different signal controls and road traffic scenarios.",
        "dcterms:title": "PTV Vissim",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Traffic simulation",
            "Traffic demand modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Deep Q-Network (DQN) is a reinforcement learning algorithm that uses a neural network to approximate the Q-value function for decision making in environments.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Q-learning",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Advantage Actor Critic (A2C) is a reinforcement learning algorithm that combines policy gradient methods with value function approximation to improve learning stability.",
        "dcterms:title": "A2C (Advantage Actor Critic)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Policy gradient",
            "Actor-critic methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "H.V. Hasselt"
        ],
        "dcterms:description": "Double DQN is an extension of the DQN algorithm that mitigates the overestimation bias of Q-learning by using two value functions.",
        "dcterms:title": "Double DQN",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Double Q-learning",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Prioritized Experience Replay (PER) is a technique in reinforcement learning that improves the efficiency of learning by prioritizing important experiences.",
        "dcterms:title": "PER (Prioritized Experience Replay)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Experience replay",
            "Prioritization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "K. Kavukcuoglu",
            "D. Silver",
            "A. Graves",
            "I. Antonoglou",
            "D. Wierstra",
            "M. Riedmiller"
        ],
        "dcterms:description": "Atari Games dataset is used in reinforcement learning to train agents to play video games, providing a benchmark for evaluating learning algorithms.",
        "dcterms:title": "Atari Games",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Video games",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Silver",
            "J. Schrittwieser",
            "K. Simonyan",
            "I. Antonoglou",
            "A. Huang",
            "A. Guez",
            "T. Hubert",
            "L. Baker",
            "M. Lai",
            "A. Bolton"
        ],
        "dcterms:description": "The Go dataset is used in reinforcement learning to train agents to play the game of Go, showcasing advanced learning techniques.",
        "dcterms:title": "Go",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement learning",
            "Game playing",
            "Artificial intelligence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]