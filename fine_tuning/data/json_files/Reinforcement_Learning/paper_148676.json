[
    {
        "dcterms:creator": [
            "Alekh Agarwal",
            "Mikael Henaff",
            "Sham Kakade",
            "Wen Sun"
        ],
        "dcterms:description": "A dataset used for the Bidirectional Diabolical Combination Lock task, which is designed to be particularly difficult for exploration in reinforcement learning.",
        "dcterms:title": "Bidirectional Diabolical Combination Lock",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2007.08459",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration"
        ],
        "dcat:keyword": [
            "Exploration",
            "Reinforcement Learning",
            "Combination Lock"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Exploration in Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Wang Chi Cheung",
            "David Simchi-Levi",
            "Ruihao Zhu"
        ],
        "dcterms:description": "A dataset used for the Inventory Control Problem, focusing on managing stock levels across related products with time-varying demands.",
        "dcterms:title": "Inventory Control Problem",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "SSRN Preprint 3397818",
        "dcat:theme": [
            "Operations Research",
            "Inventory Management"
        ],
        "dcat:keyword": [
            "Inventory Control",
            "Reinforcement Learning",
            "Non-Stationarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Inventory Management"
        ]
    },
    {
        "dcterms:creator": [
            "Thomas Jaksch",
            "Ronald Ortner",
            "Peter Auer"
        ],
        "dcterms:description": "A dataset used for the JAO MDP, which provides near-optimal regret bounds for reinforcement learning.",
        "dcterms:title": "JAO MDP",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "10.5555/3157382.3157384",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Processes"
        ],
        "dcat:keyword": [
            "Regret Bounds",
            "Reinforcement Learning",
            "MDP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Goran Radanovic",
            "Rati Devidze",
            "David Parkes",
            "Adish Singla"
        ],
        "dcterms:description": "A dataset used for Multi-Agent RL, focusing on learning to collaborate in Markov decision processes.",
        "dcterms:title": "Multi-Agent RL",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.5555/3327757.3328268",
        "dcat:theme": [
            "Multi-Agent Systems",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Multi-Agent Learning",
            "Collaboration",
            "Markov Decision Processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Multi-Agent Collaboration"
        ]
    },
    {
        "dcterms:creator": [
            "Wang Chi Cheung",
            "David Simchi-Levi",
            "Ruihao Zhu"
        ],
        "dcterms:description": "A dataset used for Non-Stationary MDPs, focusing on reinforcement learning for non-stationary environments.",
        "dcterms:title": "Non-Stationary MDPs",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2006.14389",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Processes"
        ],
        "dcat:keyword": [
            "Non-Stationarity",
            "Reinforcement Learning",
            "MDP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]