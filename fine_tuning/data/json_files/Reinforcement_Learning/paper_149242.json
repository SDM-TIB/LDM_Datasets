[
    {
        "dcterms:creator": [
            "Christopher JCH Watkins",
            "Peter Dayan"
        ],
        "dcterms:description": "A model-free reinforcement learning algorithm that iteratively refines an estimate for the optimal action-value function of an MDP by stochastically visiting many state-action pairs.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Action-value function",
            "MDP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Harold J. Kushner",
            "Dean S. Clark"
        ],
        "dcterms:description": "Methods for stochastic approximation applicable to both constrained and unconstrained systems.",
        "dcterms:title": "Stochastic Approximation",
        "dcterms:issued": "1978",
        "dcterms:language": "",
        "dcterms:identifier": "ISBN 0387903410",
        "dcat:theme": [
            "Stochastic Processes",
            "Optimization"
        ],
        "dcat:keyword": [
            "Stochastic approximation",
            "Constrained systems",
            "Unconstrained systems"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Eyal Even-Dar",
            "Yishay Mansour",
            "Peter Bartlett"
        ],
        "dcterms:description": "Study of learning rates for Q-learning, providing insights into convergence rates.",
        "dcterms:title": "Learning Rates for Q-learning",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Learning rates",
            "Q-learning",
            "Convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Andrei A Rusu",
            "Joel Veness",
            "Marc G Bellemare",
            "Alex Graves",
            "Martin Riedmiller",
            "Andreas K Fidjeland",
            "Georg Ostrovski"
        ],
        "dcterms:description": "A study demonstrating human-level control through deep reinforcement learning using a deep Q-network.",
        "dcterms:title": "Human-level Control through Deep Reinforcement Learning",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Deep Learning",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Deep Q-network",
            "Atari games",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Csaba Szepesv√°ri",
            "Michael L Littman"
        ],
        "dcterms:description": "Analysis of generalized Markov decision processes and the development of dynamic programming and reinforcement learning algorithms.",
        "dcterms:title": "Generalized Markov Decision Processes",
        "dcterms:issued": "1996",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Dynamic Programming"
        ],
        "dcat:keyword": [
            "Generalized MDPs",
            "Dynamic programming",
            "Reinforcement learning algorithms"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John N Tsitsiklis"
        ],
        "dcterms:description": "Exploration of asynchronous stochastic approximation and its application to Q-learning.",
        "dcterms:title": "Asynchronous Stochastic Approximation and Q-learning",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Processes",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Asynchronous algorithms",
            "Q-learning",
            "Stochastic approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Vivek S Borkar",
            "Sean P Meyn"
        ],
        "dcterms:description": "An analysis of the convergence of stochastic approximation and reinforcement learning using the ODE method.",
        "dcterms:title": "The ODE Method for Convergence of Stochastic Approximation and Reinforcement Learning",
        "dcterms:issued": "2000",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Processes",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Convergence",
            "Stochastic approximation",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Herbert Robbins",
            "Sutton Monro"
        ],
        "dcterms:description": "A foundational work on stochastic approximation methods.",
        "dcterms:title": "A Stochastic Approximation Method",
        "dcterms:issued": "1951",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Stochastic Processes",
            "Optimization"
        ],
        "dcat:keyword": [
            "Stochastic approximation",
            "Optimization methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]