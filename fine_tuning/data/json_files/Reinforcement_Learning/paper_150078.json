[
    {
        "dcterms:creator": [
            "Triantafyllos Afouras",
            "Joon Son Chung",
            "Andrew Senior",
            "Oriol Vinyals",
            "Andrew Zisserman"
        ],
        "dcterms:description": "The LRS2-2Mix dataset is created from the LRS2 corpus, containing thousands of video clips acquired through BBC. It includes a significant amount of noise and reverberation interference, making it more challenging and closer to real-world environments. The dataset consists of mixed audio from two different speakers with varying signal-to-noise ratios.",
        "dcterms:title": "LRS2-2Mix",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Audio mixing",
            "Noise interference"
        ],
        "dcat:landingPage": "https://drive.google.com/file/d/1dCWD5OIGcj43qTidmU18unoaqo_6QetW/view",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "Joris Cosentino",
            "Manuel Pariente",
            "Samuele Cornell",
            "Antoine Deleforge",
            "Emmanuel Vincent"
        ],
        "dcterms:description": "Libri2Mix is a dataset where the target speech in each mixture audio is randomly selected from a subset of LibriSpeechâ€™s train-100 and mixed with uniformly sampled Loudness Units relative to Full Scale (LUFS) between -25 and -33 dB. Each mixture audio contains two different speakers and has a duration of 3 seconds with an 8 kHz sample rate.",
        "dcterms:title": "Libri2Mix",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2005.11262",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Audio mixing",
            "LibriSpeech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "Gordon Wichern",
            "Joe Antognini",
            "Michael Flynn",
            "Licheng Richard Zhu",
            "Emmett McQuinn",
            "Dwight Crow",
            "Ethan Manilow",
            "Jonathan Le Roux"
        ],
        "dcterms:description": "WHAM! is a dataset that extends speech separation to noisy environments. It includes speeches mixed with noise recorded in various scenes such as cafes, restaurants, and bars, with a signal-to-noise ratio uniformly sampled between -6 dB and 3 dB. Each mixture audio contains two different speakers and has a duration of 4 seconds with an 8 kHz sample rate.",
        "dcterms:title": "WHAM!",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Noisy environments",
            "Audio mixing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    }
]