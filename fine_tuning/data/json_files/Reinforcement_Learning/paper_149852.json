[
    {
        "dcterms:creator": [
            "C. J. C. H. Watkins"
        ],
        "dcterms:description": "A dissertation discussing the learning from delayed rewards, which serves as a foundational work in reinforcement learning.",
        "dcterms:title": "",
        "dcterms:issued": "1989",
        "dcterms:language": "",
        "dcterms:identifier": "http://www.cs.rhul.ac.uk/∼chrisw/new thesis.pdf",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "http://www.cs.rhul.ac.uk/∼chrisw/new thesis.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Abounadi",
            "D. Bertsekas",
            "V. S. Borkar"
        ],
        "dcterms:description": "This paper presents learning algorithms for Markov decision processes with average cost, contributing to the understanding of reinforcement learning in this context.",
        "dcterms:title": "",
        "dcterms:issued": "2001",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. L. Puterman"
        ],
        "dcterms:description": "A comprehensive book on Markov decision processes and discrete stochastic dynamic programming, providing foundational knowledge in the field.",
        "dcterms:title": "",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. P. Bertsekas"
        ],
        "dcterms:description": "This paper introduces a new value iteration method for the average cost dynamic programming problem, enhancing the understanding of dynamic programming in reinforcement learning.",
        "dcterms:title": "",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1137/S0363012995291609",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "https://doi.org/10.1137/S0363012995291609",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "V. S. B. Siddharth Chandak",
            "P. Dodhia"
        ],
        "dcterms:description": "This paper discusses concentration of contractive stochastic approximation and reinforcement learning, contributing to the theoretical foundations of these methods.",
        "dcterms:title": "",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2106.14308",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "https://arxiv.org/abs/2106.14308",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Zhang",
            "Z. Zhang",
            "S. T. Maguluri"
        ],
        "dcterms:description": "This paper provides a finite sample analysis of average-reward Q-learning, contributing to the understanding of Q-learning in reinforcement learning.",
        "dcterms:title": "",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper/2021/file/096ffc299200f51751b08da6d865ae95-Paper.pdf",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper/2021/file/096ffc299200f51751b08da6d865ae95-Paper.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Tsitsiklis"
        ],
        "dcterms:description": "This technical report discusses asynchronous stochastic approximation and Q-learning, providing insights into these algorithms.",
        "dcterms:title": "",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "http://www.springerlink.com/index/QX335286076X3566.pdf",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "http://www.springerlink.com/index/QX335286076X3566.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]