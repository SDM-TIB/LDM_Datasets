To extract datasets from the research paper titled "Estimation of Appearance and Occupancy Information in Bird’s Eye View from Surround Monocular Images" by Sarthak Sharma et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.

First, I will read through the **abstract, introduction, methodology, and experiments sections** of the paper. The abstract mentions that the authors tested their approach on a synthetic dataset generated from CARLA, which indicates that there is at least one dataset to extract.

Next, I will look for specific mentions of datasets in the **introduction** and **experiments sections**. In the introduction, the authors discuss the use of a novel representation for capturing appearance and occupancy information, but I need to confirm the datasets used for training and testing.

In the **experiments section**, the authors explicitly mention that they tested their method on a synthetic dataset generated from CARLA. They also refer to the NuScenes dataset for generating training data. This gives me two datasets to document:

1. **CARLA Dataset**: This dataset is used for generating synthetic data for training and testing the proposed method. The authors mention that they collected driving data on routes from eight publicly available virtual towns in CARLA.

2. **NuScenes Dataset**: This dataset is referenced for generating real-world training data for the proposed architecture. The authors describe a pipeline for generating appearance information from the NuScenes dataset.

Now, I will check the **References section** to find the full citations for these datasets:

- For the **CARLA Dataset**, the citation is:
  > Dosovitskiy, A., Ros, G., Codevilla, F., Lopez, A., & Koltun, V. (2017). *CARLA: An open urban driving simulator*. In Conference on robot learning (pp. 1–16).

- For the **NuScenes Dataset**, the citation is:
  > Caesar, H., Bankiti, V., Lang, A. H., Vora, S., Liong, V. E., Xu, Q., Krishnan, A., Pan, Y., Baldan, G., & Beijbom, O. (2020). *NuScenes: A multimodal dataset for autonomous driving*. In Proceedings of the IEEE/CVF conference on computer vision and pattern recognition (pp. 11 621–11 631).

Having identified the datasets and their citations, I will now prepare to compile this information into a structured format for further processing or review.