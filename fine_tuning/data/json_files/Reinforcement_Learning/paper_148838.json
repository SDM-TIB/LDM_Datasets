[
    {
        "dcterms:creator": [
            "C. Busso",
            "M. Bulut",
            "C.-C. Lee",
            "A. Kazemzadeh",
            "E. Mower",
            "S. Kim",
            "J. N. Chang",
            "S. Lee",
            "S. S. Narayanan"
        ],
        "dcterms:description": "The IEMOCAP dataset features five sessions; each session includes speech segments from two speakers and is labelled with nine emotional categories. However, we use happiness, sadness, anger, and neutral for consistency with the literature.",
        "dcterms:title": "IEMOCAP",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1007/s10579-008-9076-6",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Classification"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Speech segments",
            "Emotion categories"
        ],
        "dcat:landingPage": "https://doi.org/10.1007/s10579-008-9076-6",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S. Haq",
            "P. J. B. Jackson",
            "J. Edge"
        ],
        "dcterms:description": "The SAVEE dataset is relatively smaller compared to IEMOCAP. It is collected from 4 male speakers and has 8 labels for emotions which we filtered out keeping happiness, sadness, anger, and neutral segments for alignment with IEMOCAP and the literature.",
        "dcterms:title": "SAVEE",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Emotion Classification"
        ],
        "dcat:keyword": [
            "Emotion dataset",
            "Speech segments",
            "Emotion labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]