[
    {
        "dcterms:creator": [
            "A. Köpf",
            "Y. Kilcher",
            "D. von Rütte",
            "S. Anagnostidis",
            "Z.-R. Tam",
            "K. Stevens",
            "A. Barhoum",
            "N. M. Duc",
            "O. Stanley",
            "R. Nagyfi"
        ],
        "dcterms:description": "A crowd-sourced instruction dataset with human-annotated response quality ratings, used to optimize prompts for better alignment with human preferences.",
        "dcterms:title": "OASST1",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.07327",
        "dcat:theme": [
            "Natural Language Processing",
            "Dataset for Instruction Tuning"
        ],
        "dcat:keyword": [
            "Instruction dataset",
            "Human feedback",
            "Response quality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Prompt Optimization",
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan"
        ],
        "dcterms:description": "A dataset containing human preference over the responses' helpfulness and harmfulness, used for training models to be more helpful and less harmful.",
        "dcterms:title": "HH-RLHF",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2204.05862",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Human Feedback",
            "Response Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Evaluation",
            "Alignment with Human Preferences"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "W.-L. Chiang",
            "Y. Sheng",
            "S. Zhuang",
            "Z. Wu",
            "Y. Zhuang",
            "Z. Lin",
            "Z. Li",
            "D. Li",
            "E. Xing"
        ],
        "dcterms:description": "A dataset collected from human interactions on the Chatbot Arena leaderboard, used to evaluate and improve chatbot performance.",
        "dcterms:title": "Chatbot Arena Conversations",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.05685",
        "dcat:theme": [
            "Conversational AI",
            "Chatbot Evaluation"
        ],
        "dcat:keyword": [
            "Chatbot dataset",
            "Human interactions",
            "Performance evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Chatbot Evaluation",
            "Performance Improvement"
        ]
    },
    {
        "dcterms:creator": [
            "B. Peng",
            "C. Li",
            "P. He",
            "M. Galley",
            "J. Gao"
        ],
        "dcterms:description": "A dataset used for instruction tuning with GPT-4, focusing on generating high-quality responses based on human preferences.",
        "dcterms:title": "Alpaca-GPT4",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2304.03277",
        "dcat:theme": [
            "Instruction Tuning",
            "Human Preference Learning"
        ],
        "dcat:keyword": [
            "Instruction tuning",
            "GPT-4",
            "Response generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following",
            "Response Generation"
        ]
    }
]