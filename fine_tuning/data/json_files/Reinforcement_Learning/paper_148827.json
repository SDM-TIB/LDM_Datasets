[
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "Y. Naddaf",
            "J. Veness",
            "M. Bowling"
        ],
        "dcterms:description": "An evaluation platform for general agents that includes a variety of Atari games.",
        "dcterms:title": "Atari Games",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari",
            "Game Environment",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "K. Cobbe",
            "O. Klimov",
            "C. Hesse",
            "T. Kim",
            "J. Schulman"
        ],
        "dcterms:description": "A benchmark designed to quantify the generalization ability of reinforcement learning methods across different levels and difficulties.",
        "dcterms:title": "CoinRun",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Generalization"
        ],
        "dcat:keyword": [
            "Generalization",
            "Benchmark",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Generalization Testing",
            "Level Completion"
        ]
    },
    {
        "dcterms:creator": [
            "S. Reddy",
            "A. D. Dragan",
            "S. Levine"
        ],
        "dcterms:description": "A method for imitation learning that utilizes regularized behavioral cloning to improve learning from demonstrations.",
        "dcterms:title": "SQIL",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1905.11108",
        "dcat:theme": [
            "Imitation Learning",
            "Behavioral Cloning"
        ],
        "dcat:keyword": [
            "Imitation Learning",
            "Behavioral Cloning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1905.11108",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Imitation Learning"
        ]
    },
    {
        "dcterms:creator": [
            "T. Kipf",
            "Y. Li",
            "H. Dai",
            "V. Zambaldi",
            "A. Sanchez-Gonzalez",
            "E. Grefenstette",
            "P. Kohli",
            "P. Battaglia"
        ],
        "dcterms:description": "A framework for compositional imitation learning and execution that allows for the learning of complex tasks.",
        "dcterms:title": "ComPILE",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Imitation Learning",
            "Compositional Learning"
        ],
        "dcat:keyword": [
            "Compositional Learning",
            "Imitation Learning",
            "Task Execution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task Learning",
            "Imitation Learning"
        ]
    },
    {
        "dcterms:creator": [
            "P. Bacon",
            "J. Harb",
            "D. Precup"
        ],
        "dcterms:description": "An architecture that allows for the learning of options in reinforcement learning, enabling temporal abstraction.",
        "dcterms:title": "OptionCritic",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Temporal Abstraction"
        ],
        "dcat:keyword": [
            "Options",
            "Reinforcement Learning",
            "Temporal Abstraction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Option Learning",
            "Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Ho",
            "S. Ermon"
        ],
        "dcterms:description": "A method for imitation learning that uses generative adversarial networks to learn from demonstrations.",
        "dcterms:title": "GAIL",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1606.03476",
        "dcat:theme": [
            "Imitation Learning",
            "Generative Models"
        ],
        "dcat:keyword": [
            "Generative Adversarial Networks",
            "Imitation Learning",
            "Adversarial Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1606.03476",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Imitation Learning"
        ]
    },
    {
        "dcterms:creator": [
            "B. D. Argall",
            "S. Chernova",
            "M. Veloso",
            "B. Browning"
        ],
        "dcterms:description": "A survey that reviews various approaches to robot learning from demonstration.",
        "dcterms:title": "Behavior Cloning (BC)",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Imitation Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Behavior Cloning",
            "Learning from Demonstration",
            "Robotics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Imitation Learning"
        ]
    }
]