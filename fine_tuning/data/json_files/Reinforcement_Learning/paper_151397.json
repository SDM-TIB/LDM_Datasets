[
    {
        "dcterms:creator": [],
        "dcterms:description": "A first-of-its-kind multi-view ego and fixed perception synthetic event-based dataset using multiple dynamic vision sensors within the CARLA simulator, recorded across diverse lighting and weather conditions with domain shifts, featuring various classes of objects and comprehensive annotations.",
        "dcterms:title": "SEVD (Synthetic Event-based Vision Dataset for Ego and Fixed Traffic Perception)",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://eventbasedvision.github.io/SEVD",
        "dcat:theme": [
            "Autonomous Driving",
            "Traffic Monitoring"
        ],
        "dcat:keyword": [
            "Synthetic dataset",
            "Event-based vision",
            "Traffic perception",
            "Multi-view data",
            "Dynamic vision sensors"
        ],
        "dcat:landingPage": "https://eventbasedvision.github.io/SEVD",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Traffic participant detection",
            "Object detection",
            "Scene understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Jonathan Binas",
            "Daniel Neil",
            "Shih-Chii Liu",
            "Tobi Delbruck"
        ],
        "dcterms:description": "The first open dataset offering driving recordings, annotated data for end-to-end learning approaches, and sensor fusion techniques.",
        "dcterms:title": "DDD17",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1711.01458",
        "dcat:theme": [
            "Autonomous Driving",
            "Sensor Fusion"
        ],
        "dcat:keyword": [
            "Driving dataset",
            "End-to-end learning",
            "Sensor fusion"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1711.01458",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video data",
        "mls:task": [
            "End-to-end learning",
            "Driving scenario analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Zihao Zhu",
            "Dinesh Thakur",
            "Tolga Ã–zaslan",
            "Bernd Pfrommer",
            "Vijay Kumar",
            "Kostas Daniilidis"
        ],
        "dcterms:description": "A dataset providing synchronized stereo pair event-based data captured in diverse scenarios, enabling the development and testing of algorithms for tasks like feature tracking, visual odometry, and stereo depth estimation.",
        "dcterms:title": "MVSEC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Perception",
            "Event-based Vision"
        ],
        "dcat:keyword": [
            "Stereo event camera",
            "3D perception",
            "Feature tracking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Visual odometry",
            "Stereo depth estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Amos Sironi",
            "Manuele Brambilla",
            "Nicolas Bourdis",
            "Xavier Lagorce",
            "Ryad Benosman"
        ],
        "dcterms:description": "A large dataset for object classification, showcasing improved classification performance in real-time computation for applications like autonomous vehicles and UAV vision.",
        "dcterms:title": "N-Cars",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Classification",
            "Autonomous Vehicles"
        ],
        "dcat:keyword": [
            "Object classification",
            "Real-time computation",
            "Autonomous vehicles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image data",
        "mls:task": [
            "Object classification"
        ]
    },
    {
        "dcterms:creator": [
            "Yuhuang Hu",
            "Jonathan Binas",
            "Daniel Neil",
            "Shih-Chii Liu",
            "Tobi Delbruck"
        ],
        "dcterms:description": "An expanded version of DDD17 with an additional 39 hr of data, making it the longest event camera end-to-end driving dataset.",
        "dcterms:title": "DDD20",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Event-based Vision"
        ],
        "dcat:keyword": [
            "Driving dataset",
            "End-to-end learning",
            "Event camera"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video data",
        "mls:task": [
            "End-to-end learning",
            "Driving scenario analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Pierre De Tournemire",
            "Davide Nitti",
            "Etienne Perot",
            "Davide Migliore",
            "Amos Sironi"
        ],
        "dcterms:description": "A large scale event-based detection dataset for automotive, providing manual annotations for cars and pedestrians.",
        "dcterms:title": "GEN1",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2001.08499",
        "dcat:theme": [
            "Object Detection",
            "Automotive"
        ],
        "dcat:keyword": [
            "Event-based detection",
            "Automotive dataset",
            "Object detection"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2001.08499",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Object detection",
            "Event-based vision tasks"
        ]
    },
    {
        "dcterms:creator": [
            "Etienne Perot",
            "Pierre De Tournemire",
            "Davide Nitti",
            "Jonathan Masci",
            "Amos Sironi"
        ],
        "dcterms:description": "A large-scale and high-resolution dataset containing over 14 hr of recordings with 25M bounding boxes of cars, pedestrians, and two-wheelers labeled at high frequency in automotive scenarios.",
        "dcterms:title": "1Mpx",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Automotive"
        ],
        "dcat:keyword": [
            "High-resolution dataset",
            "Automotive scenarios",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video data",
        "mls:task": [
            "Object detection"
        ]
    },
    {
        "dcterms:creator": [
            "Mathias Gehrig",
            "Willem Aarents",
            "Daniel Gehrig",
            "Davide Scaramuzza"
        ],
        "dcterms:description": "A stereo event camera dataset for driving scenarios, designed for challenging illumination conditions.",
        "dcterms:title": "DSEC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Driving Scenarios",
            "Event-based Vision"
        ],
        "dcat:keyword": [
            "Stereo event camera",
            "Driving scenarios",
            "Illumination conditions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Stereo depth estimation",
            "Event-based vision tasks"
        ]
    },
    {
        "dcterms:creator": [
            "Yuhuang Hu",
            "Shih-Chii Liu",
            "Tobi Delbruck"
        ],
        "dcterms:description": "A simulator that generates realistic synthetic DVS events from video frames, ensuring realism in the generated data.",
        "dcterms:title": "v2e",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data Generation",
            "Event-based Vision"
        ],
        "dcat:keyword": [
            "Synthetic events",
            "Video to event conversion",
            "Realistic simulation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Event data",
        "mls:task": [
            "Data generation",
            "Event-based vision tasks"
        ]
    }
]