[
    {
        "dcterms:creator": [
            "Stephen Merity"
        ],
        "dcterms:description": "A dataset used for training and fine-tuning language models, focusing on long-term dependencies in language.",
        "dcterms:title": "Wikipedia dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language dataset",
            "Text generation",
            "Coherence"
        ],
        "dcat:landingPage": "https://blog.einstein.ai/the-wikitext-long-term-dependency-language-modeling-dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation",
            "Coherence Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Stephen Merity"
        ],
        "dcterms:description": "A smaller version of the WikiText dataset, used for training language models with a focus on long-term dependencies.",
        "dcterms:title": "WikiText-2",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language dataset",
            "Text generation",
            "Coherence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation",
            "Coherence Prediction"
        ]
    }
]