[
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "Daan Wierstra",
            "Martin A. Riedmiller"
        ],
        "dcterms:description": "The Atari Pong environment consists of two rackets (the agent and the opponent), a ball, and a playing field which has a size of 80x80 pixels. The agent receives a reward of +1 when it scores, and a reward of -1 when the opponent scores.",
        "dcterms:title": "Atari Pong Environment",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Gaming"
        ],
        "dcat:keyword": [
            "Atari",
            "Pong",
            "Reinforcement Learning",
            "Game Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Game",
        "mls:task": [
            "Game Playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Road-Tree environment has a tree-like structure where the agent starts at the root and moves downward. It includes simple states with one possible action and junction states where multiple roads can be chosen.",
        "dcterms:title": "Road-Tree Environment",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Pathfinding"
        ],
        "dcat:keyword": [
            "Road-Tree",
            "Reinforcement Learning",
            "Criticality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Pathfinding",
            "Decision Making"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Shooter environment is located on a rectangular playing field containing a gun, a bullet, and a moving target. The agent controls the gun and can choose to shoot or not shoot at the target.",
        "dcterms:title": "Shooter Environment",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Shooting Game"
        ],
        "dcat:keyword": [
            "Shooter",
            "Reinforcement Learning",
            "Game Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Shooting",
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Monte Carlo algorithm is a reinforcement learning method that uses random sampling to obtain numerical results. It is often used for estimating the value of states or actions.",
        "dcterms:title": "Monte Carlo Algorithm",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Methods"
        ],
        "dcat:keyword": [
            "Monte Carlo",
            "Reinforcement Learning",
            "Sampling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value Estimation",
            "Policy Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Q-Learning algorithm is a model-free reinforcement learning algorithm that aims to learn the value of an action in a particular state. It updates the Q-values based on the action taken and the reward received.",
        "dcterms:title": "Q-Learning Algorithm",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Q-Learning"
        ],
        "dcat:keyword": [
            "Q-Learning",
            "Reinforcement Learning",
            "Value Function"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning Optimal Policy",
            "Value Estimation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Monte Carlo algorithm (Deep) is a variant of the Monte Carlo method that utilizes deep learning techniques to estimate the value of states or actions in reinforcement learning.",
        "dcterms:title": "Monte Carlo Algorithm (Deep)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Hado Van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "dcterms:description": "The DDQN algorithm is an extension of the DQN algorithm that addresses the overestimation bias of Q-learning by using two neural networks.",
        "dcterms:title": "DDQN Algorithm",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "DDQN",
            "Deep Q-Learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning Optimal Policy",
            "Value Estimation"
        ]
    }
]