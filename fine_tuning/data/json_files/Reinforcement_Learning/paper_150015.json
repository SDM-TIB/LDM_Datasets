[
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "P. Welinder",
            "V. Kumar",
            "W. Zaremba"
        ],
        "dcterms:description": "A continuous variant of the discrete 'Bit-Flipping' environment where the objective is to navigate from an initial state in d-dimensional space to a desired goal state by adding an (lâˆž)-bounded vector to the current state.",
        "dcterms:title": "ContinuousSeek",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Tasks"
        ],
        "dcat:keyword": [
            "Continuous control",
            "Sparse rewards",
            "Goal navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Goal Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "P. Welinder",
            "V. Kumar",
            "W. Zaremba"
        ],
        "dcterms:description": "An environment from the OpenAI Gym Robotics suite where the agent controls a simulated robotic hand with the goal of moving all fingertips to specified 3D positions.",
        "dcterms:title": "HandReach",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic hand",
            "High-dimensional goals",
            "Sparse rewards"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Goal Achievement"
        ]
    },
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "P. Welinder",
            "V. Kumar",
            "W. Zaremba"
        ],
        "dcterms:description": "An environment where the agent must reach any of up to 200 goals located on a 2D grid, with the position wrapping around at the edges.",
        "dcterms:title": "DriveSeek",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Tasks"
        ],
        "dcat:keyword": [
            "Goal navigation",
            "Deterministic environment",
            "Sparse rewards"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Goal Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Andrychowicz",
            "F. Wolski",
            "A. Ray",
            "J. Schneider",
            "R. Fong",
            "P. Welinder",
            "B. McGrew",
            "J. Tobin",
            "O. Pieter Abbeel",
            "W. Zaremba"
        ],
        "dcterms:description": "A sparse-reward environment where the agent must flip bits to reach a goal state, with the dimensionality of the state space being a key factor.",
        "dcterms:title": "Bit-Flipping",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Sparse Rewards"
        ],
        "dcat:keyword": [
            "Bit-flipping",
            "Sparse rewards",
            "Goal navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Goal Achievement"
        ]
    },
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "P. Welinder",
            "V. Kumar",
            "W. Zaremba"
        ],
        "dcterms:description": "An environment where the agent must navigate through a noisy space to reach clustered goals, requiring strategic planning.",
        "dcterms:title": "NoisySeek",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Tasks"
        ],
        "dcat:keyword": [
            "Noisy environment",
            "Clustered goals",
            "Sparse rewards"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Goal Navigation"
        ]
    }
]