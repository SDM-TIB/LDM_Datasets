To extract datasets from the research paper titled "Salient Object Detection From Arbitrary Modalities" by Nianchang Huang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract indicates that a new dataset named **AM-XD** is constructed to facilitate research on Arbitrary Modality Salient Object Detection (AM SOD). This is a clear indication that a dataset is present.

Next, I will examine the **experiments section**, particularly the subsection titled **Datasets and Evaluation Metrics**. Here, the authors provide detailed information about the AM-XD dataset, including its composition and the datasets it builds upon. They mention that the AM-XD dataset is constructed based on several existing datasets, which are crucial for understanding its context.

In this section, the authors list the datasets used to create the AM-XD dataset, including:

1. **DUTS-TR**: Used for RGB SOD, with 5000 images.
   - Citation: Wang, L., Lu, H., Wang, Y., Feng, M., Wang, D., Yin, B., & Ruan, X. (2017). Learning to detect salient objects with image-level supervision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 3796–3805.

2. **NJU2K**: Used for RGB-D SOD, with 1485 images.
   - Citation: Houwen, P., Bing, L., Weihua, X., Weiming, H., & Rongrong, J. (2014). RGB-D salient object detection: A benchmark and algorithms. In Proceedings of the European Conference on Computer Vision (ECCV), 92–109.

3. **NLPR**: Used for RGB-D SOD, with 700 images.
   - Citation: Ju, R., Ge, L., Geng, W., Ren, T., & Wu, G. (2014). Depth saliency based on anisotropic center-surround difference. In Proceedings of the IEEE International Conference on Image Processing (ICIP), 1115–1119.

4. **DUT-RGBD**: Used for RGB-D SOD, with 800 images.
   - Citation: Piao, Y., Ji, W., Li, J., Zhang, M., & Lu, H. (2019). Depth-induced multi-scale recurrent attention network for saliency detection. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 7254–7263.

5. **VT5K**: Used for RGB-T SOD, with 2500 images.
   - Citation: Wang, G., Li, C., Ma, Y., Zheng, A., Tang, J., & Luo, B. (2018). RGB-T saliency detection benchmark: Dataset, baselines, analysis and a novel approach. In Image and Graphics Technologies and Applications (pp. 359–369).

6. **VDT-2048**: Used for RGB-D-T SOD, with 1048 images.
   - Citation: Song, K., Wang, J., Bao, Y., Huang, L., & Yan, Y. (2023). A novel visible-depth-thermal image dataset of salient object detection for robotic visual perception. IEEE/ASME Transactions on Mechatronics, 28(3), 1558–1569.

After identifying these datasets, I will ensure to note their specific contributions to the AM-XD dataset as described in the paper.

Finally, I will compile the dataset entries with their full citations into a structured format for further processing or review. This will ensure that all relevant information is captured accurately and comprehensively.