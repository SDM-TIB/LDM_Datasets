[
    {
        "dcterms:creator": [
            "R. T. Icarte",
            "T. Q. Klassen",
            "R. A. Valenzano",
            "S. A. McIlraith"
        ],
        "dcterms:description": "A dataset that encodes high-level task specifications and decompositions in reinforcement learning using reward machines, which are a type of Mealy machine that encodes reward functions.",
        "dcterms:title": "Reward Machines",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "http://proceedings.mlr.press/v80/icarte18a.html",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Reward machines",
            "Reinforcement learning",
            "Task specification"
        ],
        "dcat:landingPage": "http://proceedings.mlr.press/v80/icarte18a.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task specification",
            "Policy learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. J. C. H. Watkins",
            "P. Dayan"
        ],
        "dcterms:description": "A foundational dataset for reinforcement learning that describes the Q-learning algorithm, which is a model-free reinforcement learning algorithm.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1007/BF00992698",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Reinforcement learning",
            "Model-free learning"
        ],
        "dcat:landingPage": "https://doi.org/10.1007/BF00992698",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy learning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Neider",
            "N. Jansen"
        ],
        "dcterms:description": "A dataset that utilizes automata learning techniques for regular model checking, which is relevant for inferring reward machines.",
        "dcterms:title": "Automata Learning Techniques",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automata Learning",
            "Model Checking"
        ],
        "dcat:keyword": [
            "Automata learning",
            "Model checking",
            "Regular languages"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Oncina",
            "P. Garcia"
        ],
        "dcterms:description": "A dataset that describes the RPNI algorithm, which infers regular languages in polynomial time and is relevant for learning reward machines.",
        "dcterms:title": "RPNI Algorithm",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Automata Learning",
            "Language Inference"
        ],
        "dcat:keyword": [
            "RPNI algorithm",
            "Regular languages",
            "Language inference"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. D. Kulkarni",
            "K. Narasimhan",
            "A. Saeedi",
            "J. Tenenbaum"
        ],
        "dcterms:description": "A dataset that explores hierarchical reinforcement learning, integrating temporal abstraction and intrinsic motivation.",
        "dcterms:title": "Hierarchical Reinforcement Learning",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Hierarchical Learning"
        ],
        "dcat:keyword": [
            "Hierarchical reinforcement learning",
            "Temporal abstraction",
            "Intrinsic motivation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "B. Bollig",
            "J. Katoen",
            "C. Kern",
            "M. Leucker",
            "D. Neider",
            "D. R. Piegdon"
        ],
        "dcterms:description": "A framework for automata learning that provides tools for inferring automata from data.",
        "dcterms:title": "libalf",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1007/978-3-642-14295-6_32",
        "dcat:theme": [
            "Automata Learning",
            "Software Framework"
        ],
        "dcat:keyword": [
            "Automata learning framework",
            "libalf",
            "Learning algorithms"
        ],
        "dcat:landingPage": "https://doi.org/10.1007/978-3-642-14295-6_32",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]