[
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A dataset used for training language models, consisting of a large collection of text from Wikipedia articles.",
        "dcterms:title": "Wikitext-103-v1",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Language modeling",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Stella Biderman",
            "Hailey Schoelkopf",
            "Quentin Gregory Anthony",
            "Herbie Bradley",
            "Kyle Oâ€™Brien",
            "Eric Hallahan",
            "Mohammad Aflah Khan",
            "Shivanshu Purohit",
            "USVSN Sai Prashanth",
            "Edward Raff"
        ],
        "dcterms:description": "A suite for analyzing large language models across training and scaling, providing various configurations and datasets for experimentation.",
        "dcterms:title": "Pythia 1B",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Large language models",
            "Model analysis",
            "Training datasets"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Training",
            "Model Evaluation"
        ]
    }
]