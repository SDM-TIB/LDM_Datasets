[
    {
        "dcterms:creator": [],
        "dcterms:description": "CLAVI is a diagnostic dataset for coupled multimodal understanding in VideoQA, consisting of temporal questions and videos that are augmented to curate balanced counterfactuals in language and video domains.",
        "dcterms:title": "CLAVI (Counterfactual in LAnguage and VIdeo)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering",
            "Multimodal Understanding"
        ],
        "dcat:keyword": [
            "Counterfactuals",
            "VideoQA",
            "Multimodal Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Zhong",
            "W. Ji",
            "J. Xiao",
            "Y. Li",
            "W. Deng",
            "T. S. Chua"
        ],
        "dcterms:description": "ActivityNet-QA contains 58K open-ended questions on 5.8K sampled videos from ActivityNet.",
        "dcterms:title": "ActivityNet-QA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.18653/v1/2022.emnlp-main.432",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Open-ended Questions",
            "Video Dataset"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.emnlp-main.432",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "X. Liu",
            "A. Sikarwar",
            "J. Hwee Lim",
            "G. Kreiman",
            "Z. Shi",
            "M. Zhang"
        ],
        "dcterms:description": "MSRVTT-QA contains 244K open-ended questions on 10K MSRVTT videos.",
        "dcterms:title": "MSRVTT-QA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Open-ended Questions",
            "Video Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xiao",
            "X. Shang",
            "A. Yao",
            "T. S. Chua"
        ],
        "dcterms:description": "NeXT-QA contains 47K 5-way multiple choice questions with one-correct answer from 5.4K videos.",
        "dcterms:title": "NeXT-QA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Multiple Choice Questions",
            "Video Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Buch",
            "C. Eyzaguirre",
            "A. Gaidon",
            "J. Wu",
            "L. Fei-Fei",
            "J. C. Niebles"
        ],
        "dcterms:description": "ATP-Hard is a subset of NeXT-QA that contains a higher concentration of temporally challenging data requiring multi-frame understanding.",
        "dcterms:title": "ATP-Hard",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Challenging Data",
            "Temporal Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Gao",
            "C. Sun",
            "Z. Yang",
            "R. Nevatia"
        ],
        "dcterms:description": "Charades-STA is a dataset for temporal activity localization via language query.",
        "dcterms:title": "Charades-STA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Activity Localization"
        ],
        "dcat:keyword": [
            "Temporal Activity",
            "Language Query"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Activity Localization"
        ]
    }
]