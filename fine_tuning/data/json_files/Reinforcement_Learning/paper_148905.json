[
    {
        "dcterms:creator": [
            "C. J. C. H. Watkins",
            "P. Dayan"
        ],
        "dcterms:description": "Q-learning is a fundamental reinforcement learning algorithm that enables an agent to learn how to optimally act in a given environment by estimating the value of action-state pairs.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Reinforcement Learning",
            "Value Estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. N. Tsitsiklis"
        ],
        "dcterms:description": "Asynchronous Q-learning is an extension of Q-learning that allows for updates to be made asynchronously, improving the efficiency of learning in certain environments.",
        "dcterms:title": "Asynchronous Q-learning",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Asynchronous Learning",
            "Q-learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Jaakkola",
            "M. I. Jordan",
            "S. P. Singh"
        ],
        "dcterms:description": "This dataset includes stochastic iterative dynamic programming algorithms that converge under certain conditions, providing insights into the behavior of reinforcement learning algorithms.",
        "dcterms:title": "Stochastic iterative dynamic programming algorithms",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Stochastic Algorithms",
            "Dynamic Programming",
            "Convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "V. S. Borkar",
            "S. P. Meyn"
        ],
        "dcterms:description": "The ODE method provides a framework for analyzing the convergence of stochastic approximation and reinforcement learning algorithms, offering insights into their stability.",
        "dcterms:title": "ODE method for convergence of stochastic approximation",
        "dcterms:issued": "2000",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Stochastic Approximation",
            "Convergence Analysis",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Szepesv√°ri"
        ],
        "dcterms:description": "This dataset provides an analysis of the asymptotic convergence rate of Q-learning, contributing to the understanding of its performance in various settings.",
        "dcterms:title": "The asymptotic convergence-rate of Q-learning",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Convergence Rate",
            "Q-learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. J. Kearns",
            "S. P. Singh"
        ],
        "dcterms:description": "This dataset explores finite-sample convergence rates for Q-learning and indirect algorithms, providing insights into their performance in practical scenarios.",
        "dcterms:title": "Finite-sample convergence rates for Q-learning",
        "dcterms:issued": "1999",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Finite-sample Analysis",
            "Q-learning",
            "Convergence Rates"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "E. Even-Dar",
            "Y. Mansour"
        ],
        "dcterms:description": "This dataset investigates learning rates for Q-learning, providing a theoretical foundation for understanding how learning rates affect convergence.",
        "dcterms:title": "Learning rates for Q-learning",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Learning Rates",
            "Q-learning",
            "Convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. G. Azar",
            "R. Munos",
            "M. Ghavamzadeh",
            "H. J. Kappen"
        ],
        "dcterms:description": "Speedy Q-learning is an enhanced version of Q-learning that aims to improve the speed of convergence in reinforcement learning tasks.",
        "dcterms:title": "Speedy Q-learning",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Speedy Q-learning",
            "Reinforcement Learning",
            "Convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. L. Beck",
            "R. Srikant"
        ],
        "dcterms:description": "This dataset provides error bounds for constant step-size Q-learning, contributing to the understanding of its stability and performance.",
        "dcterms:title": "Error bounds for constant step-size Q-learning",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Error Bounds",
            "Q-learning",
            "Stability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. J. Wainwright"
        ],
        "dcterms:description": "This dataset presents a study on stochastic approximation with cone-contractive operators, providing sharp bounds for Q-learning.",
        "dcterms:title": "Stochastic approximation with cone-contractive operators",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Stochastic Approximation",
            "Q-learning",
            "Bounds"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Qu",
            "A. Wierman"
        ],
        "dcterms:description": "This dataset provides a finite-time analysis of asynchronous stochastic approximation and Q-learning, contributing to the understanding of their performance.",
        "dcterms:title": "Finite-time analysis of asynchronous stochastic approximation and Q-learning",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Finite-time Analysis",
            "Asynchronous Learning",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Lee",
            "N. He"
        ],
        "dcterms:description": "This dataset provides a unified switching system perspective and convergence analysis of Q-learning algorithms, contributing to the theoretical foundation of Q-learning.",
        "dcterms:title": "A unified switching system perspective and convergence analysis of Q-learning algorithms",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Switching Systems",
            "Q-learning",
            "Convergence Analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "H. Lin",
            "P. J. Antsaklis"
        ],
        "dcterms:description": "This dataset surveys recent results on the stability and stabilizability of switched linear systems, providing insights into their behavior.",
        "dcterms:title": "Stability and stabilizability of switched linear systems",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Control Theory"
        ],
        "dcat:keyword": [
            "Stability",
            "Switched Systems",
            "Control Theory"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "H. V. Hasselt"
        ],
        "dcterms:description": "Double Q-learning is an extension of Q-learning that aims to reduce overestimation bias by maintaining two separate value estimates.",
        "dcterms:title": "Double Q-learning",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Double Q-learning",
            "Overestimation Bias",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Kar",
            "J. M. Moura",
            "H. V. Poor"
        ],
        "dcterms:description": "QD-learning is a collaborative distributed strategy for multi-agent reinforcement learning that utilizes consensus and innovations.",
        "dcterms:title": "QD-learning",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Agent Systems",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Collaborative Learning",
            "Multi-Agent Systems",
            "Consensus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Gosavi"
        ],
        "dcterms:description": "This dataset discusses the boundedness of iterates in Q-learning, providing insights into the stability of the learning process.",
        "dcterms:title": "Boundedness of iterates in Q-learning",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Boundedness",
            "Q-learning",
            "Stability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]