[
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "Y. Naddaf",
            "J. Veness",
            "M. Bowling"
        ],
        "dcterms:description": "An evaluation platform for general agents, providing a standard metric used to measure the performance of algorithms in reinforcement learning.",
        "dcterms:title": "Atari Learning Environment",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement learning",
            "Evaluation platform"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Algorithm evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Michael Johanson",
            "Kevin Waugh",
            "Michael Bowling",
            "Martin Zinkevich"
        ],
        "dcterms:description": "A variant of Texas Hold'em poker focusing on two-player limit games, used to study strategies and performance in imperfect information games.",
        "dcterms:title": "Heads-up Limit Texas Hold’em (HULH)",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Poker AI"
        ],
        "dcat:keyword": [
            "Poker",
            "Limit Texas Hold'em",
            "Imperfect information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Strategy evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Michael Johanson"
        ],
        "dcterms:description": "A variant of Texas Hold'em poker focusing on two-player no-limit games, used to analyze strategies and exploitability in large decision spaces.",
        "dcterms:title": "Heads-up No Limit Texas Hold’em (HUNL)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1302.7008",
        "dcat:theme": [
            "Game Theory",
            "Poker AI"
        ],
        "dcat:keyword": [
            "Poker",
            "No Limit Texas Hold'em",
            "Imperfect information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Strategy evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "David Silver",
            "Thomas Hubert",
            "Julian Schrittwieser",
            "Ioannis Antonoglou",
            "Matthew Lai",
            "Arthur Guez",
            "Marc Lanctot",
            "Laurent Sifre",
            "Dharshan Kumaran",
            "Thore Graepel",
            "Timothy Lillicrap",
            "Karen Simonyan",
            "Demis Hassabis"
        ],
        "dcterms:description": "A dataset used to train agents in perfect information games like Chess and Go, showcasing the capabilities of reinforcement learning through self-play.",
        "dcterms:title": "Chess",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Chess",
            "Perfect information",
            "Self-play"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Strategy evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "David Silver",
            "Thomas Hubert",
            "Julian Schrittwieser",
            "Ioannis Antonoglou",
            "Matthew Lai",
            "Arthur Guez",
            "Marc Lanctot",
            "Laurent Sifre",
            "Dharshan Kumaran",
            "Thore Graepel",
            "Timothy Lillicrap",
            "Karen Simonyan",
            "Demis Hassabis"
        ],
        "dcterms:description": "A dataset used to train agents in perfect information games like Go, demonstrating the effectiveness of reinforcement learning through self-play.",
        "dcterms:title": "Go",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Go",
            "Perfect information",
            "Self-play"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game playing",
            "Strategy evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Matej Moravčík",
            "Martin Schmid",
            "Neil Burch",
            "Viliam Lisý",
            "Dustin Morrill",
            "Nolan Bard",
            "Trevor Davis",
            "Kevin Waugh",
            "Michael Johanson",
            "Michael Bowling"
        ],
        "dcterms:description": "A dataset used for developing AI in Liar's Dice, focusing on strategies and performance in imperfect information games.",
        "dcterms:title": "Liar’s Dice",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Poker AI"
        ],
        "dcat:keyword": [
            "Liar's Dice",
            "Imperfect information",
            "Game AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Strategy evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Viliam Lisý",
            "Michael H. Bowling"
        ],
        "dcterms:description": "A dataset used for analyzing strategies in Leduc Poker, focusing on equilibrium approximation quality of poker bots.",
        "dcterms:title": "Leduc Poker",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Poker AI"
        ],
        "dcat:keyword": [
            "Leduc Poker",
            "Imperfect information",
            "Game AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Strategy evaluation"
        ]
    }
]