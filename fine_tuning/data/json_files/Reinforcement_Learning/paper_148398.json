[
    {
        "dcterms:creator": [
            "Erwin Coumans",
            "Yunfei Bai"
        ],
        "dcterms:description": "A physics simulation environment used for training agents in robotics and machine learning, allowing for the generation of state observations through rendered camera views.",
        "dcterms:title": "PyBullet",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/bulletphysics/pybullet",
        "dcat:theme": [
            "Robotics",
            "Physics Simulation"
        ],
        "dcat:keyword": [
            "Physics simulation",
            "Robotics",
            "Machine learning"
        ],
        "dcat:landingPage": "https://github.com/bulletphysics/pybullet",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Robotic training",
            "Reinforcement learning"
        ]
    },
    {
        "dcterms:creator": [
            "Eric Kolve",
            "Roozbeh Mottaghi",
            "Winson Han",
            "Eli VanderBilt",
            "Luca Weihs",
            "Alvaro Herrasti",
            "Daniel Gordon",
            "Yuke Zhu",
            "Abhinav Gupta",
            "Ali Farhadi"
        ],
        "dcterms:description": "An interactive 3D environment designed for visual AI research, allowing agents to navigate and interact with objects in a simulated space.",
        "dcterms:title": "AI2-THOR",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1712.05474",
        "dcat:theme": [
            "Artificial Intelligence",
            "3D Simulation"
        ],
        "dcat:keyword": [
            "Interactive environment",
            "Visual AI",
            "Navigation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1712.05474",
        "dcterms:hasVersion": "v3",
        "dcterms:format": "3D Simulation",
        "mls:task": [
            "Navigation",
            "Object interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Fei Xia",
            "Amir R Zamir",
            "Zhiyang He",
            "Alexander Sax",
            "Jitendra Malik",
            "Silvio Savarese"
        ],
        "dcterms:description": "A dataset providing real-world perception data for embodied agents, focusing on navigation and interaction in realistic environments.",
        "dcterms:title": "Gibson Env",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Real-world perception"
        ],
        "dcat:keyword": [
            "Embodied agents",
            "Navigation",
            "Real-world environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Dataset",
        "mls:task": [
            "Navigation",
            "Perception"
        ]
    },
    {
        "dcterms:creator": [
            "Claudia Yan",
            "Dipendra Misra",
            "Andrew Bennnett",
            "Aaron Walsman",
            "Yonatan Bisk",
            "Yoav Artzi"
        ],
        "dcterms:description": "A learning environment designed for agents to interact with a simulated Cornell house, focusing on navigation and manipulation tasks.",
        "dcterms:title": "Chalet",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1801.07357",
        "dcat:theme": [
            "Robotics",
            "Simulation"
        ],
        "dcat:keyword": [
            "Navigation",
            "Manipulation",
            "Simulated environment"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1801.07357",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Navigation",
            "Manipulation"
        ]
    },
    {
        "dcterms:creator": [
            "Lin Yen-Chen",
            "Shuran Zeng",
            "Andy Song",
            "Phillip Isola",
            "Tsung-Yi Lin"
        ],
        "dcterms:description": "A study focusing on visual pre-training for manipulation tasks, emphasizing the importance of visual understanding before action execution.",
        "dcterms:title": "Learning to See Before Learning to Act",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Visual pre-training",
            "Manipulation",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Manipulation",
            "Visual understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Andy Zeng"
        ],
        "dcterms:description": "A PhD thesis focusing on learning visual affordances for robotic manipulation, providing insights into how robots can understand and interact with objects.",
        "dcterms:title": "Learning Visual Affordances for Robotic Manipulation",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Manipulation"
        ],
        "dcat:keyword": [
            "Visual affordances",
            "Robotic manipulation",
            "Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Manipulation",
            "Learning"
        ]
    }
]