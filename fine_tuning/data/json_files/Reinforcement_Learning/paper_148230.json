[
    {
        "dcterms:creator": [
            "D. Silver",
            "T. Hubert",
            "J. Schrittwieser",
            "I. Antonoglou",
            "M. Lai",
            "A. Guez",
            "M. Lanctot",
            "L. Sifre",
            "D. Kumaran",
            "T. Graepel",
            "T. P. Lillicrap",
            "K. Simonyan",
            "D. Hassabis"
        ],
        "dcterms:description": "The AlphaZero algorithm learns to master a two-player competitive game starting with no knowledge except for the rules of the game. It uses a quantitative reward function for game outcomes, requiring users to balance different components of the reward.",
        "dcterms:title": "AlphaZero",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1712.01815",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "AlphaZero",
            "self-play",
            "reinforcement learning",
            "strategy games"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1712.01815",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Leela Zero is an open-source software designed to reproduce the AlphaZero algorithm, sharing its limitations in terms of reward structure.",
        "dcterms:title": "Leela Zero",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Leela Zero",
            "open-source",
            "reinforcement learning"
        ],
        "dcat:landingPage": "https://zero.sjeng.org",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Leela Chess Zero is another open-source software that aims to replicate the AlphaZero algorithm, also sharing similar limitations.",
        "dcterms:title": "Leela Chess Zero",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Leela Chess Zero",
            "open-source",
            "reinforcement learning"
        ],
        "dcat:landingPage": "https://lczero.org",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. J. Wu"
        ],
        "dcterms:description": "KataGo attempts to improve upon AlphaZero in the specific domain of Go, including dispensing a greater reward for larger wins.",
        "dcterms:title": "KataGo",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1902.10565",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "KataGo",
            "Go",
            "reinforcement learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1902.10565",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "F. Morandin",
            "G. Amato",
            "M. Fantozzi",
            "R. Gini",
            "C. Metta",
            "M. Parton"
        ],
        "dcterms:description": "SAI is an artificial intelligence that plays with handicap and targets high scores in 9x9 Go, aiming to maximize the margin of victory.",
        "dcterms:title": "SAI",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1905.10863",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "SAI",
            "Go",
            "reinforcement learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1905.10863",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "A. Laterre",
            "Y. Fu",
            "M. K. Jabri",
            "A.-S. Cohen",
            "D. Kas",
            "K. Hajjar",
            "T. S. Dahl",
            "A. Kerkeni",
            "K. Beguir"
        ],
        "dcterms:description": "CDF-based rewards utilize a cumulative distribution function of observed outcomes to define a reward function, aiming to motivate learners to win more convincingly.",
        "dcterms:title": "CDF-based rewards",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1807.01672",
        "dcat:theme": [
            "Reinforcement Learning",
            "Combinatorial Optimization"
        ],
        "dcat:keyword": [
            "CDF rewards",
            "reinforcement learning",
            "self-play"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1807.01672",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Zap",
            "T. Joppen",
            "J. F¨urnkranz"
        ],
        "dcterms:description": "Deep Ordinal Reinforcement Learning adapts Q-learning to use an ordinal reward scale, aiming to induce scale-invariance and reduce the need for manual reward-shaping.",
        "dcterms:title": "Deep Ordinal Reinforcement Learning",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1905.02005",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Ordinal reinforcement learning",
            "Q-learning",
            "scale-invariance"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1905.02005",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "I. Rechenberg"
        ],
        "dcterms:description": "Evolution Strategy is an optimization technique inspired by biological evolution, used for optimizing technical systems.",
        "dcterms:title": "Evolution Strategy",
        "dcterms:issued": "1973",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Optimization"
        ],
        "dcat:keyword": [
            "Evolution strategy",
            "optimization",
            "biological evolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Wirth",
            "R. Akrour",
            "G. Neumann",
            "J. F¨urnkranz"
        ],
        "dcterms:description": "Preference-based reinforcement learning methods focus on providing feedback that indicates the relative utility of two states or actions, rather than an absolute numerical reward.",
        "dcterms:title": "Preference-based reinforcement learning",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Preference-based learning",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Y. Ng",
            "D. Harada",
            "S. Russell"
        ],
        "dcterms:description": "Reward shaping is the practice of engineering a reward function to improve learning performance in reinforcement learning.",
        "dcterms:title": "Reward shaping",
        "dcterms:issued": "1999",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Reward shaping",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]