[
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "W. Dabney",
            "R. Munos"
        ],
        "dcterms:description": "A popular benchmark for testing deep reinforcement learning methodologies, consisting of various Atari games.",
        "dcterms:title": "Atari 2600",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Deep reinforcement learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Game",
        "mls:task": [
            "Game playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Xiao",
            "R. Huang",
            "J. Mei",
            "D. Schuurmans",
            "M. M端ller"
        ],
        "dcterms:description": "A synthetic problem designed to demonstrate the effects of Monte Carlo Tree Search algorithms.",
        "dcterms:title": "Synthetic tree toy problem",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Tree Search"
        ],
        "dcat:keyword": [
            "Synthetic problem",
            "Monte Carlo Tree Search",
            "Decision making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Decision making",
            "Algorithm evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Xiao",
            "R. Huang",
            "J. Mei",
            "D. Schuurmans",
            "M. M端ller"
        ],
        "dcterms:description": "An algorithm that combines Monte Carlo Tree Search with maximum entropy regularization.",
        "dcterms:title": "Maximum Entropy MCTS (MENTS)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Tree Search"
        ],
        "dcat:keyword": [
            "Monte Carlo Tree Search",
            "Entropy regularization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Game playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Xiao",
            "R. Huang",
            "J. Mei",
            "D. Schuurmans",
            "M. M端ller"
        ],
        "dcterms:description": "A variant of MCTS that uses relative entropy regularization.",
        "dcterms:title": "RENTS (Relative Entropy Regularized MCTS)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Tree Search"
        ],
        "dcat:keyword": [
            "Monte Carlo Tree Search",
            "Relative entropy",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Game playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Xiao",
            "R. Huang",
            "J. Mei",
            "D. Schuurmans",
            "M. M端ller"
        ],
        "dcterms:description": "A variant of MCTS that uses Tsallis entropy regularization.",
        "dcterms:title": "TENTS (Tsallis Entropy Regularized MCTS)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Tree Search"
        ],
        "dcat:keyword": [
            "Monte Carlo Tree Search",
            "Tsallis entropy",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Game playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Silver",
            "A. Huang",
            "C. J. Maddison",
            "A. Guez",
            "L. Sifre",
            "G. Van Den Driessche",
            "J. Schrittwieser",
            "I. Antonoglou",
            "V. Panneershelvam",
            "T. Lanctot"
        ],
        "dcterms:description": "An algorithm that combines deep neural networks and Monte Carlo Tree Search to play the game of Go.",
        "dcterms:title": "AlphaGo",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Game playing",
            "Monte Carlo Tree Search",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Game playing",
            "Reinforcement Learning"
        ]
    }
]