[
    {
        "dcterms:creator": [
            "C. J. C. H. Watkins"
        ],
        "dcterms:description": "The Q-learning algorithm is a foundational approach in reinforcement learning, designed to compute the state-action value function (Q-function) for Markov decision processes.",
        "dcterms:title": "Q-learning algorithm",
        "dcterms:issued": "1989",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Optimal Control"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Reinforcement Learning",
            "Markov Decision Processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "R. S. Sutton",
            "C. Szepesv√°ri",
            "H. R. Maei"
        ],
        "dcterms:description": "GQ learning is based on a stochastic gradient descent algorithm with an objective similar to the mean-square Bellman error, providing a convergent method for off-policy temporal-difference learning.",
        "dcterms:title": "GQ learning",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Temporal-Difference Learning"
        ],
        "dcat:keyword": [
            "GQ learning",
            "Stochastic Gradient Descent",
            "Temporal-Difference Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "J. Bas Serrano",
            "S. Curi",
            "A. Krause",
            "G. Neu"
        ],
        "dcterms:description": "Logistic Q-learning solves a regularized dual of the linear programming approach to reinforcement learning, providing a method for approximating the Q-function in a stochastic environment.",
        "dcterms:title": "Logistic Q-learning",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Stochastic Optimization"
        ],
        "dcat:keyword": [
            "Logistic Q-learning",
            "Regularized Dual",
            "Stochastic Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "F. Lu",
            "P. G. Mehta",
            "S. P. Meyn",
            "G. Neu"
        ],
        "dcterms:description": "Convex Q-learning introduces a deterministic convex program for optimal control in a stochastic environment, ensuring bounded solutions under certain conditions.",
        "dcterms:title": "Convex Q-learning",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Convex Optimization"
        ],
        "dcat:keyword": [
            "Convex Q-learning",
            "Optimal Control",
            "Stochastic Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "A. M. Devraj",
            "S. P. Meyn"
        ],
        "dcterms:description": "Relative Q-learning focuses on Q-learning with uniformly bounded variance, providing a framework for analyzing the stability and performance of reinforcement learning algorithms.",
        "dcterms:title": "Relative Q-learning",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Variance Analysis"
        ],
        "dcat:keyword": [
            "Relative Q-learning",
            "Bounded Variance",
            "Stability Analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "A. A. Joshi",
            "A. Taghvaei",
            "P. G. Mehta",
            "S. P. Meyn"
        ],
        "dcterms:description": "Controlled interacting particle algorithms are designed for simulation-based reinforcement learning, providing a framework for efficient exploration and learning in complex environments.",
        "dcterms:title": "Controlled interacting particle algorithms",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation Algorithms"
        ],
        "dcat:keyword": [
            "Controlled Interacting Particles",
            "Simulation-based Learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "S. P. Meyn"
        ],
        "dcterms:description": "Monte Carlo methods are used for control techniques in complex networks, providing a foundational approach for evaluating performance in stochastic environments.",
        "dcterms:title": "Monte Carlo methods",
        "dcterms:issued": "2007",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Monte Carlo Methods"
        ],
        "dcat:keyword": [
            "Monte Carlo",
            "Stochastic Control",
            "Performance Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    },
    {
        "dcterms:creator": [
            "F. Lu",
            "S. Meyn"
        ],
        "dcterms:description": "The inventory control problem is analyzed using convex Q-learning in a stochastic environment, illustrating the application of the proposed algorithms to real-world scenarios.",
        "dcterms:title": "Inventory control problem",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Inventory Management"
        ],
        "dcat:keyword": [
            "Inventory Control",
            "Stochastic Environment",
            "Convex Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Control"
        ]
    }
]