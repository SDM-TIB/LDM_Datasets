[
    {
        "dcterms:creator": [
            "Mikayel Samvelyan",
            "Tabish Rashid",
            "Christian Schroeder de Witt",
            "Gregory Farquhar",
            "Nantas Nardelli",
            "Tim GJ Rudner",
            "Chia-Man Hung",
            "Philip HS Torr",
            "Jakob Foerster",
            "Shimon Whiteson"
        ],
        "dcterms:description": "The StarCraft Multi-Agent Challenge (SMAC) is a benchmark for multi-agent reinforcement learning, where players control ally units in StarCraft using cooperative micro-tricks to defeat enemy units.",
        "dcterms:title": "StarCraft Multi-Agent Challenge (SMAC)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Agent Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "StarCraft",
            "Multi-Agent",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Agent Decision Making"
        ]
    },
    {
        "dcterms:creator": [
            "Chuming Li",
            "Jie Liu",
            "Yinmin Zhang",
            "Yuhong Wei",
            "Yazhe Niu",
            "Yaodong Yang",
            "Yu Liu",
            "Wanli Ouyang"
        ],
        "dcterms:description": "ACE is a cooperative multi-agent Q-learning framework that utilizes bidirectional action-dependency to improve learning efficiency in multi-agent environments.",
        "dcterms:title": "ACE (Cooperative Multi-Agent Q-Learning)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "Cooperative Learning",
            "Q-Learning",
            "Multi-Agent"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Agent Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Offline datasets consist of 10k or 50k expert trajectories per map collected by specific expert policies.",
        "dcterms:title": "Offline datasets (10k or 50k expert trajectories per map)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Offline Learning",
            "Expert Trajectories"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Linghui Meng",
            "Muning Wen",
            "Yaodong Yang",
            "Chenyang Le",
            "Xiyun Li",
            "Weinan Zhang",
            "Ying Wen",
            "Haifeng Zhang",
            "Jun Wang",
            "Bo Xu"
        ],
        "dcterms:description": "MADT is an offline pre-trained multi-agent decision transformer that tackles all SMAC tasks using a single big sequence model.",
        "dcterms:title": "MADT (Offline Pre-Trained Multi-Agent Decision Transformer)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Agent Reinforcement Learning",
            "Transformers"
        ],
        "dcat:keyword": [
            "Decision Transformer",
            "Multi-Agent",
            "Offline Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Agent Decision Making"
        ]
    }
]