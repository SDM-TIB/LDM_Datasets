[
    {
        "dcterms:creator": [
            "S. Bhattacharya",
            "N. Michael",
            "V. Kumar"
        ],
        "dcterms:description": "A cleaning simulation environment consisting of 5x5 and 20x20 grids used for testing path planning algorithms for cleaning robots.",
        "dcterms:title": "Cleaning Simulation Environment (5x5 and 20x20)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Simulation"
        ],
        "dcat:keyword": [
            "Cleaning robot",
            "Path planning",
            "Simulation environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Simulation",
        "mls:task": [
            "Path Planning",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "D. Silver",
            "A. Graves",
            "M. Riedmiller",
            "G. Fidjeland",
            "G. Ostrovski",
            "S. Stiennon",
            "J. Schaul",
            "J. Quan",
            "I. Antonoglou",
            "H. V. Hasselt",
            "M. G. Bellemare",
            "Y. Dabney",
            "R. Munos"
        ],
        "dcterms:description": "A deep reinforcement learning algorithm that uses a neural network to approximate the Q-function, enabling the agent to learn optimal actions in various environments.",
        "dcterms:title": "DQN (Deep Q Network)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1312.5602",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q Learning",
            "Reinforcement Learning",
            "Neural Networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "An on-policy reinforcement learning algorithm that optimizes policies using a clipped objective function to ensure stable updates.",
        "dcterms:title": "PPO (Proximal Policy Optimization)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.06347",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Policy Optimization",
            "Reinforcement Learning",
            "Clipped Objective"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Algorithm",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Lazaric"
        ],
        "dcterms:description": "A framework for transfer learning in reinforcement learning, focusing on the reuse of knowledge gained from previous tasks to improve learning efficiency in new tasks.",
        "dcterms:title": "Transfer Learning (TL)",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Transfer Learning"
        ],
        "dcat:keyword": [
            "Transfer Learning",
            "Reinforcement Learning",
            "Knowledge Reuse"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Y. Ng"
        ],
        "dcterms:description": "A technique in reinforcement learning that modifies the reward signal to facilitate learning by providing additional guidance to the agent.",
        "dcterms:title": "Reward Shaping (RS)",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Reward Engineering"
        ],
        "dcat:keyword": [
            "Reward Shaping",
            "Reinforcement Learning",
            "Learning Efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "A collection of high-performance data used to improve the learning process by preventing the agent from learning from poor performance episodes.",
        "dcterms:title": "Elite Set (ES)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Data Management"
        ],
        "dcat:keyword": [
            "Elite Set",
            "Reinforcement Learning",
            "Data Efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]