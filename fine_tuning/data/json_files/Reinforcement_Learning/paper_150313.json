[
    {
        "dcterms:creator": [
            "Author_C"
        ],
        "dcterms:description": "An online human-agent interaction simulation testbed designed to study how giving an AI the ability to verbally explain its recommendations impacts participantsâ€™ trust.",
        "dcterms:title": "Human-Agent Interaction Simulation Testbed",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human-Agent Interaction",
            "Trust in AI"
        ],
        "dcat:keyword": [
            "AI recommendations",
            "trust",
            "human-agent interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Author_A"
        ],
        "dcterms:description": "A study examining how users calibrate their trust in agents based on their interactions and outcomes.",
        "dcterms:title": "Trust Calibration Study",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Trust in AI",
            "Human-Agent Interaction"
        ],
        "dcat:keyword": [
            "trust calibration",
            "user behavior",
            "agent interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Author_B"
        ],
        "dcterms:description": "A study focused on compliance in human-agent interactions, analyzing how users respond to agent recommendations.",
        "dcterms:title": "Compliance Study",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Compliance",
            "Human-Agent Interaction"
        ],
        "dcat:keyword": [
            "compliance",
            "user behavior",
            "agent recommendations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Leslie Pack Kaelbling",
            "Michael L. Littman",
            "Anthony R. Cassandra"
        ],
        "dcterms:description": "A foundational study on planning and acting in partially observable stochastic domains, relevant for understanding decision-making in uncertain environments.",
        "dcterms:title": "Partially Observable Markov Decision Process (POMDP) Study",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Decision Making",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "POMDP",
            "decision making",
            "stochastic processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Leslie Pack Kaelbling",
            "Michael L. Littman",
            "Andrew W. Moore"
        ],
        "dcterms:description": "A comprehensive survey of reinforcement learning techniques and methodologies, providing insights into learning from interactions.",
        "dcterms:title": "Reinforcement Learning Study",
        "dcterms:issued": "1996",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "reinforcement learning",
            "learning algorithms",
            "AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]