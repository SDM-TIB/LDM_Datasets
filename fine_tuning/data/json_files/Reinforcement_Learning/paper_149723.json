[
    {
        "dcterms:creator": [
            "A. Zeng",
            "S. Song",
            "S. Welker",
            "J. Lee",
            "A. Rodriguez",
            "T. Funkhouser"
        ],
        "dcterms:description": "The VPG system is an example of a DQN algorithm applied to a robotic manipulation task where a robotic arm has to pick up individual objects from a cluttered heap. It uses RGB-D heightmaps to represent the states of the environment and trains two networks for grasping and pushing actions.",
        "dcterms:title": "Visual Pushing for Grasping (VPG) System",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic manipulation",
            "Deep Q-Learning",
            "Pushing",
            "Grasping"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object manipulation",
            "Action prediction"
        ]
    },
    {
        "dcterms:creator": [
            "M. Ewerton",
            "A. Martínez-González",
            "J.-M. Odobez"
        ],
        "dcterms:description": "The Hourglass system is an evolution of the VPG system that uses an Hourglass network architecture to solve a pushing task where the robot pushes objects into a box. It processes depth images and evaluates all action orientations simultaneously.",
        "dcterms:title": "Hourglass System",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2108.01034",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Object pushing",
            "Hourglass architecture",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2108.01034",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object manipulation",
            "Action prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Roboti LLC"
        ],
        "dcterms:description": "MuJoCo is a physics engine designed for research in optimal control, providing a simulation environment for robotic tasks.",
        "dcterms:title": "MuJoCo Simulation Environment",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "http://www.mujoco.org",
        "dcat:theme": [
            "Simulation",
            "Robotics"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Robotic simulation"
        ],
        "dcat:landingPage": "http://www.mujoco.org",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "OpenAI Gym is a toolkit for developing and comparing reinforcement learning algorithms, providing a variety of environments.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Toolkits"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Algorithm development"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1606.01540",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Raffin",
            "A. Hill",
            "M. Ernestus",
            "A. Gleave",
            "A. Kanervisto",
            "N. Dormann"
        ],
        "dcterms:description": "Stable Baselines3 is a set of reliable implementations of reinforcement learning algorithms, providing a framework for training and evaluating RL models.",
        "dcterms:title": "Stable Baselines3",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "http://github.com/DLR-RM/stable-baselines3",
        "dcat:theme": [
            "Reinforcement Learning",
            "Toolkits"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Algorithm implementation"
        ],
        "dcat:landingPage": "http://github.com/DLR-RM/stable-baselines3",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "E. Jang",
            "C. Devin",
            "V. Vanhoucke",
            "S. Levine"
        ],
        "dcterms:description": "Grasp2Vec is a system that learns object representations from self-supervised grasping, enabling better manipulation of objects.",
        "dcterms:title": "Grasp2Vec",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1811.06964",
        "dcat:theme": [
            "Robotics",
            "Self-supervised Learning"
        ],
        "dcat:keyword": [
            "Object representation",
            "Grasping"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1811.06964",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]