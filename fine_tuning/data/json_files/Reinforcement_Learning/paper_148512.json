[
    {
        "dcterms:creator": [
            "Martin L. Puterman"
        ],
        "dcterms:description": "An infinite-horizon discounted Markov decision process (MDP) defined by the tuple M = (S, A, p, r, d0, γ) where S is a finite set of states, A is a finite action set, p is the transition probability function, r is the reward function, d0 is the initial distribution of states, and γ is the discount factor.",
        "dcterms:title": "Markov Decision Processes (MDP)",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Processes"
        ],
        "dcat:keyword": [
            "MDP",
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Martin Riedmiller"
        ],
        "dcterms:description": "A data-efficient neural reinforcement learning method that utilizes fitted Q-iteration to improve learning efficiency.",
        "dcterms:title": "Fitted Q-iteration",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Q-Learning"
        ],
        "dcat:keyword": [
            "Fitted Q-iteration",
            "Neural Networks",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ronald J Williams"
        ],
        "dcterms:description": "A traditional policy gradient method that computes the gradient of the expected return with respect to the policy parameters.",
        "dcterms:title": "REINFORCE",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Policy Gradient",
            "REINFORCE",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Filip Wolski",
            "Prafulla Dhariwal",
            "Alec Radford",
            "Oleg Klimov"
        ],
        "dcterms:description": "A policy optimization algorithm that uses a surrogate objective function to improve training stability and performance.",
        "dcterms:title": "PPO (Proximal Policy Optimization)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Proximal Policy Optimization",
            "PPO",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Abbas Abdolmaleki",
            "Jost Tobias Springenberg",
            "Yuval Tassa",
            "Rémi Munos",
            "Nicolas Heess",
            "Martin A. Riedmiller"
        ],
        "dcterms:description": "A policy optimization method that focuses on maximizing the posterior probability of the policy given the data.",
        "dcterms:title": "MPO (Maximum a Posteriori Policy Optimization)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Maximum a Posteriori",
            "Policy Optimization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]