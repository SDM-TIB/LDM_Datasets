[
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "A toolkit for developing and comparing reinforcement learning algorithms, providing a variety of environments for testing.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Environment",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "A physics engine for simulating rigid body dynamics, used for continuous control tasks in reinforcement learning.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Physics Simulation"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Continuous control",
            "Simulation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Haarnoja",
            "A. Zhou",
            "P. Abbeel",
            "S. Levine"
        ],
        "dcterms:description": "An off-policy maximum entropy deep reinforcement learning algorithm that uses a stochastic actor.",
        "dcterms:title": "SAC (Soft Actor-Critic)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Maximum entropy",
            "Off-policy",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "S. Levine",
            "P. Abbeel",
            "M. Jordan",
            "P. Moritz"
        ],
        "dcterms:description": "A policy optimization algorithm that uses trust regions to ensure stable updates.",
        "dcterms:title": "TRPO (Trust Region Policy Optimization)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Trust region",
            "Policy optimization",
            "Stable updates"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "An algorithm for policy optimization that improves upon TRPO by using a clipped objective function.",
        "dcterms:title": "PPO (Proximal Policy Optimization)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Clipped objective",
            "Policy optimization",
            "Stable updates"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "K. Lee",
            "S. Choi",
            "S. Oh"
        ],
        "dcterms:description": "A method for reinforcement learning that incorporates Tsallis entropy for regularization in sparse Markov decision processes.",
        "dcterms:title": "Tsallis Entropy",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Entropy Regularization"
        ],
        "dcat:keyword": [
            "Tsallis entropy",
            "Sparse MDP",
            "Regularization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Azar",
            "V. GÃ³mez",
            "H. Kappen"
        ],
        "dcterms:description": "A framework for policy optimization that adapts dynamically to the environment.",
        "dcterms:title": "Dynamic Policy Programming",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Dynamic Programming"
        ],
        "dcat:keyword": [
            "Dynamic programming",
            "Policy optimization",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]