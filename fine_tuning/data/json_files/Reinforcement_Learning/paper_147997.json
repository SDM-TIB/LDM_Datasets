[
    {
        "dcterms:creator": [
            "P. Auer",
            "N. Cesa-Bianchi",
            "P. Fischer"
        ],
        "dcterms:description": "The UCB2 algorithm is a variant of the Upper Confidence Bound algorithm for multi-armed bandit problems, achieving the same regret bound as the original UCB but with a lower switching cost.",
        "dcterms:title": "UCB2 algorithm for multi-armed bandits",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Armed Bandits"
        ],
        "dcat:keyword": [
            "UCB2",
            "multi-armed bandits",
            "regret minimization",
            "switching cost"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Jin",
            "Z. Allen-Zhu",
            "S. Bubeck",
            "M. I. Jordan"
        ],
        "dcterms:description": "This dataset is used to analyze the efficiency of Q-learning algorithms with UCB exploration, focusing on regret bounds and performance metrics.",
        "dcterms:title": "Q-Learning with UCB exploration",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Q-Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "UCB exploration",
            "regret bounds",
            "efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Guo",
            "E. Brunskill"
        ],
        "dcterms:description": "This dataset focuses on concurrent PAC reinforcement learning, exploring the efficiency of algorithms in a concurrent setting.",
        "dcterms:title": "Concurrent PAC RL",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Concurrent Learning"
        ],
        "dcat:keyword": [
            "PAC learning",
            "concurrent algorithms",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. P. Hanna",
            "P. S. Thomas",
            "P. Stone",
            "S. Niekum"
        ],
        "dcterms:description": "This dataset is designed for data-efficient policy evaluation through behavior policy search, focusing on improving the efficiency of reinforcement learning algorithms.",
        "dcterms:title": "Data-efficient policy evaluation through behavior policy search",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Evaluation"
        ],
        "dcat:keyword": [
            "data efficiency",
            "policy evaluation",
            "behavior policy"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. G. Azar",
            "I. Osband",
            "R. Munos"
        ],
        "dcterms:description": "This dataset provides minimax regret bounds for reinforcement learning, focusing on theoretical guarantees for learning algorithms.",
        "dcterms:title": "Minimax regret bounds for reinforcement learning",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Theoretical Analysis"
        ],
        "dcat:keyword": [
            "minimax regret",
            "theoretical bounds",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Jaksch",
            "R. Ortner",
            "P. Auer"
        ],
        "dcterms:description": "This dataset presents near-optimal regret bounds for reinforcement learning, providing insights into the efficiency of learning algorithms.",
        "dcterms:title": "Near-optimal regret bounds for reinforcement learning",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Theoretical Analysis"
        ],
        "dcat:keyword": [
            "near-optimal bounds",
            "regret analysis",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Gao",
            "Y. Han",
            "Z. Ren",
            "Z. Zhou"
        ],
        "dcterms:description": "This dataset addresses the batched multi-armed bandits problem, focusing on the efficiency of algorithms in batch settings.",
        "dcterms:title": "Batched multi-armed bandits problem",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Armed Bandits"
        ],
        "dcat:keyword": [
            "batched algorithms",
            "multi-armed bandits",
            "batch learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Krishnan",
            "Z. Yang",
            "K. Goldberg",
            "J. Hellerstein",
            "I. Stoica"
        ],
        "dcterms:description": "This dataset is focused on learning to optimize join queries using deep reinforcement learning, exploring the intersection of database optimization and machine learning.",
        "dcterms:title": "Learning to optimize join queries with deep reinforcement learning",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Database Optimization"
        ],
        "dcat:keyword": [
            "join optimization",
            "deep reinforcement learning",
            "database queries"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "P. Raccuglia",
            "K. C. Elbert",
            "P. D. Adler",
            "C. Falk",
            "M. B. Wenny",
            "A. Mollo",
            "M. Zeller",
            "S. A. Friedler",
            "J. Schrier",
            "A. J. Norquist"
        ],
        "dcterms:description": "This dataset is focused on machine-learning-assisted materials discovery using failed experiments, showcasing the application of machine learning in materials science.",
        "dcterms:title": "Machine-learning-assisted materials discovery using failed experiments",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Materials Science"
        ],
        "dcat:keyword": [
            "materials discovery",
            "machine learning",
            "failed experiments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Theocharous",
            "P. S. Thomas",
            "M. Ghavamzadeh"
        ],
        "dcterms:description": "This dataset focuses on personalized ad recommendation systems for lifetime value optimization, providing insights into the effectiveness of recommendation algorithms.",
        "dcterms:title": "Personalized ad recommendation systems for life-time value optimization with guarantees",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Recommendation Systems"
        ],
        "dcat:keyword": [
            "personalized recommendations",
            "ad optimization",
            "lifetime value"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]