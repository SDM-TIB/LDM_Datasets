[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "A collection of Atari games used as a benchmark for reinforcement learning algorithms, providing a diverse set of environments for evaluating agent performance.",
        "dcterms:title": "Atari Games",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "A physics engine used for simulating continuous control tasks in reinforcement learning, providing environments for training and evaluating agents.",
        "dcterms:title": "Mujoco",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Robotics"
        ],
        "dcat:keyword": [
            "Mujoco",
            "Physics Simulation",
            "Continuous Control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robotics Control"
        ]
    },
    {
        "dcterms:creator": [
            "Hado Van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "dcterms:description": "A set of variants of the Deep Q-Network (DQN) algorithm, which improve upon the original DQN by addressing issues such as overestimation bias.",
        "dcterms:title": "DQN Variants",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "DQN",
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "S. Levine",
            "P. Moritz",
            "M. I. Jordan",
            "P. Abbeel"
        ],
        "dcterms:description": "An algorithm designed for optimizing policies in reinforcement learning, focusing on trust region methods to ensure stable updates.",
        "dcterms:title": "TRPO",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "TRPO",
            "Policy Optimization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "A. Puigdom`enech Badia",
            "M. Mirza",
            "A. Graves",
            "T. P. Lillicrap",
            "T. Harley",
            "D. Silver",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "A reinforcement learning algorithm that utilizes asynchronous updates to improve training efficiency and performance across various tasks.",
        "dcterms:title": "A3C",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Asynchronous Learning"
        ],
        "dcat:keyword": [
            "A3C",
            "Asynchronous",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Yuhuai Wu",
            "Elman Mansimov",
            "Roger B Grosse",
            "Shun Liao",
            "Jimmy Ba"
        ],
        "dcterms:description": "A scalable trust-region method for deep reinforcement learning that uses Kronecker-factored approximation to improve efficiency.",
        "dcterms:title": "ACKTR",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Trust Region Methods"
        ],
        "dcat:keyword": [
            "ACKTR",
            "Trust Region",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "An algorithm that optimizes policies using a clipped objective function to improve stability and performance in reinforcement learning.",
        "dcterms:title": "PPO",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "PPO",
            "Policy Optimization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "A variant of the PPO algorithm that uses a fixed Kullback-Leibler divergence penalty to stabilize training.",
        "dcterms:title": "Fixed KLD",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Fixed KLD",
            "Policy Optimization",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    }
]