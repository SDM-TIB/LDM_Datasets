[
    {
        "dcterms:creator": [
            "Kousha Etessami",
            "Mihalis Yannakakis"
        ],
        "dcterms:description": "Recursive Markov Decision Processes (RMDPs) are a finite collection of special MDPs, called component MDPs, with special entry and exit nodes that take the role of input parameter and return value, respectively. They can model probabilistic programs with recursive procedural calls.",
        "dcterms:title": "Recursive Markov Decision Processes (RMDPs)",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Probabilistic Modeling"
        ],
        "dcat:keyword": [
            "Markov Decision Processes",
            "Recursion",
            "Probabilistic Programs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Karim Lari",
            "Steve J Young"
        ],
        "dcterms:description": "Stochastic Context-Free Grammars are used to capture a structured evolution of a system and can be applied to modeling disease spread, population dynamics, and natural languages.",
        "dcterms:title": "Stochastic Context-Free Grammars",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Probabilistic Modeling"
        ],
        "dcat:keyword": [
            "Context-Free Grammars",
            "Stochastic Processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Modeling",
            "Learning Optimal Behavior"
        ]
    },
    {
        "dcterms:creator": [
            "Thomas Ball",
            "Sriram K Rajamani"
        ],
        "dcterms:description": "Probabilistic Program Synthesis involves the use of symbolic model checking for boolean programs, allowing for the synthesis of programs in uncertain environments.",
        "dcterms:title": "Probabilistic Program Synthesis",
        "dcterms:issued": "2000",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Software Verification",
            "Program Synthesis"
        ],
        "dcat:keyword": [
            "Symbolic Model Checking",
            "Boolean Programs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Program Verification",
            "Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Javier Esparza",
            "David Hansel",
            "Peter Rossmanith",
            "Stefan Schwoon"
        ],
        "dcterms:description": "Context-Free Reward Machines are used to model non-Markovian reward signals in reinforcement learning, allowing for more expressive reward schemes than regular languages.",
        "dcterms:title": "Context-Free Reward Machines",
        "dcterms:issued": "2000",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Reward Modeling"
        ],
        "dcat:keyword": [
            "Reward Machines",
            "Non-Markovian Signals"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reward Modeling",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Kousha Etessami",
            "Dominik Wojtczak",
            "Mihalis Yannakakis"
        ],
        "dcterms:description": "Recursive Stochastic Games with positive rewards are a framework for analyzing games that involve recursive structures and stochastic elements.",
        "dcterms:title": "Recursive Stochastic Games",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Stochastic Processes"
        ],
        "dcat:keyword": [
            "Stochastic Games",
            "Recursive Structures"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Analysis",
            "Optimal Strategy Computation"
        ]
    },
    {
        "dcterms:creator": [
            "Ernst Moritz Hahn",
            "Mateo Perez",
            "Sven Schewe",
            "Fabio Somenzi",
            "Ashutosh Trivedi",
            "Dominik Wojtczak"
        ],
        "dcterms:description": "Model-Free Reinforcement Learning for Branching Markov Decision Processes focuses on learning optimal policies without a model of the environment, specifically in branching MDPs.",
        "dcterms:title": "Model-Free Reinforcement Learning for Branching Markov Decision Processes",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Decision Processes"
        ],
        "dcat:keyword": [
            "Model-Free Learning",
            "Branching Processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Learning",
            "Reinforcement Learning"
        ]
    }
]