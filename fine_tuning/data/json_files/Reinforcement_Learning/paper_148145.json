[
    {
        "dcterms:creator": [
            "Dmitry Kalashnikov",
            "Alex Irpan",
            "Peter Pastor",
            "Julian Ibarz",
            "Alexander Herzog",
            "Eric Jang",
            "Deirdre Quillen",
            "Ethan Holly",
            "Mrinal Kalakrishnan",
            "Vincent Vanhoucke"
        ],
        "dcterms:description": "QT-Opt is a distributed Q-learning algorithm suitable for continuous action spaces, achieving a high vision-based grasp success rate on unseen objects.",
        "dcterms:title": "QT-Opt",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic manipulation",
            "Vision-based grasping",
            "Q-learning",
            "Continuous action spaces"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robotic grasping"
        ]
    },
    {
        "dcterms:creator": [
            "Jeffrey Mahler",
            "Jacky Liang",
            "Sherdil Niyaz",
            "Michael Laskey",
            "Richard Doan",
            "Xinyu Liu",
            "Juan Aparicio Ojea",
            "Ken Goldberg"
        ],
        "dcterms:description": "Dex-net 2.0 is a dataset that uses deep learning to plan robust grasps with synthetic point clouds and analytic grasp metrics.",
        "dcterms:title": "Dex-net 2.0",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Grasp Planning"
        ],
        "dcat:keyword": [
            "Deep learning",
            "Grasp planning",
            "Synthetic point clouds"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Grasp planning"
        ]
    },
    {
        "dcterms:creator": [
            "Marc G Bellemare",
            "Will Dabney",
            "RÂ´emi Munos"
        ],
        "dcterms:description": "The Arcade Game Environments dataset provides a distributional perspective on reinforcement learning, showcasing various Q-learning algorithms.",
        "dcterms:title": "Arcade Game Environments",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Environments"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Q-learning",
            "Game environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement learning"
        ]
    },
    {
        "dcterms:creator": [
            "Gabriel Barth-Maron",
            "Matthew W Hoffman",
            "David Budden",
            "Will Dabney",
            "Dan Horgan",
            "Alistair Muldal",
            "Nicolas Heess",
            "Timothy Lillicrap"
        ],
        "dcterms:description": "D4PG is a distributed and distributional version of DDPG that achieves superior performance in continuous-control environments.",
        "dcterms:title": "D4PG",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Continuous Control"
        ],
        "dcat:keyword": [
            "Distributed learning",
            "Continuous control",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous control"
        ]
    },
    {
        "dcterms:creator": [
            "Rishabh Agarwal",
            "Dale Schuurmans",
            "Mohammad Norouzi"
        ],
        "dcterms:description": "The Batch RL Dataset is used for off-policy deep reinforcement learning, focusing on simplicity and efficiency.",
        "dcterms:title": "Batch RL Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Off-Policy Learning"
        ],
        "dcat:keyword": [
            "Off-policy learning",
            "Deep reinforcement learning",
            "Batch learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Off-policy learning"
        ]
    }
]