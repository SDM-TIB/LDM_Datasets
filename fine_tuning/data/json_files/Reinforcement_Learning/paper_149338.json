[
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "A benchmark suite for evaluating reinforcement learning algorithms, consisting of various Atari games.",
        "dcterms:title": "Atari Benchmark Tasks",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "benchmark",
            "reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "K. Kavukcuoglu",
            "D. Silver",
            "A. Rusu",
            "J. Veness",
            "M. G. Bellemare",
            "A. Graves",
            "M. Riedmiller",
            "A. K. Fidjeland",
            "G. Ostrovski"
        ],
        "dcterms:description": "A deep reinforcement learning algorithm that combines Q-learning with deep neural networks to achieve human-level performance in Atari games.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Network",
            "Q-learning",
            "Atari games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "H. Van Hasselt",
            "A. Guez",
            "D. Silver"
        ],
        "dcterms:description": "An extension of DQN that mitigates overestimation bias by using two value functions.",
        "dcterms:title": "Double DQN",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Double DQN",
            "Q-learning",
            "Atari games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Fujimoto",
            "H. Hoof",
            "D. Meger"
        ],
        "dcterms:description": "A method that addresses function approximation error in actor-critic methods, improving stability and performance.",
        "dcterms:title": "Clipped Double Q-Learning",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Clipped Double Q-Learning",
            "actor-critic",
            "function approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "O. Anschel",
            "N. Baram",
            "N. Shimkin"
        ],
        "dcterms:description": "A method that reduces variance and stabilizes deep reinforcement learning through averaging.",
        "dcterms:title": "Averaged DQN",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Averaged DQN",
            "variance reduction",
            "deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Q. Lan",
            "Y. Pan",
            "A. Fyshe",
            "M. White"
        ],
        "dcterms:description": "A method that controls the estimation bias of Q-learning by using a max-min approach.",
        "dcterms:title": "Maxmin DQN",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Maxmin Q-learning",
            "estimation bias",
            "deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Wang",
            "T. Schaul",
            "M. Hessel",
            "H. Van Hasselt",
            "M. Lanctot",
            "N. Freitas"
        ],
        "dcterms:description": "A network architecture that separates value and advantage streams to improve learning efficiency.",
        "dcterms:title": "Dueling DDQN",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Dueling DDQN",
            "value function",
            "advantage function"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Fujimoto",
            "D. Meger",
            "D. Precup"
        ],
        "dcterms:description": "An off-policy deep reinforcement learning method that operates without exploration.",
        "dcterms:title": "Clipped Double DQN",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Clipped Double DQN",
            "off-policy",
            "deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]