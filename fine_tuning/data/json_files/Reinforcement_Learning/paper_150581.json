[
    {
        "dcterms:creator": [
            "L. Bu¸soniu",
            "R. Babuˇska",
            "B. D. Schutter"
        ],
        "dcterms:description": "A framework for multiple agents to optimize their strategies by repeatedly interacting with the environment, modeled as a stochastic game.",
        "dcterms:title": "Multi-agent reinforcement learning (MARL)",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1007/978-3-642-14435-6",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "Multi-agent",
            "Reinforcement learning",
            "Stochastic games"
        ],
        "dcat:landingPage": "https://doi.org/10.1007/978-3-642-14435-6",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. T. Icarte",
            "T. Klassen",
            "R. Valenzano",
            "S. McIlraith"
        ],
        "dcterms:description": "A method for high-level task specification and decomposition in reinforcement learning using reward machines.",
        "dcterms:title": "Reward machines",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Task Specification"
        ],
        "dcat:keyword": [
            "Reward machines",
            "Task decomposition",
            "High-level specification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. E. Lemke",
            "J. T. Howson, Jr"
        ],
        "dcterms:description": "A method for finding equilibrium points in bimatrix games.",
        "dcterms:title": "Lemke-Howson method",
        "dcterms:issued": "1964",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory"
        ],
        "dcat:keyword": [
            "Equilibrium points",
            "Bimatrix games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Hu",
            "M. P. Wellman"
        ],
        "dcterms:description": "A reinforcement learning algorithm for general-sum stochastic games that incorporates Nash equilibrium strategies.",
        "dcterms:title": "Nash Q-learning",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "Nash equilibrium",
            "Q-learning",
            "Stochastic games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Lowe",
            "Y. I. Wu",
            "A. Tamar",
            "J. Harb",
            "O. Pieter Abbeel",
            "I. Mordatch"
        ],
        "dcterms:description": "An actor-critic algorithm designed for mixed cooperative-competitive environments in multi-agent settings.",
        "dcterms:title": "Multi-agent deep deterministic policy gradient (MADDPG)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "Actor-critic",
            "Multi-agent",
            "Cooperative-competitive environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "X. Zhang",
            "K. Zhang",
            "E. Miehling",
            "T. Basar"
        ],
        "dcterms:description": "A method for learning reward functions in non-cooperative settings by observing expert behavior.",
        "dcterms:title": "Non-cooperative inverse reinforcement learning",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper/2019/file/56bd37d3a2fda0f2f41925019c81011d-Paper.pdf",
        "dcat:theme": [
            "Reinforcement Learning",
            "Inverse Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Non-cooperative",
            "Inverse reinforcement learning",
            "Expert behavior"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper/2019/file/56bd37d3a2fda0f2f41925019c81011d-Paper.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "X. Lin",
            "S. C. Adams",
            "P. A. Beling"
        ],
        "dcterms:description": "A method for multi-agent inverse reinforcement learning in general-sum stochastic games.",
        "dcterms:title": "Multi-agent inverse reinforcement learning",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Inverse Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Multi-agent",
            "Inverse reinforcement learning",
            "General-sum games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Toro Icarte",
            "E. Waldie",
            "T. Klassen",
            "R. Valenzano",
            "M. Castro",
            "S. McIlraith"
        ],
        "dcterms:description": "A method for learning reward machines specifically for partially observable reinforcement learning scenarios.",
        "dcterms:title": "Learning reward machines",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Reward machines",
            "Partially observable",
            "Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Xu",
            "B. Wu",
            "A. Ojha",
            "D. Neider",
            "U. Topcu"
        ],
        "dcterms:description": "A method for active inference of finite reward automata using queries and counterexamples.",
        "dcterms:title": "Active finite reward automaton inference",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Automata Theory"
        ],
        "dcat:keyword": [
            "Active inference",
            "Reward automata",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Neider",
            "J.-R. Gaglione",
            "I. Gavran",
            "U. Topcu",
            "B. Wu",
            "Z. Xu"
        ],
        "dcterms:description": "A method for reinforcement learning that incorporates advice in non-Markovian environments.",
        "dcterms:title": "Advice-guided reinforcement learning",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Advice Systems"
        ],
        "dcat:keyword": [
            "Advice-guided",
            "Reinforcement learning",
            "Non-Markovian"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]