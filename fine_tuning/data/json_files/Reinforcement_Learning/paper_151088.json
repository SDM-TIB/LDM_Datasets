[
    {
        "dcterms:creator": [
            "Holger Caesar",
            "Varun Bankiti",
            "Alex H. Lang",
            "Sourabh Vora",
            "Venice Erin Liong",
            "Qiang Xu",
            "Anush Krishnan",
            "Yuxin Pan",
            "Giancarlo Baldan",
            "Oscar Beijbom"
        ],
        "dcterms:description": "DriveLM-nuScenes consists of annotated QAs, arranged in a graph, linking images with driving behavior through logical reasoning. It provides significantly more text annotations per frame compared to existing benchmarks.",
        "dcterms:title": "DriveLM-nuScenes",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Graph Visual Question Answering",
            "Autonomous Driving",
            "Multi-modal Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering",
            "Driving Behavior Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Alexey Dosovitskiy",
            "German Ros",
            "Felipe Codevilla",
            "Antonio Lopez",
            "Vladlen Koltun"
        ],
        "dcterms:description": "DriveLM-CARLA consists of automatically generated frame-level question-answer pairs structured with an interconnected graph, allowing for scalable annotations and data without manual effort.",
        "dcterms:title": "DriveLM-CARLA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Simulation"
        ],
        "dcat:keyword": [
            "Graph Structure",
            "Driving Simulator",
            "Question-Answer Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering",
            "Driving Behavior Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "Tianwen Qian",
            "Jingjing Chen",
            "Linhai Zhuo",
            "Yang Jiao",
            "Yu-Gang Jiang"
        ],
        "dcterms:description": "NuScenes-QA is a multi-modal visual question answering benchmark for autonomous driving scenarios, providing a structured way to evaluate the understanding of driving contexts.",
        "dcterms:title": "nuScenes-QA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.14836",
        "dcat:theme": [
            "Autonomous Driving",
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Multi-modal",
            "Visual Question Answering",
            "Driving Scenarios"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dongming Wu",
            "Wencheng Han",
            "Tiancai Wang",
            "Yingfei Liu",
            "Xiangyu Zhang",
            "Jianbing Shen"
        ],
        "dcterms:description": "nuPrompt introduces language prompts for autonomous driving, facilitating the interaction between language models and driving tasks.",
        "dcterms:title": "nuPrompt",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2309.04379",
        "dcat:theme": [
            "Autonomous Driving",
            "Language Processing"
        ],
        "dcat:keyword": [
            "Language Prompt",
            "Autonomous Driving",
            "Interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Processing",
            "Driving Task Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Jinkyu Kim",
            "Teruhisa Misu",
            "Yi-Ting Chen",
            "Ashish Tawari",
            "John Canny"
        ],
        "dcterms:description": "HAD focuses on grounding human-to-vehicle advice for self-driving vehicles, providing insights into human interactions with autonomous systems.",
        "dcterms:title": "HAD",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Human Interaction"
        ],
        "dcat:keyword": [
            "Human Advice",
            "Self-Driving Vehicles",
            "Interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Human Interaction",
            "Driving Advice"
        ]
    },
    {
        "dcterms:creator": [
            "Jinkyu Kim",
            "Anna Rohrbach",
            "Trevor Darrell",
            "John Canny",
            "Zeynep Akata"
        ],
        "dcterms:description": "BDD-X provides textual explanations for self-driving vehicles, enhancing the interpretability of autonomous driving decisions.",
        "dcterms:title": "BDD-X",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Explainability"
        ],
        "dcat:keyword": [
            "Textual Explanations",
            "Self-Driving Vehicles",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Explainability",
            "Driving Decisions"
        ]
    },
    {
        "dcterms:creator": [
            "Srikanth Malla",
            "Chiho Choi",
            "Isht Dwivedi",
            "Joon Hee Choi",
            "Jiachen Li"
        ],
        "dcterms:description": "DRAMA focuses on joint risk localization and captioning in driving, providing a framework for understanding risks in autonomous driving scenarios.",
        "dcterms:title": "DRAMA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Risk Assessment"
        ],
        "dcat:keyword": [
            "Risk Localization",
            "Captioning",
            "Driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Risk Assessment",
            "Driving Safety"
        ]
    },
    {
        "dcterms:creator": [
            "Enna Sachdeva",
            "Nakul Agarwal",
            "Suhas Chundhok",
            "Shubham Priyadarshan",
            "Anushka Jain",
            "Arun Singh",
            "Siddharth Srivastava",
            "Krishna Murthy Jatavallabhula",
            "Madhava Krishna"
        ],
        "dcterms:description": "Rank2Tell is a multimodal driving dataset for joint importance ranking and reasoning, enhancing the understanding of driving scenarios.",
        "dcterms:title": "Rank2Tell",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2309.06597",
        "dcat:theme": [
            "Autonomous Driving",
            "Multimodal Reasoning"
        ],
        "dcat:keyword": [
            "Importance Ranking",
            "Driving Dataset",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multimodal Reasoning",
            "Driving Analysis"
        ]
    }
]