[
    {
        "dcterms:creator": [
            "M. Mnih",
            "K. Kavukcuoglu",
            "D. Silver",
            "A. Rusu",
            "J. Veness",
            "M. G. Bellemare",
            "A. Graves",
            "M. Riedmiller",
            "A. K. Fidjeland",
            "G. Ostrovski"
        ],
        "dcterms:description": "A dataset of various Atari games used to demonstrate human-level control through deep reinforcement learning.",
        "dcterms:title": "Atari games (Deep Q-network)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Gaming"
        ],
        "dcat:keyword": [
            "Atari",
            "Deep Q-network",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "N. Agarwal",
            "S. Chaudhuri",
            "P. Jain",
            "D. Nagaraj",
            "P. Netrapalli"
        ],
        "dcterms:description": "A dataset used for online target Q-learning with reverse experience replay, focusing on efficiently finding the optimal policy for linear MDPs.",
        "dcterms:title": "Gaussian auto-regressive model",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.08440",
        "dcat:theme": [
            "Reinforcement Learning",
            "Gaussian Processes"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Gaussian model",
            "Experience Replay"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "L. Lin"
        ],
        "dcterms:description": "Experience replay memory is a first-in-first-out queue that facilitates the adoption of mini-batch techniques in reinforcement learning.",
        "dcterms:title": "Experience replay memory",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Experience Replay",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning from Experience"
        ]
    },
    {
        "dcterms:creator": [
            "V. Konda",
            "J. Tsitsiklis"
        ],
        "dcterms:description": "Actor-critic algorithms are a class of reinforcement learning algorithms that utilize both value function approximation and policy optimization.",
        "dcterms:title": "Actor-critic algorithm",
        "dcterms:issued": "1999",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "R. S. Sutton"
        ],
        "dcterms:description": "A tabular setup for reinforcement learning that allows for the prediction of future rewards based on current states.",
        "dcterms:title": "Tabular setup",
        "dcterms:issued": "1988",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Tabular Methods",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "S. P. Singh",
            "R. S. Sutton"
        ],
        "dcterms:description": "Linear function approximation is a method used in reinforcement learning to generalize learning across similar states.",
        "dcterms:title": "Linear function approximation",
        "dcterms:issued": "1996",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Function Approximation",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "D. A. Levin",
            "Y. Peres"
        ],
        "dcterms:description": "Monte Carlo methods are used in reinforcement learning to estimate the value of states based on sampled returns.",
        "dcterms:title": "Monte Carlo methods",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Monte Carlo",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "C. J. Watkins",
            "P. Dayan"
        ],
        "dcterms:description": "Q-learning is a model-free reinforcement learning algorithm that seeks to learn the value of actions in states.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "N. Lazic",
            "D. Yin",
            "Y. Abbasi-Yadkori",
            "C. Szepesvari"
        ],
        "dcterms:description": "Regularized policy iteration is a reinforcement learning method that improves the regret bound using experience replay.",
        "dcterms:title": "Regularized policy iteration",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Policy Iteration",
            "Experience Replay"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "D. Ernst",
            "P. Geurts",
            "L. Wehenkel"
        ],
        "dcterms:description": "Fitted Q-learning is a batch reinforcement learning method that uses decision trees to approximate the Q-function.",
        "dcterms:title": "Fitted Q-learning",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Fitted Q-learning",
            "Batch Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value Function Approximation"
        ]
    }
]