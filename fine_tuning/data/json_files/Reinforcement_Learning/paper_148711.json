[
    {
        "dcterms:creator": [
            "R. Williams"
        ],
        "dcterms:description": "The REINFORCE algorithm is a vanilla policy gradient method that computes a stochastic approximate gradient with a single trajectory or a fixed size mini-batch of trajectories.",
        "dcterms:title": "REINFORCE algorithm",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Policy Gradient",
            "Stochastic Gradient",
            "Trajectory Sampling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "V. Mnih",
            "A. Badia",
            "M. Mirza",
            "A. Graves",
            "T. Lillicrap",
            "T. Harley",
            "D. Silver",
            "K. Kavukcuoglu"
        ],
        "dcterms:description": "A3C is an asynchronous method for deep reinforcement learning that allows for multiple agents to learn in parallel.",
        "dcterms:title": "A3C",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Asynchronous Learning",
            "Deep Reinforcement Learning",
            "Parallel Agents"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Silver",
            "G. Lever",
            "N. Heess",
            "T. Degris",
            "D. Wierstra",
            "M. Riedmiller"
        ],
        "dcterms:description": "DPG is a deterministic policy gradient algorithm that optimizes policies directly in continuous action spaces.",
        "dcterms:title": "DPG",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Deterministic Policy",
            "Continuous Actions",
            "Gradient Optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "S. Levine",
            "P. Abbeel",
            "M. Jordan",
            "P. Moritz"
        ],
        "dcterms:description": "PPO is a policy optimization algorithm that uses a trust region approach to improve training stability and performance.",
        "dcterms:title": "PPO",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Trust Region",
            "Policy Optimization",
            "Stability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "F. Wolski",
            "P. Dhariwal",
            "A. Radford",
            "O. Klimov"
        ],
        "dcterms:description": "TRPO is a policy optimization algorithm that ensures monotonic improvement in policy performance through a constrained optimization approach.",
        "dcterms:title": "TRPO",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Constrained Optimization",
            "Policy Improvement",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Fazel",
            "R. Ge",
            "S. Kakade",
            "M. Mesbahi"
        ],
        "dcterms:description": "Linear-quadratic regulators are a class of control problems that can be solved using policy gradient methods, providing insights into their global convergence properties.",
        "dcterms:title": "Linear-quadratic regulators",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Control Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Control Problems",
            "Policy Gradient",
            "Global Convergence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "L. Shani",
            "Y. Efroni",
            "S. Mannor"
        ],
        "dcterms:description": "Adaptive trust region policy optimization is a method that improves convergence rates for regularized Markov decision processes.",
        "dcterms:title": "Adaptive trust region policy optimization",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Adaptive Optimization",
            "Trust Region",
            "Convergence Rates"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "V. Konda",
            "J. Tsitsiklis"
        ],
        "dcterms:description": "Actor-critic methods combine value function approximation with policy gradient methods to improve learning efficiency.",
        "dcterms:title": "Actor-critic methods",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Value Function",
            "Policy Gradient"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Agarwal",
            "S. Kakade",
            "J. Lee",
            "G. Mahajan"
        ],
        "dcterms:description": "Natural policy gradient methods improve the efficiency of policy gradient methods by incorporating information about the curvature of the policy space.",
        "dcterms:title": "Natural policy gradient methods",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Natural Gradient",
            "Policy Optimization",
            "Curvature Information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Agarwal",
            "M. Henaff",
            "S. Kakade",
            "W. Sun"
        ],
        "dcterms:description": "Policy Cover Directed Exploration is a method that enhances exploration in policy gradient learning by using a policy cover.",
        "dcterms:title": "Policy Cover Directed Exploration",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Exploration",
            "Policy Gradient",
            "Directed Exploration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]