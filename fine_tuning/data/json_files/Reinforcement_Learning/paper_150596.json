[
    {
        "dcterms:creator": [
            "Emanuel Todorov",
            "Tom Erez",
            "Yuval Tassa"
        ],
        "dcterms:description": "MuJoCo is a physics engine for model-based control, widely used for continuous control tasks in reinforcement learning.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Physics Simulation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Model-based control",
            "Continuous control"
        ],
        "dcat:landingPage": "http://www.mujoco.org",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Chris Hesse",
            "Jacob Hilton",
            "John Schulman"
        ],
        "dcterms:description": "ProcGen is a set of 16 environments where game levels are procedurally generated, creating a virtually unlimited set of unique levels for benchmarking reinforcement learning.",
        "dcterms:title": "ProcGen",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Environments",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Procedural generation",
            "Benchmarking",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "Gymnasium is a toolkit for developing and comparing reinforcement learning algorithms, providing a variety of environments.",
        "dcterms:title": "Gymnasium",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Toolkits"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Environment toolkit",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Daniel Freeman",
            "Erik Frey",
            "Anton Raichuk",
            "Sertan Girgin",
            "Igor Mordatch",
            "Olivier Bachem"
        ],
        "dcterms:description": "Brax is a differentiable physics engine designed for large scale rigid body simulation, facilitating reinforcement learning research.",
        "dcterms:title": "Brax",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "http://github.com/google/brax",
        "dcat:theme": [
            "Physics Simulation",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Differentiable physics",
            "Rigid body simulation",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "http://github.com/google/brax",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Simulation"
        ]
    },
    {
        "dcterms:creator": [
            "Shengyi Huang",
            "Rousslan Fernand Julien Dossa",
            "Chang Ye",
            "Jeff Braga",
            "Dipam Chakraborty",
            "Kinal Mehta",
            "João G.M. Araújo"
        ],
        "dcterms:description": "CleanRL provides high-quality single-file implementations of deep reinforcement learning algorithms, aimed at reproducibility and ease of use.",
        "dcterms:title": "CleanRL",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "http://jmlr.org/papers/v23/21-1342.html",
        "dcat:theme": [
            "Reinforcement Learning",
            "Implementations"
        ],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Implementations",
            "Reproducibility"
        ],
        "dcat:landingPage": "http://jmlr.org/papers/v23/21-1342.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]