[
    {
        "dcterms:creator": [
            "Marc G Bellemare",
            "Yavar Naddaf",
            "Joel Veness",
            "Michael Bowling"
        ],
        "dcterms:description": "The Atari 2600 test-bed is used as a test environment for evaluating the performance of reinforcement learning algorithms.",
        "dcterms:title": "Atari 2600 test-bed",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Environment"
        ],
        "dcat:keyword": [
            "Atari",
            "Reinforcement Learning",
            "Test Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Koray Kavukcuoglu",
            "David Silver",
            "Alex Graves",
            "Ioannis Antonoglou",
            "Daan Wierstra",
            "Martin A. Riedmiller"
        ],
        "dcterms:description": "DQN is a deep reinforcement learning algorithm that uses a neural network to approximate the optimal action-value function.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1312.5602",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Network",
            "Reinforcement Learning",
            "Neural Network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Hado van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "dcterms:description": "Double DQN is an extension of DQN that reduces overestimation bias by using two separate networks for action selection and evaluation.",
        "dcterms:title": "Double DQN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1509.06461",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Double DQN",
            "Reinforcement Learning",
            "Neural Network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Tom Schaul",
            "John Quan",
            "Ioannis Antonoglou",
            "David Silver"
        ],
        "dcterms:description": "Prioritized Experience Replay improves the learning efficiency of DQN by replaying important transitions more frequently.",
        "dcterms:title": "Prioritized Experience Replay",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1511.05952",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Experience Replay",
            "Reinforcement Learning",
            "Learning Efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Ziyu Wang",
            "Nando de Freitas",
            "Marc Lanctot"
        ],
        "dcterms:description": "Dueling DQN introduces a new architecture that separates the representation of state value and action advantage, improving learning.",
        "dcterms:title": "Dueling DQN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1511.06581",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Dueling DQN",
            "Reinforcement Learning",
            "Neural Network"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "Xiaolin Wang",
            "Masao Utiyama",
            "Eiichiro Sumita"
        ],
        "dcterms:description": "CytonMT is an efficient neural machine translation open-source toolkit implemented in C++.",
        "dcterms:title": "CytonMT",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1802.07170",
        "dcat:theme": [
            "Machine Translation",
            "Open Source Toolkit"
        ],
        "dcat:keyword": [
            "Neural Machine Translation",
            "Open Source",
            "C++ Toolkit"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]