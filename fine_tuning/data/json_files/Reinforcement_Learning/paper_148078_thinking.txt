To extract datasets from the research paper titled "Vision-based Navigation Using Deep Reinforcement Learning" by Jonáš Kulhánek et al., I will follow a systematic approach to identify and document the datasets mentioned in the text.

First, I will read through the **abstract, introduction, and experiments sections** to look for any references to datasets. The abstract mentions the use of the **AI2-THOR environment simulator**, which suggests that this is a dataset or environment used for training and evaluation.

Next, I will examine the **experiments section** in detail, particularly the parts where the authors describe the environments used for their experiments. In this section, they mention three different 3D environment simulators:

1. **DeepMind Lab**: This is described as a 3D framework allowing agents to move and collect objects in synthetic environments. It is used for training AI agents and comparing algorithms.

2. **AI2-THOR**: This is highlighted as a photo-realistic interactive framework with high-quality indoor images. The authors modified this environment to allow for continuous space navigation.

3. **House3D with SUNCG**: This framework utilizes environments from the SUNCG dataset, which consists of over 45,000 indoor environments.

In the **references section**, I will look for full citations for these datasets and environments. The relevant citations are:

- For **AI2-THOR**, the citation is:
  > E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. "AI2-THOR: An Interactive 3D Environment for Visual AI." arXiv, Dec 2017.

- For **SUNCG**, the citation is:
  > S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, and T. Funkhouser. "Semantic scene completion from a single depth image." Proceedings of 29th IEEE Conference on Computer Vision and Pattern Recognition, 2017.

Now, I will compile the dataset entries with their full citations. 

1. **AI2-THOR Environment**: A photo-realistic interactive framework for visual AI, used for training agents in indoor navigation tasks.
   - Citation: E. Kolve, R. Mottaghi, D. Gordon, Y. Zhu, A. Gupta, and A. Farhadi. "AI2-THOR: An Interactive 3D Environment for Visual AI." arXiv, Dec 2017.

2. **SUNCG Dataset**: A dataset consisting of over 45,000 indoor environments, primarily used in the House3D framework for training AI agents.
   - Citation: S. Song, F. Yu, A. Zeng, A. X. Chang, M. Savva, and T. Funkhouser. "Semantic scene completion from a single depth image." Proceedings of 29th IEEE Conference on Computer Vision and Pattern Recognition, 2017.

After gathering this information, I will ensure that the dataset entries are structured properly for any further processing or review.