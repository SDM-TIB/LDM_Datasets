[
    {
        "dcterms:creator": [
            "M. G. Bellemare",
            "Y. Naddaf",
            "J. Veness",
            "M. Bowling"
        ],
        "dcterms:description": "The Arcade Learning Environment is an evaluation platform for general agents, providing a suite of Atari games for testing reinforcement learning algorithms.",
        "dcterms:title": "Atari Games",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Gaming"
        ],
        "dcat:keyword": [
            "Atari",
            "Game Environment",
            "Reinforcement Learning Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Berner",
            "G. Brockman",
            "B. Chan",
            "V. Cheung",
            "P. Debiak",
            "C. Dennison",
            "D. Farhi",
            "Q. Fischer",
            "S. Hashme",
            "C. Hesse"
        ],
        "dcterms:description": "Dota 2 with large scale deep reinforcement learning is a project that applies deep reinforcement learning techniques to the game Dota 2.",
        "dcterms:title": "Dota 2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1912.06680",
        "dcat:theme": [
            "Reinforcement Learning",
            "Gaming"
        ],
        "dcat:keyword": [
            "Dota 2",
            "Deep Reinforcement Learning",
            "Game AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "L. Espeholt",
            "H. Soyer",
            "R. Munos",
            "K. Simonyan",
            "V. Mnih",
            "T. Ward",
            "Y. Doron",
            "V. Firoiu",
            "T. Harley",
            "I. Dunning"
        ],
        "dcterms:description": "IMPALA is a scalable distributed deep reinforcement learning architecture that utilizes importance weighted actor-learner architectures.",
        "dcterms:title": "IMPALA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Distributed Systems"
        ],
        "dcat:keyword": [
            "IMPALA",
            "Deep Reinforcement Learning",
            "Distributed Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Kapturowski",
            "G. Ostrovski",
            "W. Dabney",
            "J. Quan",
            "R. Munos"
        ],
        "dcterms:description": "R2D2 is a reinforcement learning algorithm that incorporates recurrent experience replay in distributed reinforcement learning.",
        "dcterms:title": "R2D2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Distributed Systems"
        ],
        "dcat:keyword": [
            "R2D2",
            "Reinforcement Learning",
            "Experience Replay"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Harutyunyan",
            "M. G. Bellemare",
            "T. Stepleton",
            "R. Munos"
        ],
        "dcterms:description": "Q(位) with Off-Policy Corrections is a method that combines off-policy corrections with the Q(位) algorithm for reinforcement learning.",
        "dcterms:title": "Q(位)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Off-Policy Learning"
        ],
        "dcat:keyword": [
            "Q(位)",
            "Off-Policy Learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Schulman",
            "P. Moritz",
            "S. Levine",
            "M. Jordan",
            "P. Abbeel"
        ],
        "dcterms:description": "Generalized Advantage Estimation (GAE) is a method for estimating advantages in high-dimensional continuous control tasks.",
        "dcterms:title": "Generalized Advantage Estimation (GAE)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control"
        ],
        "dcat:keyword": [
            "GAE",
            "Advantage Estimation",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]