[
    {
        "dcterms:creator": [
            "D. Assaf",
            "M. Shared",
            "J. G. Shanthikumar"
        ],
        "dcterms:description": "The Mean First Passage Time (MFPT) analysis is built on the Markov chain and gives information about the short range behavior of the chain, providing insights into the reachability of states in Markov Decision Processes.",
        "dcterms:title": "First-passage times with pfr densities",
        "dcterms:issued": "1985",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Mean First Passage Time",
            "Markov Chains",
            "Reachability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. H. Golub",
            "C. F. Van Loan"
        ],
        "dcterms:description": "This dataset provides foundational knowledge on matrix computations, which is essential for solving linear systems involved in calculating Mean First Passage Times.",
        "dcterms:title": "Matrix Computations",
        "dcterms:issued": "1996",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Matrix Computations",
            "Linear Systems"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Boutilier",
            "R. I. Brafman",
            "C. Geib"
        ],
        "dcterms:description": "Structured reachability analysis for Markov Decision Processes, which evaluates whether a state is reachable or not, thus reducing the computational burden of solving an MDP.",
        "dcterms:title": "Structured reachability analysis for markov decision processes",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Structured Reachability",
            "Markov Decision Processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. G. Barto",
            "S. J. Bradtke",
            "S. P. Singh"
        ],
        "dcterms:description": "This dataset discusses learning to act using real-time dynamic programming, which is relevant for understanding the dynamics of decision-making in uncertain environments.",
        "dcterms:title": "Learning to act using real-time dynamic programming",
        "dcterms:issued": "1995",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Real-time Dynamic Programming",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. W. Moore",
            "C. G. Atkeson"
        ],
        "dcterms:description": "Prioritized sweeping is a reinforcement learning technique that allows for learning with less data and less time, which is crucial for efficient MDP solving.",
        "dcterms:title": "Prioritized sweeping: Reinforcement learning with less data and less time",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Prioritized Sweeping",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. S. Sutton"
        ],
        "dcterms:description": "This work discusses integrated architectures for learning, planning, and reacting based on approximating dynamic programming, which is fundamental for MDP applications.",
        "dcterms:title": "Integrated architectures for learning, planning, and reacting based on approximating dynamic programming",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Dynamic Programming",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "O. Sigaud",
            "O. Buffet"
        ],
        "dcterms:description": "This book provides a comprehensive overview of Markov Decision Processes in artificial intelligence, covering various applications and theoretical foundations.",
        "dcterms:title": "Markov decision processes in artificial intelligence",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Markov Decision Processes",
            "Artificial Intelligence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Busoniu",
            "R. Babuska",
            "B. De Schutter",
            "D. Ernst"
        ],
        "dcterms:description": "This work discusses reinforcement learning and dynamic programming using function approximators, which is relevant for solving MDPs efficiently.",
        "dcterms:title": "Reinforcement learning and dynamic programming using function approximators",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Dynamic Programming"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Russell",
            "P. Norvig"
        ],
        "dcterms:description": "This book provides a modern approach to artificial intelligence, covering various foundational concepts including decision-making processes.",
        "dcterms:title": "Artificial intelligence: A modern approach",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "http://aima.cs.berkeley.edu/",
        "dcat:theme": [],
        "dcat:keyword": [
            "Artificial Intelligence",
            "Decision Making"
        ],
        "dcat:landingPage": "http://aima.cs.berkeley.edu/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. J. White"
        ],
        "dcterms:description": "This survey discusses various applications of Markov Decision Processes, providing insights into their practical implementations.",
        "dcterms:title": "A survey of applications of markov decision processes",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Markov Decision Processes",
            "Applications"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]