[
    {
        "dcterms:creator": [
            "Yuntao Bai",
            "Andy Jones",
            "Kamal Ndousse",
            "Amanda Askell",
            "Anna Chen",
            "Nova DasSarma",
            "Dawn Drain",
            "Stanislav Fort",
            "Deep Ganguli",
            "Tom Henighan"
        ],
        "dcterms:description": "The Helpful and Harmless dataset provides chosen and rejected responses for each query based on human preferences, specifically focusing on generating helpful and harmless responses.",
        "dcterms:title": "Helpful and Harmless dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Human Preferences",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Generation",
            "Preference Alignment"
        ]
    },
    {
        "dcterms:creator": [
            "Rohan Taori",
            "Ishaan Gulrajani",
            "Tianyi Zhang",
            "Yann Dubois",
            "Xuechen Li",
            "Carlos Guestrin",
            "Percy Liang",
            "Tatsunori B. Hashimoto"
        ],
        "dcterms:description": "The Alpaca prompts dataset consists of instruction-following prompts designed to train language models to follow human instructions effectively.",
        "dcterms:title": "Alpaca prompts",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction Tuning",
            "Language Models",
            "Prompt Engineering"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Thibaut Lavril",
            "Gautier Izacard",
            "Xavier Martinet",
            "Marie-Anne Lachaux",
            "Timothée Lacroix",
            "Baptiste Rozière",
            "Naman Goyal",
            "Eric Hambro",
            "Faisal Azhar"
        ],
        "dcterms:description": "LLaMA is an open and efficient foundation language model designed for various natural language processing tasks.",
        "dcterms:title": "LLaMA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Foundation Models",
            "Language Models",
            "Open Source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Wei-Lin Chiang",
            "Zhuohan Li",
            "Zi Lin",
            "Ying Sheng",
            "Zhanghao Wu",
            "Hao Zhang",
            "Lianmin Zheng",
            "Siyuan Zhuang",
            "Yonghao Zhuang",
            "Joseph E. Gonzalez",
            "Ion Stoica",
            "Eric P. Xing"
        ],
        "dcterms:description": "The Vicuna test set is designed to evaluate the performance of chatbots, specifically comparing their quality to that of GPT-4.",
        "dcterms:title": "Vicuna test set",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Chatbot Evaluation"
        ],
        "dcat:keyword": [
            "Chatbot Quality",
            "Evaluation Dataset",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Chatbot Evaluation"
        ]
    }
]