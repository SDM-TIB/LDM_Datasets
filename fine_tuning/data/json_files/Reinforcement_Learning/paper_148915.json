[
    {
        "dcterms:creator": [
            "M. Vecerik",
            "T. Hester",
            "J. Scholz",
            "F. Wang",
            "O. Pietquin",
            "B. Piot",
            "N. Heess",
            "T. Rothörl",
            "T. Lampe",
            "M. Riedmiller"
        ],
        "dcterms:description": "Data collected from human demonstrations to train the robot's collision avoidance algorithm.",
        "dcterms:title": "Human demonstration data",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.08817",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Human demonstration",
            "Collision avoidance",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Collision avoidance"
        ]
    },
    {
        "dcterms:creator": [
            "P. Long",
            "T. Fanl",
            "X. Liao",
            "W. Liu",
            "H. Zhang",
            "J. Pan"
        ],
        "dcterms:description": "Data generated from simulated agents for training collision avoidance algorithms.",
        "dcterms:title": "Simulated agent data",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Simulated data",
            "Collision avoidance",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Collision avoidance"
        ]
    },
    {
        "dcterms:creator": [
            "L. Tai",
            "G. Paolo",
            "M. Liu"
        ],
        "dcterms:description": "Laser data used to inform the robot's navigation and collision avoidance strategies.",
        "dcterms:title": "Laser data",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Navigation"
        ],
        "dcat:keyword": [
            "Laser data",
            "Navigation",
            "Collision avoidance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Collision avoidance"
        ]
    },
    {
        "dcterms:creator": [
            "M. Vecerik",
            "T. Hester",
            "J. Scholz",
            "F. Wang",
            "O. Pietquin",
            "B. Piot",
            "N. Heess",
            "T. Rothörl",
            "T. Lampe",
            "M. Riedmiller"
        ],
        "dcterms:description": "Transition data collected from human demonstrators to enhance the learning process of the robot.",
        "dcterms:title": "Transition data from human demonstrators",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.08817",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Transition data",
            "Human demonstration",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Collision avoidance"
        ]
    },
    {
        "dcterms:creator": [
            "J. Zhang",
            "J. T. Springenberg",
            "J. Boedecker",
            "W. Burgard"
        ],
        "dcterms:description": "Data containing Q-values and rewards used to evaluate the performance of the navigation algorithm.",
        "dcterms:title": "Q-value and reward data",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Q-value data",
            "Reward data",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Collision avoidance"
        ]
    },
    {
        "dcterms:creator": [
            "M. Vecerik",
            "T. Hester",
            "J. Scholz",
            "F. Wang",
            "O. Pietquin",
            "B. Piot",
            "N. Heess",
            "T. Rothörl",
            "T. Lampe",
            "M. Riedmiller"
        ],
        "dcterms:description": "Experience replay buffer data used to enhance the learning efficiency of the robot.",
        "dcterms:title": "Experience replay buffer data",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.08817",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Experience replay",
            "Reinforcement learning",
            "Data buffer"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Collision avoidance"
        ]
    }
]