[
    {
        "dcterms:creator": [
            "R. Agarwal",
            "M. Schwarzer",
            "P. S. Castro",
            "A. C. Courville",
            "M. Bellemare"
        ],
        "dcterms:description": "The Atari benchmark is a widely used suite of games for evaluating reinforcement learning algorithms, providing a diverse set of environments for testing various learning strategies.",
        "dcterms:title": "Atari benchmark",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Reinforcement Learning Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "M. C. Machado",
            "M. G. Bellemare",
            "E. Talvitie",
            "J. Veness",
            "M. Hausknecht",
            "M. Bowling"
        ],
        "dcterms:description": "The Arcade Learning Environment (ALE) provides a framework for developing and evaluating reinforcement learning agents on Atari games, allowing for standardized testing and comparison.",
        "dcterms:title": "Arcade Learning Environment (ALE)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement Learning",
            "Evaluation Framework"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing",
            "Reinforcement Learning Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "I. Osband",
            "C. Blundell",
            "A. Pritzel",
            "B. Van Roy"
        ],
        "dcterms:description": "Bootstrapped DQN is a reinforcement learning algorithm that enhances exploration by using multiple heads in a neural network to estimate Q-values, allowing for more diverse action selection.",
        "dcterms:title": "Bootstrapped DQN",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Deep Q-Learning",
            "Exploration",
            "Bootstrapping"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Exploration"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Wang",
            "T. Schaul",
            "M. Hessel",
            "H. Hasselt",
            "M. Lanctot",
            "N. Freitas"
        ],
        "dcterms:description": "Dueling Q-learning is an architecture that separates the representation of state values and action advantages, improving the stability and performance of Q-learning algorithms.",
        "dcterms:title": "Dueling Q-learning",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Dueling Architecture",
            "Q-Learning",
            "Deep Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "H. Hasselt"
        ],
        "dcterms:description": "Double Q-learning is a technique that mitigates the overestimation bias in Q-learning by maintaining two separate value functions, improving the learning stability.",
        "dcterms:title": "Double Q-learning",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Double Q-Learning",
            "Bias Reduction",
            "Stability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Game Playing"
        ]
    },
    {
        "dcterms:creator": [
            "M. Fortunato",
            "M. G. Azar",
            "B. Piot",
            "J. Menick",
            "I. Osband",
            "A. Graves",
            "V. Mnih",
            "R. Munos",
            "D. Hassabis",
            "O. Pietquin"
        ],
        "dcterms:description": "Noisy networks introduce noise into the weights of neural networks to enhance exploration in reinforcement learning, allowing agents to explore more effectively.",
        "dcterms:title": "Noisy networks",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration"
        ],
        "dcat:keyword": [
            "Exploration",
            "Noise",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Exploration",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "L. Chen",
            "K. Lu",
            "A. Rajeswaran",
            "K. Lee",
            "A. Grover",
            "M. Laskin",
            "P. Abbeel",
            "A. Srinivas",
            "I. Mordatch"
        ],
        "dcterms:description": "The Decision Transformer is a novel approach that applies sequence modeling techniques to reinforcement learning, enabling agents to learn from past experiences more effectively.",
        "dcterms:title": "Decision Transformer",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Sequence Modeling"
        ],
        "dcat:keyword": [
            "Sequence Modeling",
            "Reinforcement Learning",
            "Transformers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning",
            "Decision Making"
        ]
    }
]