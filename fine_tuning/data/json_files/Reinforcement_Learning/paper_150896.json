[
    {
        "dcterms:creator": [
            "H. Hasselt"
        ],
        "dcterms:description": "Grid World is an environment where the agent can take one of four actions at each state: move up, down, left, or right. The episode starts at a designated state, and the goal state is reached by navigating through the grid. The agent receives random rewards during transitions and a specific reward upon reaching the goal state.",
        "dcterms:title": "Grid World",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Process"
        ],
        "dcat:keyword": [
            "Grid World",
            "Q-learning",
            "Reinforcement Learning Environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "R. Sutton",
            "A. Barto"
        ],
        "dcterms:description": "Sutton's MDP is a well-known example used to illustrate maximization bias in Q-learning. It consists of non-terminal states where actions lead to either immediate termination or transitions to other states with associated rewards drawn from a normal distribution.",
        "dcterms:title": "Sutton’s MDP",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Process"
        ],
        "dcat:keyword": [
            "Sutton's MDP",
            "Maximization Bias",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "W. Weng",
            "H. Gupta",
            "N. He",
            "L. Ying",
            "R. Srikant"
        ],
        "dcterms:description": "Weng's MDP is adapted to demonstrate maximization bias in Q-learning. It features multiple states and actions, where actions lead to either immediate termination or transitions to other states, with rewards drawn from a normal distribution.",
        "dcterms:title": "Weng’s MDP",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Markov Decision Process"
        ],
        "dcat:keyword": [
            "Weng's MDP",
            "Maximization Bias",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]