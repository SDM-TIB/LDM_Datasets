[
    {
        "dcterms:creator": [
            "Alex Wilson"
        ],
        "dcterms:description": "A corpus of approximately 240,300 Tweets used to compute word frequencies for the purpose of linguistic steganography.",
        "dcterms:title": "Stanford Sentiment Analysis Dataset",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Tweets",
            "Word frequencies",
            "Linguistic steganography"
        ],
        "dcat:landingPage": "ui.adsabs.harvard.edu/abs/2014SPIE.9028E..03W/abstract",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis",
            "Linguistic Steganography"
        ]
    }
]