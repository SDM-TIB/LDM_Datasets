[
    {
        "dcterms:creator": [
            "C. J. Watkins",
            "P. Dayan"
        ],
        "dcterms:description": "A dataset used to study the Q-learning algorithm, which is a reinforcement learning method that estimates the optimal action-value function.",
        "dcterms:title": "Q-learning with linear function approximation",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Reinforcement learning",
            "Function approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. S. Sutton"
        ],
        "dcterms:description": "A dataset related to the TD-learning algorithm, which is a method for learning predictions based on temporal differences.",
        "dcterms:title": "TD-learning algorithm",
        "dcterms:issued": "1988",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Temporal difference learning",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Baird"
        ],
        "dcterms:description": "A counter-example dataset used to illustrate the divergence of Q-learning with linear function approximation.",
        "dcterms:title": "Bairdâ€™s counter-example",
        "dcterms:issued": "1995",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Counter-examples"
        ],
        "dcat:keyword": [
            "Counter-example",
            "Divergence",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. N. Tsitsiklis"
        ],
        "dcterms:description": "A dataset used to analyze asynchronous Q-learning, which is a variant of Q-learning that updates estimates asynchronously.",
        "dcterms:title": "Asynchronous Q-learning",
        "dcterms:issued": "1994",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Asynchronous Learning"
        ],
        "dcat:keyword": [
            "Asynchronous Q-learning",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Chen",
            "S. T. Maguluri",
            "S. Shakkottai",
            "K. Shanmugam"
        ],
        "dcterms:description": "A dataset that provides finite-sample analysis of stochastic approximation methods using smooth convex envelopes.",
        "dcterms:title": "Finite-sample analysis of stochastic approximation",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2002.00874",
        "dcat:theme": [
            "Stochastic Approximation",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Stochastic approximation",
            "Finite-sample analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Qu",
            "A. Wierman"
        ],
        "dcterms:description": "A dataset that studies the sample complexity of asynchronous Q-learning, providing finite-time analysis.",
        "dcterms:title": "Sample complexity of asynchronous Q-learning",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2002.00260",
        "dcat:theme": [
            "Reinforcement Learning",
            "Sample Complexity"
        ],
        "dcat:keyword": [
            "Asynchronous Q-learning",
            "Sample complexity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. L. Beck",
            "R. Srikant"
        ],
        "dcterms:description": "A dataset that provides improved upper bounds on the expected error in constant step-size Q-learning.",
        "dcterms:title": "Improved upper bounds on the expected error in constant step-size Q-learning",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Error Bounds"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Error bounds"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "E. Even-Dar",
            "Y. Mansour"
        ],
        "dcterms:description": "A dataset that provides concentration results for asynchronous Q-learning, focusing on learning rates.",
        "dcterms:title": "Concentration results for asynchronous Q-learning",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Asynchronous Learning"
        ],
        "dcat:keyword": [
            "Asynchronous Q-learning",
            "Learning rates"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Bhandari",
            "D. Russo",
            "R. Singal"
        ],
        "dcterms:description": "A dataset that provides finite-sample convergence bounds for Q-learning with linear function approximation.",
        "dcterms:title": "Finite-sample convergence bounds for Q-learning with linear function approximation",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Convergence Bounds"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Convergence bounds",
            "Linear function approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]