[
    {
        "dcterms:creator": [
            "Ouyang et al."
        ],
        "dcterms:description": "A large-scale collection of pair-level human preferences in AI responses, used to evaluate the effectiveness of alignment algorithms.",
        "dcterms:title": "Anthropic-RLHF-HH dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/datasets/Anthropic/hh-rlhf",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Human preferences",
            "AI responses",
            "Reinforcement Learning from Human Feedback"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/Anthropic/hh-rlhf",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference modeling",
            "Response evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset focused on personalized preferences featuring 536 samples spanning five preference domains, aiming to model a diverse range of user needs.",
        "dcterms:title": "Personalized preference dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Personalization",
            "User Preferences"
        ],
        "dcat:keyword": [
            "Personalized preferences",
            "User needs",
            "Preference modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference modeling",
            "Response generation"
        ]
    },
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A large dataset containing video clips with 13 joints annotated in all frames, including head, shoulders, elbows, wrists, hips, knees, and ankles.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human pose",
            "Joint estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. ZufÔ¨Å",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "A dataset for action recognition that includes video clips with annotated actions.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Action recognition",
            "Video dataset",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    }
]