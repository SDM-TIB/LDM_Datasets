[
    {
        "dcterms:creator": [
            "Pei-Hao Su",
            "Milica Gasic",
            "Nikola Mrkˇsi´c",
            "Lina Rojas-Barahona",
            "Stefan Ultes",
            "David Vandyke",
            "Tsung-Hsien Wen",
            "Steve Young"
        ],
        "dcterms:description": "A corpus of 720 real user spoken dialogues in the Cambridge restaurant domain, used to mitigate poor performance in the early stages of learning.",
        "dcterms:title": "Cambridge restaurant domain corpus",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Spoken Dialogue",
            "User Interaction",
            "Dialogue Management"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "D. Dahlb¨ack",
            "A. J¨onsson",
            "L. Ahrenberg"
        ],
        "dcterms:description": "Methods for collecting domain-specific training corpora through simulated user interactions.",
        "dcterms:title": "Wizard-of-Oz (WoZ) methods",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "User Simulation",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "User Studies",
            "Training Data Collection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Stefan Ultes",
            "Lina M. Rojas Barahona",
            "Pei-Hao Su",
            "David Vandyke",
            "Dongho Kim",
            "Inigo Casanueva",
            "Pawel Budzianowski",
            "Nikola Mrkˇsi´c",
            "Tsung-Hsien Wen",
            "Milica Gaˇsi´c",
            "Steve Young"
        ],
        "dcterms:description": "A multi-domain statistical dialogue system toolkit that provides a platform for modular spoken dialogue systems.",
        "dcterms:title": "PyDial",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Dialogue Management",
            "Toolkit",
            "Statistical Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Milica Gaˇsi´c",
            "Steve Young"
        ],
        "dcterms:description": "A method for optimizing dialogue managers using Gaussian processes, providing estimates of uncertainty and enabling sample-efficient exploration.",
        "dcterms:title": "Gaussian Processes (GP)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Gaussian Processes",
            "Dialogue Management",
            "Optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Hado Van Hasselt",
            "Arthur Guez",
            "David Silver"
        ],
        "dcterms:description": "A deep reinforcement learning algorithm that improves the stability and performance of Q-learning through double Q-learning.",
        "dcterms:title": "DQN (Deep Q-Network)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Deep Learning",
            "Q-Learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Milica Gaˇsi´c",
            "Filip Jurcicek",
            "Blaise Thomson",
            "Kai Yu",
            "Steve Young"
        ],
        "dcterms:description": "A reinforcement learning approach that utilizes Gaussian processes to optimize dialogue policies through live interaction.",
        "dcterms:title": "GPRL (Gaussian Process Reinforcement Learning)",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "Gaussian Processes",
            "Reinforcement Learning",
            "Dialogue Management"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Verena Rieser",
            "Oliver Lemon"
        ],
        "dcterms:description": "A supervised learning approach that initializes reinforcement learning-based dialogue systems using logistic regression.",
        "dcterms:title": "SL (Supervised Learning)",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Supervised Learning",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "Logistic Regression",
            "Dialogue Management",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Sergey Levine",
            "Philipp Moritz",
            "Michael I Jordan",
            "Pieter Abbeel"
        ],
        "dcterms:description": "A reinforcement learning algorithm that optimizes policies using trust region methods and experience replay.",
        "dcterms:title": "eNACER (Episodic Natural Actor-Critic with Experience Replay)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "Natural Actor-Critic",
            "Experience Replay",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]