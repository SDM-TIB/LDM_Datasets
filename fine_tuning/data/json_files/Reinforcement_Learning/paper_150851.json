[
    {
        "dcterms:creator": [
            "Justin Fu",
            "Aviral Kumar",
            "Ofir Nachum",
            "George Tucker",
            "Sergey Levine"
        ],
        "dcterms:description": "D4RL Gym locomotion datasets are used for evaluating offline reinforcement learning algorithms, providing various environments for testing.",
        "dcterms:title": "D4RL Gym locomotion datasets",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Offline Reinforcement Learning",
            "D4RL",
            "Gym Environments"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2004.07219",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Justin Fu",
            "Aviral Kumar",
            "Ofir Nachum",
            "George Tucker",
            "Sergey Levine"
        ],
        "dcterms:description": "MuJoCo environments are a set of physics-based simulation environments used for benchmarking reinforcement learning algorithms.",
        "dcterms:title": "MuJoCo environments",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation"
        ],
        "dcat:keyword": [
            "MuJoCo",
            "Physics Simulation",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2004.07219",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Machel Reid",
            "Yutaro Yamada",
            "Shixiang Shane Gu"
        ],
        "dcterms:description": "The Wikipedia corpus is utilized for pre-training reinforcement learning models, providing a large language dataset to improve performance.",
        "dcterms:title": "Wikipedia corpus",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/2201.12122",
        "dcat:theme": [
            "Natural Language Processing",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Language Model",
            "Pre-training",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2201.12122",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling",
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Machel Reid",
            "Yutaro Yamada",
            "Shixiang Shane Gu"
        ],
        "dcterms:description": "IID synthetic data is generated to evaluate the performance of reinforcement learning algorithms in a controlled setting.",
        "dcterms:title": "IID synthetic data",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2201.12122",
        "dcat:theme": [
            "Synthetic Data",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Synthetic Data",
            "Reinforcement Learning",
            "Evaluation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2201.12122",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Machel Reid",
            "Yutaro Yamada",
            "Shixiang Shane Gu"
        ],
        "dcterms:description": "Identity and Case-Mapping synthetic data is used to assess the robustness of reinforcement learning algorithms under different data conditions.",
        "dcterms:title": "Identity and Case-Mapping synthetic data",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2201.12122",
        "dcat:theme": [
            "Synthetic Data",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Synthetic Data",
            "Reinforcement Learning",
            "Evaluation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2201.12122",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Synthetic Markov Chain data is generated for pre-training reinforcement learning models, providing a simple yet effective data source.",
        "dcterms:title": "Synthetic Markov Chain data",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Synthetic Markov Decision Process (MDP) data is created to evaluate the performance of reinforcement learning algorithms in a structured environment.",
        "dcterms:title": "Synthetic Markov Decision Process (MDP) data",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Justin Fu",
            "Aviral Kumar",
            "Ofir Nachum",
            "George Tucker",
            "Sergey Levine"
        ],
        "dcterms:description": "Various D4RL datasets include specific environments like HalfCheetah, Hopper, Walker, and Ant, used for benchmarking offline reinforcement learning.",
        "dcterms:title": "Various D4RL datasets",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2004.07219",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Offline Reinforcement Learning",
            "D4RL",
            "Benchmarking"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2004.07219",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]