[
    {
        "dcterms:creator": [
            "Maria De-Arteaga",
            "Alexey Romanov",
            "Hanna Wallach",
            "Jennifer Chayes",
            "Christian Borgs",
            "Alexandra Chouldechova",
            "Sahin Geyik",
            "Krishnaram Kenthapadi",
            "Adam Tauman Kalai"
        ],
        "dcterms:description": "A benchmark to evaluate occupation-related gender bias in large vision-language models using counterfactual visual questions under individual fairness criteria. It comprises 34,581 visual question counterfactual pairs covering 177 occupations.",
        "dcterms:title": "GenderBias-VL",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Gender Bias",
            "Counterfactuals",
            "Visual Questions",
            "Occupation Bias"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation",
            "Fairness Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Phillip Howard",
            "Avinash Madasu",
            "Tiep Le",
            "Gustavo Lujan Moreno",
            "Anahita Bhiwandiwalla",
            "Vasudev Lal"
        ],
        "dcterms:description": "A dataset that probes intersectional social biases in vision-language models using counterfactual examples, comprising 171k generated counterfactual image-text pairs.",
        "dcterms:title": "SocialCounterfactuals",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2312.00825",
        "dcat:theme": [
            "Bias Evaluation",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Intersectional Bias",
            "Counterfactuals",
            "Vision-Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation",
            "Fairness Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Kathleen C Fraser",
            "Svetlana Kiritchenko"
        ],
        "dcterms:description": "A dataset comprising 40 images depicting visually ambiguous yet stereotyped working scenarios to examine gender and racial biases in large vision-language models.",
        "dcterms:title": "PAIRS",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2402.05779",
        "dcat:theme": [
            "Bias Evaluation",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Gender Bias",
            "Racial Bias",
            "Stereotyped Scenarios"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Bias Evaluation",
            "Fairness Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Siobhan Mackenzie Hall",
            "Fernanda Gon√ßalves Abrantes",
            "Hanwen Zhu",
            "Grace Sodunke",
            "Aleksandar Shtedritski",
            "Hannah Rose Kirk"
        ],
        "dcterms:description": "A dataset designed for benchmarking gender bias in image-text pronoun resolution, providing a comprehensive resource for evaluating biases in vision-language models.",
        "dcterms:title": "Visogender",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Gender Bias",
            "Image-Text Resolution",
            "Pronoun Resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation",
            "Fairness Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "Alec Radford",
            "Jong Wook Kim",
            "Chris Hallacy",
            "Aditya Ramesh",
            "Gabriel Goh",
            "Sandhini Agarwal",
            "Girish Sastry",
            "Amanda Askell",
            "Pamela Mishkin",
            "Jack Clark"
        ],
        "dcterms:description": "A dataset that facilitates learning transferable visual models from natural language supervision, serving as a foundational resource for vision-language tasks.",
        "dcterms:title": "CLIP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Models",
            "Transfer Learning"
        ],
        "dcat:keyword": [
            "Visual Models",
            "Natural Language Supervision",
            "Transfer Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Vision-Language Tasks"
        ]
    }
]