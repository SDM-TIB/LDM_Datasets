[
    {
        "dcterms:creator": [
            "Marc G Bellemare",
            "Yavar Naddaf",
            "Joel Veness",
            "Michael Bowling"
        ],
        "dcterms:description": "An evaluation platform for general agents, providing a suite of Atari games for testing reinforcement learning algorithms.",
        "dcterms:title": "Arcade Learning Environment",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1207.4708",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari games",
            "Reinforcement learning",
            "Evaluation platform"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Art B Owen",
            "Dean Eckles"
        ],
        "dcterms:description": "A statistical method for bootstrapping data arrays of arbitrary order, providing theoretical guarantees for its application.",
        "dcterms:title": "Bootstrapping data arrays of arbitrary order",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Statistics",
            "Data Analysis"
        ],
        "dcat:keyword": [
            "Bootstrapping",
            "Statistical methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yarin Gal",
            "Zoubin Ghahramani"
        ],
        "dcterms:description": "A method that uses dropout in neural networks as a Bayesian approximation to represent model uncertainty.",
        "dcterms:title": "Dropout as a Bayesian approximation",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1506.02142",
        "dcat:theme": [
            "Machine Learning",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Dropout",
            "Bayesian methods",
            "Uncertainty estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih"
        ],
        "dcterms:description": "A landmark paper demonstrating human-level control through deep reinforcement learning using deep Q-networks.",
        "dcterms:title": "Human-level control through deep reinforcement learning",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "10.1038/nature14236",
        "dcat:theme": [
            "Reinforcement Learning",
            "Artificial Intelligence"
        ],
        "dcat:keyword": [
            "Deep Q-Networks",
            "Reinforcement learning",
            "Human-level performance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Arthur Guez",
            "David Silver",
            "Peter Dayan"
        ],
        "dcterms:description": "A method for efficient bayes-adaptive reinforcement learning using sample-based search.",
        "dcterms:title": "Efficient bayes-adaptive reinforcement learning using sample-based search",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Bayesian Methods"
        ],
        "dcat:keyword": [
            "Bayes-adaptive learning",
            "Sample-based search"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Christoph Dann",
            "Emma Brunskill"
        ],
        "dcterms:description": "A study on the sample complexity of episodic fixed-horizon reinforcement learning.",
        "dcterms:title": "Sample complexity of episodic fixed-horizon reinforcement learning",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Theoretical Analysis"
        ],
        "dcat:keyword": [
            "Sample complexity",
            "Episodic learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Bradly C Stadie",
            "Sergey Levine",
            "Pieter Abbeel"
        ],
        "dcterms:description": "A method for incentivizing exploration in reinforcement learning using deep predictive models.",
        "dcterms:title": "Incentivizing exploration in reinforcement learning with deep predictive models",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1507.00814",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Exploration",
            "Predictive models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]