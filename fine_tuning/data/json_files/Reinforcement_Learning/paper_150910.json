[
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan"
        ],
        "dcterms:description": "A dataset used for training a helpful and harmless assistant with reinforcement learning from human feedback, consisting of 112k samples for training and 12.5k for evaluation.",
        "dcterms:title": "full-hh-rlhf",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Reinforcement Learning from Human Feedback",
            "Language Models",
            "Training Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Training Language Models",
            "Human Feedback Alignment"
        ]
    },
    {
        "dcterms:creator": [
            "S. Li",
            "X. Zhang",
            "T. Dubois",
            "Y. Taori",
            "I. Gulrajani",
            "C. Guestrin",
            "P. Liang",
            "T. B. Hashimoto"
        ],
        "dcterms:description": "An automatic evaluator of instruction-following models, used to assess response quality from diverse prompts.",
        "dcterms:title": "AlpacaEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/alpaca_eval",
        "dcat:theme": [
            "Evaluation Metrics",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Automatic Evaluation",
            "Instruction Following",
            "Language Models"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/alpaca_eval",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation",
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "S. Zheng",
            "W.-L. Chiang",
            "Y. Sheng",
            "S. Zhuang",
            "Z. Wu",
            "Y. Zhuang",
            "Z. Li",
            "D. Li",
            "E. Xing"
        ],
        "dcterms:description": "A benchmark for evaluating language models as judges, assessing their performance in multi-turn dialogue.",
        "dcterms:title": "MT-bench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2306.05685",
        "dcat:theme": [
            "Evaluation Metrics",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Language Model Evaluation",
            "Dialogue Systems",
            "Benchmarking"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2306.05685",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation",
            "Dialogue Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "G. Cui",
            "L. Yuan",
            "N. Ding",
            "G. Yao",
            "W. Zhu",
            "Y. Ni",
            "G. Xie",
            "Z. Liu",
            "M. Sun"
        ],
        "dcterms:description": "A dataset aimed at boosting language models with high-quality feedback, used for training and evaluation.",
        "dcterms:title": "ultrafeedback",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2310.01377",
        "dcat:theme": [
            "Feedback Mechanisms",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "High-Quality Feedback",
            "Language Models",
            "Training Dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2310.01377",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Training",
            "Feedback Utilization"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "W.-L. Chiang",
            "Y. Sheng",
            "S. Zhuang",
            "Z. Wu",
            "Y. Zhuang",
            "Z. Li",
            "D. Li",
            "E. Xing"
        ],
        "dcterms:description": "A large-scale real-world conversation dataset for training language models in chat applications.",
        "dcterms:title": "lmsys-chat-1m",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2309.11998",
        "dcat:theme": [
            "Conversational AI",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Conversation Dataset",
            "Chat Models",
            "Language Models"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2309.11998",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Conversational Modeling",
            "Chatbot Training"
        ]
    },
    {
        "dcterms:creator": [
            "G. Cui",
            "L. Yuan",
            "N. Ding",
            "G. Yao",
            "W. Zhu",
            "Y. Ni",
            "G. Xie",
            "Z. Liu",
            "M. Sun"
        ],
        "dcterms:description": "A high-quality instruction tuning dataset used for enhancing language models.",
        "dcterms:title": "sharegpt-en",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2310.01377",
        "dcat:theme": [
            "Instruction Tuning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Instruction Dataset",
            "Language Models",
            "Training Data"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2310.01377",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following",
            "Model Training"
        ]
    }
]