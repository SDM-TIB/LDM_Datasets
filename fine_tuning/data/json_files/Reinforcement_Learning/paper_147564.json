[
    {
        "dcterms:creator": [
            "A.S. Gupta",
            "M.A.A. van der Meer",
            "D.S. Touretzky",
            "A.D. Redish"
        ],
        "dcterms:description": "A dataset used to analyze hippocampal replay in a T-maze navigation task, focusing on the relationship between replay and experience.",
        "dcterms:title": "T-maze navigation task",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neuroscience",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Hippocampal replay",
            "Navigation task",
            "T-maze",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Memory consolidation"
        ]
    },
    {
        "dcterms:creator": [
            "R.S. Sutton"
        ],
        "dcterms:description": "A dataset containing transitions used in reinforcement learning, particularly in the context of Dyna algorithms.",
        "dcterms:title": "Transitions dataset (S)",
        "dcterms:issued": "1990",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Transitions",
            "Reinforcement learning",
            "Dyna algorithms"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning",
            "Planning"
        ]
    },
    {
        "dcterms:creator": [
            "R. Sutton",
            "A. Barto"
        ],
        "dcterms:description": "A dataset that includes reward networks used for reinforcement learning tasks.",
        "dcterms:title": "Reward networks dataset (N_a)",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Reward networks",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning",
            "Reward prediction"
        ]
    },
    {
        "dcterms:creator": [
            "A.W. Moore",
            "C.G. Atkeson"
        ],
        "dcterms:description": "A dataset focused on predecessor states in reinforcement learning, used to improve learning efficiency.",
        "dcterms:title": "Predecessor states dataset (P)",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Predecessor states",
            "Reinforcement learning",
            "Prioritized sweeping"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning",
            "Planning"
        ]
    },
    {
        "dcterms:creator": [
            "R.A. Jacobs",
            "M.I. Jordan",
            "S.J. Nowlan",
            "G.E. Hinton"
        ],
        "dcterms:description": "A dataset related to the GALMO algorithm, which is designed to learn multiple outputs from a single input.",
        "dcterms:title": "GALMO algorithm dataset",
        "dcterms:issued": "1991",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning"
        ],
        "dcat:keyword": [
            "GALMO",
            "Multiple outputs",
            "Neural networks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Learning",
            "Output prediction"
        ]
    }
]