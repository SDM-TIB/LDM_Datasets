[
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "M. Chociej",
            "P. Welinder"
        ],
        "dcterms:description": "The FetchReach environment is a robotic arm environment where the objective is for the extremity of the arm to reach a given 3D position. It is deterministic and allows for testing various reinforcement learning algorithms.",
        "dcterms:title": "FetchReach Environment",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic arm",
            "3D position",
            "Deterministic environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reaching",
            "Robotic control"
        ]
    },
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "M. Chociej",
            "P. Welinder"
        ],
        "dcterms:description": "The FetchPush environment is a robotic environment where the objective is to push a cube with a robotic arm to a given goal. It is a more complex task compared to FetchReach and is used to evaluate the performance of various reinforcement learning algorithms.",
        "dcterms:title": "FetchPush Environment",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Robotic arm",
            "Pushing",
            "Goal-directed task"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Pushing",
            "Robotic control"
        ]
    },
    {
        "dcterms:creator": [
            "T. Schaul",
            "D. Horgan",
            "K. Gregor",
            "D. Silver"
        ],
        "dcterms:description": "Universal Value Function Approximators (UVFA) extend classical Q-learning to multi-goal settings by learning goal-conditioned value functions for every state-goal pair. This dataset is used to evaluate the performance of reinforcement learning algorithms in multi-goal environments.",
        "dcterms:title": "Universal Value Function Approximators (UVFA)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "http://proceedings.mlr.press/v37/schaul15.html",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-goal Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Value function",
            "Multi-goal"
        ],
        "dcat:landingPage": "http://proceedings.mlr.press/v37/schaul15.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-goal learning",
            "Value function approximation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Andrychowicz",
            "F. Wolski",
            "A. Ray",
            "J. Schneider",
            "R. Fong",
            "P. Welinder",
            "B. McGrew",
            "J. Tobin",
            "O. P. Abbeel",
            "W. Zaremba"
        ],
        "dcterms:description": "Hindsight Experience Replay (HER) is a method that allows agents to learn from failed attempts by treating them as if they were successful. This dataset is used to evaluate the performance of HER in various reinforcement learning tasks.",
        "dcterms:title": "Hindsight Experience Replay (HER)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Experience Replay"
        ],
        "dcat:keyword": [
            "Hindsight learning",
            "Experience replay",
            "Multi-goal"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-goal learning",
            "Experience replay"
        ]
    },
    {
        "dcterms:creator": [
            "M. Plappert",
            "M. Andrychowicz",
            "A. Ray",
            "B. McGrew",
            "B. Baker",
            "G. Powell",
            "J. Schneider",
            "J. Tobin",
            "M. Chociej",
            "P. Welinder"
        ],
        "dcterms:description": "The Torus environment is a continuous version of the flipping coin environment, where the state space is an n-dimensional torus. This dataset is used to evaluate the performance of various reinforcement learning algorithms in a multi-goal setting.",
        "dcterms:title": "Torus Environment",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Continuous environment",
            "Multi-goal",
            "Torus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-goal learning",
            "Continuous control"
        ]
    }
]