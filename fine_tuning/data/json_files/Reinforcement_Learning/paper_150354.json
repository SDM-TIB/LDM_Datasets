[
    {
        "dcterms:creator": [],
        "dcterms:description": "A variation of box world environments where multiple agents are tasked with collecting gems and depositing them in a bank, located in the center of the grid.",
        "dcterms:title": "Bank world",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multi-agent",
            "Reinforcement Learning",
            "Grid environment",
            "Task coordination"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task allocation",
            "Gem collection"
        ]
    },
    {
        "dcterms:creator": [
            "M. Stolle",
            "D. Precup"
        ],
        "dcterms:description": "A hierarchical learning framework that divides the main task into a sequence of smaller tasks, each learned using a reinforcement learning algorithm.",
        "dcterms:title": "Options Framework",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Hierarchical learning",
            "Reinforcement learning",
            "Task decomposition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task learning",
            "Policy optimization"
        ]
    },
    {
        "dcterms:creator": [
            "S. Natarajan",
            "P. Tadepalli",
            "T. G. Dietterich",
            "A. Fern"
        ],
        "dcterms:description": "A dataset used for learning first-order probabilistic models with combining rules.",
        "dcterms:title": "FOCI (First Order Conditional Inference)",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Probabilistic models",
            "Conditional inference",
            "First-order logic"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Probabilistic reasoning",
            "Model learning"
        ]
    },
    {
        "dcterms:creator": [
            "T. Hester",
            "M. Vecerik",
            "O. Pietquin",
            "M. Lanctot",
            "T. Schaul",
            "B. Piot",
            "D. Horgan",
            "J. Quan",
            "A. Sendonaris",
            "I. Osband"
        ],
        "dcterms:description": "A dataset used for deep Q-learning from demonstrations, optimizing Q-values of state-action pairs.",
        "dcterms:title": "Q-learning",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Deep Q-learning",
            "Reinforcement learning",
            "Demonstrations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy learning",
            "Value optimization"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An experimental setup where agents follow a random policy without learning, used as a baseline for comparison.",
        "dcterms:title": "Random Policy",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Baseline",
            "Random actions",
            "No learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "An experimental setup that combines Q-learning with the Options Framework to learn subtasks separately.",
        "dcterms:title": "Q-learning + Options",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Hierarchical learning",
            "Subtask learning",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Task learning",
            "Policy optimization"
        ]
    },
    {
        "dcterms:creator": [
            "S. Natarajan",
            "G. Kunapuli",
            "K. Judah",
            "P. Tadepalli",
            "K. Kersting",
            "J. Shavlik"
        ],
        "dcterms:description": "A dataset for multi-agent inverse reinforcement learning.",
        "dcterms:title": "Multi-agent inverse reinforcement learning",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Inverse reinforcement learning",
            "Multi-agent systems",
            "Learning from multiple agents"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Policy learning",
            "Multi-agent coordination"
        ]
    }
]