[
    {
        "dcterms:creator": [
            "S. Gehman",
            "S. Gururangan",
            "M. Sap",
            "Y. Choi",
            "N. A. Smith"
        ],
        "dcterms:description": "The REALTOXICITYPROMPTS dataset is used to evaluate the toxicity of language model outputs by prompting them with seemingly harmless text and measuring the toxicity of their responses.",
        "dcterms:title": "REALTOXICITYPROMPTS",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.11462",
        "dcat:theme": [
            "Toxicity Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "toxicity",
            "language models",
            "evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Reduction"
        ]
    },
    {
        "dcterms:creator": [
            "M. VÃ¶lske",
            "M. Potthast",
            "S. Syed",
            "B. Stein"
        ],
        "dcterms:description": "The Reddit TL;DR dataset is used for summarization tasks, where the goal is to generate concise summaries of Reddit posts while maintaining coherence and coverage of the main points.",
        "dcterms:title": "Reddit TL;DR",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Summarization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "summarization",
            "Reddit",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Fan",
            "M. Lewis",
            "Y. Dauphin"
        ],
        "dcterms:description": "The WRITINGPROMPTS2 dataset is utilized for generating creative writing prompts and evaluating story generation models.",
        "dcterms:title": "WRITINGPROMPTS2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1805.04833",
        "dcat:theme": [
            "Story Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "story generation",
            "creative writing",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Story Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan"
        ],
        "dcterms:description": "The Anthropic HH dataset is used for training models to generate helpful and harmless responses in dialogue settings.",
        "dcterms:title": "Anthropic HH dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2204.05862",
        "dcat:theme": [
            "Dialogue Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "dialogue",
            "helpfulness",
            "harmlessness"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Response Generation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Liu",
            "C. Sferrazza",
            "P. Abbeel"
        ],
        "dcterms:description": "The OASST dataset is used for training models to align language models with feedback.",
        "dcterms:title": "OASST",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2302.02676",
        "dcat:theme": [
            "Feedback Alignment",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "alignment",
            "feedback",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Alignment"
        ]
    },
    {
        "dcterms:creator": [
            "N. Stiennon",
            "L. Ouyang",
            "J. Wu",
            "D. Ziegler",
            "R. Lowe",
            "C. Voss",
            "A. Radford",
            "D. Amodei",
            "P. F. Christiano"
        ],
        "dcterms:description": "The Human preference dataset is used for training models to summarize text based on human feedback.",
        "dcterms:title": "Human preference dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Feedback",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "human feedback",
            "summarization",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    }
]