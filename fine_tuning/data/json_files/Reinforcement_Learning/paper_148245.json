[
    {
        "dcterms:creator": [
            "Shayegan OmidshaÔ¨Åei",
            "Jason Pazis",
            "Christopher Amato",
            "Jonathan P How",
            "John Vian"
        ],
        "dcterms:description": "An environment used for multi-agent reinforcement learning experiments focusing on decentralized multi-task learning under partial observability.",
        "dcterms:title": "",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multi-agent reinforcement learning",
            "Decentralized learning",
            "Partial observability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ziyu Wang",
            "Nando de Freitas",
            "Marc Lanctot"
        ],
        "dcterms:description": "A deep reinforcement learning architecture that combines dueling network structures to improve learning efficiency.",
        "dcterms:title": "Dueling Double Deep Q-Network (DDDQN)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "abs/1511.06581",
        "dcat:theme": [],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Dueling network architecture",
            "Q-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Volodymyr Mnih",
            "Adria Puigdomenech Badia",
            "Mehdi Mirza",
            "Alex Graves",
            "Timothy Lillicrap",
            "Tim Harley",
            "David Silver",
            "Koray Kavukcuoglu"
        ],
        "dcterms:description": "An asynchronous method for deep reinforcement learning that combines actor-critic methods with parallel training.",
        "dcterms:title": "Asynchronous Advantage Actor-Critic (A2C)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Deep reinforcement learning",
            "Actor-critic",
            "Asynchronous methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Julien Perolat",
            "Joel Z Leibo",
            "Vinicius Zambaldi",
            "Charles Beattie",
            "Karl Tuyls",
            "Thore Graepel"
        ],
        "dcterms:description": "A multi-agent reinforcement learning model designed to study common-pool resource appropriation.",
        "dcterms:title": "",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multi-agent reinforcement learning",
            "Common-pool resources",
            "Resource appropriation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]