[
    {
        "dcterms:creator": [
            "W. Sandra",
            "M. Brent",
            "R. Chris"
        ],
        "dcterms:description": "Counterfactual explanations without opening the black-box, focusing on automated decisions and GDPR compliance.",
        "dcterms:title": "WatcherCF",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Counterfactuals",
            "GDPR",
            "Automated Decisions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. V. Looveren",
            "J. Klaise"
        ],
        "dcterms:description": "Interpretable counterfactual explanations guided by prototypes to enhance understanding.",
        "dcterms:title": "Prototype Counterfactuals",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Prototypes",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. M. Grath",
            "L. Costabello",
            "C. L. Van",
            "P. Sweeney",
            "F. Kamiab",
            "Z. Shen",
            "F. Lecue"
        ],
        "dcterms:description": "Weighted counterfactuals that enhance interpretability in credit application predictions.",
        "dcterms:title": "Weighted Counterfactuals",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Credit Predictions",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Poyiadzi",
            "K. Sokol",
            "R. Santos-Rodriguez",
            "T. De Bie",
            "P. Flach"
        ],
        "dcterms:description": "FACE provides feasible and actionable counterfactual explanations to enhance decision-making.",
        "dcterms:title": "FACE (Feasible and Actionable Counterfactual Explanations)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Feasibility",
            "Actionability",
            "Counterfactuals"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Laugel",
            "M.-J. Lesot",
            "C. Marsala",
            "X. Renard",
            "M. Detyniecki"
        ],
        "dcterms:description": "TRUCE addresses the dangers of unjustified counterfactual explanations in machine learning.",
        "dcterms:title": "TRUCE (Unjustified Counterfactual Explanations)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Unjustified Explanations",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Mothilal",
            "A. Sharma",
            "C. Tan"
        ],
        "dcterms:description": "DiCE generates diverse counterfactual explanations to enhance interpretability of machine learning classifiers.",
        "dcterms:title": "DiCE (Diverse Counterfactual Explanations)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Diversity",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Downs",
            "J. L. Chu",
            "Y. Yacoby",
            "F. Doshi-Velez",
            "W. Pan"
        ],
        "dcterms:description": "CRUDS provides counterfactual recourse using disentangled subspaces to enhance interpretability.",
        "dcterms:title": "CRUDS (Counterfactual Recourse Using Disentangled Subspaces)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Counterfactuals",
            "Disentangled Representations",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Ghazimatin",
            "O. Balalau",
            "R. Saha Roy",
            "G. Weikum"
        ],
        "dcterms:description": "PRINCE provides provider-side interpretability with counterfactual explanations in recommender systems.",
        "dcterms:title": "PRINCE (Provider-side Interpretability with Counterfactual Explanations in Recommender Systems)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Recommender Systems",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Pawelczyk",
            "K. Broelemann",
            "G. Kasneci"
        ],
        "dcterms:description": "C-CHVAE learns model-agnostic counterfactual explanations for tabular data.",
        "dcterms:title": "C-CHVAE (Counterfactual Conditional Heterogeneous Autoencoder)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Autoencoders",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Lucic",
            "H. Haned",
            "M. de Rijke"
        ],
        "dcterms:description": "MC-BRP focuses on generating reasonable predictions using Monte Carlo methods.",
        "dcterms:title": "MC-BRP (Monte Carlo Bounds for Reasonable Predictions)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Monte Carlo",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. Guidotti",
            "A. Monreale",
            "S. Matwin",
            "D. Pedreschi"
        ],
        "dcterms:description": "ABELE generates black box explanations by learning image exemplars in the latent feature space.",
        "dcterms:title": "Abele (Adversarial Black box Explainer generating Latent Exemplars)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Adversarial Learning",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Karimi",
            "B. J. von Kügelgen",
            "B. Schölkopf",
            "I. Valera"
        ],
        "dcterms:description": "Recourse provides algorithmic recourse under imperfect causal knowledge.",
        "dcterms:title": "Recourse (Algorithmic Recourse Under Imperfect Causal Knowledge)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Counterfactual Explanations"
        ],
        "dcat:keyword": [
            "Causal Knowledge",
            "Counterfactuals",
            "Interpretability"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]