[
    {
        "dcterms:creator": [
            "Yuntao Bai",
            "Andy Jones",
            "Kamal Ndousse",
            "Amanda Askell",
            "Anna Chen",
            "Nova DasSarma",
            "Dawn Drain",
            "Stanislav Fort",
            "Deep Ganguli",
            "Tom Henighan"
        ],
        "dcterms:description": "Stanford Human Preference (SHP) is a human preference dataset over agent responses to usersâ€™ questions and instructions. Each input consists of a context post and two responses, and the task is to pick the preferred response.",
        "dcterms:title": "Stanford Human Preference",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human-Computer Interaction",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Human preference",
            "Reinforcement learning",
            "Response selection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference modeling",
            "Response evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Mor Geva",
            "Daniel Khashabi",
            "Elad Segal",
            "Tushar Khot",
            "Dan Roth",
            "Jonathan Berant"
        ],
        "dcterms:description": "StrategyQA is a multi-hop question-answering dataset on open-domain questions. The answer to each question is either 'yes' or 'no'. Answering questions in StrategyQA requires implicit step-by-step reasoning, which makes explanations useful.",
        "dcterms:title": "StrategyQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-hop reasoning",
            "Question answering",
            "Implicit reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question answering",
            "Reasoning"
        ]
    }
]