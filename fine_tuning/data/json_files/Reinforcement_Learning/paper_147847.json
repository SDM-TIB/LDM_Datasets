[
    {
        "dcterms:creator": [
            "T. Hester",
            "M. Vecerik",
            "O. Pietquin",
            "M. Lanctot",
            "T. Schaul",
            "B. Piot",
            "D. Horgan",
            "J. Quan",
            "A. Sendonaris",
            "I. Osband",
            "G. Dulac-Arnold",
            "J. Agapiou",
            "J. Z. Leibo",
            "A. Gruslys"
        ],
        "dcterms:description": "A method that leverages expert demonstration data to accelerate the learning process of DQN by combining rewards and expert demonstrations.",
        "dcterms:title": "DQfD (Deep Q-learning from Demonstration)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16976",
        "dcat:theme": [
            "Reinforcement Learning",
            "Demonstration Learning"
        ],
        "dcat:keyword": [
            "Deep Q-learning",
            "Demonstration",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16976",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "I. Osband",
            "C. Blundell",
            "A. Pritzel",
            "B. V. Roy"
        ],
        "dcterms:description": "A modification of DQN that improves exploration during training by using multiple value function heads to approximate a distribution over Q-values.",
        "dcterms:title": "Bootstrapped DQN",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Bootstrapped DQN",
            "Exploration",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "http://papers.nips.cc/paper/6501-deep-exploration-via-bootstrapped-dqn",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Exploration in Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Fortunato",
            "M. G. Azar",
            "B. Piot",
            "J. Menick",
            "I. Osband",
            "A. Graves",
            "V. Mnih",
            "R. Munos",
            "D. Hassabis",
            "O. Pietquin",
            "C. Blundell",
            "S. Legg",
            "S. Blundell"
        ],
        "dcterms:description": "A method that introduces noise into the parameters of a neural network to improve exploration in reinforcement learning.",
        "dcterms:title": "Noisy DQN",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1706.10295",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Noisy Networks",
            "Exploration",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1706.10295",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Exploration in Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "G. Brockman",
            "V. Cheung",
            "L. Pettersson",
            "J. Schneider",
            "J. Schulman",
            "J. Tang",
            "W. Zaremba"
        ],
        "dcterms:description": "A toolkit for developing and comparing reinforcement learning algorithms, providing a variety of environments.",
        "dcterms:title": "OpenAI Gym Environments",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation Environments"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Simulation",
            "Environment"
        ],
        "dcat:landingPage": "http://arxiv.org/abs/1606.01540",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]