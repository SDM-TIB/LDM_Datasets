[
    {
        "dcterms:creator": [
            "T. Jaksch",
            "R. Ortner",
            "P. Auer"
        ],
        "dcterms:description": "A model-based reinforcement learning algorithm that achieves near-optimal regret bounds.",
        "dcterms:title": "UCRL2",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Model-Based Learning"
        ],
        "dcat:keyword": [
            "Regret Bounds",
            "Reinforcement Learning",
            "Model-Based Algorithms"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Mohammad Gheshlaghi Azar",
            "Ian Osband",
            "R´emi Munos"
        ],
        "dcterms:description": "A reinforcement learning algorithm that provides minimax regret bounds.",
        "dcterms:title": "UCBVI",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Minimax Regret"
        ],
        "dcat:keyword": [
            "Regret Bounds",
            "Reinforcement Learning",
            "UCB Algorithms"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Sham Kakade",
            "Mengdi Wang",
            "Lin F Yang"
        ],
        "dcterms:description": "A reinforcement learning algorithm that focuses on variance reduction methods for sublinear learning.",
        "dcterms:title": "vUCQ",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Variance Reduction"
        ],
        "dcat:keyword": [
            "Sublinear Learning",
            "Variance Reduction",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Michael Kearns",
            "Satinder Singh"
        ],
        "dcterms:description": "A reinforcement learning algorithm that utilizes ε-greedy exploration.",
        "dcterms:title": "Q-learning (ε-greedy)",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Q-learning",
            "ε-greedy",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Alexander L Strehl",
            "Lihong Li",
            "Eric Wiewiora",
            "John Langford",
            "Michael L Littman"
        ],
        "dcterms:description": "A model-free reinforcement learning algorithm that introduces delayed updates for Q-learning.",
        "dcterms:title": "Delayed Q-learning",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Model-Free Learning"
        ],
        "dcat:keyword": [
            "Delayed Updates",
            "Q-learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Refers to a variant of Q-learning that uses upper confidence bounds for exploration.",
        "dcterms:title": "Q-learning (UCB-H)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Refers to a variant of Q-learning that uses upper confidence bounds for exploration with a different approach.",
        "dcterms:title": "Q-learning (UCB-B)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Refers to a specific construction of a Markov Decision Process (MDP) used in the paper.",
        "dcterms:title": "JAO MDP",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]