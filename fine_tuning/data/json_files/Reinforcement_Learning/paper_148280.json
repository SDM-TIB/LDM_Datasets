[
    {
        "dcterms:creator": [
            "L. Espeholt",
            "H. Soyer",
            "R. Munos",
            "K. Simonyan",
            "V. Mnih",
            "T. Ward",
            "Y. Doron",
            "V. Firoiu",
            "T. Harley",
            "I. Dunning"
        ],
        "dcterms:description": "The V-trace algorithm is an off-policy TD-learning algorithm that uses importance sampling with truncation to control bias and variance in the estimates of the value function.",
        "dcterms:title": "V-trace Algorithm",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Off-policy Learning"
        ],
        "dcat:keyword": [
            "V-trace",
            "Off-policy TD-learning",
            "Importance Sampling",
            "Bias-Variance Trade-off"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value Function Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "R. S. Sutton",
            "A. G. Barto"
        ],
        "dcterms:description": "The TD(n) algorithm is a multi-step temporal difference learning method that updates value estimates based on n-step returns.",
        "dcterms:title": "TD(n) Algorithm",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "On-policy Learning"
        ],
        "dcat:keyword": [
            "TD(n)",
            "Temporal Difference Learning",
            "Multi-step Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Value Function Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "C. J. Watkins",
            "P. Dayan"
        ],
        "dcterms:description": "Q-learning is a model-free reinforcement learning algorithm that seeks to learn the value of an action in a particular state.",
        "dcterms:title": "Q-learning Algorithm",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Learning"
        ],
        "dcat:keyword": [
            "Q-learning",
            "Model-free Learning",
            "Value Function Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Optimal Policy Learning"
        ]
    },
    {
        "dcterms:creator": [
            "P. Mirowski",
            "M. Grimes",
            "M. Malinowski",
            "K. M. Hermann",
            "K. Anderson",
            "D. Teplyashin",
            "K. Simonyan",
            "A. Zisserman",
            "R. Hadsell"
        ],
        "dcterms:description": "The DeepMind City Navigation Project 'Street Learn' dataset is used for training agents to navigate in urban environments without a map.",
        "dcterms:title": "Deepmind City Navigation Project 'Street Learn'",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Navigation"
        ],
        "dcat:keyword": [
            "City Navigation",
            "Urban Environments",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation Task"
        ]
    }
]