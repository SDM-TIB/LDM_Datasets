[
    {
        "dcterms:creator": [
            "Peter Anderson",
            "Qi Wu",
            "Damien Teney",
            "Jake Bruce",
            "Mark Johnson",
            "Niko Sunderhauf",
            "Ian Reid",
            "Stephen Gould",
            "Anton Van Den Hengel"
        ],
        "dcterms:description": "The Room-to-Room (R2R) dataset is the first Vision-Language Navigation (VLN) benchmark that combines real imagery and natural language navigation instructions, containing 22K instruction-path pairs.",
        "dcterms:title": "Room-to-Room (R2R) dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Navigation"
        ],
        "dcat:keyword": [
            "Navigation",
            "Natural Language Instructions",
            "Real Imagery"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Howard Chen",
            "Alane Suhr",
            "Dipendra Misra",
            "Noah Snavely",
            "Yoav Artzi"
        ],
        "dcterms:description": "The TOUCHDOWN dataset is designed for natural language navigation and spatial reasoning in visual street environments.",
        "dcterms:title": "TOUCHDOWN dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Navigation"
        ],
        "dcat:keyword": [
            "Street Navigation",
            "Natural Language Instructions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Phil Ammirato",
            "Patrick Poirson",
            "Eunbyung Park",
            "Jana Kosecka",
            "Alexander C. Berg"
        ],
        "dcterms:description": "The Active Vision dataset consists of dense scans of 16 different houses, aimed at developing and benchmarking active vision.",
        "dcterms:title": "Active Vision dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Active Vision",
            "House Scans"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Vision Benchmarking"
        ]
    },
    {
        "dcterms:creator": [
            "Angel Chang",
            "Angela Dai",
            "Thomas Funkhouser",
            "Maciej Halber",
            "Matthias Niebner",
            "Manolis Savva",
            "Shuran Song",
            "Andy Zeng",
            "Yinda Zhang"
        ],
        "dcterms:description": "The Matterport3D dataset provides RGB-D data in indoor environments, facilitating learning from real-world imagery.",
        "dcterms:title": "Matterport3D dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Environments"
        ],
        "dcat:keyword": [
            "RGB-D Data",
            "Indoor Environments"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "3D Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Fei Xia",
            "Amir R. Zamir",
            "Zhiyang He",
            "Alexander Sax",
            "Jitendra Malik",
            "Silvio Savarese"
        ],
        "dcterms:description": "The Gibson dataset provides real-world perception data for embodied agents, focusing on navigation tasks.",
        "dcterms:title": "Gibson dataset",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Embodied AI"
        ],
        "dcat:keyword": [
            "Real-World Perception",
            "Navigation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Navigation"
        ]
    },
    {
        "dcterms:creator": [
            "Eric Kolve",
            "Roozbeh Mottaghi",
            "Daniel Gordon",
            "Yuke Zhu",
            "Abhinav Gupta",
            "Ali Farhadi"
        ],
        "dcterms:description": "The AI2-THOR dataset is an interactive 3D environment for visual AI, allowing agents to interact with objects.",
        "dcterms:title": "AI2-THOR dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Interactive Environments"
        ],
        "dcat:keyword": [
            "3D Environment",
            "Interactive AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Vihan Jain",
            "Gabriel Magalhaes",
            "Alexander Ku",
            "Ashish Vaswani",
            "Eugene Ie",
            "Jason Baldridge"
        ],
        "dcterms:description": "The R4R dataset builds upon the R2R dataset and aims to provide a more challenging setting for embodied navigation agents.",
        "dcterms:title": "R4R dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Navigation"
        ],
        "dcat:keyword": [
            "Navigation",
            "Challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Navigation"
        ]
    }
]