[
    {
        "dcterms:creator": [
            "M. Andrychowicz",
            "F. Wolski",
            "A. Ray",
            "J. Schneider",
            "R. Fong",
            "P. Welinder",
            "B. McGrew",
            "J. Tobin",
            "O. Pieter Abbeel",
            "W. Zaremba"
        ],
        "dcterms:description": "A model-free algorithm that allows for efficient learning in goal-conditioned reinforcement learning by re-labeling transitions with goals achieved later in the trajectory.",
        "dcterms:title": "Hindsight Experience Replay (HER)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Learning"
        ],
        "dcat:keyword": [
            "Model-free",
            "Sparse rewards",
            "Goal achievement"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "E. Todorov",
            "T. Erez",
            "Y. Tassa"
        ],
        "dcterms:description": "A physics engine designed for model-based control, providing a simulation environment for robotic tasks.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Simulation"
        ],
        "dcat:keyword": [
            "Physics engine",
            "Robotic control",
            "Simulation environment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robotic control",
            "Simulation"
        ]
    },
    {
        "dcterms:creator": [
            "P. Dhariwal",
            "C. Hesse",
            "O. Klimov",
            "A. Nichol",
            "M. Plappert",
            "A. Radford",
            "J. Schulman",
            "S. Sidor",
            "Y. Wu",
            "P. Zhokhov"
        ],
        "dcterms:description": "A set of high-quality implementations of reinforcement learning algorithms.",
        "dcterms:title": "OpenAI Baselines",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/openai/baselines",
        "dcat:theme": [
            "Reinforcement Learning",
            "Algorithm Implementations"
        ],
        "dcat:keyword": [
            "Reinforcement learning",
            "Algorithm implementations",
            "OpenAI"
        ],
        "dcat:landingPage": "https://github.com/openai/baselines",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "M. Fang",
            "T. Zhou",
            "Y. Du",
            "L. Han",
            "Z. Zhang"
        ],
        "dcterms:description": "An adaptive mechanism that enhances Hindsight Experience Replay by guiding the selection of experiences based on the diversity of achieved goals.",
        "dcterms:title": "Curriculum-Guided Hindsight Experience Replay (CHER)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Learning"
        ],
        "dcat:keyword": [
            "Adaptive learning",
            "Experience replay",
            "Goal diversity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Q. He",
            "L. Zhuang",
            "H. Li"
        ],
        "dcterms:description": "A method that combines Hindsight Experience Replay with maximum entropy reinforcement learning to improve sample efficiency.",
        "dcterms:title": "Soft Hindsight Experience Replay (SHER)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Goal-Conditioned Learning"
        ],
        "dcat:keyword": [
            "Maximum entropy",
            "Experience replay",
            "Sample efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset of simulated demonstrations for locomotion tasks, used for comparison with PlanGAN.",
        "dcterms:title": "Simulated Locomotion Demonstrations (SLD)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robotics",
            "Simulation"
        ],
        "dcat:keyword": [
            "Simulated demonstrations",
            "Locomotion tasks",
            "Robotic learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robotic control",
            "Simulation"
        ]
    }
]