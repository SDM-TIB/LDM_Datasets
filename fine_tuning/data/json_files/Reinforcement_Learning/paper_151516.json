[
    {
        "dcterms:creator": [
            "Andy Zou",
            "Zifan Wang",
            "J Zico Kolter",
            "Matt Fredrikson"
        ],
        "dcterms:description": "A benchmark dataset containing 500 instances of harmful behaviors articulated through specific instructions, used to evaluate the effectiveness of adversarial attacks on language models.",
        "dcterms:title": "AdvBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Attacks",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Benchmark dataset",
            "Harmful behaviors",
            "Adversarial attacks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Adversarial Attack Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Wei-Lin Chiang",
            "Zhuohan Li",
            "Zi Lin",
            "Ying Sheng",
            "Zhanghao Wu",
            "Hao Zhang",
            "Lianmin Zheng",
            "Siyuan Zhuang",
            "Yonghao Zhuang",
            "Joseph E Gonzalez"
        ],
        "dcterms:description": "A dataset containing 125K conversations used to fine-tune the Vicuna model, aimed at achieving high-quality chatbot responses.",
        "dcterms:title": "ShareGPT",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://lmsys.org/blog/2023-03-30-vicuna",
        "dcat:theme": [
            "Chatbot Development",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Chatbot dataset",
            "Conversational AI",
            "Fine-tuning"
        ],
        "dcat:landingPage": "https://lmsys.org/blog/2023-03-30-vicuna",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Chatbot Training"
        ]
    },
    {
        "dcterms:creator": [
            "Zihao Xu",
            "Yi Liu",
            "Gelei Deng",
            "Yuekang Li",
            "Stjepan Picek"
        ],
        "dcterms:description": "A model designed to evaluate harmful outputs generated by language models, achieving high accuracy in detecting malicious content.",
        "dcterms:title": "Harmful Evaluation Model",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/zhx123/ftrobertallm",
        "dcat:theme": [
            "Adversarial Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Harmful content detection",
            "Evaluation model",
            "Language models"
        ],
        "dcat:landingPage": "https://huggingface.co/zhx123/ftrobertallm",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Harmful Content Detection"
        ]
    }
]