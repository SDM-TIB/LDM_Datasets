[
    {
        "dcterms:creator": [
            "M. Potthast",
            "T. Gollub",
            "M. Hagen",
            "B. Stein"
        ],
        "dcterms:description": "A large dataset collected from Twitter posts, including tweet headlines and paragraphs, used for clickbait detection. The training and test sets are judged on a four-point scale by at least five annotators.",
        "dcterms:title": "Clickbait Challenge 2017",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification"
        ],
        "dcat:keyword": [
            "Clickbait detection",
            "Twitter dataset",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Clickbait detection"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhang",
            "J. Zhao",
            "Y. LeCun"
        ],
        "dcterms:description": "A dataset of news articles used for text classification, containing titles and descriptions. It is widely used for benchmarking text classification algorithms.",
        "dcterms:title": "AG's News",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification"
        ],
        "dcat:keyword": [
            "News articles",
            "Text classification",
            "NLP dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text classification"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhang",
            "J. Zhao",
            "Y. LeCun"
        ],
        "dcterms:description": "A dataset constructed from Wikipedia articles, used for ontology classification tasks. Each sample contains the title and abstract of a Wikipedia article.",
        "dcterms:title": "DBpedia",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Classification"
        ],
        "dcat:keyword": [
            "Wikipedia dataset",
            "Ontology classification",
            "Text classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text classification"
        ]
    }
]