[
    {
        "dcterms:creator": [
            "Brendan O’Donoghue"
        ],
        "dcterms:description": "An adaptation of the DeepSea environment used to study risk sensitivity, where the agent navigates a 5x5 grid with choices affecting rewards based on actions taken.",
        "dcterms:title": "DeepSea",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1807.09647",
        "dcat:theme": [
            "Reinforcement Learning",
            "Risk Sensitivity"
        ],
        "dcat:keyword": [
            "Grid environment",
            "Risk-seeking behavior",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Risk-sensitive policy learning"
        ]
    },
    {
        "dcterms:creator": [
            "Maxime Chevalier-Boisvert",
            "Dzmitry Bahdanau",
            "Salem Lahlou",
            "Lucas Willems",
            "Chitwan Saharia",
            "Thien Huu Nguyen",
            "Yoshua Bengio"
        ],
        "dcterms:description": "A partially observable grid-world environment where the agent observes a 7x7 grid and has to navigate through connected rooms, opening doors and reaching a goal state.",
        "dcterms:title": "MiniGrid-MultiRoom-N6-v0",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Grid Navigation"
        ],
        "dcat:keyword": [
            "Partially observable environment",
            "Grid navigation",
            "Door opening"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Navigation",
            "Task completion"
        ]
    },
    {
        "dcterms:creator": [
            "Nicolo Cesa-Bianchi",
            "Gábor Lugosi"
        ],
        "dcterms:description": "A framework for combinatorial bandits where the environment is defined by a graph, and the agent makes decisions about including edges in a spanning tree based on rewards.",
        "dcterms:title": "Combinatorial Bandits",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bandit Problems",
            "Combinatorial Optimization"
        ],
        "dcat:keyword": [
            "Graph-based rewards",
            "Spanning trees",
            "Decision making"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Decision making",
            "Reward maximization"
        ]
    }
]