To extract datasets from the research paper titled "Semantic Visual Navigation by Watching YouTube Videos" by Matthew Chang et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper, ensuring to include full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned. The abstract discusses the use of YouTube videos for navigation, which suggests that there may be a dataset derived from these videos.

Next, I will focus on the **experiments section**, particularly **section 4 (Experiments)**, where the authors typically describe the datasets used for their experiments. Here, I will look for specific names and descriptions of datasets.

In **section 4.1 (Video Dataset)**, the authors mention the **YouTube House Tours Dataset**, which consists of 1,387 videos with a total run length of 119 hours. This dataset is crucial for their experiments, as it provides the video data used to learn semantic cues for navigation.

Additionally, I will check the **References section** to find full citations for the datasets mentioned. The citation for the **YouTube House Tours Dataset** is not explicitly provided in the references, but I can infer that it is a collection of publicly available videos from YouTube.

Now, I will summarize the findings:

1. **YouTube House Tours Dataset**: This dataset consists of 1,387 videos sourced from YouTube, totaling 119 hours of video content. It is used to derive semantic cues for navigation in indoor environments.

Since the paper does not provide a formal citation for the YouTube dataset, I will note that it is derived from publicly available YouTube videos, and I will document it accordingly.

Finally, I will compile the dataset entries into a structured format for clarity and future reference, ensuring that the information is ready for review or further processing.