[
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A large dataset containing video clips with 13 joints annotated in all frames, including head, shoulders, elbows, wrists, hips, knees, and ankles.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human pose",
            "Joint estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. Zufﬁ",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "A dataset aimed at understanding action recognition, containing various actions performed by subjects.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Action dataset",
            "Video clips",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Yu Bai",
            "Chi Jin"
        ],
        "dcterms:description": "A dataset used for studying competitive reinforcement learning in two-player zero-sum Markov games.",
        "dcterms:title": "Two-player zero-sum Markov games",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "Markov games",
            "Reinforcement learning",
            "Zero-sum games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Kaiqing Zhang",
            "Sham M. Kakade",
            "Tamer Başar",
            "Lin F. Yang"
        ],
        "dcterms:description": "A generative model for two-player zero-sum Markov games that achieves near-optimal sample complexity.",
        "dcterms:title": "Generative model for two-player zero-sum Markov games",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game Theory"
        ],
        "dcat:keyword": [
            "Markov games",
            "Generative model",
            "Sample complexity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Chi Jin",
            "Qinghua Liu",
            "Yuanhao Wang",
            "Tiancheng Yu"
        ],
        "dcterms:description": "A decentralized algorithm for multi-agent reinforcement learning that is simple and efficient.",
        "dcterms:title": "V-learning algorithm",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "Decentralized learning",
            "Multi-agent reinforcement learning",
            "V-learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Bowen Baker",
            "Ingmar Kanitscheider",
            "Todor Markov",
            "Yi Wu",
            "Glenn Powell",
            "Bob McGrew",
            "Igor Mordatch"
        ],
        "dcterms:description": "A dataset exploring emergent tool use from multi-agent autocurricula.",
        "dcterms:title": "Emergent tool use from multi-agent autocurricula",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Multi-Agent Systems"
        ],
        "dcat:keyword": [
            "Tool use",
            "Emergent behavior",
            "Multi-agent learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Lloyd S. Shapley"
        ],
        "dcterms:description": "A foundational dataset for modeling multi-agent interactions in stochastic environments.",
        "dcterms:title": "Markov Decision Processes (MDPs)",
        "dcterms:issued": "1953",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Markov processes",
            "Decision making",
            "Stochastic games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Filar",
            "K. Vrieze"
        ],
        "dcterms:description": "A dataset focused on competitive Markov decision processes.",
        "dcterms:title": "Competitive Markov Decision Processes",
        "dcterms:issued": "1997",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Competitive processes",
            "Markov decision processes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Thomas Dueholm Hansen",
            "Peter Bro Miltersen",
            "Uri Zwick"
        ],
        "dcterms:description": "A dataset related to strategy iteration for two-player turn-based stochastic games.",
        "dcterms:title": "Strategy iteration for 2-player turn-based stochastic games",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Strategy iteration",
            "Stochastic games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Junling Hu",
            "Michael P. Wellman"
        ],
        "dcterms:description": "A dataset focused on Nash Q-learning for general-sum stochastic games.",
        "dcterms:title": "Nash Q-learning for general-sum stochastic games",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Game Theory",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Nash Q-learning",
            "General-sum games"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]