[
    {
        "dcterms:creator": [
            "Pratyush Maini",
            "Zhili Feng",
            "Avi Schwarzschild",
            "Zachary C Lipton",
            "J Zico Kolter"
        ],
        "dcterms:description": "The TOFU dataset consists of synthetically generated biographies of 200 fictitious authors, designed to evaluate unlearning methods for large language models (LLMs). The dataset introduces tasks aimed at forgetting 1%, 5%, and 10% of the data.",
        "dcterms:title": "TOFU Dataset",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2401.06121",
        "dcat:theme": [
            "Machine Learning",
            "Unlearning"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Biographies",
            "Unlearning tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Unlearning"
        ]
    },
    {
        "dcterms:creator": [
            "Jiaming Ji",
            "Mickel Liu",
            "Josef Dai",
            "Xuehai Pan",
            "Chi Zhang",
            "Ce Bian",
            "Boyuan Chen",
            "Ruiyang Sun",
            "Yizhou Wang",
            "Yaodong Yang"
        ],
        "dcterms:description": "The PKUSafe dataset is a human-preference dataset aimed at improving the safety alignment of large language models (LLMs). It is utilized for benchmarking unlearning methods.",
        "dcterms:title": "PKUSafe Dataset",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Safety",
            "Human Preferences"
        ],
        "dcat:keyword": [
            "Safety alignment",
            "Human-preference dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Benchmarking"
        ]
    },
    {
        "dcterms:creator": [
            "Nathaniel Li",
            "Alexander Pan",
            "Anjali Gopal",
            "Summer Yue",
            "Daniel Berrios",
            "Alice Gatti",
            "Justin D Li",
            "Ann-Kathrin Dombrowski",
            "Shashwat Goel",
            "Long Phan"
        ],
        "dcterms:description": "The Weapons of Mass Destruction Proxy (WMDP) dataset is designed to measure and reduce the malicious use of large language models (LLMs) through unlearning techniques.",
        "dcterms:title": "Weapons of Mass Destruction Proxy (WMDP)",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2403.03218",
        "dcat:theme": [
            "Malicious Use",
            "Unlearning"
        ],
        "dcat:keyword": [
            "Malicious use",
            "Unlearning methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "",
        "dcterms:title": "Real Authors set",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "",
        "dcterms:title": "Real World set",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]