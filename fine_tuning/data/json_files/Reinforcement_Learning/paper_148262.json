[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "A novel racing environment for OpenAI Gym where agents control a car to navigate a randomly generated racetrack, learning to manage acceleration and steering.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.01540",
        "dcat:theme": [
            "Reinforcement Learning",
            "Simulation Environment"
        ],
        "dcat:keyword": [
            "Racing environment",
            "Continuous action space",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous control",
            "Agent training"
        ]
    },
    {
        "dcterms:creator": [
            "Anton Orell Wiehe",
            "Nil Stolt Ans√≥",
            "Madalina M Drugan",
            "Marco A Wiering"
        ],
        "dcterms:description": "An algorithm that updates the actor using action samples chosen by a Q-value network, tested in the racing environment.",
        "dcterms:title": "Sampled Policy Gradient (SPG)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1809.05763",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Actor-critic",
            "Continuous action space",
            "Racing game"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous control",
            "Agent training"
        ]
    },
    {
        "dcterms:creator": [
            "John Schulman",
            "Filip Wolski",
            "Prafulla Dhariwal",
            "Alec Radford",
            "Oleg Klimov"
        ],
        "dcterms:description": "A reinforcement learning algorithm that optimizes policies in a stable manner, tested in the racing environment.",
        "dcterms:title": "Proximal Policy Optimization (PPO)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1707.06347",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Actor-critic",
            "Continuous action space",
            "Racing game"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous control",
            "Agent training"
        ]
    },
    {
        "dcterms:creator": [
            "Long-Ji Lin"
        ],
        "dcterms:description": "A method that allows agents to learn from past experiences by storing state transitions in a memory buffer.",
        "dcterms:title": "Experience Replay (ER)",
        "dcterms:issued": "1993",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Memory Management"
        ],
        "dcat:keyword": [
            "Experience replay",
            "Reinforcement learning",
            "Training efficiency"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous control",
            "Agent training"
        ]
    }
]