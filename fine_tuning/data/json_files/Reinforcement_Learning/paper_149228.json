[
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A large dataset containing video clips with 13 joints annotated in all frames, including head, shoulders, elbows, wrists, hips, knees, and ankles.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human pose",
            "Joint estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. Zufﬁ",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "A dataset aimed at understanding action recognition, containing various action classes.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Action dataset",
            "Video clips",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Ding",
            "J. Zhang",
            "J. Lavaei"
        ],
        "dcterms:description": "A dataset used for studying the global optimum convergence of momentum-based policy gradient methods.",
        "dcterms:title": "Fisher-non-degenerate parametrized policies",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Policy optimization",
            "Momentum-based methods"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Mei",
            "C. Xiao",
            "R. Huang",
            "D. Schuurmans",
            "M. Müller"
        ],
        "dcterms:description": "A dataset for studying the principles of entropy exploration in policy optimization.",
        "dcterms:title": "Gaussian policy",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.24963/ijcai.2019/434",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Optimization"
        ],
        "dcat:keyword": [
            "Entropy exploration",
            "Policy optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Peters",
            "S. Schaal"
        ],
        "dcterms:description": "A dataset for reinforcement learning of motor skills using policy gradients.",
        "dcterms:title": "Softmax tabular policy",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Motor Skills"
        ],
        "dcat:keyword": [
            "Motor skills",
            "Policy gradients"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Motor Skill Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Zhang",
            "A. Koppel",
            "A. S. Bedi",
            "C. Szepesvari",
            "M. Wang"
        ],
        "dcterms:description": "A dataset for reinforcement learning with general utilities using a variational policy gradient method.",
        "dcterms:title": "Softmax with log barrier",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Variational methods",
            "Policy optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Zhang",
            "C. Ni",
            "Z. Yu",
            "C. Szepesvari",
            "M. Wang"
        ],
        "dcterms:description": "A dataset for studying the convergence and sample efficiency of variance-reduced policy gradient methods.",
        "dcterms:title": "Softmax with entropy",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Variance reduction",
            "Policy optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "R. J. Williams"
        ],
        "dcterms:description": "A foundational dataset for statistical gradient-following algorithms in reinforcement learning.",
        "dcterms:title": "REINFORCE",
        "dcterms:issued": "1992",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Gradient methods",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Baxter",
            "P. L. Bartlett"
        ],
        "dcterms:description": "A dataset for infinite-horizon policy-gradient estimation.",
        "dcterms:title": "GPOMDP",
        "dcterms:issued": "2001",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Policy gradient",
            "Infinite horizon"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Papini",
            "D. Binaghi",
            "G. Canonaco",
            "M. Pirotta",
            "M. Restelli"
        ],
        "dcterms:description": "A dataset for stochastic variance-reduced policy gradient methods.",
        "dcterms:title": "Variance-reduced policy gradient",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Policy Gradient Methods"
        ],
        "dcat:keyword": [
            "Variance reduction",
            "Policy optimization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]