[
    {
        "dcterms:creator": [
            "Albert Q Jiang",
            "Alexandre Sablayrolles",
            "Arthur Mensch",
            "Chris Bamford",
            "Devendra Singh Chaplot",
            "Diego de las Casas",
            "Florian Bressand",
            "Gianna Lengyel",
            "Guillaume Lample",
            "Lucile Saulnier",
            "Lélio Renard Lavaud",
            "Marie-Anne Lachaux",
            "Pierre Stock",
            "Teven Le Scao",
            "Thibaut Lavril",
            "Thomas Wang",
            "Timothée Lacroix",
            "William El Sayed"
        ],
        "dcterms:description": "Mistral-7B is a language model that reduces the total number of weights by removing certain linear layers, making it more efficient in terms of compute and memory complexity.",
        "dcterms:title": "Mistral-7B",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2310.06825",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language model",
            "Efficiency",
            "Weights reduction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Ben Wang",
            "Aran Komatsuzaki"
        ],
        "dcterms:description": "Pythia-6.9B is a 6 billion parameter autoregressive language model that serves as a baseline for various transformer architectures.",
        "dcterms:title": "Pythia-6.9B",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language model",
            "Autoregressive",
            "Transformer"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Hugo Touvron",
            "Louis Martin",
            "Kevin Stone",
            "Peter Albert",
            "Amjad Almahairi",
            "Yasmine Babaei",
            "Nikolay Bashlykov",
            "Soumya Batra",
            "Prajjwal Bhargava",
            "Shruti Bhosale",
            "Dan Bikel",
            "Lukas Blecher",
            "Cristian Canton Ferrer",
            "Moya Chen",
            "Guillem Cucurull",
            "David Esiobu",
            "Jude Fernandes",
            "Jeremy Fu",
            "Wenyin Fu",
            "Brian Fuller",
            "Cynthia Gao",
            "Vedanuj Goswami",
            "Naman Goyal",
            "Anthony Hartshorn",
            "Saghar Hosseini",
            "Rui Hou",
            "Hakan Inan",
            "Marcin Kardas",
            "Viktor Kerkez",
            "Madian Khabsa",
            "Isabel Kloumann",
            "Artem Korenev",
            "Punit Singh Koura",
            "Marie-Anne Lachaux",
            "Thibaut Lavril",
            "Jenya Lee",
            "Diana Liskovich",
            "Yinghai Lu",
            "Yuning Mao",
            "Xavier Martinet",
            "Todor Mihaylov",
            "Pushkar Mishra",
            "Igor Molybog",
            "Yixin Nie",
            "Andrew Poulton",
            "Jeremy Reizenstein",
            "Rashi Rungta",
            "Kalyan Saladi",
            "Alan Schelten",
            "Ruan Silva",
            "Eric Michael Smith",
            "Ranjan Subramanian",
            "Xiaoqing Ellen Tan",
            "Binh Tang",
            "Ross Taylor",
            "Adina Williams",
            "Jian Xiang Kuan",
            "Puxin Xu",
            "Zheng Yan",
            "Iliyan Zarov",
            "Yuchen Zhang",
            "Angela Fan",
            "Melanie Kambadur",
            "Sharan Narang",
            "Aurelien Rodriguez",
            "Robert Stojnic",
            "Sergey Edunov",
            "Thomas Scialom"
        ],
        "dcterms:description": "Llama 2 is an open foundation and fine-tuned chat model that serves as a benchmark for various language modeling tasks.",
        "dcterms:title": "Llama 2",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.09288",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language model",
            "Chat model",
            "Open foundation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Albert Q Jiang",
            "Alexandre Sablayrolles",
            "Antoine Roux",
            "Arthur Mensch",
            "Blanche Savary",
            "Chris Bamford",
            "Devendra Singh Chaplot",
            "Diego de las Casas",
            "Emma Bou Hanna",
            "Florian Bressand",
            "Gianna Lengyel",
            "Guillaume Bour",
            "Guillaume Lample",
            "Lélio Renard Lavaud",
            "Lucile Saulnier",
            "Marie-Anne Lachaux",
            "Pierre Stock",
            "Sandeep Subramanian",
            "Sophia Yang",
            "Szymon Antoniak",
            "Teven Le Scao",
            "Théophile Gervet",
            "Thibaut Lavril",
            "Thomas Wang",
            "Timothée Lacroix",
            "William El Sayed"
        ],
        "dcterms:description": "Mixtral is a model that combines multiple experts to enhance performance in various language tasks.",
        "dcterms:title": "Mixtral",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2401.04088",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Expert model",
            "Language model",
            "Performance enhancement"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Aakanksha Chowdhery",
            "Sharan Narang",
            "Jacob Devlin",
            "Maarten Bosma",
            "Gaurav Mishra",
            "Adam Roberts",
            "Paul Barham",
            "Hyung Won Chung",
            "Charles Sutton",
            "Sebastian Gehrmann",
            "Parker Schuh",
            "Kensen Shi",
            "Sasha Tsvyashchenko",
            "Joshua Maynez",
            "Abhishek Rao",
            "Parker Barnes",
            "Yi Tay",
            "Noam Shazeer",
            "Vinodkumar Prabhakaran",
            "Emily Reif",
            "Nan Du",
            "Ben Hutchinson",
            "Reiner Pope",
            "James Bradbury",
            "Jacob Austin",
            "Michael Isard",
            "Guy Gur-Ari",
            "Pengcheng Yin",
            "Toju Duke",
            "Anselm Levskaya",
            "Sanjay Ghemawat",
            "Sunipa Dev",
            "Henryk Michalewski",
            "Xavier Garcia",
            "Vedant Misra",
            "Kevin Robinson",
            "Liam Fedus",
            "Denny Zhou",
            "Daphne Ippolito",
            "David Luan",
            "Hyeontaek Lim",
            "Barret Zoph",
            "Alexander Spiridonov",
            "Ryan Sepassi",
            "David Dohan",
            "Shivani Agrawal",
            "Mark Omernick",
            "Andrew M Dai",
            "Thanumalayan Sankaranarayana Pillai",
            "Marie Pellat",
            "Aitor Lewkowycz",
            "Erica Moreira",
            "Rewon Child",
            "Oleksandr Polozov",
            "Katherine Lee",
            "Zongwei Zhou",
            "Xuezhi Wang",
            "Brennan Saeta",
            "Mark Diaz",
            "Orhan Firat",
            "Michele Catasta",
            "Jason Wei",
            "Kathy Meier-Hellstern",
            "Douglas Eck",
            "Jeff Dean",
            "Slav Petrov",
            "Noah Fiedel"
        ],
        "dcterms:description": "PaLM is a language model that scales language modeling tasks using the Pathways architecture.",
        "dcterms:title": "PaLM",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2204.02311",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Language model",
            "Scaling",
            "Pathways architecture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]