[
    {
        "dcterms:creator": [
            "Bingchen Zhao",
            "Shaozuo Yu",
            "Wufei Ma",
            "Mingxin Yu",
            "Shenxiao Mei",
            "Angtian Wang",
            "Ju He",
            "Alan Yuille",
            "Adam Korytlewski"
        ],
        "dcterms:description": "A novel VQA dataset grounded on images from OODCV, designed to assess model performance under out-of-distribution scenarios, including questions that can be answered with yes/no responses or digits.",
        "dcterms:title": "OODCV-VQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Out-of-Distribution Evaluation"
        ],
        "dcat:keyword": [
            "VQA",
            "OOD",
            "visual reasoning",
            "image-text pairs"
        ],
        "dcat:landingPage": "https://github.com/UCSC-VLAA/vllm-safety-benchmark",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Letian Zhang",
            "Xiaotong Zhai",
            "Zhongkai Zhao",
            "Xin Wen",
            "Bingchen Zhao"
        ],
        "dcterms:description": "A variant of the OODCV-VQA dataset that includes counterfactual questions paired with images, designed to test model performance when the textual question deviates from the default distribution.",
        "dcterms:title": "OODCV-Counterfactual",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Counterfactual Reasoning"
        ],
        "dcat:keyword": [
            "Counterfactual",
            "VQA",
            "visual reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mathias Eitz",
            "James Hays",
            "Marc Alexa"
        ],
        "dcterms:description": "A dataset containing sketch images used for visual question answering, where questions are generated based on the appearance of objects in the sketches.",
        "dcterms:title": "Sketchy-VQA",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Sketch Recognition"
        ],
        "dcat:keyword": [
            "Sketch",
            "VQA",
            "visual reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mathias Eitz",
            "James Hays",
            "Marc Alexa"
        ],
        "dcterms:description": "A challenging variant of the Sketchy-VQA dataset that includes less frequently appearing categories for visual question answering.",
        "dcterms:title": "Sketchy-Challenging",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Sketch Recognition"
        ],
        "dcat:keyword": [
            "Challenging",
            "Sketch",
            "VQA",
            "visual reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Google Brain"
        ],
        "dcterms:description": "A dataset used for evaluating adversarial robustness in models, containing images annotated for adversarial attack scenarios.",
        "dcterms:title": "NIPS17",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.kaggle.com/competitions/nips-2017-non-targeted-adversarial-attack",
        "dcat:theme": [
            "Adversarial Robustness",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Adversarial Attack",
            "Robustness",
            "Image Dataset"
        ],
        "dcat:landingPage": "https://www.kaggle.com/competitions/nips-2017-non-targeted-adversarial-attack",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Adversarial Evaluation"
        ]
    }
]