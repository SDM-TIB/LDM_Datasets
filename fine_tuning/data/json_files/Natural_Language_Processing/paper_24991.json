[
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1804.07461",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Natural Language Understanding",
            "Multi-task Benchmark",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Lianmin Zheng",
            "Wei-Lin Chiang",
            "Ying Sheng",
            "Siyuan Zhuang",
            "Zhanghao Wu",
            "Yonghao Zhuang",
            "Zi Lin",
            "Zhuohan Li",
            "Dacheng Li",
            "Eric Xing"
        ],
        "dcterms:description": "A dataset designed to assess large language models through multi-turn questions.",
        "dcterms:title": "MT-Bench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Multi-turn Questions",
            "Language Model Assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano"
        ],
        "dcterms:description": "A dataset for training verifiers to solve math word problems.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.14168",
        "dcat:theme": [
            "Mathematics",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Math Word Problems",
            "Verification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Mark Chen",
            "Jerry Tworek",
            "Heewoo Jun",
            "Qiming Yuan",
            "Henrique Ponde de Oliveira Pinto",
            "Jared Kaplan",
            "Harri Edwards",
            "Yuri Burda",
            "Nicholas Joseph",
            "Greg Brockman"
        ],
        "dcterms:description": "A dataset for evaluating large language models trained on code.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2107.03374",
        "dcat:theme": [
            "Programming",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Code Evaluation",
            "Programming Tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Longhui Yu",
            "Weisen Jiang",
            "Han Shi",
            "Jincheng Yu",
            "Zhengying Liu",
            "Yu Zhang",
            "James T. Kwok",
            "Zhenguo Li",
            "Adrian Weller",
            "Weiyang Liu"
        ],
        "dcterms:description": "A dataset for bootstrapping mathematical questions for large language models.",
        "dcterms:title": "MetaMathQA",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematics",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Mathematical Questions",
            "Bootstrapping"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Tianyu Zheng",
            "Ge Zhang",
            "Tianhao Shen",
            "Xueling Liu",
            "Bill Yuchen Lin",
            "Jie Fu",
            "Wenhu Chen",
            "Xiang Yue"
        ],
        "dcterms:description": "A high-quality code instruction dataset integrating code generation with execution and refinement.",
        "dcterms:title": "Code-Feedback",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Programming",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Code Generation",
            "Instruction Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    }
]