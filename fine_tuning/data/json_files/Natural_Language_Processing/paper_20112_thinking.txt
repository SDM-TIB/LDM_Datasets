To extract datasets from the research paper titled "Deep Adaptative Spectral Zoom for Improved Remote Heart Rate Estimation" by Joaquim Comas et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract** and **introduction** sections to identify any datasets mentioned. The abstract indicates that the authors validate their model using three publicly available datasets: **UCLA-rPPG**, **PURE**, and **UBFC-rPPG**. This is a strong indication that these datasets will be discussed in detail later in the paper.

Next, I will navigate to the **experiments section**, specifically **section IV (Experiments)**, where the authors provide a detailed description of the datasets used. In this section, they outline the characteristics of each dataset, including the number of videos, subjects, and the context in which the data was collected.

1. **UCLA-rPPG Dataset**: This dataset consists of 489 videos from 98 subjects, capturing diverse characteristics such as skin tones and ages. Each video is approximately 1 minute long, recorded at a resolution of 640 × 480 pixels and 30 frames per second. The authors mention that synchronous gold-standard PPG and HR measurements were collected alongside the facial videos.

2. **UBFC-rPPG Dataset**: This dataset includes 42 RGB videos from 42 subjects who participated in a time-sensitive mathematical game. The recordings were made indoors under varying lighting conditions, also at 30 FPS and a resolution of 640 × 480 pixels. The ground truth for bio-signals was obtained using a CMS50E transmissive pulse oximeter.

3. **PURE Dataset**: The PURE dataset contains 60 videos from 10 subjects performing various head motion tasks. The videos were recorded at 30 FPS with a resolution of 640 × 480 pixels. Ground truth measures of BVP and SpO2 were collected using a finger pulse oximeter.

After identifying the datasets, I will check the **References section** to find the full citations for each dataset. The citations are crucial for proper attribution and to allow others to access the datasets.

- For the **UCLA-rPPG Dataset**, the citation is:
  > Z. Wang, Y. Ba, P. Chari, O. D. Bozkurt, G. Brown, P. Patwa, N. Vaddi, L. Jalilian, and A. Kadambi. *Synthetic generation of face videos with plethysmograph physiology*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 20587–20596, 2022.

- For the **UBFC-rPPG Dataset**, the citation is:
  > S. Bobbia, R. Macwan, Y. Benezeth, A. Mansouri, and J. Dubois. *Unsupervised skin tissue segmentation for remote photoplethysmography*. Pattern Recognition Letters, 124:82–90, 2019.

- For the **PURE Dataset**, the citation is:
  > W. Wang, A. C. den Brinker, S. Stuijk, and G. De Haan. *Algorithmic principles of remote PPG*. IEEE Transactions on Biomedical Engineering, 64(7):1479–1491, 2016.

Now that I have gathered all the necessary information about the datasets and their citations, I will compile this into a structured format for further processing or review.