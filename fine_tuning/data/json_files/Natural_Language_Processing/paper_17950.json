[
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R Bowman"
        ],
        "dcterms:description": "The GLUE benchmark provides a comprehensive evaluation of models across a range of linguistic tasks.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1804.07461",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Linguistic tasks",
            "Natural Language Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "The MMLU benchmark consists of 57 tasks including elementary mathematics, US history, computer science, law, and more.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask",
            "Evaluation",
            "Natural Language Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Warstadt",
            "Amanpreet Singh",
            "Samuel R Bowman"
        ],
        "dcterms:description": "CoLA is a dataset for assessing the acceptability of sentences in English.",
        "dcterms:title": "CoLA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Linguistic Acceptability"
        ],
        "dcat:keyword": [
            "Acceptability judgments",
            "Linguistics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Linguistic Acceptability"
        ]
    },
    {
        "dcterms:creator": [
            "Richard Socher",
            "Alex Perelygin",
            "Jean Wu",
            "Jason Chuang",
            "Christopher D Manning",
            "Andrew Y Ng",
            "Christopher Potts"
        ],
        "dcterms:description": "SST-2 is a dataset for sentiment analysis, providing a sentiment treebank.",
        "dcterms:title": "SST-2",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment analysis",
            "Treebank"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Bill Dolan",
            "Chris Brockett"
        ],
        "dcterms:description": "MRPC is a dataset for paraphrase identification, constructed from a corpus of sentential paraphrases.",
        "dcterms:title": "MRPC",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Paraphrase Identification"
        ],
        "dcat:keyword": [
            "Paraphrase",
            "Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "QNLI is a dataset for question answering, derived from the SQuAD dataset.",
        "dcterms:title": "QNLI",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.05250",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "SQuAD"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Shankar Iyer"
        ],
        "dcterms:description": "QQP is a dataset containing pairs of questions from Quora, used for identifying duplicate questions.",
        "dcterms:title": "QQP",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs",
        "dcat:theme": [
            "Natural Language Processing",
            "Duplicate Question Identification"
        ],
        "dcat:keyword": [
            "Question pairs",
            "Duplicate questions"
        ],
        "dcat:landingPage": "https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Duplicate Question Identification"
        ]
    },
    {
        "dcterms:creator": [
            "Adina Williams",
            "Nikita Nangia",
            "Samuel R Bowman"
        ],
        "dcterms:description": "MNLI is a dataset for natural language inference, providing a broad-coverage challenge corpus.",
        "dcterms:title": "MNLI",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1704.05426",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Challenge corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    }
]