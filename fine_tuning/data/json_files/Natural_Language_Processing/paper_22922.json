[
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Caiming Xiong",
            "James Bradbury",
            "Richard Socher"
        ],
        "dcterms:description": "A dataset used for evaluating language models, specifically for measuring perplexity.",
        "dcterms:title": "WikiText2",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1609.07843",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Perplexity",
            "Text dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1609.07843",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Colin Raffel",
            "Noam Shazeer",
            "Adam Roberts",
            "Katherine Lee",
            "Sharan Narang",
            "Michael Matena",
            "Yanqi Zhou",
            "Wei Li",
            "Peter J Liu"
        ],
        "dcterms:description": "A large-scale dataset for training and evaluating text-to-text models.",
        "dcterms:title": "C4",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Text-to-text",
            "Transfer learning",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation",
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Peter Clark",
            "Isaac Cowhey",
            "Oren Etzioni",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Carissa Schoenick",
            "Oyvind Tafjord"
        ],
        "dcterms:description": "A dataset designed to evaluate AI's reasoning capabilities in question answering.",
        "dcterms:title": "ARC (AI2 Reasoning Challenge)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1803.05457",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Reasoning",
            "Question answering",
            "AI evaluation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1803.05457",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Kenton Lee",
            "Ming-Wei Chang",
            "Tom Kwiatkowski",
            "Michael Collins",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset for evaluating models on natural yes/no questions.",
        "dcterms:title": "BoolQ",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1905.10044",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Yes/No questions",
            "Natural language understanding"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1905.10044",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Rowan Zellers",
            "Ari Holtzman",
            "Yonatan Bisk",
            "Ali Farhadi",
            "Yejin Choi"
        ],
        "dcterms:description": "A dataset for evaluating the ability of models to complete sentences.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "https://arxiv.org/abs/1905.07830",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Sentence completion",
            "Natural language understanding"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1905.07830",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Completion"
        ]
    },
    {
        "dcterms:creator": [
            "Yonatan Bisk",
            "Rowan Zellers",
            "Jianfeng Gao",
            "Yejin Choi"
        ],
        "dcterms:description": "A dataset for reasoning about physical commonsense in natural language.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Physical commonsense",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Keisuke Sakaguchi",
            "Ronan Le Bras",
            "Chandra Bhagavatula",
            "Yejin Choi"
        ],
        "dcterms:description": "An adversarial dataset designed to challenge models with Winograd schema-like questions.",
        "dcterms:title": "Winogrande",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Winograd schema",
            "Adversarial dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    }
]