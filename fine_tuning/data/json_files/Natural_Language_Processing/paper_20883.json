[
    {
        "dcterms:creator": [
            "Andrea Esuli",
            "Giovanni Puccetti"
        ],
        "dcterms:description": "A benchmark dataset designed to evaluate language models' mathematical reasoning abilities in Italian, consisting of various question types including multiple choice, true/false, and fill the gap.",
        "dcterms:title": "Invalsi MATH",
        "dcterms:issued": "2023",
        "dcterms:language": "Italian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematical Understanding",
            "Language Evaluation"
        ],
        "dcat:keyword": [
            "Mathematics",
            "Language Models",
            "Italian Language",
            "Benchmark Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematical Reasoning Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Andrea Esuli",
            "Giovanni Puccetti"
        ],
        "dcterms:description": "A benchmark dataset aimed at assessing language understanding capabilities of language models in Italian, featuring a variety of question types that require comprehension of longer text passages.",
        "dcterms:title": "Invalsi ITA",
        "dcterms:issued": "2023",
        "dcterms:language": "Italian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Understanding",
            "Language Evaluation"
        ],
        "dcat:keyword": [
            "Language Comprehension",
            "Italian Language",
            "Benchmark Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Understanding Evaluation"
        ]
    }
]