[
    {
        "dcterms:creator": [
            "X. Zhai",
            "J. Puigcerver",
            "A. Kolesnikov",
            "P. Ruyssen",
            "C. Riquelme",
            "M. Lucic",
            "J. Djolonga",
            "A. S. Pinto",
            "M. Neumann",
            "A. Dosovitskiy",
            "L. Beyer",
            "O. Bachem",
            "M. Tschannen",
            "M. Michalski",
            "O. Bousquet",
            "S. Gelly",
            "N. Houlsby"
        ],
        "dcterms:description": "The VTAB-1k benchmark is used for fine-tuning and evaluating the performance of various vision models across a combination of 16 different vision datasets.",
        "dcterms:title": "VTAB-1k",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Vision datasets",
            "Fine-tuning",
            "Model evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Fine-tuning",
            "Model evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Raffel",
            "N. Shazeer",
            "A. Roberts",
            "K. Lee",
            "S. Narang",
            "M. Matena",
            "Y. Zhou",
            "W. Li",
            "P. J. Liu"
        ],
        "dcterms:description": "The C4 dataset is utilized for pre-training language models, providing a large-scale corpus for training and evaluation.",
        "dcterms:title": "C4",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Data"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Pre-training",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Pre-training",
            "Language modeling"
        ]
    },
    {
        "dcterms:creator": [
            "A. Wang",
            "A. Singh",
            "J. Michael",
            "F. Hill",
            "O. Levy",
            "S. R. Bowman"
        ],
        "dcterms:description": "GLUE is a multi-task benchmark for evaluating natural language understanding systems, providing a diverse set of tasks.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "NLP benchmark",
            "Multi-task learning",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding",
            "Multi-task evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "T. Rohan",
            "I. Gulrajani",
            "T. Zhang",
            "Y. Dubois",
            "X. Li",
            "C. Guestrin",
            "P. Liang",
            "T. B. Hashimoto"
        ],
        "dcterms:description": "The Alpaca dataset is designed for instruction-following tasks, providing a framework for fine-tuning language models.",
        "dcterms:title": "Alpaca",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction-following",
            "Fine-tuning",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following",
            "Fine-tuning"
        ]
    }
]