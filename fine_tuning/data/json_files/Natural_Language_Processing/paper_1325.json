[
    {
        "dcterms:creator": [
            "F. Hill",
            "R. Reichart",
            "A. Korhonen"
        ],
        "dcterms:description": "SimLex-999 is a dataset that evaluates semantic models with genuine similarity estimation, providing a set of 999 word pairs annotated for semantic similarity.",
        "dcterms:title": "SimLex-999",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word pairs",
            "Semantic models",
            "Similarity estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic similarity evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Gerz",
            "I. Vuli´c",
            "F. Hill",
            "R. Reichart",
            "A. Korhonen"
        ],
        "dcterms:description": "SimVerb-3500 is a large-scale evaluation set of verb similarity, containing 3,500 verb pairs annotated for semantic similarity.",
        "dcterms:title": "SimVerb-3500",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Verb pairs",
            "Semantic models",
            "Similarity evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Verb similarity evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "M. T. Pilehvar",
            "D. Kartsaklis",
            "V. Prokhorov",
            "N. Collier"
        ],
        "dcterms:description": "CARD-660 is a dataset focused on measuring the semantic similarity of infrequent concepts, providing a reliable benchmark for infrequent word representation models.",
        "dcterms:title": "CARD-660",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Rare words",
            "Semantic models",
            "Similarity evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic similarity evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Camacho-Collados",
            "M. T. Pilehvar",
            "N. Collier",
            "R. Navigli"
        ],
        "dcterms:description": "SEMEVAL-500 is a dataset for multilingual and cross-lingual semantic word similarity, containing 500 concept pairs.",
        "dcterms:title": "SEMEVAL-500",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multilingual",
            "Cross-lingual",
            "Semantic similarity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic similarity evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Conneau",
            "R. Rinott",
            "G. Lample",
            "A. Williams",
            "S. Bowman",
            "H. Schwenk",
            "V. Stoyanov"
        ],
        "dcterms:description": "XNLI is a dataset for evaluating cross-lingual sentence representations, providing a benchmark for multilingual natural language inference.",
        "dcterms:title": "XNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cross-lingual",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Sentence representations",
            "Natural language inference",
            "Cross-lingual evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural language inference"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Yang",
            "Y. Zhang",
            "C. Tar",
            "J. Baldridge"
        ],
        "dcterms:description": "PAWS-X is a cross-lingual adversarial dataset for paraphrase identification, designed to evaluate models on paraphrase detection across languages.",
        "dcterms:title": "PAWS-X",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Paraphrase Identification",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Cross-lingual",
            "Adversarial dataset",
            "Paraphrase detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase identification"
        ]
    },
    {
        "dcterms:creator": [
            "J. Nivre",
            "M. Abrams",
            "Ž. Agi´c",
            "L. Ahrenberg",
            "G. ˙e Alekandraviˇci ¯ut ˙e",
            "L. Antonsen",
            "K. Aplonova",
            "M. J. Aranzabe",
            "G. Arutie",
            "M. Asahara"
        ],
        "dcterms:description": "Universal Dependencies (UD) is a framework for consistent annotations across languages, providing a resource for multilingual parsing and cross-lingual studies.",
        "dcterms:title": "Universal Dependencies (UD)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Linguistic Typology",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Dependency parsing",
            "Cross-lingual studies",
            "Multilingual resources"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dependency parsing"
        ]
    },
    {
        "dcterms:creator": [
            "L. Finkelstein",
            "E. Gabrilovich",
            "Y. Matias",
            "E. Rivlin",
            "Z. Solan",
            "G. Wolfman",
            "E. Ruppin"
        ],
        "dcterms:description": "WordSim-353 is a dataset for evaluating word similarity, containing 353 word pairs annotated for similarity.",
        "dcterms:title": "WordSim-353",
        "dcterms:issued": "2002",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word pairs",
            "Similarity evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word similarity evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "E. Bruni",
            "N. Tran",
            "M. Baroni"
        ],
        "dcterms:description": "MEN is a dataset for evaluating semantic similarity, containing 3,000 word pairs annotated for similarity.",
        "dcterms:title": "MEN",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Word pairs",
            "Semantic evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic similarity evaluation"
        ]
    }
]