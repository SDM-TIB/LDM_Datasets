[
    {
        "dcterms:creator": [
            "A. Zou",
            "Z. Wang",
            "J. Zico Kolter",
            "M. Fredrikson"
        ],
        "dcterms:description": "AdvBench consists of 520 harmful behaviors formulated as instructions that reflect harmful or toxic behavior, covering a wide spectrum of detrimental content such as profanity, graphic depictions, threatening behavior, misinformation, discrimination, cybercrime, and dangerous or illegal suggestions.",
        "dcterms:title": "AdvBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Attacks",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Harmful behaviors",
            "Toxic content",
            "Adversarial prompts"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluating LLM vulnerabilities"
        ]
    },
    {
        "dcterms:creator": [
            "G. Deng",
            "Y. Liu",
            "Y. Li",
            "K. Wang",
            "Y. Zhang",
            "Z. Li",
            "H. Wang",
            "T. Zhang",
            "Y. Liu"
        ],
        "dcterms:description": "MasterKey comprises 11 prohibitive scenarios delineated by four key LLM chatbot service providers: OpenAI, Bard, Bing Chat, and Ernie. Five question prompts are created per scenario, resulting in 55 instances to ensure a diverse representation of perspectives and nuances within each prohibited scenario.",
        "dcterms:title": "MasterKey",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Attacks",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Prohibitive scenarios",
            "Chatbot safety",
            "Malicious intents"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluating LLM vulnerabilities"
        ]
    }
]