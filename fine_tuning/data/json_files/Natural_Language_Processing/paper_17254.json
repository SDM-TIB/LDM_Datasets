[
    {
        "dcterms:creator": [
            "E. Leurent"
        ],
        "dcterms:description": "An environment where a reinforcement learning agent controls a vehicle navigating a multi-lane highway, interacting with other vehicles. The agent's reward is determined by its driving regime, allowing for diverse strategies.",
        "dcterms:title": "Highway Environment",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Highway driving",
            "Reinforcement learning",
            "Multi-lane navigation"
        ],
        "dcat:landingPage": "https://github.com/eleurent/highway-env",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Autonomous driving decision-making"
        ]
    },
    {
        "dcterms:creator": [
            "E. Leurent"
        ],
        "dcterms:description": "Implementations of various reinforcement learning algorithms, providing a framework for testing and developing RL agents.",
        "dcterms:title": "rl-agents",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Reinforcement learning algorithms",
            "Agent implementations"
        ],
        "dcat:landingPage": "https://github.com/eleurent/rl-agents",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement learning algorithm implementation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Van Seijen",
            "M. Fatemi",
            "J. Romoff",
            "R. Laroche",
            "T. Barnes",
            "J. Tsang"
        ],
        "dcterms:description": "A hierarchical reward architecture that decomposes the agent's reward function into distinct components, facilitating easier approximation of the Q-function and faster learning.",
        "dcterms:title": "Hierarchical Reward Architecture (HRA)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1706.04208",
        "dcat:theme": [
            "Reinforcement Learning",
            "Reward Structures"
        ],
        "dcat:keyword": [
            "Reward decomposition",
            "Hierarchical architecture",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement learning"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Juozapaitis",
            "A. Koul",
            "A. Fern",
            "M. Erwig",
            "F. Doshi-Velez"
        ],
        "dcterms:description": "A method for explainable reinforcement learning that provides insights into an agent's expected utility by decomposing the environment's reward into meaningful components.",
        "dcterms:title": "Reward Decomposition",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Explainable AI",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Explainable reinforcement learning",
            "Reward decomposition",
            "Utility explanation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Explainable reinforcement learning"
        ]
    }
]