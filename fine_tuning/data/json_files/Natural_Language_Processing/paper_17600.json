[
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "MSCOCO comprises images paired with corresponding captions, forming text-image pairs. It is used to generate original prompts by captioning the images with GPT-4.",
        "dcterms:title": "MSCOCO",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Text-image pairs",
            "Caption generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Captioning",
            "Text-to-Image Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Jia Deng",
            "Wei Dong",
            "Richard Socher",
            "Li-Jia Li",
            "Kai Li",
            "Li Fei-Fei"
        ],
        "dcterms:description": "ImageNet contains an extensive collection of images organized according to the WordNet hierarchy, used for training and evaluating image classification models.",
        "dcterms:title": "ImageNet",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Image Classification"
        ],
        "dcat:keyword": [
            "Image dataset",
            "Hierarchical classification",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    },
    {
        "dcterms:creator": [
            "Zijie J Wang",
            "Evan Montoya",
            "David Munechika",
            "Haoyang Yang",
            "Benjamin Hoover",
            "Duen Horng Chau"
        ],
        "dcterms:description": "DiffusionDB is a large-scale prompt gallery dataset for text-to-image generative models, containing captions of images that can be summarized and filtered for prompt generation.",
        "dcterms:title": "DiffusionDB",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Image Generation",
            "Prompt Engineering"
        ],
        "dcat:keyword": [
            "Prompt dataset",
            "Text-to-image synthesis",
            "Image captions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text-to-Image Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Tingfeng Cao",
            "Chengyu Wang",
            "Bingyan Liu",
            "Ziheng Wu",
            "Jinhui Zhu",
            "Jun Huang"
        ],
        "dcterms:description": "BeautifulPrompt is designed to enhance the quality of generated images through Reinforcement Learning by training on both low-quality and high-quality prompt pairs.",
        "dcterms:title": "BeautifulPrompt",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Image Generation",
            "Prompt Engineering"
        ],
        "dcat:keyword": [
            "Prompt dataset",
            "Image synthesis",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text-to-Image Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "BERT is a pre-trained model for language understanding, used for fine-tuning in the context of optimizing prompts for image generation.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Language model",
            "Text processing",
            "Fine-tuning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification",
            "Prompt Optimization"
        ]
    }
]