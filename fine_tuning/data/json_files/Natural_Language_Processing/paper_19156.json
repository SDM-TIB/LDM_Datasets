[
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A large dataset containing video clips with 13 joints annotated in all frames, including head, shoulders, elbows, wrists, hips, knees, and ankles.",
        "dcterms:title": "Penn Action Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Human Pose Estimation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human pose",
            "Joint estimation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Pose Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Jhuang",
            "J. Gall",
            "S. ZufÔ¨Å",
            "C. Schmid",
            "M. J. Black"
        ],
        "dcterms:description": "A dataset designed for understanding action recognition, containing video clips with annotated actions.",
        "dcterms:title": "sub-JHMDB Dataset",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Action dataset",
            "Video clips",
            "Annotated actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "P. F. Christiano",
            "J. Leike",
            "T. Brown",
            "M. Martic",
            "S. Legg",
            "D. Amodei"
        ],
        "dcterms:description": "A dataset used for deep reinforcement learning from human preferences, focusing on learning from human feedback.",
        "dcterms:title": "RLHF (Reinforcement Learning from Human Feedback)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Human preferences",
            "Feedback learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Achiam",
            "S. Adler",
            "S. Agarwal",
            "L. Ahmad",
            "I. Akkaya",
            "F. L. Aleman",
            "D. Almeida",
            "J. Altenschmidt",
            "S. Altman",
            "S. Anadkat"
        ],
        "dcterms:description": "A dataset related to the technical report of GPT-4, focusing on human feedback.",
        "dcterms:title": "Human Feedback Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2303.08774",
        "dcat:theme": [
            "Natural Language Processing",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "GPT-4",
            "Human feedback",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Processing"
        ]
    },
    {
        "dcterms:creator": [
            "A. Xu",
            "Y. Wang",
            "R. Yang",
            "L. Singh",
            "A. Dubrawski"
        ],
        "dcterms:description": "A dataset for preference-based reinforcement learning with finite-time guarantees.",
        "dcterms:title": "Tabular MDPs Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Decision Making"
        ],
        "dcat:keyword": [
            "Tabular MDPs",
            "Reinforcement Learning",
            "Preference learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "E. Novoseller",
            "Y. Wei",
            "Y. Sui",
            "Y. Yue",
            "J. D. Burdick"
        ],
        "dcterms:description": "A dataset for preference-based reinforcement learning focusing on dueling posterior sampling.",
        "dcterms:title": "Online RLHF Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Sampling Techniques"
        ],
        "dcat:keyword": [
            "Online learning",
            "Reinforcement Learning",
            "Preference-based learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "W. Zhan",
            "M. Uehara",
            "N. Kallus",
            "J. D. Lee",
            "W. Sun"
        ],
        "dcterms:description": "A dataset for offline reinforcement learning with human feedback.",
        "dcterms:title": "Offline RLHF Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.14816",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Offline learning",
            "Reinforcement Learning",
            "Human feedback"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "L. Wang",
            "Q. Cai",
            "Z. Yang",
            "Z. Wang"
        ],
        "dcterms:description": "A dataset for neural policy gradient methods focusing on global optimality and rates of convergence.",
        "dcterms:title": "Neural Function Approximation Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Neural networks",
            "Policy gradient",
            "Function approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reinforcement Learning"
        ]
    }
]