To extract datasets from the research paper titled "TokenHMR: Advancing Human Mesh Recovery with a Tokenized Pose Representation" by Sai Kumar Dwivedi et al., I will follow a systematic approach to ensure I capture all relevant datasets and their citations accurately.

First, I will read through the **abstract, introduction, and experiments sections** of the paper. The abstract mentions that extensive experiments were conducted on the **EMDB** and **3DPW** datasets, indicating that these are key datasets used in the research.

Next, I will look for specific mentions of datasets in the **introduction**. Here, the authors discuss the importance of leveraging large datasets for training and evaluation, specifically mentioning **BEDLAM**, which is a synthetic dataset with accurate ground-truth data. This suggests that BEDLAM is also a significant dataset for their experiments.

In the **experiments section**, I will look for detailed descriptions of how each dataset was used. The authors provide a table summarizing the performance of their method on the **EMDB** and **3DPW** datasets, confirming their use in the evaluation of TokenHMR. They also mention that the **AMASS** and **MOYO** datasets were used for training the tokenizer, which is crucial for understanding the model's performance.

Now, I will check the **References section** to gather full citations for each dataset mentioned:

1. **EMDB** (Electromagnetic Database of Global 3D Human Pose and Shape in the Wild):
   > Kaufmann, M., Song, J., Guo, C., Shen, K., Jiang, T., Tang, C., ZÃ¡rate, J. J., & Hilliges, O. (2023). EMDB: The Electromagnetic Database of Global 3D Human Pose and Shape in the Wild. In Proceedings of the IEEE International Conference on Computer Vision (ICCV).

2. **3DPW** (3D Poses in the Wild):
   > von Marcard, T., Henschel, R., Black, M. J., Rosenhahn, B., & Pons-Moll, G. (2018). Recovering accurate 3D human pose in the wild using IMUs and a moving camera. In Proceedings of the European Conference on Computer Vision (ECCV).

3. **BEDLAM** (a synthetic dataset of bodies exhibiting detailed lifelike animated motion):
   > Black, M. J., Patel, P., Tesch, J., & Yang, J. (2023). BEDLAM: A synthetic dataset of bodies exhibiting detailed lifelike animated motion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

4. **AMASS** (Archive of Motion Capture as Surface Shapes):
   > Mahmood, N., Ghorbani, N., Troje, N. K., Pons-Moll, G., & Black, M. J. (2019). AMASS: Archive of motion capture as surface shapes. In Proceedings of the International Conference on Computer Vision (ICCV).

5. **MOYO** (a dataset for yoga poses):
   > Kocabas, M., Athanasiou, N., & Black, M. J. (2022). MOYO: A dataset for yoga poses. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR).

After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described and cited according to the requirements of the task. This structured approach will help ensure that I do not miss any important datasets or details in the extraction process.