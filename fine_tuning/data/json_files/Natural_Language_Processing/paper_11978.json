[
    {
        "dcterms:creator": [
            "Kate Sanders",
            "David Etter",
            "Reno Kriz",
            "Benjamin Van Durme"
        ],
        "dcterms:description": "MultiVENT is a dataset of multilingual, event-centric videos grounded in text documents across five target languages, including news broadcast videos and non-professional event footage, aimed at analyzing online news videos and building robust models.",
        "dcterms:title": "MultiVENT",
        "dcterms:issued": "",
        "dcterms:language": "Arabic, Chinese, English, Korean, Russian",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Information Retrieval",
            "Multilingual Video Analysis"
        ],
        "dcat:keyword": [
            "Multilingual videos",
            "Event-centric content",
            "Natural language descriptions",
            "Video retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Video Retrieval",
            "Information Acquisition"
        ]
    },
    {
        "dcterms:creator": [
            "David Chen",
            "William B Dolan"
        ],
        "dcterms:description": "The Microsoft Research Video Description Corpus is a dataset used for evaluating paraphrase generation and understanding in video descriptions.",
        "dcterms:title": "Microsoft Research Video Description Corpus",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Description",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Video description",
            "Paraphrase evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Paraphrase Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Jun Xu",
            "Tao Mei",
            "Ting Yao",
            "Yong Rui"
        ],
        "dcterms:description": "MSR-VTT is a large video description dataset that bridges video and language, providing a rich resource for video understanding and retrieval tasks.",
        "dcterms:title": "MSR-VTT",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Understanding",
            "Language Processing"
        ],
        "dcat:keyword": [
            "Video description",
            "Video-language bridging"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Video Retrieval",
            "Video Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Lisa Anne Hendricks",
            "Oliver Wang",
            "Eli Shechtman",
            "Josef Sivic",
            "Trevor Darrell",
            "Bryan Russell"
        ],
        "dcterms:description": "DiDeMo is a dataset designed for localizing moments in video using natural language, facilitating research in video understanding and temporal localization.",
        "dcterms:title": "DiDeMo",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Localization",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Moment localization",
            "Video understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Moment Localization"
        ]
    },
    {
        "dcterms:creator": [
            "Antoine Miech",
            "Dimitri Zhukov",
            "Jean-Baptiste Alayrac",
            "Makarand Tapaswi",
            "Ivan Laptev",
            "Josef Sivic"
        ],
        "dcterms:description": "HowTo100M is a dataset consisting of over 130 million narrated instructional video clips, aimed at learning text-video embeddings.",
        "dcterms:title": "HowTo100M",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Instructional Videos",
            "Text-Video Learning"
        ],
        "dcat:keyword": [
            "Instructional videos",
            "Text-video embedding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Text-Video Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Xin Wang",
            "Jiawei Wu",
            "Junkun Chen",
            "Lei Li",
            "Yuan-Fang Wang",
            "William Yang Wang"
        ],
        "dcterms:description": "VaTeX is a large-scale, high-quality multilingual dataset for video-and-language research, facilitating cross-lingual video retrieval tasks.",
        "dcterms:title": "VaTeX",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multilingual Video Retrieval",
            "Video-Language Research"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Video-language research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Video Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Rishabh Dabral",
            "Ganesh Ramakrishnan",
            "Preethi Jyothi"
        ],
        "dcterms:description": "Rudder is a cross-lingual video and text retrieval dataset designed to facilitate research in multilingual video understanding.",
        "dcterms:title": "Rudder",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2103.05457",
        "dcat:theme": [
            "Cross-lingual Retrieval",
            "Video Understanding"
        ],
        "dcat:keyword": [
            "Cross-lingual retrieval",
            "Video-text retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Cross-lingual Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Jie Lei",
            "Tamara L Berg",
            "Mohit Bansal"
        ],
        "dcterms:description": "MTVR is a multilingual moment retrieval dataset in videos, extending the capabilities of video retrieval systems to handle multiple languages.",
        "dcterms:title": "MTVR",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2108.00061",
        "dcat:theme": [
            "Multilingual Video Retrieval",
            "Moment Retrieval"
        ],
        "dcat:keyword": [
            "Moment retrieval",
            "Multilingual dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Moment Retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Po-Yao Huang",
            "Mandela Patrick",
            "Junjie Hu",
            "Graham Neubig",
            "Florian Metze",
            "Alexander Hauptmann"
        ],
        "dcterms:description": "Multi-HowTo100M is an extension of HowTo100M, scraping YouTube for subtitles in multiple languages to enhance multilingual video understanding.",
        "dcterms:title": "Multi-HowTo100M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2103.08849",
        "dcat:theme": [
            "Multilingual Instructional Videos",
            "Video Understanding"
        ],
        "dcat:keyword": [
            "Multilingual dataset",
            "Instructional videos"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Multilingual Video Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Aozhu Chen",
            "Ziyuan Wang",
            "Chengbo Dong",
            "Kaibin Tian",
            "Ruixiang Zhao",
            "Xun Liang",
            "Zhanhui Kang",
            "Xirong Li"
        ],
        "dcterms:description": "ChinaOpen is a dataset for open-world multimodal learning, containing a wide range of video-caption pairs originally produced in Chinese.",
        "dcterms:title": "ChinaOpen",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.05880",
        "dcat:theme": [
            "Open-world Learning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Chinese dataset",
            "Video-caption pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Text",
        "mls:task": [
            "Multimodal Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Jennifer Tracey",
            "Ann Bies",
            "Jeremy Getman",
            "Kira Griffitt",
            "Stephanie Strassel"
        ],
        "dcterms:description": "AIDA is a dataset focusing on informational conflict in Russia-Ukraine relations, providing data and annotations for studying contradictions in information.",
        "dcterms:title": "AIDA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Information Conflict",
            "Data Annotation"
        ],
        "dcat:keyword": [
            "Informational conflict",
            "Data annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Data Annotation"
        ]
    }
]