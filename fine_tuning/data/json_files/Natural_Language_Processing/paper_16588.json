[
    {
        "dcterms:creator": [
            "T. Hartvigsen",
            "S. Gabriel",
            "H. Palangi",
            "M. Sap",
            "D. Ray",
            "E. Kamar"
        ],
        "dcterms:description": "AdvPromptSet is a comprehensive and challenging adversarial text prompt set with 197,628 prompts of varying toxicity levels and more than 24 sensitive demographic identity groups and combinations.",
        "dcterms:title": "AdvPromptSet",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Toxicity Evaluation"
        ],
        "dcat:keyword": [
            "Adversarial prompts",
            "Toxicity",
            "Bias",
            "Demographic identities"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/ResponsibleNLP/tree/main/AdvPromptSet",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Measurement",
            "Toxicity Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "J. Dhamala",
            "V. Kumar",
            "R. Gupta",
            "K.-W. Chang",
            "A. Galstyan"
        ],
        "dcterms:description": "BOLD is a dataset and metrics for measuring biases in open-ended language generation, extracted from Wikipedia articles across five demographic axes.",
        "dcterms:title": "BOLD",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Bias measurement",
            "Open-ended generation",
            "Demographic axes"
        ],
        "dcat:landingPage": "https://dl.acm.org/doi/10.1145/3442188.3445920",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "E. M. Smith",
            "M. Hall",
            "M. Kambadur",
            "E. Presani",
            "A. Williams"
        ],
        "dcterms:description": "HolisticBiasR is an extension of the Regard dataset that replaces demographic noun phrases in the original prompts with those from the HolisticBias dataset.",
        "dcterms:title": "HolisticBiasR",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Bias measurement",
            "Demographic descriptors",
            "Language generation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.emnlp-main.746/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "S. Gehman",
            "S. Gururangan",
            "M. Sap",
            "Y. Choi",
            "N. A. Smith"
        ],
        "dcterms:description": "RealToxicityPrompts is a dataset designed to evaluate neural toxic degeneration in language models, consisting of prompts that elicit toxic responses.",
        "dcterms:title": "RealToxicityPrompts",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Evaluation",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Toxicity",
            "Language models",
            "Evaluation"
        ],
        "dcat:landingPage": "https://aclanthology.org/2020.findings-emnlp.303/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "E. Sheng",
            "K.-W. Chang",
            "P. Natarajan",
            "N. Peng"
        ],
        "dcterms:description": "Regard is a dataset of templates to measure the modelâ€™s regard (i.e., respect, esteem) for different demographic groups.",
        "dcterms:title": "Regard",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Bias measurement",
            "Demographic groups",
            "Language generation"
        ],
        "dcat:landingPage": "https://aclanthology.org/D19-1340/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "T. Hartvigsen",
            "S. Gabriel",
            "H. Palangi",
            "M. Sap",
            "D. Ray",
            "E. Kamar"
        ],
        "dcterms:description": "ToxiGen (v2) is a large-scale machine-generated dataset for adversarial and implicit hate speech detection.",
        "dcterms:title": "ToxiGen (v2)",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Hate Speech Detection",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Hate speech",
            "Adversarial generation",
            "Implicit bias"
        ],
        "dcat:landingPage": "https://aclanthology.org/2022.acl-long.3309/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Hate Speech Detection"
        ]
    }
]