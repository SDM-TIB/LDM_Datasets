[
    {
        "dcterms:creator": [],
        "dcterms:description": "A new benchmark for evaluating the factual consistency of large language models through summarization, comparing scores assigned to factually consistent versus inconsistent summaries.",
        "dcterms:title": "FIB (Factual Inconsistency Benchmark)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "factual consistency",
            "language models",
            "summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "factual consistency evaluation",
            "summarization"
        ]
    },
    {
        "dcterms:creator": [
            "S. Narayan",
            "S. B. Cohen",
            "M. Lapata"
        ],
        "dcterms:description": "A dataset for extreme summarization that consists of documents and their corresponding single-sentence summaries.",
        "dcterms:title": "XSum",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "https://huggingface.co/datasets/xsum",
        "dcat:theme": [
            "Text Summarization"
        ],
        "dcat:keyword": [
            "extreme summarization",
            "single-sentence summaries",
            "news articles"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/xsum",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "summarization"
        ]
    },
    {
        "dcterms:creator": [
            "K. M. Hermann",
            "T. Kocisky",
            "E. Grefenstette",
            "L. Espeholt",
            "W. Kay",
            "M. Suleyman",
            "P. Blunsom"
        ],
        "dcterms:description": "A dataset consisting of news articles and their corresponding multi-sentence summaries, used for teaching machines to read and comprehend.",
        "dcterms:title": "CNN/DM (CNN/Daily Mail)",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "https://huggingface.co/datasets/cnn_dailymail",
        "dcat:theme": [
            "Text Summarization"
        ],
        "dcat:keyword": [
            "news articles",
            "multi-sentence summaries",
            "reading comprehension"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/cnn_dailymail",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "summarization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Pagnoni",
            "V. Balachandran",
            "Y. Tsvetkov"
        ],
        "dcterms:description": "A benchmark for evaluating factuality metrics in abstractive summarization, containing model-generated summaries with factuality labels.",
        "dcterms:title": "FRANK",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Factuality Evaluation"
        ],
        "dcat:keyword": [
            "factuality metrics",
            "abstractive summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "factuality evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Gabriel",
            "A. Celikyilmaz",
            "R. Jha",
            "Y. Choi",
            "J. Gao"
        ],
        "dcterms:description": "A meta-evaluation framework for factuality in summarization, containing model-generated summaries with factuality labels.",
        "dcterms:title": "GO FIGURE",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Factuality Evaluation"
        ],
        "dcat:keyword": [
            "meta-evaluation",
            "factuality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "factuality evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "L. Ribeiro",
            "M. Liu",
            "I. Gurevych",
            "M. Dreyer",
            "M. Bansal"
        ],
        "dcterms:description": "A dataset that combines labeled summaries from multiple works to evaluate factuality in summarization.",
        "dcterms:title": "FactCollect",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Factuality Evaluation"
        ],
        "dcat:keyword": [
            "factuality labels",
            "summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "factuality evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Thorne",
            "A. Vlachos",
            "C. Christodoulopoulos",
            "A. Mittal"
        ],
        "dcterms:description": "A large-scale dataset for fact extraction and verification, designed to evaluate the factual accuracy of claims.",
        "dcterms:title": "FEVER",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Fact Verification"
        ],
        "dcat:keyword": [
            "fact extraction",
            "verification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "fact verification"
        ]
    }
]