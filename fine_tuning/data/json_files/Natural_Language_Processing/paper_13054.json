[
    {
        "dcterms:creator": [
            "T. Afouras",
            "J. S. Chung",
            "A. Senior",
            "O. Vinyals",
            "A. Zisserman"
        ],
        "dcterms:description": "The LRS2 dataset consists of thousands of BBC video clips, created by randomly selecting two different speakers and mixing their speeches with signal-to-noise ratios between -5 dB and 5 dB. It contains reverberation and noise, making it closer to real-world scenarios.",
        "dcterms:title": "LRS2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Speech Separation"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "Video clips",
            "Audio-visual integration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "T. Afouras",
            "J. S. Chung",
            "A. Zisserman"
        ],
        "dcterms:description": "The LRS3 dataset includes thousands of spoken sentences from TED and TEDx videos, constructed by randomly selecting voices of two different speakers. It has relatively less noise compared to LRS2.",
        "dcterms:title": "LRS3",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Speech Separation"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "TED videos",
            "Audio-visual integration"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "J. S. Chung",
            "A. Nagrani",
            "A. Zisserman"
        ],
        "dcterms:description": "The VoxCeleb2 dataset contains over one million sentences from 6,112 individuals extracted from YouTube videos. It presents a complex acoustic environment and is used for speaker recognition.",
        "dcterms:title": "VoxCeleb2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Recognition"
        ],
        "dcat:keyword": [
            "Speech dataset",
            "YouTube videos",
            "Speaker recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Recognition"
        ]
    }
]