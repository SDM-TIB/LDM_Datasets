[
    {
        "dcterms:creator": [
            "Zhirong Wu",
            "Shuran Song",
            "Aditya Khosla",
            "Fisher Yu",
            "Linguang Zhang",
            "Xiaoou Tang",
            "Jianxiong Xiao"
        ],
        "dcterms:description": "A widely used benchmark in the field of 3D object recognition, consisting of 12,311 CAD models from 40 categories, with 9,843 training samples and 2,468 testing samples.",
        "dcterms:title": "ModelNet40 (MN40)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Object Recognition"
        ],
        "dcat:keyword": [
            "3D models",
            "CAD",
            "object recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "3D shape classification"
        ]
    },
    {
        "dcterms:creator": [
            "Matt Deitke",
            "Dustin Schwenk",
            "Jordi Salvador",
            "Luca Weihs",
            "Oscar Michel",
            "Eli VanderBilt",
            "Ludwig Schmidt",
            "Kiana Ehsani",
            "Aniruddha Kembhavi",
            "Ali Farhadi"
        ],
        "dcterms:description": "An annotated subset of Objaverse consisting of 46,832 shapes from 1,156 categories, designed to reflect the model's performance in open-world scenarios.",
        "dcterms:title": "Objaverse-LVIS (O-LVIS)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Object Recognition"
        ],
        "dcat:keyword": [
            "3D shapes",
            "object categories",
            "open-world scenarios"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "3D shape classification"
        ]
    },
    {
        "dcterms:creator": [
            "Mikaela Angelina Uy",
            "Quang-Hieu Pham",
            "Binh-Son Hua",
            "Thanh Nguyen",
            "Sai-Kit Yeung"
        ],
        "dcterms:description": "A significant resource in the domain of 3D object recognition and segmentation, containing 2,902 objects distributed across 15 categories.",
        "dcterms:title": "ScanObjectNN (SONN)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "3D Object Recognition"
        ],
        "dcat:keyword": [
            "3D objects",
            "segmentation",
            "recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "3D Model",
        "mls:task": [
            "3D shape classification"
        ]
    },
    {
        "dcterms:creator": [
            "Shuran Song",
            "Samuel P Lichtenberg",
            "Jianxiong Xiao"
        ],
        "dcterms:description": "A benchmark suite for RGB-D scene understanding, providing paired RGB and depth maps along with associated class labels.",
        "dcterms:title": "SUN Depth-only (SUN-D)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "RGB-D",
            "scene understanding",
            "depth maps"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Depth Map",
        "mls:task": [
            "Scene classification"
        ]
    },
    {
        "dcterms:creator": [
            "Pushmeet Kohli",
            "Nathan Silberman",
            "Derek Hoiem",
            "Rob Fergus"
        ],
        "dcterms:description": "A dataset containing depth maps from indoor scenes, used for segmentation and support inference tasks.",
        "dcterms:title": "NYU-v2 Depth-only (NYU-D)",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Depth Estimation"
        ],
        "dcat:keyword": [
            "depth maps",
            "indoor scenes",
            "segmentation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Depth Map",
        "mls:task": [
            "Scene classification"
        ]
    },
    {
        "dcterms:creator": [
            "Jort F. Gemmeke",
            "Daniel P. W. Ellis",
            "Dylan Freedman",
            "Aren Jansen",
            "Wade Lawrence",
            "R. Channing Moore",
            "Manoj Plakal",
            "Marvin Ritter"
        ],
        "dcterms:description": "An ontology and human-labeled dataset for audio events, containing 10-second videos sourced from YouTube.",
        "dcterms:title": "Audioset (AS-A)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Classification"
        ],
        "dcat:keyword": [
            "audio events",
            "YouTube videos",
            "ontology"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio classification"
        ]
    },
    {
        "dcterms:creator": [
            "Karol J. Piczak"
        ],
        "dcterms:description": "A dataset for environmental sound classification, comprising a collection of 2,000 sound recordings organized into 50 classes.",
        "dcterms:title": "ESC 5-folds (ESC)",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Classification"
        ],
        "dcat:keyword": [
            "environmental sounds",
            "sound classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Audio classification"
        ]
    },
    {
        "dcterms:creator": [
            "Konstantinos Drossos",
            "Samuel Lipping",
            "Tuomas Virtanen"
        ],
        "dcterms:description": "An audio captioning dataset comprising a development set of 2,893 audio clips and a test set of 1,045 audio clips, each associated with five descriptions.",
        "dcterms:title": "Clotho",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Captioning"
        ],
        "dcat:keyword": [
            "audio clips",
            "text descriptions",
            "captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-audio retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Chris Dongjoo Kim",
            "Byeongchang Kim",
            "Hyunmin Lee",
            "Gunhee Kim"
        ],
        "dcterms:description": "A dataset comprising audio-visual clips sourced from YouTube, accompanied by textual descriptions for text-to-audio retrieval tasks.",
        "dcterms:title": "AudioCaps (ACaps)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio Captioning"
        ],
        "dcat:keyword": [
            "audio-visual clips",
            "text descriptions",
            "retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-audio retrieval"
        ]
    },
    {
        "dcterms:creator": [
            "Honglie Chen",
            "Weidi Xie",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A large-scale audio-visual dataset containing around 200k video clips of 10 seconds long, annotated into 309 classes.",
        "dcterms:title": "VGGSound (VGGS)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Classification"
        ],
        "dcat:keyword": [
            "audio-visual dataset",
            "video clips",
            "classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Audio classification"
        ]
    },
    {
        "dcterms:creator": [
            "Fengyu Yang",
            "Chenyang Ma",
            "Jiacheng Zhang",
            "Jing Zhu",
            "Wenzhen Yuan",
            "Andrew Owens"
        ],
        "dcterms:description": "A dataset comprising real-world visual and tactile data gathered by human data collectors probing objects in natural settings using tactile sensors while simultaneously recording egocentric video.",
        "dcterms:title": "Touch-and-go (TAG)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Tactile Data Collection"
        ],
        "dcat:keyword": [
            "visual data",
            "tactile data",
            "human data collectors"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Visual and Tactile Data",
        "mls:task": [
            "Material classification"
        ]
    },
    {
        "dcterms:creator": [
            "Concetto Spampinato",
            "Simone Palazzo",
            "Isaak Kavasidis",
            "Daniela Giordano",
            "Nasim Souly",
            "Mubarak Shah"
        ],
        "dcterms:description": "A dataset comprising EEG recordings obtained from six subjects while they were presented with 2,000 images across 40 categories from the ImageNet dataset.",
        "dcterms:title": "ImageNet-EEG (IN-EEG)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "EEG Data Collection"
        ],
        "dcat:keyword": [
            "EEG recordings",
            "ImageNet categories",
            "visual classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "EEG Data",
        "mls:task": [
            "Visual classification"
        ]
    }
]