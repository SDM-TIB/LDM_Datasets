[
    {
        "dcterms:creator": [
            "Yuhe Liu",
            "Changhua Pei",
            "Longlong Xu",
            "Bohan Chen",
            "Mingze Sun",
            "Zhirui Zhang",
            "Yongqian Sun",
            "Shenglin Zhang",
            "Kun Wang",
            "Haiming Zhang",
            "Jianhui Li",
            "Gaogang Xie",
            "Xidao Wen",
            "Xiaohui Nie",
            "Minghua Ma",
            "Dan Pei"
        ],
        "dcterms:description": "OpsEval is a comprehensive benchmark suite for evaluating large language models' capability in the IT operations domain, containing 7,184 multiple-choice questions and 1,736 QA questions, designed to assist researchers in preliminary evaluations of their LLMs tailored for Ops.",
        "dcterms:title": "OpsEval",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/NetManAIOps/OpsEval-Datasets",
        "dcat:theme": [
            "IT Operations",
            "Benchmarking",
            "Large Language Models"
        ],
        "dcat:keyword": [
            "IT Operations",
            "Benchmark",
            "Large Language Models",
            "Evaluation",
            "Question Answering"
        ],
        "dcat:landingPage": "https://github.com/NetManAIOps/OpsEval-Datasets",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yuzhen Huang",
            "Yuzhuo Bai",
            "Zhihao Zhu",
            "Junlei Zhang",
            "Jinghan Zhang",
            "Tangjun Su",
            "Junteng Liu",
            "Chuancheng Lv",
            "Yikai Zhang",
            "Jiayi Lei"
        ],
        "dcterms:description": "C-Eval is a multi-level multi-discipline Chinese evaluation suite for foundation models, designed to rigorously assess Chinese LLMs' advanced knowledge and reasoning abilities.",
        "dcterms:title": "C-Eval",
        "dcterms:issued": "2023",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2305",
        "dcat:theme": [
            "Chinese Language Processing",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Chinese Evaluation",
            "Foundation Models",
            "Knowledge Assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "MMLU is a benchmark designed to measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings, covering 57 subjects across STEM.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multitask Learning",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask Learning",
            "Benchmark",
            "STEM Subjects"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Liwen Zhang",
            "Weige Cai",
            "Zhaowei Liu",
            "Zhi Yang",
            "Wei Dai",
            "Yujie Liao",
            "Qianru Qin",
            "Yifei Li",
            "Xingyu Liu",
            "Zhiqiang Liu"
        ],
        "dcterms:description": "FinEval is a Chinese financial domain knowledge evaluation benchmark for large language models, aimed at assessing their capabilities in the financial sector.",
        "dcterms:title": "FinEval",
        "dcterms:issued": "2023",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2308",
        "dcat:theme": [
            "Financial Domain",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Financial Evaluation",
            "Chinese Language",
            "Large Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Xidong Wang",
            "Guiming Hardy Chen",
            "Dingjie Song",
            "Zhiyi Zhang",
            "Zhihong Chen",
            "Qingying Xiao",
            "Feng Jiang",
            "Jianquan Li",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "dcterms:description": "CMB is a comprehensive medical benchmark in Chinese, including multi-choice questions and complex clinical questions based on real case studies.",
        "dcterms:title": "CMB",
        "dcterms:issued": "2023",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2308",
        "dcat:theme": [
            "Medical Domain",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Medical Evaluation",
            "Chinese Language",
            "Clinical Knowledge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Yukai Miao",
            "Yu Bai",
            "Li Chen",
            "Dan Li",
            "Haifeng Sun",
            "Xizheng Wang",
            "Ziqiu Luo",
            "Dapeng Sun",
            "Xiuting Xu",
            "Qi Zhang",
            "Chao Xiang",
            "Xinchi Li"
        ],
        "dcterms:description": "NetOps is an empirical study of the NetOps capability of pre-trained large language models, focusing on evaluations in the network field.",
        "dcterms:title": "NetOps",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "abs/2309.05557",
        "dcat:theme": [
            "Network Operations",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Network Operations",
            "Evaluation",
            "Large Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation"
        ]
    }
]