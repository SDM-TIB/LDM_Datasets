[
    {
        "dcterms:creator": [
            "S. Kim",
            "J. Suk",
            "S. Longpre",
            "B. Y. Lin",
            "J. Shin",
            "S. Welleck",
            "G. Neubig",
            "M. Lee",
            "K. Lee",
            "M. Seo"
        ],
        "dcterms:description": "A dataset designed to evaluate context-specific preferences, consisting of paired tuples of prompts, contexts, and preference judgments, where preference can reverse based on context.",
        "dcterms:title": "RPR Criteria",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Preference Modeling",
            "Contextual Evaluation"
        ],
        "dcat:keyword": [
            "Preference Reversal",
            "Context-Aware",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Kim",
            "J. Suk",
            "S. Longpre",
            "B. Y. Lin",
            "J. Shin",
            "S. Welleck",
            "G. Neubig",
            "M. Lee",
            "K. Lee",
            "M. Seo"
        ],
        "dcterms:description": "A dataset that provides context-specific scenarios for evaluating preferences, structured similarly to the RPR Criteria dataset.",
        "dcterms:title": "RPR Scenarios",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Preference Modeling",
            "Contextual Evaluation"
        ],
        "dcat:keyword": [
            "Preference Reversal",
            "Context-Aware",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Kim",
            "J. Suk",
            "S. Longpre",
            "B. Y. Lin",
            "J. Shin",
            "S. Welleck",
            "G. Neubig",
            "M. Lee",
            "K. Lee",
            "M. Seo"
        ],
        "dcterms:description": "A benchmark dataset for evaluating preferences in language models, consisting of context-conditioned preference samples.",
        "dcterms:title": "Preference Bench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Preference Modeling",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "Preference Evaluation",
            "Context-Aware",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Lee",
            "S. H. Park",
            "S. Kim",
            "M. Seo"
        ],
        "dcterms:description": "A dataset that aligns language models to thousands of preferences via system message generalization, providing a multifaceted evaluation framework.",
        "dcterms:title": "Multifaceted Bench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Preference Modeling",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "System Message",
            "Preference Alignment",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Askell",
            "Y. Bai",
            "A. Chen",
            "D. Drain",
            "D. Ganguli",
            "T. Henighan",
            "A. Jones",
            "N. Joseph",
            "B. Mann",
            "N. DasSarma"
        ],
        "dcterms:description": "A dataset containing human preference samples emphasizing different aspects such as harmlessness, helpfulness, and honesty.",
        "dcterms:title": "HHH",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Preference Modeling",
            "Human Feedback"
        ],
        "dcat:keyword": [
            "Human Preferences",
            "Alignment",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Lambert",
            "V. Pyatkin",
            "J. Morrison",
            "L. Miranda",
            "B. Y. Lin",
            "K. Chandu",
            "N. Dziri",
            "S. Kumar",
            "T. Zick",
            "Y. Choi"
        ],
        "dcterms:description": "A curated dataset for evaluating reward models in language modeling, containing diverse preference samples.",
        "dcterms:title": "Reward Bench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reward Modeling",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "Reward Models",
            "Language Models",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reward Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "W.-L. Chiang",
            "Y. Sheng",
            "S. Zhuang",
            "Z. Wu",
            "Y. Zhuang",
            "Z. Lin",
            "Z. Li",
            "D. Li",
            "E. Xing"
        ],
        "dcterms:description": "A dataset containing human preferences regarding conversations on the Chatbot Arena platform, used for evaluating conversational models.",
        "dcterms:title": "Chatbot Arena",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Conversational AI",
            "Preference Evaluation"
        ],
        "dcat:keyword": [
            "Chatbot Evaluation",
            "Human Preferences",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Preference Evaluation"
        ]
    }
]