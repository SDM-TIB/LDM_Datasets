[
    {
        "dcterms:creator": [
            "Yinhan Liu",
            "Jiatao Gu",
            "Naman Goyal",
            "Xian Li",
            "Sergey Edunov",
            "Marjan Ghazvininejad",
            "Mike Lewis",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "The ML50 benchmark is a dataset covering low, mid, and high resource languages, designed to facilitate reproducible research by standardizing training and evaluation data.",
        "dcterms:title": "ML50 Benchmark",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Multilingual NLP"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Multilingual",
            "Machine Translation",
            "Evaluation Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Yinhan Liu",
            "Myle Ott",
            "Naman Goyal",
            "Jingfei Du",
            "Mandar Joshi",
            "Danqi Chen",
            "Omer Levy",
            "Mike Lewis",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "mBART is a sequence-to-sequence generative pretraining scheme that incorporates multiple languages by concatenating monolingual documents.",
        "dcterms:title": "mBART",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Translation"
        ],
        "dcat:keyword": [
            "Pretraining",
            "Multilingual",
            "Sequence-to-Sequence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Machine Translation",
            "Text Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Guillaume Lample",
            "Alexis Conneau"
        ],
        "dcterms:description": "Commoncrawl is a version of the web used for training language models, providing a large corpus of multilingual text.",
        "dcterms:title": "Commoncrawl",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Web Data",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Web Corpus",
            "Multilingual Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Wikipedia is commonly used as a source for monolingual data in various languages.",
        "dcterms:title": "Wikipedia",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Monolingual Data",
            "Text Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "WMT is cited multiple times in the context of training data for machine translation.",
        "dcterms:title": "WMT (Workshop on Machine Translation)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Translation",
            "Evaluation Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "IWSLT is cited multiple times in the context of training data for machine translation.",
        "dcterms:title": "IWSLT (International Workshop on Spoken Language Translation)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Translation",
            "Spoken Language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "TED Talks are cited multiple times in the context of training data for machine translation.",
        "dcterms:title": "TED Talks",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Translation",
            "Spoken Language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Flores is cited multiple times in the context of training data for machine translation.",
        "dcterms:title": "Flores",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Translation",
            "Evaluation Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "OPUS100 is cited in comparison to ML50 but not listed in the references.",
        "dcterms:title": "OPUS100",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Translation",
            "Parallel Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Alexis Conneau",
            "Kartikay Khandelwal",
            "Naman Goyal",
            "Vishrav Chaudhary",
            "Guillaume Wenzek",
            "Francisco Guzm√°n",
            "Edouard Grave",
            "Myle Ott",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "XLMR is an unsupervised cross-lingual representation learning model that operates at scale.",
        "dcterms:title": "XLMR (Cross-lingual Language Model)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Cross-lingual Learning"
        ],
        "dcat:keyword": [
            "Cross-lingual",
            "Representation Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]