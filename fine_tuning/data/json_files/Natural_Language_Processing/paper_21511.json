[
    {
        "dcterms:creator": [
            "Will Kay",
            "Jo√£o Carreira",
            "Karen Simonyan",
            "Brian Zhang",
            "Chloe Hillier",
            "Sudheendra Vijayanarasimhan",
            "Fabio Viola",
            "Tim Green",
            "Trevor Back",
            "Paul Natsev",
            "Mustafa Suleyman",
            "Andrew Zisserman"
        ],
        "dcterms:description": "The Kinetics-400 dataset is used for video action recognition, specifically for visualizing outcomes of Grad-CAM and formulating the Video-TCAV framework.",
        "dcterms:title": "Kinetics-400 dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Action Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Action recognition",
            "Human actions",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Chien-Yao Wang",
            "Alexey Bochkovskiy",
            "Hong-Yuan Mark Liao"
        ],
        "dcterms:description": "YOLO-v7 is utilized for object detection in videos, generating spatial and spatiotemporal concepts for testing in the Video-TCAV framework.",
        "dcterms:title": "YOLO-v7",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Object detection",
            "Real-time detection",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Detection"
        ]
    }
]