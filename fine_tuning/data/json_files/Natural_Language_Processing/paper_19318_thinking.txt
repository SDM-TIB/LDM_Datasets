To extract datasets from the research paper titled "Question Calibration and Multi-Hop Modeling for Temporal Question Answering" by Chao Xue et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and datasets sections** of the paper. The abstract mentions that the proposed model achieves better performance on benchmark datasets, indicating that datasets are involved. 

Next, I will focus on the **Datasets and Baselines section** where the authors explicitly list the datasets used for evaluation. Here, they mention two datasets:

1. **CRONQUESTIONS**: This dataset is described as the largest known dataset for temporal knowledge graph question answering, containing 125K entities, 1.7K timestamps, 203 relations, and 328K facts. It also includes 410K unique question-answer pairs, categorized by question type and reasoning complexity.

2. **Time-Questions**: This dataset consists of 16K manually tagged temporal questions, divided into four categories based on the type of time reasoning.

Now, I will look at the **References section** to find the full citations for these datasets:

- For **CRONQUESTIONS**, the citation is:
  > Saxena, A., Chakrabarti, S., & Talukdar, P. (2021). Question Answering Over Temporal Knowledge Graphs. In Proceedings of the Annual Meeting of the ACL and IJCNLP, 6663–6676.

- For **Time-Questions**, the citation is:
  > Jia, Z., Pramanik, S., Saha Roy, R., & Weikum, G. (2021). Complex temporal question answering on knowledge graphs. In Proceedings of the 30th ACM International Conference on Information and Knowledge Management, 792–802.

After gathering this information, I will compile the dataset entries, ensuring that each entry includes the dataset name, description, and full citation. This structured approach will help ensure that I accurately represent the datasets used in the research paper.