[
    {
        "dcterms:creator": [
            "Triantafyllos Afouras",
            "Joon Son Chung",
            "Andrew Zisserman"
        ],
        "dcterms:description": "LRS3 dataset collects 433 hours of transcribed English videos in TED and TEDx talks from over 5000 speakers, which is the largest publicly available labeled audio-visual speech recognition dataset.",
        "dcterms:title": "LRS3",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1809.00496",
        "dcat:theme": [
            "Audio-Visual Speech Recognition",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Audio-Visual",
            "Speech Recognition",
            "Dataset",
            "Transcribed Videos"
        ],
        "dcat:landingPage": "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs3.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Joon Son Chung",
            "Andrew Senior",
            "Oriol Vinyals",
            "Andrew Zisserman"
        ],
        "dcterms:description": "LRS2 dataset contains 224 hours of video speech, with a total of 144K clips from BBC programs.",
        "dcterms:title": "LRS2",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Audio-Visual Speech Recognition",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Audio-Visual",
            "Speech Recognition",
            "Dataset",
            "BBC Programs"
        ],
        "dcat:landingPage": "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Recognition"
        ]
    }
]