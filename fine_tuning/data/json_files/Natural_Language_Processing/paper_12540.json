[
    {
        "dcterms:creator": [
            "Greg Brockman",
            "Vicki Cheung",
            "Ludwig Pettersson",
            "Jonas Schneider",
            "John Schulman",
            "Jie Tang",
            "Wojciech Zaremba"
        ],
        "dcterms:description": "A standard benchmark problem for reinforcement learning where the goal is to balance a pendulum upright.",
        "dcterms:title": "OpenAI Gym Pendulum",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Pendulum",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "David Ha"
        ],
        "dcterms:description": "A problem where the goal is to swing up a cartpole from a downward position to an upright position.",
        "dcterms:title": "Cartpole Swing-Up Problem",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Cartpole",
            "Swing-Up",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Emanuel Todorov",
            "Tom Erez",
            "Yuval Tassa"
        ],
        "dcterms:description": "A physics engine for model-based control, widely used in robotics and reinforcement learning.",
        "dcterms:title": "MuJoCo",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Physics Simulation",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Physics Engine",
            "Robotics",
            "Model-Based Control"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Yuval Tassa",
            "Yotam Doron",
            "Alistair Muldal",
            "Tom Erez",
            "Yazhe Li",
            "Diego de Las Casas",
            "David Budden",
            "Abbas Abdolmaleki",
            "Josh Merel",
            "Andrew Lefrancq",
            "Timothy Lillicrap",
            "Martin Riedmiller"
        ],
        "dcterms:description": "A suite of continuous control tasks for reinforcement learning research.",
        "dcterms:title": "DeepMind Control Suite",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1801.00690",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Control Suite",
            "Reinforcement Learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Scott Fujimoto",
            "Herke van Hoof",
            "David Meger"
        ],
        "dcterms:description": "An algorithm that addresses function approximation error in actor-critic methods.",
        "dcterms:title": "TD3 Algorithm",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1802.09477",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Systems"
        ],
        "dcat:keyword": [
            "Actor-Critic",
            "Reinforcement Learning",
            "Function Approximation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Mikel Landajuela",
            "Brenden K Petersen",
            "Sookyung Kim",
            "Claudio P Santiago",
            "Ruben Glatt",
            "Nathan Mundhenk",
            "Jacob F Pettit",
            "Daniel Faisol"
        ],
        "dcterms:description": "Datasets used for discovering symbolic policies with deep reinforcement learning.",
        "dcterms:title": "Symbolic Regression Datasets",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Symbolic Regression",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Symbolic Policies",
            "Deep Learning",
            "Reinforcement Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Control"
        ]
    },
    {
        "dcterms:creator": [
            "Christian Kuehn",
            "Elena Queirolo"
        ],
        "dcterms:description": "A study on the computer validation of neural network dynamics.",
        "dcterms:title": "Computer-Assisted Proofs (CAPs)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Science",
            "Neural Networks"
        ],
        "dcat:keyword": [
            "Computer Validation",
            "Neural Networks",
            "Dynamic Systems"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]