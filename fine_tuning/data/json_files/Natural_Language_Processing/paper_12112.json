[
    {
        "dcterms:creator": [
            "Kristen Grauman",
            "Andrew Westbury",
            "Eugene Byrne",
            "Zachary Chavis",
            "Antonino Furnari",
            "Rohit Girdhar",
            "Jackson Hamburger",
            "Hao Jiang",
            "Miao Liu",
            "Xingyu Liu"
        ],
        "dcterms:description": "Ego4d is a large-scale dataset comprising 3,000 hours of egocentric video collected from diverse scenarios and participants, aimed at advancing research in egocentric action recognition.",
        "dcterms:title": "Ego4d",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Egocentric Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric video",
            "Action recognition",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Dima Damen",
            "Hazel Doughty",
            "Giovanni Maria Farinella",
            "Antonino Furnari",
            "Jian Ma",
            "Evangelos Kazakos",
            "Davide Moltisanti",
            "Jonathan Munro",
            "Toby Perrett",
            "Will Price",
            "Michael Wray"
        ],
        "dcterms:description": "EPIC-KITCHENS-100 is a dataset containing 100 hours of egocentric video focused on kitchen activities, designed to facilitate research in action recognition.",
        "dcterms:title": "EPIC-KITCHENS-100",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Egocentric Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric video",
            "Kitchen activities",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Will Kay",
            "João Carreira",
            "Karen Simonyan",
            "Brian Zhang",
            "Chloe Hillier",
            "Sudheendra Vijayanarasimhan",
            "Fabio Viola",
            "Tim Green",
            "Trevor Back",
            "Paul Natsev",
            "Mustafa Suleyman",
            "Andrew Zisserman"
        ],
        "dcterms:description": "Kinetics-400 is a large-scale dataset for human action recognition in videos, containing 400 action classes and over 300,000 video clips.",
        "dcterms:title": "Kinetics-400",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Human action",
            "Video dataset",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Jianren Wang",
            "Xin Wang",
            "Yue Shang-Guan",
            "Abhinav Gupta"
        ],
        "dcterms:description": "Wanderlust is a dataset for online continual object detection, featuring video collected over nine months of a graduate student's life.",
        "dcterms:title": "Wanderlust",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Object detection",
            "Egocentric video",
            "Continual learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Bart Thomee",
            "David A. Shamma",
            "Gerald Friedland",
            "Benjamin Elizalde",
            "Karl Ni",
            "Douglas Poland",
            "Damian Borth",
            "Li-Jia Li"
        ],
        "dcterms:description": "YFCC100M is a dataset containing 100 million media objects, including images and videos, aimed at multimedia research.",
        "dcterms:title": "YFCC100M",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimedia",
            "Image and Video Analysis"
        ],
        "dcat:keyword": [
            "Multimedia dataset",
            "Image and video",
            "Research"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image/Video",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Vincenzo Lomonaco",
            "Davide Maltoni"
        ],
        "dcterms:description": "Core50 is a dataset and benchmark for continuous object recognition, designed to evaluate algorithms in a continual learning setting.",
        "dcterms:title": "Core50",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Recognition"
        ],
        "dcat:keyword": [
            "Object recognition",
            "Continual learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "David Lopez-Paz",
            "Marc’Aurelio Ranzato"
        ],
        "dcterms:description": "Rotated-MNIST is a dataset used for continual learning, featuring the MNIST dataset with rotated images to evaluate learning algorithms.",
        "dcterms:title": "Rotated-MNIST",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Learning",
            "Continual Learning"
        ],
        "dcat:keyword": [
            "MNIST",
            "Continual learning",
            "Image classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Image Classification"
        ]
    }
]