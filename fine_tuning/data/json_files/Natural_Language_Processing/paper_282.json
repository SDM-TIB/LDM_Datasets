[
    {
        "dcterms:creator": [
            "M. Imran",
            "P. Mitra",
            "C. Castillo"
        ],
        "dcterms:description": "A collection of small datasets where each dataset contains annotated tweets related to a crisis event. The tweets are labelled based on their corresponding informative class (e.g. affected individuals, donations and volunteering, infrastructure and utilities, sympathy and support, other useful information and irrelevant).",
        "dcterms:title": "CrisisNLP dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1605.05894",
        "dcat:theme": [
            "Crisis Response",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Crisis-related tweets",
            "Annotated dataset",
            "Social media",
            "Disaster response"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1605.05894",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Tweet classification"
        ]
    },
    {
        "dcterms:creator": [
            "J. Pennington",
            "R. Socher",
            "C. Manning"
        ],
        "dcterms:description": "A general pretrained word embedding created from 6 billion words from web text and Wikipedia, which is similar to social media texts such as tweets.",
        "dcterms:title": "GloVe embedding",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Word embedding",
            "Natural Language Processing",
            "General-purpose embedding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Vector",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. T. Nguyen",
            "S. Joty",
            "M. Imran",
            "H. Sajjad",
            "P. Mitra"
        ],
        "dcterms:description": "A domain-specific pretrained word embedding trained on 20 million words from 57,908 disaster-related tweets.",
        "dcterms:title": "Crisis embedding",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1610.01030",
        "dcat:theme": [],
        "dcat:keyword": [
            "Word embedding",
            "Crisis-related",
            "Domain-specific embedding"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1610.01030",
        "dcterms:hasVersion": "",
        "dcterms:format": "Vector",
        "mls:task": []
    }
]