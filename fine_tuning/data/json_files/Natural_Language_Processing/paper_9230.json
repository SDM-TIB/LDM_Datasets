[
    {
        "dcterms:creator": [
            "G. Chen",
            "S. Chai",
            "G. Wang",
            "J. Du",
            "W.-Q. Zhang",
            "C. Weng",
            "D. Povey",
            "J. Trmal",
            "J. Zhang",
            "M. Jin",
            "S. Khudanpur",
            "S. Watanabe",
            "S. Zhao",
            "W. Zou",
            "X. Li",
            "X. Yao",
            "Y. Wang",
            "Y. Wang",
            "Z. You",
            "Z. Yan"
        ],
        "dcterms:description": "An ASR corpus containing transcribed audio from audiobooks, Podcasts, and YouTube with a 16 kHz sampling rate. The dataset used for training contains 896 hours and for validation 2.4 hours, with utterance durations ranging from 5 to 15 seconds.",
        "dcterms:title": "GigaSpeech",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "ASR corpus",
            "transcribed audio",
            "real-world speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "A. Nagrani",
            "J. S. Chung",
            "W. Xie",
            "A. Zisserman"
        ],
        "dcterms:description": "A large-scale dataset for speaker verification in the wild, used to ensure speaker diversity in evaluations.",
        "dcterms:title": "VoxCeleb",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Verification"
        ],
        "dcat:keyword": [
            "speaker verification",
            "diversity",
            "real-world data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Verification"
        ]
    },
    {
        "dcterms:creator": [
            "K. Ito",
            "L. Johnson"
        ],
        "dcterms:description": "The LJ Speech Dataset is a single speaker English speech dataset used for training TTS systems.",
        "dcterms:title": "LJSpeech",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-to-Speech"
        ],
        "dcat:keyword": [
            "single speaker",
            "English speech",
            "TTS training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "R. LotÔ¨Åan",
            "C. Busso"
        ],
        "dcterms:description": "A corpus built by retrieving emotional speech from existing podcast recordings to create a naturalistic emotionally balanced speech dataset.",
        "dcterms:title": "MSP-Podcast",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Speech Processing"
        ],
        "dcat:keyword": [
            "emotionally balanced",
            "podcast recordings",
            "naturalistic speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]