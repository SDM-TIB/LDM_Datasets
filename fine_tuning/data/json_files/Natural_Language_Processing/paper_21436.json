[
    {
        "dcterms:creator": [
            "J. Liu",
            "A. Shahroudy",
            "M. Perez",
            "G. Wang",
            "L.-Y. Duan",
            "A. C. Kot"
        ],
        "dcterms:description": "A large-scale benchmark for 3D human activity understanding, containing 56880 action samples with multi-modalities, including RGB, depth map, skeleton, and infrared (IR) video, performed by 40 subjects and classified into 60 action categories.",
        "dcterms:title": "NTU RGB+D 60",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "3D Human Activity Understanding"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "RGB-D",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Zero-Shot Learning",
            "Generalized Zero-Shot Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Liu",
            "A. Shahroudy",
            "M. Perez",
            "G. Wang",
            "L.-Y. Duan",
            "A. C. Kot"
        ],
        "dcterms:description": "An extension of the NTU RGB+D 60 dataset, containing 114,480 action samples of 120 action categories with the same multi-modalities.",
        "dcterms:title": "NTU RGB+D 120",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "3D Human Activity Understanding"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "RGB-D",
            "Action recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Zero-Shot Learning",
            "Generalized Zero-Shot Learning"
        ]
    },
    {
        "dcterms:creator": [
            "L. Chunhui",
            "H. Yueyu",
            "L. Yanghao",
            "S. Sijie",
            "L. Jiaying"
        ],
        "dcterms:description": "A large scale benchmark for continuous multi-modal human action understanding, containing two phases for action recognition with increasing difficulty.",
        "dcterms:title": "PKU-MMD",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1703.07475",
        "dcat:theme": [
            "Human Action Recognition",
            "Multi-modal Understanding"
        ],
        "dcat:keyword": [
            "Skeleton data",
            "Action recognition",
            "Multi-modal data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Zero-Shot Learning",
            "Generalized Zero-Shot Learning"
        ]
    }
]