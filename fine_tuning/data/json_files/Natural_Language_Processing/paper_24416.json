[
    {
        "dcterms:creator": [
            "Fangyu Liu",
            "Guy Edward Toh Emerson",
            "Nigel Collier"
        ],
        "dcterms:description": "The VSR dataset is used to evaluate spatial reasoning capabilities in visual question answering tasks.",
        "dcterms:title": "VSR",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Reasoning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Spatial reasoning",
            "Visual question answering",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Aishwarya Agrawal",
            "Jiasen Lu",
            "Stanislaw Antol",
            "Margaret Mitchell",
            "C. Lawrence Zitnick",
            "Devi Parikh",
            "Dhruv Batra"
        ],
        "dcterms:description": "VQA 2.0 is a benchmark dataset for visual question answering that requires models to answer questions based on images.",
        "dcterms:title": "VQA 2.0",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Image understanding",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tsung-Yi Lin",
            "Michael Maire",
            "Serge Belongie",
            "James Hays",
            "Pietro Perona",
            "Deva Ramanan",
            "Piotr Doll√°r",
            "C Lawrence Zitnick"
        ],
        "dcterms:description": "COCO Caption is a dataset that provides captions for images, used for training models in image captioning tasks.",
        "dcterms:title": "COCO Caption",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Image captioning",
            "Visual understanding",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Kaican Li",
            "Kai Chen",
            "Haoyu Wang",
            "Lanqing Hong",
            "Chaoqiang Ye",
            "Jianhua Han",
            "Yukuai Chen",
            "Wei Zhang",
            "Chunjing Xu",
            "Dit-Yan Yeung"
        ],
        "dcterms:description": "CODA is a dataset designed for object detection in corner cases, particularly in autonomous driving scenarios.",
        "dcterms:title": "CODA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Object detection",
            "Corner cases",
            "Autonomous driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Jianhua Han",
            "Xiwen Liang",
            "Hang Xu",
            "Kai Chen",
            "Lanqing Hong",
            "Jiageng Mao",
            "Chaoqiang Ye",
            "Wei Zhang",
            "Zhenguo Li",
            "Xiaodan Liang",
            "Chunjing Xu"
        ],
        "dcterms:description": "SODA10M is a large-scale dataset for self/semi-supervised object detection, aimed at improving detection capabilities in autonomous driving.",
        "dcterms:title": "SODA10M",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Detection",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Self-supervised learning",
            "Object detection",
            "Autonomous driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Harsh Agrawal",
            "Karan Desai",
            "Yufei Wang",
            "Xinlei Chen",
            "Rishabh Jain",
            "Mark Johnson",
            "Dhruv Batra",
            "Devi Parikh",
            "Stefan Lee",
            "Peter Anderson"
        ],
        "dcterms:description": "NoCaps is a dataset for novel object captioning, focusing on the ability to generate captions for previously unseen objects.",
        "dcterms:title": "NoCaps",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.1109/iccv.2019.00904",
        "dcat:theme": [
            "Image Captioning",
            "Novel Object Recognition"
        ],
        "dcat:keyword": [
            "Novel object captioning",
            "Image understanding",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "http://dx.doi.org/10.1109/ICCV.2019.00904",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Yifan Li",
            "Yifan Du",
            "Kun Zhou",
            "Jinpeng Wang",
            "Wayne Xin Zhao",
            "Ji-Rong Wen"
        ],
        "dcterms:description": "POPE is a dataset used to evaluate object hallucination in large vision-language models.",
        "dcterms:title": "POPE",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Hallucination",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Object hallucination",
            "Vision-language models",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Kenneth Marino",
            "Mohammad Rastegari",
            "Ali Farhadi",
            "Roozbeh Mottaghi"
        ],
        "dcterms:description": "OKVQA is a visual question answering benchmark that requires external knowledge to answer questions based on images.",
        "dcterms:title": "OKVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Knowledge Integration"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "External knowledge",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yash Goyal",
            "Tejas Khot",
            "Douglas Summers-Stay",
            "Dhruv Batra",
            "Devi Parikh"
        ],
        "dcterms:description": "VQAV2 is an updated version of the VQA dataset that emphasizes the importance of image understanding in visual question answering.",
        "dcterms:title": "VQAV2",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Image Understanding"
        ],
        "dcat:keyword": [
            "Visual question answering",
            "Image understanding",
            "Multimodal comprehension"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]