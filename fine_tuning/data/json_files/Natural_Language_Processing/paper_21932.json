[
    {
        "dcterms:creator": [
            "M. Gabel",
            "R. Gilad-Bachrach",
            "E. Renshaw",
            "A. Schuster"
        ],
        "dcterms:description": "A dataset for full body gait analysis using Kinect technology.",
        "dcterms:title": "Gabel et al.",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Gait Analysis"
        ],
        "dcat:keyword": [
            "Kinect",
            "Gait Analysis",
            "Full Body Motion"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Gait Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "F. Ofli",
            "R. Chaudhry",
            "G. Kurillo",
            "R. Vidal",
            "R. Bajcsy"
        ],
        "dcterms:description": "A comprehensive multimodal human action database that includes various actions captured through multiple sensors.",
        "dcterms:title": "Berkeley MHAD",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Multimodal",
            "Human Actions",
            "Sensor Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "B. Delachaux",
            "J. Rebetez",
            "A. Perez-Uribe",
            "H. F. Satizábal Mejia"
        ],
        "dcterms:description": "A dataset for indoor activity recognition that combines neural network classifiers with wearable and depth sensors.",
        "dcterms:title": "Delachaux et al.",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Indoor Activity Recognition",
            "Sensor Fusion"
        ],
        "dcat:keyword": [
            "Wearable Sensors",
            "Depth Sensors",
            "Activity Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "K. Liu",
            "C. Chen",
            "R. Jafari",
            "N. Kehtarnavaz"
        ],
        "dcterms:description": "A dataset that fuses inertial and depth sensor data for robust hand gesture recognition.",
        "dcterms:title": "Liu et al.",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Sensor Fusion"
        ],
        "dcat:keyword": [
            "Inertial Sensors",
            "Depth Sensors",
            "Gesture Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Chen",
            "R. Jafari",
            "N. Kehtarnavaz"
        ],
        "dcterms:description": "A multi-modal dataset for human action recognition utilizing a depth camera and a wearable inertial sensor.",
        "dcterms:title": "UTD-MHAD",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Action Recognition",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Depth Camera",
            "Wearable Sensors",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Malleson",
            "A. Gilbert",
            "M. Trumble",
            "J. Collomosse",
            "A. Hilton",
            "M. Volino"
        ],
        "dcterms:description": "A dataset for real-time full-body motion capture from video and inertial measurement units (IMUs).",
        "dcterms:title": "Malleson et al.",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Motion Capture",
            "Real-time Processing"
        ],
        "dcat:keyword": [
            "Motion Capture",
            "Video Data",
            "IMUs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Motion Capture"
        ]
    },
    {
        "dcterms:creator": [
            "N. Dawar",
            "N. Kehtarnavaz"
        ],
        "dcterms:description": "A dataset for action detection and recognition in continuous action streams using deep learning-based sensing fusion.",
        "dcterms:title": "Dawar et al.",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Detection",
            "Continuous Streams"
        ],
        "dcat:keyword": [
            "Deep Learning",
            "Sensing Fusion",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Action Detection",
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A. Manzi",
            "A. Moschetti",
            "R. Limosani",
            "L. Fiorini",
            "F. Cavallo"
        ],
        "dcterms:description": "A dataset that enhances activity recognition of self-localized robots through depth camera and wearable sensors.",
        "dcterms:title": "Manzi et al.",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robot Activity Recognition",
            "Sensor Fusion"
        ],
        "dcat:keyword": [
            "Depth Camera",
            "Wearable Sensors",
            "Robot Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Activity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Q. Kong",
            "Z. Wu",
            "Z. Deng",
            "M. Klinkigt",
            "B. Tong",
            "T. Murakami"
        ],
        "dcterms:description": "A large-scale dataset for cross-modal human action understanding.",
        "dcterms:title": "MMAct",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cross-modal Learning",
            "Human Action Understanding"
        ],
        "dcat:keyword": [
            "Large-scale Dataset",
            "Cross-modal",
            "Action Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Action Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "L. Wang",
            "B. Sun",
            "J. Robinson",
            "T. Jing",
            "Y. Fu"
        ],
        "dcterms:description": "A multi-modal action dataset that combines electromyography and vision data.",
        "dcterms:title": "EV-Action",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Electromyography",
            "Vision"
        ],
        "dcat:keyword": [
            "Electromyography",
            "Vision Data",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "N. Rai",
            "H. Chen",
            "J. Ji",
            "R. Desai",
            "K. Kozuka",
            "S. Ishizaka",
            "E. Adeli",
            "J. C. Niebles"
        ],
        "dcterms:description": "A dataset for cooperative compositional action understanding in home environments.",
        "dcterms:title": "HOMAGE",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Home Action Recognition",
            "Compositional Understanding"
        ],
        "dcat:keyword": [
            "Home Actions",
            "Cooperative Learning",
            "Action Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Sensor Data",
        "mls:task": [
            "Action Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "K. Grauman",
            "A. Westbury",
            "E. Byrne",
            "Z. Chavis",
            "A. Furnari",
            "R. Girdhar",
            "J. Hamburger",
            "H. Jiang",
            "M. Liu",
            "X. Liu"
        ],
        "dcterms:description": "A large-scale dataset consisting of 3,000 hours of egocentric video for various action recognition tasks.",
        "dcterms:title": "Ego4D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Egocentric Video",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric Video",
            "Large-scale Dataset",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "D. Damen",
            "H. Doughty",
            "G. M. Farinella",
            "A. Furnari",
            "E. Kazakos",
            "J. Ma",
            "D. Moltisanti",
            "J. Munro",
            "T. Perrett",
            "W. Price"
        ],
        "dcterms:description": "A dataset focused on rescaling egocentric vision with challenges for action recognition.",
        "dcterms:title": "EPIC-KITCHENS-100",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Egocentric Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Egocentric Video",
            "Action Recognition",
            "Kitchen Activities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Martínez-Zarzuela",
            "J. González-Alonso",
            "M. Antón-Rodríguez",
            "F. J. Díaz-Pernas",
            "H. Müller",
            "C. Simón-Martínez"
        ],
        "dcterms:description": "A multimodal dataset capturing daily life activities using affordable devices.",
        "dcterms:title": "VIDIMU",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Daily Life Activities",
            "Multimodal Data"
        ],
        "dcat:keyword": [
            "Daily Activities",
            "Multimodal",
            "Affordable Devices"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video, Sensor Data",
        "mls:task": [
            "Activity Recognition"
        ]
    }
]