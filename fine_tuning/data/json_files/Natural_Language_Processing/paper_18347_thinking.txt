To extract datasets from the research paper titled "MEDs for PETs: Multilingual Euphemism Disambiguation for Potentially Euphemistic Terms" by Patrick Lee et al., I will follow a systematic approach to ensure that I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract and introduction** sections to identify any mentions of datasets. The abstract indicates that the study involves training a multilingual transformer model on euphemistic terms across multiple languages, which suggests that datasets are involved.

Next, I will focus on **section 3 (Multilingual Corpus of Euphemisms)**, where the authors describe the datasets used for their experiments. Here, they mention that they utilize datasets for four languages: Mandarin Chinese (ZH), American English (EN), Spanish (ES), and Yorùbá (YO). The authors also provide statistics about the datasets, including the total examples and the number of euphemistic and non-euphemistic examples.

The paper states that the datasets were created by Lee et al. (2023), which is crucial for citation purposes. I will need to ensure I capture the details of this reference.

In the **References section**, I will locate the full citation for the dataset created by Lee et al. (2023). The citation is as follows:
> Patrick Lee, Iyanuoluwa Shode, Alain Trujillo, Yuan Zhao, Olumide Ojo, Diana Plancarte, Anna Feldman, and Jing Peng. 2023. FEED PETs: Further experimentation and expansion on the disambiguation of potentially euphemistic terms. In Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023), pages 437–448, Toronto, Canada. Association for Computational Linguistics.

Now, I will summarize the datasets extracted from the paper:

1. **Mandarin Chinese Euphemism Dataset**: Contains examples annotated by native speakers, modified to include boundary tokens and balanced with other datasets.
2. **American English Euphemism Dataset**: Similar to the Mandarin dataset, it includes examples annotated for euphemistic usage.
3. **Spanish Euphemism Dataset**: Also modified and balanced, with additional examples added by native speakers.
4. **Yorùbá Euphemism Dataset**: This dataset was adjusted to include boundary tokens and balanced with the others.

Each of these datasets is derived from the work of Lee et al. (2023), and I will ensure to include this citation when documenting the datasets.

Finally, I will compile the dataset entries, ensuring that each entry includes the dataset name, a brief description, and the full citation for the source of the datasets. This will provide a comprehensive overview of the datasets used in the research paper.