[
    {
        "dcterms:creator": [
            "Guillaume Wenzek",
            "Marie-Anne Lachaux",
            "Alexis Conneau",
            "Vishrav Chaudhary",
            "Francisco Guzman",
            "Armand Joulin",
            "Edouard Grave"
        ],
        "dcterms:description": "A dataset used for training multilingual masked language models, containing 167 billion tokens in 100 languages.",
        "dcterms:title": "CC100",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Masked Language Modeling",
            "Web Crawl Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Alexis Conneau",
            "Ruty Rinott",
            "Guillaume Lample",
            "Adina Williams",
            "Samuel R. Bowman",
            "Holger Schwenk",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "A dataset for evaluating cross-lingual sentence representations, providing ground-truth dev and test sets in 15 languages.",
        "dcterms:title": "XNLI",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Cross-lingual",
            "Natural Language Inference",
            "Sentence Representations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Patrick Lewis",
            "Barlas OË˜guz",
            "Ruty Rinott",
            "Sebastian Riedel",
            "Holger Schwenk"
        ],
        "dcterms:description": "A dataset for evaluating cross-lingual extractive question answering.",
        "dcterms:title": "MLQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Cross-lingual",
            "Question Answering",
            "Extractive"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mikel Artetxe",
            "Sebastian Ruder",
            "Dani Yogatama"
        ],
        "dcterms:description": "A benchmark for evaluating cross-lingual question answering, extending SQuAD to more languages.",
        "dcterms:title": "XQuad",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Cross-lingual",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing over 100,000 questions for machine comprehension of text.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Machine Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding.",
        "dcterms:title": "GLUE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Natural Language Understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    }
]