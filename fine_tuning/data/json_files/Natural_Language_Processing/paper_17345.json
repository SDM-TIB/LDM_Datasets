[
    {
        "dcterms:creator": [
            "Y. Abbasi-Yadkori",
            "D. Pál",
            "C. Szepesvári"
        ],
        "dcterms:description": "A dataset used for exploring improved algorithms for linear stochastic bandits.",
        "dcterms:title": "Linear Upper Confidence Bound (UCB)",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bandit Algorithms",
            "Recommender Systems"
        ],
        "dcat:keyword": [
            "Linear Bandits",
            "UCB",
            "Stochastic Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "S. Agrawal",
            "N. Goyal"
        ],
        "dcterms:description": "A dataset for studying Thompson sampling in contextual bandits with linear payoffs.",
        "dcterms:title": "Linear Thompson Sampling (TS)",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bandit Algorithms",
            "Recommender Systems"
        ],
        "dcat:keyword": [
            "Thompson Sampling",
            "Linear Bandits",
            "Contextual Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Li",
            "W. Chu",
            "J. Langford",
            "R. E. Schapire"
        ],
        "dcterms:description": "A dataset that applies contextual bandit approaches to personalized news article recommendations.",
        "dcterms:title": "Linear Personalized Recommendation",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Recommender Systems",
            "Contextual Bandits"
        ],
        "dcat:keyword": [
            "Personalized Recommendation",
            "News Articles",
            "Contextual Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "D. Zhou",
            "L. Li",
            "Q. Gu"
        ],
        "dcterms:description": "A dataset for neural contextual bandits that utilizes UCB-based exploration strategies.",
        "dcterms:title": "Neural Upper Confidence Bound (UCB)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Neural Bandits",
            "UCB",
            "Contextual Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "W. Zhang",
            "D. Zhou",
            "L. Li",
            "Q. Gu"
        ],
        "dcterms:description": "A dataset for exploring neural Thompson sampling methods in contextual bandits.",
        "dcterms:title": "Neural Thompson Sampling (TS)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Neural Bandits",
            "Thompson Sampling",
            "Contextual Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Ban",
            "J. He"
        ],
        "dcterms:description": "A dataset focusing on local clustering techniques in contextual multi-armed bandits.",
        "dcterms:title": "Clustering of Bandits",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Clustering",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Clustering",
            "Contextual Bandits",
            "Multi-Armed Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Ban",
            "Y. Qi",
            "T. Wei",
            "J. He"
        ],
        "dcterms:description": "A dataset for neural collaborative filtering bandits using meta-learning techniques.",
        "dcterms:title": "Neural Clustering of Bandits",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2201.13395",
        "dcat:theme": [
            "Neural Networks",
            "Clustering",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Neural Bandits",
            "Collaborative Filtering",
            "Meta Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Qi",
            "Y. Ban",
            "J. He"
        ],
        "dcterms:description": "A dataset for neural bandit learning with arm group graphs.",
        "dcterms:title": "Graph Bandits Learning",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Graph Theory",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Graph Bandits",
            "Neural Networks",
            "Contextual Bandits"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Y. Ban",
            "J. He",
            "C. B. Cook"
        ],
        "dcterms:description": "A dataset that explores multi-facet contextual bandits from a neural network perspective.",
        "dcterms:title": "Applications in Recommender Systems",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Recommender Systems",
            "Bandit Algorithms"
        ],
        "dcat:keyword": [
            "Contextual Bandits",
            "Neural Networks",
            "Recommendation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]