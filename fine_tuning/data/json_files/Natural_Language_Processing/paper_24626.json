[
    {
        "dcterms:creator": [
            "Shankar Kantharaj",
            "Rixie Tiffany Ko Leong",
            "Xiang Lin",
            "Ahmed Masry",
            "Megh Thakkar",
            "Enamul Hoque",
            "Shafiq Joty"
        ],
        "dcterms:description": "A large dataset of 44,096 items, including charts, data tables, and captions, primarily at level 2 of semantic content.",
        "dcterms:title": "Chart-to-text",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Chart Summarization"
        ],
        "dcat:keyword": [
            "Chart dataset",
            "Captioning",
            "Visualization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Chart Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Benny J. Tang",
            "Angie Boggust",
            "Arvind Satyanarayan"
        ],
        "dcterms:description": "A dataset of 12,441 items, comprising charts, scene-graphs, data tables, and structured captions, incorporating levels 2 and 3 through crowdsourcing.",
        "dcterms:title": "Vistext",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Chart Captioning"
        ],
        "dcat:keyword": [
            "Chart dataset",
            "Semantic captioning",
            "Visualization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Chart Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Lei Li",
            "Yuqi Wang",
            "Runxin Xu",
            "Peiyi Wang",
            "Xiachong Feng",
            "Lingpeng Kong",
            "Qi Liu"
        ],
        "dcterms:description": "A dataset designed to improve scientific comprehension of large vision-language models, focusing on multiple figure and contextualized captioning tasks.",
        "dcterms:title": "Multimodal arxiv",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Models"
        ],
        "dcat:keyword": [
            "Multimodal dataset",
            "Scientific comprehension",
            "Captioning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Figure Captioning",
            "Contextualized Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Mengsha Liu",
            "Daoyuan Chen",
            "Yaliang Li",
            "Guian Fang",
            "Ying Shen"
        ],
        "dcterms:description": "A dataset that employs a contextual chain-of-thought approach to optimize chart summarization.",
        "dcterms:title": "Chartthinker",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Chart Summarization"
        ],
        "dcat:keyword": [
            "Chart dataset",
            "Summarization",
            "Contextual learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Chart Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Ashish Singh",
            "Prateek Agarwal",
            "Zixuan Huang",
            "Arpita Singh",
            "Tong Yu",
            "Sungchul Kim",
            "Victor Bursztyn",
            "Nikos Vlassis",
            "Ryan A. Rossi"
        ],
        "dcterms:description": "A generative framework and benchmark for figure-to-caption tasks, optimized with human feedback.",
        "dcterms:title": "Figcaps-hf",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Figure Captioning"
        ],
        "dcat:keyword": [
            "Figure dataset",
            "Generative framework",
            "Human feedback"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Figure Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "Kung-Hsiang Huang",
            "Mingyang Zhou",
            "Hou Pong Chan",
            "Yi R. Fung",
            "Zhenhailong Wang",
            "Lingyu Zhang",
            "Shih-Fu Chang",
            "Heng Ji"
        ],
        "dcterms:description": "A comprehensive analysis of factual errors in chart captioning, focusing on the understanding of charts by large vision-language models.",
        "dcterms:title": "Do lvlms understand charts?",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Chart Captioning"
        ],
        "dcat:keyword": [
            "Factual errors",
            "Chart understanding",
            "Vision-language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Error Analysis",
            "Chart Captioning"
        ]
    }
]