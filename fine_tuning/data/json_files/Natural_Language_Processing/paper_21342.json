[
    {
        "dcterms:creator": [
            "Junpeng Liu",
            "Yifan Song",
            "Bill Yuchen Lin",
            "Wai Lam",
            "Graham Neubig",
            "Yuanzhi Li",
            "Xiang Yue"
        ],
        "dcterms:description": "VisualWebBench is a multimodal benchmark designed to assess the capabilities of multimodal large language models (MLLMs) across a variety of web tasks, comprising 1.5K human-curated instances from 139 real websites, covering 87 sub-domains.",
        "dcterms:title": "VisualWebBench",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://visualwebbench.github.io/",
        "dcat:theme": [
            "Multimodal Learning",
            "Web Understanding"
        ],
        "dcat:keyword": [
            "benchmark",
            "multimodal",
            "web tasks",
            "MLLMs"
        ],
        "dcat:landingPage": "https://visualwebbench.github.io/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Web Page Understanding",
            "Grounding"
        ]
    },
    {
        "dcterms:creator": [
            "Shunyu Yao",
            "Howard Chen",
            "John Yang",
            "Karthik Narasimhan"
        ],
        "dcterms:description": "WebShop is a dataset aimed at scalable real-world web interaction with grounded language agents.",
        "dcterms:title": "WebShop",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf",
        "dcat:theme": [
            "Web Interaction",
            "Grounded Language Agents"
        ],
        "dcat:keyword": [
            "web interaction",
            "grounded language agents",
            "scalability"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper_files/paper/2022/file/82ad13ec01f9fe44c01cb91814fd7b8c-Paper-Conference.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Web Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Xiang Deng",
            "Yu Gu",
            "Boyuan Zheng",
            "Shijie Chen",
            "Sam Stevens",
            "Boshi Wang",
            "Huan Sun",
            "Yu Su"
        ],
        "dcterms:description": "Mind2Web is a dataset aimed at developing a generalist agent for the web.",
        "dcterms:title": "Mind2Web",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://proceedings.neurips.cc/paper_files/paper/2023/file/5950bf290a1570ea401bf98882128160-Paper-Datasets_and_Benchmarks.pdf",
        "dcat:theme": [
            "Web Interaction",
            "Generalist Agents"
        ],
        "dcat:keyword": [
            "generalist agent",
            "web tasks"
        ],
        "dcat:landingPage": "https://proceedings.neurips.cc/paper_files/paper/2023/file/5950bf290a1570ea401bf98882128160-Paper-Datasets_and_Benchmarks.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Web Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "Jing Yu Koh",
            "Robert Lo",
            "Lawrence Jang",
            "Vikram Duvvur",
            "Ming Chong Lim",
            "Po-Yu Huang",
            "Graham Neubig",
            "Shuyan Zhou",
            "Ruslan Salakhutdinov",
            "Daniel Fried"
        ],
        "dcterms:description": "VisualWebArena is a dataset for evaluating multimodal agents on realistic visual web tasks.",
        "dcterms:title": "VisualWebArena",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2401.13649",
        "dcat:theme": [
            "Multimodal Learning",
            "Web Tasks"
        ],
        "dcat:keyword": [
            "multimodal agents",
            "visual web tasks"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2401.13649",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Web Task Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Bryan Wang",
            "Gang Li",
            "Xin Zhou",
            "Zhourong Chen",
            "Tovi Grossman",
            "Yang Li"
        ],
        "dcterms:description": "Screen2Words is a dataset for automatic mobile UI summarization with multimodal learning.",
        "dcterms:title": "Screen2Words",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://dl.acm.org/doi/pdf/10.1145/3472749.3474765",
        "dcat:theme": [
            "Mobile UI",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "mobile UI",
            "summarization",
            "multimodal learning"
        ],
        "dcat:landingPage": "https://dl.acm.org/doi/pdf/10.1145/3472749.3474765",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "UI Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Xingyu Chen",
            "Zihan Zhao",
            "Lu Chen",
            "JiaBao Ji",
            "Danyang Zhang",
            "Ao Luo",
            "Yuxuan Xiong",
            "Kai Yu"
        ],
        "dcterms:description": "WebSRC is a dataset for web-based structural reading comprehension.",
        "dcterms:title": "WebSRC",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://aclanthology.org/2021.emnlp-main.343",
        "dcat:theme": [
            "Reading Comprehension",
            "Web Tasks"
        ],
        "dcat:keyword": [
            "reading comprehension",
            "web-based tasks"
        ],
        "dcat:landingPage": "https://aclanthology.org/2021.emnlp-main.343",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Stanislaw Antol",
            "Aishwarya Agrawal",
            "Jiasen Lu",
            "Margaret Mitchell",
            "Dhruv Batra",
            "C. Lawrence Zitnick",
            "Devi Parikh"
        ],
        "dcterms:description": "VQA is a dataset for visual question answering.",
        "dcterms:title": "VQA",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.1109/ICCV.2015.279",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "visual question answering",
            "image understanding"
        ],
        "dcat:landingPage": "https://doi.org/10.1109/ICCV.2015.279",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    }
]