[
    {
        "dcterms:creator": [
            "Bram Grooten",
            "Ghada Sokar",
            "Shibhansh Dohare",
            "Elena Mocanu",
            "Matthew E. Taylor",
            "Mykola Pechenizkiy",
            "Decebal Constantin Mocanu"
        ],
        "dcterms:description": "A reinforcement learning problem setting where up to 95% of the state features are irrelevant distractions, designed to study the effectiveness of robust-to-noise algorithms.",
        "dcterms:title": "Extremely Noisy Environment (ENE)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2302.06548",
        "dcat:theme": [
            "Reinforcement Learning",
            "Noise Robustness"
        ],
        "dcat:keyword": [
            "Reinforcement Learning",
            "Noise",
            "Preference-based Learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2302.06548",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference-based Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Yuval Tassa",
            "Yotam Doron",
            "Alistair Muldal",
            "Tom Erez",
            "Yazhe Li",
            "Diego de Las Casas",
            "David Budden",
            "Abbas Abdolmaleki",
            "Josh Merel",
            "Andrew Lefrancq"
        ],
        "dcterms:description": "A suite of continuous control tasks for reinforcement learning, providing a variety of environments to benchmark algorithms.",
        "dcterms:title": "DeepMind Control Suite (DMC)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1801.00690",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Tasks"
        ],
        "dcat:keyword": [
            "Control Suite",
            "Reinforcement Learning",
            "Benchmarking"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1801.00690",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "Kimin Lee",
            "Laura M Smith",
            "Pieter Abbeel"
        ],
        "dcterms:description": "A feedback-efficient interactive reinforcement learning algorithm that utilizes relabeling experience and unsupervised pre-training to improve learning from human preferences.",
        "dcterms:title": "PEBBLE",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2106.05091",
        "dcat:theme": [
            "Reinforcement Learning",
            "Human-in-the-loop Learning"
        ],
        "dcat:keyword": [
            "Feedback Efficiency",
            "Interactive Learning",
            "Preference Learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2106.05091",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference-based Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Jongjin Park",
            "Younggyo Seo",
            "Jinwoo Shin",
            "Honglak Lee",
            "Pieter Abbeel",
            "Kimin Lee"
        ],
        "dcterms:description": "A semi-supervised reward learning framework that incorporates data augmentation techniques to enhance feedback efficiency in preference-based reinforcement learning.",
        "dcterms:title": "SURF",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2203.10050",
        "dcat:theme": [
            "Reinforcement Learning",
            "Preference Learning"
        ],
        "dcat:keyword": [
            "Semi-supervised Learning",
            "Data Augmentation",
            "Feedback Efficiency"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2203.10050",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference-based Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Xinran Liang",
            "Katherine Shu",
            "Kimin Lee",
            "Pieter Abbeel"
        ],
        "dcterms:description": "A framework that incorporates reward uncertainty to enhance exploration strategies in preference-based reinforcement learning.",
        "dcterms:title": "RUNE",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2205.12401",
        "dcat:theme": [
            "Reinforcement Learning",
            "Exploration Strategies"
        ],
        "dcat:keyword": [
            "Reward Uncertainty",
            "Exploration",
            "Preference Learning"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2205.12401",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Preference-based Reinforcement Learning"
        ]
    },
    {
        "dcterms:creator": [
            "Tuomas Haarnoja",
            "Aurick Zhou",
            "Pieter Abbeel",
            "Sergey Levine"
        ],
        "dcterms:description": "An off-policy maximum entropy deep reinforcement learning algorithm that utilizes a stochastic actor to improve exploration and learning efficiency.",
        "dcterms:title": "SAC",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1801.01290",
        "dcat:theme": [
            "Reinforcement Learning",
            "Maximum Entropy"
        ],
        "dcat:keyword": [
            "Off-Policy Learning",
            "Entropy Regularization",
            "Stochastic Actor"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1801.01290",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Deep Reinforcement Learning"
        ]
    }
]