[
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "A dataset containing questions based on a set of Wikipedia articles, including unanswerable questions.",
        "dcterms:title": "SQuAD2",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1806.03822",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Natural Language Processing",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Extractive Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Adam Trischler",
            "Tong Wang",
            "Xingdi Yuan",
            "Justin Harris",
            "Alessandro Sordoni",
            "Philip Bachman",
            "Kaheer Suleman"
        ],
        "dcterms:description": "A machine comprehension dataset based on news articles, designed for evaluating reading comprehension models.",
        "dcterms:title": "NewsQA",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1611.09830",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Natural Language Processing",
            "Reading Comprehension",
            "News Articles"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Extractive Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tomáš Koˇcisk`y",
            "Jonathan Schwarz",
            "Phil Blunsom",
            "Chris Dyer",
            "Karl Moritz Hermann",
            "Gábor Melis",
            "Edward Grefenstette"
        ],
        "dcterms:description": "A reading comprehension challenge that includes narrative texts and questions requiring understanding of the narrative.",
        "dcterms:title": "NarrativeQA (NarQA)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Narrative Understanding",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Abstractive Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dheeru Dua",
            "Yizhong Wang",
            "Pradeep Dasigi",
            "Gabriel Stanovsky",
            "Sameer Singh",
            "Matt Gardner"
        ],
        "dcterms:description": "A reading comprehension benchmark that requires discrete reasoning over paragraphs.",
        "dcterms:title": "DROP",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1903.00161",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Discrete Reasoning",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Extractive Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Matthew Richardson",
            "Christopher JC Burges",
            "Erin Renshaw"
        ],
        "dcterms:description": "A challenge dataset for the open-domain machine comprehension of text, consisting of multiple-choice questions.",
        "dcterms:title": "MCTest",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Multiple Choice",
            "Reading Comprehension",
            "Open-Domain"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple-Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Isaac Cowhey",
            "Oren Etzioni",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Carissa Schoenick",
            "Oyvind Tafjord"
        ],
        "dcterms:description": "A dataset for the AI2 Reasoning Challenge, consisting of questions that require reasoning over elementary science concepts.",
        "dcterms:title": "ARC (easy)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1803.05457",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Reasoning",
            "Elementary Science",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple-Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Isaac Cowhey",
            "Oren Etzioni",
            "Tushar Khot",
            "Ashish Sabharwal",
            "Carissa Schoenick",
            "Oyvind Tafjord"
        ],
        "dcterms:description": "A dataset for the AI2 Reasoning Challenge, consisting of more challenging questions that require reasoning over elementary science concepts.",
        "dcterms:title": "ARC (challenge)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1803.05457",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Reasoning",
            "Elementary Science",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple-Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Todor Mihaylov",
            "Peter Clark",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "A new dataset for open book question answering that requires reasoning and knowledge retrieval.",
        "dcterms:title": "OpenBookQA (OBQA)",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Open Book",
            "Question Answering",
            "Knowledge Retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple-Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tushar Khot",
            "Peter Clark",
            "Michal Guerquin",
            "Peter Jansen",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "A dataset for question answering via sentence composition, requiring reasoning across multiple sentences.",
        "dcterms:title": "QASC",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Sentence Composition",
            "Question Answering",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Guokun Lai",
            "Qizhe Xie",
            "Hanxiao Liu",
            "Yiming Yang",
            "Eduard Hovy"
        ],
        "dcterms:description": "A large-scale reading comprehension dataset derived from examinations, designed for evaluating reading comprehension models.",
        "dcterms:title": "RACE",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1704.04683",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Examinations",
            "Reading Comprehension",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multiple-Choice Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Christopher Clark",
            "Kenton Lee",
            "Ming-Wei Chang",
            "Tom Kwiatkowski",
            "Michael Collins",
            "Kristina Toutanova"
        ],
        "dcterms:description": "A dataset exploring the difficulty of natural yes/no questions, designed for evaluating binary question answering models.",
        "dcterms:title": "BoolQ",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1905.10044",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Yes/No Questions",
            "Binary Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Yes/No Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Khashabi",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "An extension of BoolQ that introduces natural perturbations for robust question answering.",
        "dcterms:title": "BoolQ-NP",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2004.04849",
        "dcat:theme": [
            "Machine Reading Comprehension",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Natural Perturbation",
            "Robust Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Yes/No Question Answering"
        ]
    }
]