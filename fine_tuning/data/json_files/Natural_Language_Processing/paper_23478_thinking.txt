To extract datasets from the research paper titled "IrokoBench: A New Benchmark for African Languages in the Age of Large Language Models" by David Ifeoluwa Adelani et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper.

First, I will read through the **abstract, introduction, and methodology sections** to gather initial insights about the datasets. The abstract mentions the introduction of **IrokoBench**, which is a benchmark dataset for 16 low-resource African languages covering three tasks. This indicates that there are specific datasets associated with these tasks.

Next, I will focus on the **methodology section**, particularly the parts that describe the datasets in detail. The authors explicitly mention three datasets:

1. **AfriXNLI**: This dataset is designed for natural language inference tasks and includes translations of the XNLI dataset into 15 African languages (excluding Swahili). The dataset consists of 450 development instances and 600 test instances.

2. **AfriMMLU**: This is a multi-choice knowledge-based question-answering dataset that includes 17 languages (including French). It consists of 25 training instances, 83 development instances, and 500 test instances, covering various subjects such as geography and mathematics.

3. **AfriMGSM**: This dataset focuses on mathematical reasoning and includes 15 languages (excluding Swahili). It has 8 training instances and 250 test instances.

After identifying these datasets, I will check the **references section** of the paper to find the full citations for the original datasets that were adapted or translated for IrokoBench. The citations for the original datasets are as follows:

- For **XNLI**, the citation is:
  > Alexis Conneau et al. "XNLI: Evaluating cross-lingual sentence representations." In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 2475â€“2485, 2018. doi: 10.18653/v1/D18-1269.

- For **MMLU**, the citation is:
  > Dan Hendrycks et al. "Measuring massive multitask language understanding." Proceedings of the International Conference on Learning Representations (ICLR), 2021.

- For **MGSM**, the citation is:
  > Dan Hendrycks et al. "Measuring mathematical problem solving with the MATH dataset." In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2), 2021.

Now, I will compile the dataset entries, ensuring that I include the full citations for each dataset as required. This will provide a comprehensive overview of the datasets used in the research paper.