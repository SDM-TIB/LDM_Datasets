[
    {
        "dcterms:creator": [
            "H. Touvron",
            "L. Martin",
            "K. Stone",
            "P. Albert",
            "A. Almahairi",
            "Y. Babaei",
            "N. Bashlykov",
            "S. Batra",
            "P. Bhargava",
            "S. Bhosale"
        ],
        "dcterms:description": "Llama 2 (70B) is a large language model designed for various NLP tasks, showcasing improvements in performance and efficiency.",
        "dcterms:title": "Llama 2 (70B)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Large Language Model",
            "NLP",
            "Open Source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Inference",
            "Fine-tuning"
        ]
    },
    {
        "dcterms:creator": [
            "BigScience"
        ],
        "dcterms:description": "BLOOM (176B) is a multilingual language model with 176 billion parameters, aimed at providing open-access capabilities for various language tasks.",
        "dcterms:title": "BLOOM (176B)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Large Language Model",
            "Open Access"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Inference",
            "Fine-tuning"
        ]
    },
    {
        "dcterms:creator": [
            "BigScience"
        ],
        "dcterms:description": "BLOOM (7.1B) is a smaller version of the BLOOM model, containing 7.1 billion parameters, designed for more accessible language processing tasks.",
        "dcterms:title": "BLOOM (7.1B)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/bigscience/bloom-7b1",
        "dcat:theme": [],
        "dcat:keyword": [
            "Language Model",
            "NLP",
            "Open Access"
        ],
        "dcat:landingPage": "https://huggingface.co/bigscience/bloom-7b1",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Inference",
            "Fine-tuning"
        ]
    }
]