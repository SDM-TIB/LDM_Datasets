[
    {
        "dcterms:creator": [
            "Tom Kocmi",
            "Rachel Bawden",
            "Ondřej Bojar",
            "Anton Dvorkovich",
            "Christian Federmann",
            "Mark Fishel",
            "Thamme Gowda",
            "Yvette Graham",
            "Roman Grundkiewicz",
            "Barry Haddow",
            "Rebecca Knowles",
            "Philipp Koehn",
            "Christof Monz",
            "Makoto Morishita",
            "Masaaki Nagata",
            "Toshiaki Nakazawa",
            "Michal Novák",
            "Martin Popel",
            "Maja Popović"
        ],
        "dcterms:description": "The WMT22 test sets are used for evaluating machine translation systems, providing a benchmark for translation quality across multiple language pairs.",
        "dcterms:title": "WMT22 test sets",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "WMT",
            "Machine Translation",
            "Evaluation",
            "Translation Quality"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Francisco Guzmán",
            "Peng-Jen Chen",
            "Myle Ott",
            "Juan Pino",
            "Guillaume Lample",
            "Philipp Koehn",
            "Vishrav Chaudhary",
            "Marc’Aurelio Ranzato"
        ],
        "dcterms:description": "The FLORES-200 dev set is designed for low-resource machine translation evaluation, specifically for languages like Nepali and Sinhala.",
        "dcterms:title": "FLORES-200 dev set",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Low-Resource Languages"
        ],
        "dcat:keyword": [
            "FLORES",
            "Low-Resource",
            "Machine Translation",
            "Nepali",
            "Sinhala"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Naman Goyal",
            "Cynthia Gao",
            "Vishrav Chaudhary",
            "Peng-Jen Chen",
            "Guillaume Wenzek",
            "Da Ju",
            "Sanjana Krishnan",
            "Marc’Aurelio Ranzato",
            "Francisco Guzmán",
            "Angela Fan"
        ],
        "dcterms:description": "The FLORES-101 evaluation benchmark provides a comprehensive evaluation framework for low-resource and multilingual machine translation.",
        "dcterms:title": "FLORES-101 evaluation benchmark",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Machine Translation",
            "Multilingual Evaluation"
        ],
        "dcat:keyword": [
            "FLORES",
            "Evaluation Benchmark",
            "Low-Resource",
            "Multilingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Machine Translation"
        ]
    }
]