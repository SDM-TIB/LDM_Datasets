[
    {
        "dcterms:creator": [
            "W. Zhou",
            "J. S. Berrio",
            "C. De Alvis",
            "M. Shan",
            "S. Worrall",
            "J. Ward",
            "E. Nebot"
        ],
        "dcterms:description": "A dataset collected from the University of Sydney campus, used to develop and test robust autonomy in autonomous vehicles, capturing various driving scenarios and environmental data.",
        "dcterms:title": "University of Sydney Campus Dataset",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Vehicles",
            "Driver Monitoring"
        ],
        "dcat:keyword": [
            "Autonomous driving",
            "Driver attention",
            "Safety monitoring"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Driver attention classification"
        ]
    },
    {
        "dcterms:creator": [
            "C.-Y. Wang",
            "A. Bochkovskiy",
            "H.-Y. M. Liao"
        ],
        "dcterms:description": "A lightweight version of the YOLOv7 model used for real-time object detection, particularly for detecting the safety driver's head in this study.",
        "dcterms:title": "YOLOv7-tiny Model",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2207.02696",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Real-time detection",
            "Object detection",
            "Head detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object detection"
        ]
    },
    {
        "dcterms:creator": [
            "C. Lugaresi",
            "J. Tang",
            "H. Nash",
            "C. McClanahan",
            "E. Uboweja",
            "M. Hays",
            "F. Zhang",
            "C.-L. Chang",
            "M. G. Yong",
            "J. Lee",
            "W.-T. Chang",
            "W. Hua",
            "M. Georg",
            "M. Grundmann"
        ],
        "dcterms:description": "A framework for building perception pipelines, utilized in this study for real-time facial landmark detection to estimate head pose.",
        "dcterms:title": "MediaPipe",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1906.08172",
        "dcat:theme": [
            "Computer Vision",
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Facial landmarks",
            "Head pose estimation",
            "Real-time processing"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1906.08172",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Facial landmark detection"
        ]
    },
    {
        "dcterms:creator": [
            "T. Collins",
            "A. Bartoli"
        ],
        "dcterms:description": "A method for pose estimation based on infinitesimal planes, applied in this study to enhance head pose estimation accuracy.",
        "dcterms:title": "Infinitesimal Plane-based Pose Estimation",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Pose Estimation"
        ],
        "dcat:keyword": [
            "Pose estimation",
            "Head orientation",
            "Geometric models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Pose estimation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Guo",
            "X.-l. Lv",
            "Y. Zhang",
            "M.-l. Zhang"
        ],
        "dcterms:description": "An improved version of the YOLOv4-tiny network designed for real-time electronic component detection, referenced in the context of detecting objects in the driving environment.",
        "dcterms:title": "YOLOv4-tiny",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Object Detection"
        ],
        "dcat:keyword": [
            "Real-time detection",
            "Object detection",
            "Vehicle detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object detection"
        ]
    },
    {
        "dcterms:creator": [
            "B.-T. Vo",
            "W.-K. Ma"
        ],
        "dcterms:description": "A filtering technique used to track and smooth paths of detected objects in the vehicle's environment, enhancing the accuracy of object detection.",
        "dcterms:title": "Gaussian Mixture Probability Hypothesis Density Filter",
        "dcterms:issued": "2006",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Signal Processing",
            "Object Tracking"
        ],
        "dcat:keyword": [
            "Object tracking",
            "Filtering",
            "Data smoothing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Y.-y. Ren",
            "X.-s. Li",
            "X.-l. Zheng",
            "Z. Li",
            "Q.-c. Zhao"
        ],
        "dcterms:description": "A study analyzing drivers' eye-movement characteristics, referenced to understand visual attention in driving scenarios.",
        "dcterms:title": "Driversâ€™ Eye-Movement Characteristics",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Factors",
            "Driver Behavior"
        ],
        "dcat:keyword": [
            "Eye movement",
            "Driver attention",
            "Driving behavior"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Behavior analysis"
        ]
    },
    {
        "dcterms:creator": [
            "B. Wolfe",
            "J. Dobres",
            "R. Rosenholtz",
            "B. Reimer"
        ],
        "dcterms:description": "A study focusing on peripheral vision in driving, referenced to highlight the importance of peripheral awareness for driver safety.",
        "dcterms:title": "Peripheral Vision in Driving",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.sciencedirect.com/science/article/pii/S0003687017301631",
        "dcat:theme": [
            "Human Factors",
            "Driver Behavior"
        ],
        "dcat:keyword": [
            "Peripheral vision",
            "Driver awareness",
            "Situational awareness"
        ],
        "dcat:landingPage": "https://www.sciencedirect.com/science/article/pii/S0003687017301631",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Behavior analysis"
        ]
    }
]