[
    {
        "dcterms:creator": [
            "M. Ott",
            "S. Shleifer",
            "M. Xu",
            "P. Goyal",
            "Q. D. Duval",
            "V. Caggiano"
        ],
        "dcterms:description": "FSDP features heavy communication, with at least 50% increased communication cost compared to conventional data-parallel training.",
        "dcterms:title": "Fully Sharded Data-Parallel (FSDP)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://engineering.fb.com/2021/07/15/open-source/fsdp/",
        "dcat:theme": [
            "Distributed Training",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Data Parallelism",
            "GPU Training",
            "Communication Cost"
        ],
        "dcat:landingPage": "https://engineering.fb.com/2021/07/15/open-source/fsdp/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "N. Shazeer",
            "A. Mirhoseini",
            "K. Maziarz",
            "A. Davis",
            "Q. Le",
            "G. Hinton",
            "J. Dean"
        ],
        "dcterms:description": "MoE training implements a gating network-based routing mechanism between distributed experts using AllToAll pattern that has higher communication cost than traditional AllReduce pattern.",
        "dcterms:title": "Mixture of Experts (MoE)",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1701.06538",
        "dcat:theme": [
            "Distributed Training",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Gating Networks",
            "Expert Models",
            "Communication Cost"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Howard",
            "M. Sandler",
            "G. Chu",
            "L.-C. Chen",
            "B. Chen",
            "M. Tan",
            "W. Wang",
            "Y. Zhu",
            "R. Pang",
            "V. Vasudevan"
        ],
        "dcterms:description": "MobileNetV3 is designed for efficient mobile vision applications, balancing performance and resource usage.",
        "dcterms:title": "MobileNetV3",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision",
            "Mobile Applications"
        ],
        "dcat:keyword": [
            "MobileNet",
            "Efficient Models",
            "Vision Tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "M. Naumov",
            "D. Mudigere",
            "H.-J. M. Shi",
            "J. Huang",
            "N. Sundaraman",
            "J. Park",
            "X. Wang",
            "U. Gupta",
            "C.-J. Wu",
            "A. G. Azzolini"
        ],
        "dcterms:description": "DLRM is used for personalization and recommendation systems, focusing on deep learning techniques for recommendations.",
        "dcterms:title": "Deep Learning Recommendation Model (DLRM)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1906.00091",
        "dcat:theme": [
            "Recommendation Systems",
            "Deep Learning"
        ],
        "dcat:keyword": [
            "Personalization",
            "Recommendation",
            "Deep Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Dai",
            "Z. Yang",
            "Y. Yang",
            "J. Carbonell",
            "Q. V. Le",
            "R. Salakhutdinov"
        ],
        "dcterms:description": "Transformer-XL is designed for language modeling, extending the context length beyond fixed-length sequences.",
        "dcterms:title": "Transformer-XL",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1901.02860",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Transformers",
            "Language Models",
            "Context Length"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Z. Dai",
            "Z. Yang",
            "Y. Yang",
            "J. Carbonell",
            "Q. V. Le",
            "R. Salakhutdinov"
        ],
        "dcterms:description": "Wikitext-103 is a large dataset for language modeling, providing a diverse set of text data.",
        "dcterms:title": "Wikitext-103",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1901.02860",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text Dataset",
            "Language Modeling",
            "Large Corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "A. Radford",
            "J. Wu",
            "R. Child",
            "D. Luan",
            "D. Amodei",
            "I. Sutskever"
        ],
        "dcterms:description": "Wikitext-2 is a smaller dataset for language modeling, often used for benchmarking language models.",
        "dcterms:title": "Wikitext-2",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text Dataset",
            "Language Modeling",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "W. Hamilton",
            "Z. Ying",
            "J. Leskovec"
        ],
        "dcterms:description": "Reddit dataset is used for inductive representation learning on large graphs, providing a rich source of social network data.",
        "dcterms:title": "Reddit",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Graph Representation Learning",
            "Social Networks"
        ],
        "dcat:keyword": [
            "Graph Data",
            "Inductive Learning",
            "Social Media"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]