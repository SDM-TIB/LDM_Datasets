[
    {
        "dcterms:creator": [
            "S. Lin",
            "J. Hilton",
            "O. Evans"
        ],
        "dcterms:description": "A benchmark for measuring how models mimic human falsehoods, focusing on the accuracy of generated responses.",
        "dcterms:title": "TruthfulQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2109.07958",
        "dcat:theme": [
            "Natural Language Processing",
            "Factuality Evaluation"
        ],
        "dcat:keyword": [
            "Factuality",
            "Language Models",
            "Evaluation Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factuality Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Min",
            "K. Krishna",
            "X. Lyu",
            "M. Lewis",
            "W.-t. Yih",
            "P. W. Koh",
            "M. Iyyer",
            "L. Zettlemoyer",
            "H. Hajishirzi"
        ],
        "dcterms:description": "A fine-grained evaluation benchmark for assessing factual precision in long-form text generation.",
        "dcterms:title": "FACTSCORE",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.14251",
        "dcat:theme": [
            "Natural Language Processing",
            "Factuality Evaluation"
        ],
        "dcat:keyword": [
            "Factual Precision",
            "Text Generation",
            "Evaluation Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factuality Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Zhong",
            "Z. Wu",
            "C. D. Manning",
            "C. Potts",
            "D. Chen"
        ],
        "dcterms:description": "A dataset for assessing knowledge editing in language models through multi-hop questions.",
        "dcterms:title": "MQUAKE-CF-3k",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2305.14795",
        "dcat:theme": [
            "Natural Language Processing",
            "Knowledge Editing"
        ],
        "dcat:keyword": [
            "Multi-hop Questions",
            "Knowledge Editing",
            "Evaluation Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Knowledge Editing"
        ]
    },
    {
        "dcterms:creator": [
            "D. Vrandeˇci´c",
            "M. Kr ¨otzsch"
        ],
        "dcterms:description": "A free collaborative knowledge base that provides structured data for various applications.",
        "dcterms:title": "WikiData",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Knowledge Base",
            "Structured Data"
        ],
        "dcat:keyword": [
            "Knowledge Base",
            "Collaborative Data",
            "Structured Information"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]