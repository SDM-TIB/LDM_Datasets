[
    {
        "dcterms:creator": [
            "Nikita Drobyshev",
            "Jenya Chelishev",
            "Taras Khakhulin",
            "Aleksei Ivakhnenko",
            "Victor Lempitsky",
            "Egor Zakharov"
        ],
        "dcterms:description": "A novel dataset designed to capture a wide range of intense and asymmetric facial expressions, including complex movements like blinks, winks, and head and tongue movements, aimed at addressing the scarcity of high-quality video data in existing datasets.",
        "dcterms:title": "FEED (Facial Extreme Emotions Dataset)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Expression Recognition",
            "Emotion Analysis"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Extreme emotions",
            "Multi-view videos",
            "Video dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition",
            "Facial Animation"
        ]
    },
    {
        "dcterms:creator": [
            "Kaisiyuan Wang",
            "Qianyi Wu",
            "Linsen Song",
            "Zhuoqian Yang",
            "Wayne Wu",
            "Chen Qian",
            "Ran He",
            "Yu Qiao",
            "Chen Change Loy"
        ],
        "dcterms:description": "A large-scale audio-visual dataset for emotional talking-face generation, providing detailed multi-view data across three intensities of emotions.",
        "dcterms:title": "MEAD (Multimodal Emotion Dataset)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-visual dataset",
            "Emotional speech",
            "Talking-face generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition",
            "Facial Animation"
        ]
    },
    {
        "dcterms:creator": [
            "Philip Jackson",
            "SJUoSG Haq"
        ],
        "dcterms:description": "A database capturing audio-visual expressed emotions, designed for research in emotion recognition and analysis.",
        "dcterms:title": "SAVEE (Surrey Audio-Visual Expressed Emotion)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Audio-visual dataset",
            "Expressed emotions",
            "Emotion analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Steven R Livingstone",
            "Frank A Russo"
        ],
        "dcterms:description": "A dynamic, multimodal set of facial and vocal expressions in North American English, aimed at studying emotional speech and song.",
        "dcterms:title": "RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "Audio-visual dataset",
            "Facial expressions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Houwei Cao",
            "David G Cooper",
            "Michael K Keutmann",
            "Ruben C Gur",
            "Ani Nenkova",
            "Ragini Verma"
        ],
        "dcterms:description": "A crowd-sourced emotional multimodal actors dataset designed for affective computing research.",
        "dcterms:title": "CREMA-D (Crowd-sourced Emotional Multimodal Actors Dataset)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Affective Computing"
        ],
        "dcat:keyword": [
            "Crowd-sourced dataset",
            "Emotional expressions",
            "Multimodal dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Maja Pantic",
            "Michel Valstar",
            "Ron Rademaker",
            "Ludo Maat"
        ],
        "dcterms:description": "A web-based database for facial expression analysis, providing a range of facial expressions for research.",
        "dcterms:title": "MMI (Multimodal Emotion Recognition Database)",
        "dcterms:issued": "2005",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Facial Expression Analysis"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion analysis",
            "Multimodal dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Joon Son Chung",
            "Arsha Nagrani",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A dataset for deep speaker recognition, providing a large collection of audio-visual data for speaker identification.",
        "dcterms:title": "VoxCeleb2",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speaker Recognition",
            "Audio-Visual Processing"
        ],
        "dcat:keyword": [
            "Speaker recognition",
            "Audio-visual dataset",
            "Deep learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio-Visual",
        "mls:task": [
            "Speaker Recognition"
        ]
    }
]