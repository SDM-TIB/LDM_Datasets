To extract datasets from the research paper titled "Can AI Models Appreciate Document Aesthetics? An Exploration of Legibility and Layout Quality in Relation to Prediction Confidence" by Hsiu-Wei Yang et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract provides a general overview, but I will focus on the methods section, particularly **section 3.1.1 (Datasets)**, where the authors typically describe the datasets used in their experiments.

In **section 3.1.1**, the authors explicitly mention two datasets:

1. **FUNSD**: This dataset is described as a KIE (Key Information Extraction) dataset consisting of 199 noisy, scanned forms with a total of 9,707 annotated semantic entities. The authors note that it is widely used for tasks such as OCR, spatial layout analysis, and entity extraction/linking.

2. **IDL**: This dataset is a vast collection of documents created by industries that influence public health. The authors focus on a subset of about 15,000 OCR'd documents for the task of document page classification.

Next, I will check the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution and to guide readers to the original sources.

- For **FUNSD**, the citation is:
  > G. Jaume, H. K. Ekenel, J.-P. Thiran. *FUNSD: A dataset for form understanding in noisy scanned documents*. In: 2019 International Conference on Document Analysis and Recognition Workshops (ICDARW), volume 2, IEEE, 2019, pp. 1–6.

- For **IDL**, the citation is:
  > A. F. Biten, R. Tito, L. Gomez, E. Valveny, D. Karatzas. *OCR-IDL: OCR annotations for industry document library dataset*. In: Computer Vision–ECCV 2022 Workshops: Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part IV, Springer, 2023, pp. 241–252.

Now that I have identified the datasets and their citations, I will summarize the findings:

1. **FUNSD**: A KIE dataset with 199 noisy scanned forms and 9,707 annotated entities.
   - Citation: G. Jaume, H. K. Ekenel, J.-P. Thiran. *FUNSD: A dataset for form understanding in noisy scanned documents*. In: 2019 International Conference on Document Analysis and Recognition Workshops (ICDARW), volume 2, IEEE, 2019, pp. 1–6.

2. **IDL**: A collection of documents for document page classification, focusing on a subset of about 15,000 OCR'd documents.
   - Citation: A. F. Biten, R. Tito, L. Gomez, E. Valveny, D. Karatzas. *OCR-IDL: OCR annotations for industry document library dataset*. In: Computer Vision–ECCV 2022 Workshops: Tel Aviv, Israel, October 23–27, 2022, Proceedings, Part IV, Springer, 2023, pp. 241–252.

With this information, I can now compile the dataset entries into a structured format for further processing or review.