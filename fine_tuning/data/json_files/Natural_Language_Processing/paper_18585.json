[
    {
        "dcterms:creator": [
            "Xiang Chen",
            "Chenxi Wang",
            "Yida Xue",
            "Ningyu Zhang",
            "Xiaoyan Yang",
            "Qiang Li",
            "Yue Shen",
            "Lei Liang",
            "Jinjie Gu",
            "Huajun Chen"
        ],
        "dcterms:description": "A meta-evaluation benchmark designed to assess the progress of unified multimodal hallucination detectors for MLLMs, encompassing various hallucination categories and multimodal tasks.",
        "dcterms:title": "MHaluBench",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Multimodal",
            "Hallucination",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Hallucination Detection",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Wojciech Kryscinski",
            "Bryan McCann",
            "Caiming Xiong",
            "Richard Socher"
        ],
        "dcterms:description": "A dataset for evaluating the factual consistency of abstractive text summarization.",
        "dcterms:title": "FactCC",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Factual Consistency",
            "Text Summarization",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factual Consistency Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Kyunghyun Cho",
            "Mike Lewis"
        ],
        "dcterms:description": "A dataset for asking and answering questions to evaluate the factual consistency of summaries.",
        "dcterms:title": "QAGS",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Factual Consistency",
            "Question Answering",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factual Consistency Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Junyi Li",
            "Xiaoxue Cheng",
            "Xin Zhao",
            "Jian-Yun Nie",
            "Ji-Rong Wen"
        ],
        "dcterms:description": "A large-scale hallucination evaluation benchmark for large language models.",
        "dcterms:title": "HaluEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Hallucination",
            "Evaluation",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Hallucination Detection",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Yifan Li",
            "Yifan Du",
            "Kun Zhou",
            "Jinpeng Wang",
            "Wayne Xin Zhao",
            "Ji-Rong Wen"
        ],
        "dcterms:description": "A dataset for evaluating object hallucination in large vision-language models.",
        "dcterms:title": "POPE",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Vision-Language Models",
            "Hallucination Detection"
        ],
        "dcat:keyword": [
            "Object Hallucination",
            "Evaluation",
            "Vision-Language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Object Hallucination Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Fuxiao Liu",
            "Kevin Lin",
            "Linjie Li",
            "Jianfeng Wang",
            "Yaser Yacoob",
            "Lijuan Wang"
        ],
        "dcterms:description": "A framework for aligning large multi-modal models with robust instruction tuning.",
        "dcterms:title": "HaELM",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Model Alignment"
        ],
        "dcat:keyword": [
            "Multi-modal",
            "Instruction Tuning",
            "Model Alignment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Alignment"
        ]
    },
    {
        "dcterms:creator": [
            "Cunxiang Wang",
            "Xiaoze Liu",
            "Yuanhao Yue",
            "Xiangru Tang",
            "Tianhang Zhang",
            "Jiayang Cheng",
            "Yunzhi Yao",
            "Wenyang Gao",
            "Xuming Hu",
            "Zehan Qi",
            "Yidong Wang",
            "Linyi Yang",
            "Jindong Wang",
            "Xing Xie",
            "Zheng Zhang",
            "Yue Zhang"
        ],
        "dcterms:description": "A survey on factuality in large language models, focusing on knowledge, retrieval, and domain-specificity.",
        "dcterms:title": "AMBER",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Factuality"
        ],
        "dcat:keyword": [
            "Factuality",
            "Survey",
            "Large Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factuality Evaluation"
        ]
    }
]