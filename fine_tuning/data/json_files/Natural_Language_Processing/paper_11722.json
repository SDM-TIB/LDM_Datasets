[
    {
        "dcterms:creator": [
            "Leo Gao",
            "Jonathan Tow",
            "Stella Biderman",
            "Sid Black",
            "Anthony DiPofi",
            "Charles Foster",
            "Laurence Golding",
            "Jeffrey Hsu",
            "Kyle McDonell",
            "Niklas Muennighoff",
            "Jason Phang",
            "Laria Reynolds",
            "Eric Tang",
            "Anish Thite",
            "Ben Wang",
            "Kevin Wang",
            "Andy Zou"
        ],
        "dcterms:description": "A dataset used for evaluating language models in a few-shot setting, providing a benchmark for model performance.",
        "dcterms:title": "Wiki-Text-103",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.5281/zenodo.5371628",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Model Evaluation"
        ],
        "dcat:keyword": [
            "Language model",
            "Evaluation",
            "Few-shot learning"
        ],
        "dcat:landingPage": "https://doi.org/10.5281/zenodo.5371628",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Percy Liang",
            "Rishi Bommasani",
            "Tony Lee",
            "Dimitris Tsipras",
            "Dilara Soylu",
            "Michihiro Yasunaga",
            "Yian Zhang",
            "Deepak Narayanan",
            "Yuhuai Wu",
            "Ananya Kumar"
        ],
        "dcterms:description": "A comprehensive framework for evaluating language models across various tasks and metrics.",
        "dcterms:title": "HELM",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2211.09110",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Evaluation"
        ],
        "dcat:keyword": [
            "Language model",
            "Evaluation framework",
            "Holistic evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Melissa Roemmele",
            "Cosmin Adrian Bejan",
            "Andrew S Gordon"
        ],
        "dcterms:description": "A dataset designed to evaluate commonsense causal reasoning through choice of plausible alternatives.",
        "dcterms:title": "COPA",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Causal reasoning",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Causal Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Aida Amini",
            "Saadia Gabriel",
            "Shanchuan Lin",
            "Rik Koncel-Kedziorski",
            "Yejin Choi",
            "Hannaneh Hajishirzi"
        ],
        "dcterms:description": "A dataset aimed at interpretable math word problem solving using operation-based formalisms.",
        "dcterms:title": "MathQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Mathematics"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Interpretable AI",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Math Problem Solving"
        ]
    },
    {
        "dcterms:creator": [
            "Todor Mihaylov",
            "Peter Clark",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "A dataset for open book question answering, focusing on questions that require external knowledge.",
        "dcterms:title": "OpenBookQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Open book QA",
            "Knowledge-based questions",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yonatan Bisk",
            "Rowan Zellers",
            "Ronan Le Bras",
            "Jianfeng Gao",
            "Yejin Choi"
        ],
        "dcterms:description": "A dataset for reasoning about physical commonsense in natural language.",
        "dcterms:title": "PiQA",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Physical commonsense",
            "Reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Wang",
            "Amanpreet Singh",
            "Julian Michael",
            "Felix Hill",
            "Omer Levy",
            "Samuel R Bowman"
        ],
        "dcterms:description": "A multi-task benchmark and analysis platform for natural language understanding.",
        "dcterms:title": "RTE",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1804.07461",
        "dcat:theme": [
            "Natural Language Processing",
            "Natural Language Understanding"
        ],
        "dcat:keyword": [
            "Multi-task benchmark",
            "Natural language understanding",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Keisuke Sakaguchi",
            "Ronan Le Bras",
            "Chandra Bhagavatula",
            "Yejin Choi"
        ],
        "dcterms:description": "An adversarial Winograd schema challenge at scale for evaluating commonsense reasoning.",
        "dcterms:title": "Winogrande",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Adversarial dataset",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Shashi Narayan",
            "Shay B Cohen",
            "Mirella Lapata"
        ],
        "dcterms:description": "A dataset for extreme summarization, focusing on generating concise summaries.",
        "dcterms:title": "XSUM",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1808.08745",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Extreme summarization",
            "Text summarization",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "Ramesh Nallapati",
            "Bowen Zhou",
            "Caglar Gulcehre",
            "Bing Xiang"
        ],
        "dcterms:description": "A dataset for abstractive text summarization using sequence-to-sequence RNNs.",
        "dcterms:title": "CNN/Daily Mail",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1602.06023",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Abstractive summarization",
            "Text summarization",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Summarization"
        ]
    }
]