[
    {
        "dcterms:creator": [],
        "dcterms:description": "A multimodal HRI dataset encompassing human commands through speech and gestures that are natural, synchronized with robot behavior demonstrations. It includes 1143 commands issued by 18 individuals, covering 11 actions, 20 objects, and 16 states, with each command accompanied by an expert demonstration.",
        "dcterms:title": "NatSGD",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://www.snehesh.com/natsgd/",
        "dcat:theme": [
            "Human-Robot Interaction",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Multimodal dataset",
            "Speech",
            "Gestures",
            "Robot demonstrations",
            "Human commands"
        ],
        "dcat:landingPage": "https://www.snehesh.com/natsgd/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Multi-Modal Human Task Understanding",
            "Robot Learning"
        ]
    },
    {
        "dcterms:creator": [
            "J. Novoa",
            "J. P. Escudero",
            "J. Fredes",
            "J. Wuth",
            "R. Mahu",
            "N. B. Yoma"
        ],
        "dcterms:description": "A multichannel robot speech recognition database designed for speech recognition tasks in robotic applications.",
        "dcterms:title": "MCHRSR",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1801.00061",
        "dcat:theme": [
            "Speech Recognition",
            "Robotics"
        ],
        "dcat:keyword": [
            "Speech recognition",
            "Robot speech",
            "Multichannel database"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1801.00061",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. James",
            "L. Tian",
            "C. I. Watson"
        ],
        "dcterms:description": "An open-source interaction emotional speech corpus designed for human-robot applications.",
        "dcterms:title": "Emotional Speech Corpus",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Emotion Recognition",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "Human-robot interaction",
            "Open-source corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "P. K. Pisharady",
            "M. Saerbeck"
        ],
        "dcterms:description": "A review of recent methods and databases in vision-based hand gesture recognition.",
        "dcterms:title": "Gesture Recognition Dataset",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Gesture recognition",
            "Vision-based",
            "Hand gestures"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "D. Shukla",
            "Ö. Erkent",
            "J. Piater"
        ],
        "dcterms:description": "A multi-view hand gesture RGB-D dataset for human-robot interaction scenarios.",
        "dcterms:title": "Multi-view Hand Gesture RGB-D Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "RGB-D dataset",
            "Multi-view",
            "Hand gestures"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "A. Gomez Chavez",
            "A. Ranieri",
            "D. Chiarella",
            "E. Zereik",
            "A. Babić",
            "A. Birk"
        ],
        "dcterms:description": "A dataset for human-robot interaction in the context of diver activities using underwater stereo-vision.",
        "dcterms:title": "Caddy Underwater Stereo-Vision Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Underwater Robotics",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "Underwater dataset",
            "Stereo vision",
            "Human-robot interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Robot Interaction"
        ]
    },
    {
        "dcterms:creator": [
            "C. Nuzzi",
            "S. Pasinetti",
            "R. Pagani",
            "G. Coffetti",
            "G. Sansoni"
        ],
        "dcterms:description": "An RGB-D dataset of static hand-gestures for human-robot interaction.",
        "dcterms:title": "Hands Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "RGB-D dataset",
            "Static hand gestures",
            "Human-robot interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. de Wit",
            "E. Krahmer",
            "P. Vogt"
        ],
        "dcterms:description": "A dataset collected through a gameful human-robot interaction focusing on iconic gestures.",
        "dcterms:title": "Nemo-Lowlands Iconic Gesture Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "Iconic gestures",
            "Human-robot interaction",
            "Gameful interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Gesture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "P. Azagra",
            "F. Golemo",
            "Y. Mollard",
            "M. Lopes",
            "J. Civera",
            "A. C. Murillo"
        ],
        "dcterms:description": "A multimodal dataset for object model learning from natural human-robot interaction.",
        "dcterms:title": "Multimodal Dataset for Object Model Learning",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Object Recognition",
            "Human-Robot Interaction"
        ],
        "dcat:keyword": [
            "Multimodal dataset",
            "Object model learning",
            "Human-robot interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Object Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "H. Chen",
            "M. C. Leu",
            "Z. Yin"
        ],
        "dcterms:description": "A dataset for real-time multi-modal human-robot collaboration using gestures and speech.",
        "dcterms:title": "Real-time Multi-modal Human-Robot Collaboration Dataset",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human-Robot Collaboration",
            "Speech and Gesture Interaction"
        ],
        "dcat:keyword": [
            "Real-time collaboration",
            "Multi-modal interaction",
            "Human-robot interaction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Human-Robot Collaboration"
        ]
    }
]