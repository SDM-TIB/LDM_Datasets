To extract datasets from the research paper titled "AfriVEC: Word Embedding Models for African Languages. Case Study of Fon and Nobiin" by Bonaventure F. P. Dossou and Mohammed Sabry, I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract highlights the creation of Word2Vec and Poincaré word embedding models for Fon and Nobiin, indicating that datasets are likely involved.

Next, I will focus on **section 3 (Creation of our Word Embedding: Case Study of Fon and Nobiin Languages)**, where the authors describe the datasets used for training their models. Here, I find specific details about the datasets:

1. **Fon Word2Vec Dataset**: The authors mention that they filtered and extracted sentences from the FFR parallel dataset, which contains 739 sentences focused on the family domain. This dataset is crucial for training the Fon Word2Vec model.

2. **Nobiin Word2Vec Dataset**: For Nobiin, the dataset consists of nearly 40 sentences reflecting daily lifestyle contexts, which is also essential for training the Nobiin Word2Vec model.

3. **Fon Poincaré Embedding Dataset**: The authors describe a dataset consisting of 642 samples, including names, cities, and date components, used for training the Fon Poincaré model.

4. **Nobiin Poincaré Embedding Dataset**: This dataset consists of 108 samples of Nobiin names, used for training the Nobiin Poincaré model.

Now, I will check the **References section** to find full citations for the datasets mentioned. The paper cites several works that may provide context or original sources for the datasets used:

- For the **FFR parallel dataset**, the citation is:
  > Bonaventure F. P. Dossou and Chris C. Emezue. *Ffr v1.1: Fon-French Neural Machine Translation*. 2020.

- For the **work on Yoruba and Twi embeddings**, which is referenced in the context of low-resourced languages, the citation is:
  > Jesujoba O. Alabi, Kwabena Amponsah-Kaakyire, David I. Adelani, and Cristina España-Bonet. *Massive vs. curated word embeddings for low-resourced languages: the case of yorùbá and twi*. 2019.

- The **HyperLex format** used for the Poincaré datasets is cited as:
  > Ivan Vulić, Daniela Gerz, Douwe Kiela, Felix Hill, and Anna Korhonen. *Hyperlex: A large-scale evaluation of graded lexical entailment*. 2016.

After gathering this information, I will compile the dataset entries, ensuring to include the full citations for each dataset as required. This structured approach will ensure that I accurately capture all relevant datasets and their sources from the paper.