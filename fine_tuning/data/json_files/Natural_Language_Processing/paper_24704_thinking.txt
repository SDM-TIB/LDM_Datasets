To extract datasets from the research paper titled "Mask and Compress: Efficient Skeleton-based Action Recognition in Continual Learning" by Matteo Mosconi et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will start by reviewing the **abstract** and **introduction** sections. The abstract mentions that the authors conducted experiments on "Split NTU-60 and the proposed Split NTU-120 datasets," which indicates that these datasets are central to their research.

Next, I will look into **section 4.1 (Datasets)**, where the authors provide detailed descriptions of the datasets used. Here, they describe:

1. **Split NTU-60**: This dataset is derived from the NTU RGB+D dataset, originally comprising 60 classes and 56,578 samples. It is used for action recognition on skeletal data and is split into 6 tasks, each defining a 10-class classification problem.

2. **Split NTU-120**: This is an extension of the NTU RGB+D dataset, expanded to 120 classes and 113,945 samples. Similar to Split NTU-60, it is structured into 12 tasks, each with 10 classes.

In the **experiments section**, the authors confirm that they evaluated their method on these two datasets, reinforcing their importance in the study.

Now, I will refer to the **References section** to gather the full citations for these datasets:

- For **NTU RGB+D 60**, the citation is:
  > Shahroudy, A., Liu, J., Ng, T., & Wang, G. (2016). NTU RGB+D: A large scale dataset for 3D human activity analysis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2016–2024.

- For **NTU RGB+D 120**, the citation is:
  > Liu, J., Shahroudy, A., Perez, M., Wang, G., Duan, L.Y., & Kot, A.C. (2019). NTU RGB+D 120: A large-scale benchmark for 3D human activity understanding. IEEE Transactions on Pattern Analysis and Machine Intelligence, 42(10), 2510–2526.

With this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will prepare the information for structured output or further analysis.