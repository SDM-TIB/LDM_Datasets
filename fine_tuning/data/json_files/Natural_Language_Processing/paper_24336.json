[
    {
        "dcterms:creator": [
            "Leyan Wang",
            "Yonggang Jin",
            "Tianhao Shen",
            "Tianyu Zheng",
            "Xinrun Du",
            "Chenchen Zhang",
            "Wenhao Huang",
            "Jiaheng Liu",
            "Shi Wang",
            "Ge Zhang",
            "Liuyu Xiang",
            "Zhaofeng He"
        ],
        "dcterms:description": "GIEBench is a comprehensive benchmark designed to evaluate the empathy of large language models (LLMs) towards diverse group identities, covering 11 identity dimensions and 97 group identities with a total of 999 single-choice questions.",
        "dcterms:title": "GIEBench",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/GIEBench/GIEBench",
        "dcat:theme": [
            "Empathy Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Group Identity",
            "Empathy",
            "Large Language Models",
            "Benchmark"
        ],
        "dcat:landingPage": "https://github.com/GIEBench/GIEBench",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Empathy Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "J. Huang",
            "M. H. Lam",
            "E. J. Li",
            "S. Ren",
            "W. Wang",
            "W. Jiao",
            "Z. Tu",
            "M. R. Lyu"
        ],
        "dcterms:description": "EmotionBench is a benchmark designed to evaluate how large language models (LLMs) respond emotionally in various situations, focusing on their ability to adapt responses based on emotional context.",
        "dcterms:title": "EmotionBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2308.03656",
        "dcat:theme": [
            "Emotion Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Emotion",
            "Large Language Models",
            "Benchmark"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2308.03656",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Shen",
            "Y. Kim",
            "M. Hulse",
            "W. Zulfiqar",
            "S. Alghowinem",
            "C. Breazeal",
            "H. W. Park"
        ],
        "dcterms:description": "Empathicstories++ is a multimodal dataset designed to evaluate empathy towards personal experiences, providing a rich set of narratives and responses.",
        "dcterms:title": "Empathicstories++",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2405.15708",
        "dcat:theme": [
            "Empathy Evaluation",
            "Multimodal Dataset"
        ],
        "dcat:keyword": [
            "Empathy",
            "Narratives",
            "Multimodal"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2405.15708",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Empathy Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "L. Aroyo",
            "A. Taylor",
            "M. Diaz",
            "C. Homan",
            "A. Parrish",
            "G. Serapio-Garc√≠a",
            "V. Prabhakaran",
            "D. Wang"
        ],
        "dcterms:description": "Dices Dataset focuses on diversity in conversational AI evaluation for safety, providing a framework for assessing conversational agents.",
        "dcterms:title": "Dices Dataset",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Conversational AI",
            "Safety Evaluation"
        ],
        "dcat:keyword": [
            "Diversity",
            "Conversational AI",
            "Safety"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Safety Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Parrish",
            "A. Chen",
            "N. Nangia",
            "V. Padmakumar",
            "J. Phang",
            "J. Thompson",
            "P. Mon Htut",
            "S. Bowman"
        ],
        "dcterms:description": "BBQ is a hand-built bias benchmark for question answering, designed to evaluate biases in AI systems.",
        "dcterms:title": "BBQ",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Bias",
            "Question Answering",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Bias Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "D. Omitaomu",
            "S. Tafreshi",
            "T. Liu",
            "S. Buechel",
            "C. Callison-Burch",
            "J. Eichstaedt",
            "L. Ungar",
            "J. Sedoc"
        ],
        "dcterms:description": "Empathic Conversations is a multi-level dataset of contextualized conversations aimed at evaluating empathy in dialogue systems.",
        "dcterms:title": "Empathic Conversations",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2205.12698",
        "dcat:theme": [
            "Dialogue Systems",
            "Empathy Evaluation"
        ],
        "dcat:keyword": [
            "Empathy",
            "Conversations",
            "Dialogue"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2205.12698",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Empathy Assessment"
        ]
    }
]