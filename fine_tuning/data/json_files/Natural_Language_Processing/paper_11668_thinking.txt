To extract datasets from the research paper titled "FunQA: Towards Surprising Video Comprehension" by Binzhu Xie et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper, ensuring to include full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned. The abstract introduces **FunQA**, which is described as a video question answering dataset designed to evaluate video reasoning based on surprising videos. This indicates that there are specific datasets involved.

Next, I will look for detailed descriptions of the datasets in the **main body of the paper**, particularly in sections that discuss the dataset construction and the experiments. In the paper, the authors mention three subsets of the FunQA dataset:

1. **HumorQA**: This subset consists of videos that are humorous in nature. The authors state that it includes 1,769 curated web videos, focusing on humor comprehension.

2. **CreativeQA**: This subset contains 927 videos from a TV show called "Kasou Taishou," which showcases creative performances. The average length of these videos is noted to be 48 seconds.

3. **MagicQA**: This subset includes 1,672 magic performance videos, emphasizing the understanding of magical effects and illusions.

In the **dataset statistics section**, the authors provide quantitative details about each subset, including the number of videos and the average length of the videos. This information is crucial for understanding the scope of each dataset.

Now, I will check the **References section** for full citations of the datasets mentioned. The FunQA dataset itself is the primary focus, and the authors do not provide separate citations for the subsets since they are part of the overall FunQA dataset. However, I will ensure to document the citation for the FunQA dataset as follows:

- For **FunQA**, the citation is:
  > Binzhu Xie, Sicheng Zhang, Zitang Zhou, Bo Li, Yuanhan Zhang, Jack Hessel, Jingkang Yang, and Ziwei Liu. *FunQA: Towards Surprising Video Comprehension*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023.

After gathering all this information, I will compile the dataset entries into a structured format that highlights the key aspects of each dataset, including their names, descriptions, and citations. This will ensure that the extracted information is clear and ready for further use or analysis.