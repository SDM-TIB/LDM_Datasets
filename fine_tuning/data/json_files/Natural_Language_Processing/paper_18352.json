[
    {
        "dcterms:creator": [
            "S. Merity",
            "C. Xiong",
            "J. Bradbury",
            "R. Socher"
        ],
        "dcterms:description": "A dataset used for language modeling, providing a diverse set of text samples for training and evaluating models.",
        "dcterms:title": "WikiText-2",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "R. Taori",
            "I. Gulrajani",
            "T. Zhang",
            "Y. Dubois",
            "X. Li",
            "C. Guestrin",
            "P. Liang",
            "T. B. Hashimoto"
        ],
        "dcterms:description": "A dataset designed for instruction-following tasks, providing examples for training models to follow natural language instructions.",
        "dcterms:title": "Alpaca",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction following",
            "Text dataset"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bisk",
            "R. Zellers",
            "R. Le Bras",
            "J. Gao",
            "Y. Choi"
        ],
        "dcterms:description": "A dataset for evaluating reasoning about physical commonsense in natural language, focusing on understanding physical interactions.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Physical commonsense",
            "Reasoning dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "K. Sakaguchi",
            "R. Le Bras",
            "C. Bhagavatula",
            "Y. Choi"
        ],
        "dcterms:description": "An adversarial dataset designed to challenge models on the Winograd schema, providing a large-scale evaluation of pronoun resolution.",
        "dcterms:title": "WinoGrande",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Pronoun Resolution"
        ],
        "dcat:keyword": [
            "Adversarial dataset",
            "Pronoun resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Pronoun Resolution"
        ]
    },
    {
        "dcterms:creator": [
            "R. Zellers",
            "A. Holtzman",
            "Y. Bisk",
            "A. Farhadi",
            "Y. Choi"
        ],
        "dcterms:description": "A dataset for evaluating the ability of models to complete sentences in a coherent manner, focusing on commonsense reasoning.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Sentence completion",
            "Commonsense reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Completion"
        ]
    },
    {
        "dcterms:creator": [
            "P. Clark",
            "I. Cowhey",
            "O. Etzioni",
            "T. Khot",
            "A. Sabharwal",
            "C. Schoenick",
            "O. Tafjord"
        ],
        "dcterms:description": "A dataset designed for evaluating question answering capabilities, focusing on reasoning and comprehension.",
        "dcterms:title": "ARC-e",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Reasoning dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "P. Clark",
            "I. Cowhey",
            "O. Etzioni",
            "T. Khot",
            "A. Sabharwal",
            "C. Schoenick",
            "O. Tafjord"
        ],
        "dcterms:description": "A dataset designed for evaluating question answering capabilities, focusing on reasoning and comprehension.",
        "dcterms:title": "ARC-c",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Reasoning dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]