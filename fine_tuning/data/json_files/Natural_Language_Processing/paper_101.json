[
    {
        "dcterms:creator": [],
        "dcterms:description": "20 Newsgroups dataset is widely used for text classification tasks. It includes approximately 20,000 emails across 20 different newsgroups.",
        "dcterms:title": "20 Newsgroups",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Classification"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Email classification",
            "Newsgroups"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Fudan Text Classification dataset is a Chinese text classification corpus that includes 20 categories.",
        "dcterms:title": "Fudan Text Classification",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Classification"
        ],
        "dcat:keyword": [
            "Chinese text dataset",
            "Text classification",
            "Fudan dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Classification"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "ACL Anthology Network corpus includes papers from various conferences and journals under the Association for Computational Linguistics.",
        "dcterms:title": "ACL Anthology",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Research Papers"
        ],
        "dcat:keyword": [
            "ACL",
            "Research papers",
            "Linguistics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Stanford Sentiment Treebank is a dataset for sentiment analysis that includes fine-grained sentiment labels for phrases in movie reviews.",
        "dcterms:title": "Stanford Sentiment Treebank",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Sentiment dataset",
            "Movie reviews",
            "Sentiment analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "IMDB Movie Reviews dataset contains reviews of movies from the IMDB website, used for sentiment analysis tasks.",
        "dcterms:title": "IMDB Movie Reviews",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis"
        ],
        "dcat:keyword": [
            "Movie reviews",
            "Sentiment dataset",
            "IMDB"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "WordSim353 is a dataset used to evaluate the semantic similarity of words based on human judgments.",
        "dcterms:title": "WordSim353",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Word similarity",
            "Semantic dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "TOEFL dataset contains synonym questions used to evaluate the ability of word embeddings to capture semantic similarity.",
        "dcterms:title": "TOEFL Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Similarity"
        ],
        "dcat:keyword": [
            "Synonym questions",
            "Word embeddings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Similarity"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "CoNLL03 is a dataset used for named entity recognition tasks, containing annotated text for various entities.",
        "dcterms:title": "CoNLL03",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Named Entity Recognition"
        ],
        "dcat:keyword": [
            "NER dataset",
            "Annotated text"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Named Entity Recognition"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "SIGHAN 2005 is a Chinese word segmentation dataset used for evaluating segmentation algorithms.",
        "dcterms:title": "SIGHAN 2005",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Word Segmentation"
        ],
        "dcat:keyword": [
            "Chinese segmentation",
            "Segmentation algorithms"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Segmentation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Wikipedia Corpus is a large-scale dataset used for training word embeddings, containing a vast amount of text data.",
        "dcterms:title": "Wikipedia Corpus",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Word embeddings"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]