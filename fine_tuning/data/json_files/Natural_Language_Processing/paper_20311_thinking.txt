To extract datasets from the research paper titled "CoBra: Complementary Branch Fusing Class and Semantic Knowledge for Robust Weakly Supervised Semantic Segmentation" by Woojung Han et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methods sections** to identify any datasets mentioned. The abstract states that the authors conducted extensive experiments on the **PASCAL VOC 2012** and **MS COCO 2014** datasets, indicating that these are the primary datasets used in their research.

Next, I will look for specific details about these datasets in the **experiments section**. The authors mention that the **PASCAL VOC 2012** dataset contains 20 foreground classes and 1 background class, with a total of 1,464 training images, 1,449 validation images, and 1,456 test images. They also note that an augmented set of 10,582 images is used for training. For the **MS COCO 2014** dataset, they mention it contains 80 object classes and one background class, with 80,000 training images and 40,000 validation images.

I will also check the **references section** to find the full citations for these datasets. The citations are as follows:

- For the **PASCAL VOC 2012** dataset:
  > Mark Everingham, Luc Van Gool, Christopher KI Williams, John Winn, and Andrew Zisserman. *The PASCAL Visual Object Classes (VOC) Challenge*. International Journal of Computer Vision, 88(2):303–338, 2010.

- For the **MS COCO 2014** dataset:
  > Tsung-Yi Lin, Michael Maire, Sergio F. G. Vasconcelos, et al. *Microsoft COCO: Common Objects in Context*. In European Conference on Computer Vision (ECCV), pages 740–755, 2014.

Now that I have identified the datasets and their full citations, I will compile this information into a structured format for further use. This includes ensuring that I have accurately captured the details and citations for both datasets mentioned in the paper.