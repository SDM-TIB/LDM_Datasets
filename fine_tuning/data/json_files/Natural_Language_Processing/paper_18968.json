[
    {
        "dcterms:creator": [
            "D. Jin",
            "E. Pan",
            "N. Oufattole",
            "W. H. Weng",
            "H. Fang",
            "P. Szolovits"
        ],
        "dcterms:description": "A large-scale open domain question answering dataset from medical exams, specifically designed to assess the ability to diagnose diseases based on medical questions.",
        "dcterms:title": "MedQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Medical exams",
            "Question answering",
            "Disease diagnosis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Medical Question Answering"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A publicly accessible dataset used for training LLaMA, containing a vast amount of web data collected from various sources.",
        "dcterms:title": "CommonCrawl",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Web data",
            "Text corpus"
        ],
        "dcat:landingPage": "https://commoncrawl.org/get-started",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Raffel",
            "N. Shazeer",
            "A. Roberts",
            "K. Lee",
            "S. Narang",
            "M. Matena",
            "P. J. Liu"
        ],
        "dcterms:description": "A large dataset designed for training language models, focusing on diverse text sources to enhance transfer learning capabilities.",
        "dcterms:title": "C4",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Transfer Learning"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Language modeling",
            "Transfer learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A publicly accessible dataset used for training LLaMA, consisting of code and documentation from various repositories.",
        "dcterms:title": "Github",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Code repository",
            "Documentation"
        ],
        "dcat:landingPage": "https://github.com/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A publicly accessible dataset used for training LLaMA, containing a vast amount of encyclopedic content.",
        "dcterms:title": "Wikipedia",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Encyclopedic content",
            "Text corpus"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/wikipedia",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Gao",
            "S. Biderman",
            "S. Black",
            "L. Golding",
            "T. Hoppe",
            "C. Foster",
            "C. Leahy"
        ],
        "dcterms:description": "An 800GB dataset of diverse text for language modeling, designed to support various NLP tasks.",
        "dcterms:title": "Books",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2101.00027",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Text corpus",
            "Diverse text",
            "Language modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A publicly accessible dataset used for training LLaMA, consisting of research papers and articles.",
        "dcterms:title": "ArXiv",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Research papers",
            "Academic articles"
        ],
        "dcat:landingPage": "https://arxiv.org/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A publicly accessible dataset used for training LLaMA, containing questions and answers from various topics.",
        "dcterms:title": "StackExchange",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Q&A data",
            "Community-driven content"
        ],
        "dcat:landingPage": "https://stackexchange.com/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]