[
    {
        "dcterms:creator": [],
        "dcterms:description": "A comprehensive Chinese medical dataset that captures the full spectrum of the diagnostic process, containing 92K Q&A samples from 22 tasks and 27 specialists.",
        "dcterms:title": "DoctorFLAN",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Dataset",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Chinese medical dataset",
            "Q&A samples",
            "diagnostic process"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Medical Assistance"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset designed for single-turn evaluations in medical scenarios, containing 550 instances.",
        "dcterms:title": "DoctorFLAN-test",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Dataset",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "single-turn evaluation",
            "medical scenarios"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset for evaluating multi-turn dialogues among medical assistants, reflecting real-world needs where medical assistants must handle multiple rounds of Q&A.",
        "dcterms:title": "DotaBench",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Dataset",
            "Evaluation Benchmark"
        ],
        "dcat:keyword": [
            "multi-turn dialogues",
            "medical assistants"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation",
            "Dialogue Management"
        ]
    },
    {
        "dcterms:creator": [
            "Jianquan Li",
            "Xidong Wang",
            "Xiangbo Wu",
            "Zhiyi Zhang",
            "Xiaolong Xu",
            "Jie Fu",
            "Prayag Tiwari",
            "Xiang Wan",
            "Benyou Wang"
        ],
        "dcterms:description": "A large-scale Chinese medical QA dataset.",
        "dcterms:title": "Huatuo-26M",
        "dcterms:issued": "2023",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "arXiv:2305.01526",
        "dcat:theme": [
            "Medical Dataset",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Chinese medical QA",
            "large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Pal",
            "L. Kumar Umapathi",
            "M. Sankarasubbu"
        ],
        "dcterms:description": "A large-scale multi-subject multi-choice dataset for medical domain question answering.",
        "dcterms:title": "MedMCQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Dataset",
            "Question Answering"
        ],
        "dcat:keyword": [
            "multi-choice questions",
            "medical domain"
        ],
        "dcat:landingPage": "https://medmcqa.github.io",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Pal",
            "L. Kumar Umapathi",
            "M. Sankarasubbu"
        ],
        "dcterms:description": "A large-scale multi-subject multi-choice dataset for medical domain question answering.",
        "dcterms:title": "cMedQA2",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical Dataset",
            "Question Answering"
        ],
        "dcat:keyword": [
            "multi-choice questions",
            "medical domain"
        ],
        "dcat:landingPage": "https://github.com/zhangsheng93/cMedQ&A2",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]