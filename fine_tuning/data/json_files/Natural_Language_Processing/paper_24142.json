[
    {
        "dcterms:creator": [
            "Karttikeya Mangalam",
            "Raiymbek Akshulakov",
            "Jitendra Malik"
        ],
        "dcterms:description": "EgoSchema dataset consists of 5000 multiple-choice questions sourced from 5000 three-minute egocentric videos. This dataset only has a subset of 500 questions with publicly accessible labels.",
        "dcterms:title": "EgoSchema",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2308.09126",
        "dcat:theme": [
            "Video Understanding",
            "Benchmark Dataset"
        ],
        "dcat:keyword": [
            "Egocentric Videos",
            "Multiple-choice Questions",
            "Long Video Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Enxin Song",
            "Wenhao Chai",
            "Guanhong Wang",
            "Yucheng Zhang",
            "Haoyang Zhou",
            "Feiyang Wu",
            "Xun Guo",
            "Tian Ye",
            "Yan Lu",
            "Jenq-Neng Hwang"
        ],
        "dcterms:description": "MovieChat-1K is a longer video understanding benchmark, which contains 1000 videos from movies and TV shows, typically lasting approximately 10 minutes.",
        "dcterms:title": "MovieChat-1K",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2307.16449",
        "dcat:theme": [
            "Video Understanding",
            "Benchmark Dataset"
        ],
        "dcat:keyword": [
            "Movies",
            "TV Shows",
            "Long Video Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Yanwei Li",
            "Chengyao Wang",
            "Jiaya Jia"
        ],
        "dcterms:description": "LLama-Vid-QA is a benchmark created from MovieNet dataset and LLama-Vid dataset, focusing on hour-level video understanding with 400 questions and 23 videos.",
        "dcterms:title": "LLama-Vid-QA",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2311.17043",
        "dcat:theme": [
            "Video Understanding",
            "Benchmark Dataset"
        ],
        "dcat:keyword": [
            "Long Videos",
            "Question Answering",
            "MovieNet"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Question Answering"
        ]
    }
]