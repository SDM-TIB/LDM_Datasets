[
    {
        "dcterms:creator": [
            "T. Yoshioka",
            "I. Abramovski",
            "C. Aksoylar",
            "Z. Chen",
            "M. David",
            "D. Dimitriadis",
            "Y. Gong",
            "I. Gurvich",
            "X. Huang",
            "Y. Huang"
        ],
        "dcterms:description": "A dataset comprising approximately 315 unique meetings, each lasting on average 6 minutes, featuring authentic, multi-participant English conversations recorded in about 30 different conference rooms at Microsoft offices. It captures a wide spectrum of real-world acoustic conditions and conversational dynamics.",
        "dcterms:title": "NOTSOFAR Meeting Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Speaker Diarization"
        ],
        "dcat:keyword": [
            "Meeting dataset",
            "Distant speech recognition",
            "Multi-channel recording",
            "Acoustic diversity"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Distant Automatic Speech Recognition",
            "Speaker Diarization"
        ]
    },
    {
        "dcterms:creator": [
            "D. Raj",
            "P. Denisov",
            "Z. Chen",
            "H. Erdogan",
            "Z. Huang",
            "M. He",
            "S. Watanabe",
            "J. Du",
            "T. Yoshioka",
            "Y. Luo"
        ],
        "dcterms:description": "A 1000-hour simulated training dataset synthesized with enhanced authenticity for real-world generalization, incorporating 15,000 real acoustic transfer functions. It is designed for speech separation and enhancement.",
        "dcterms:title": "NOTSOFAR Simulated Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation",
            "Speech Enhancement"
        ],
        "dcat:keyword": [
            "Simulated dataset",
            "Speech separation",
            "Acoustic transfer functions",
            "Training data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation",
            "Speech Enhancement"
        ]
    },
    {
        "dcterms:creator": [
            "W. Kraaij",
            "T. Hain",
            "M. Lincoln",
            "W. Post"
        ],
        "dcterms:description": "The AMI meeting corpus is a collection of real meeting recordings designed for research in speech recognition and understanding.",
        "dcterms:title": "AMI",
        "dcterms:issued": "2005",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Meeting Analysis"
        ],
        "dcat:keyword": [
            "Meeting corpus",
            "Speech recognition",
            "Dialog act labeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "R. Dhillon",
            "S. Bhagat",
            "H. Carvey",
            "E. Shriberg"
        ],
        "dcterms:description": "The ICSI Meeting Recorder Project provides a dataset with dialog act labeling for meeting recordings.",
        "dcterms:title": "ICSI",
        "dcterms:issued": "2004",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Dialog Act Analysis"
        ],
        "dcat:keyword": [
            "Meeting recordings",
            "Dialog act labeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Dialog Act Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Fox",
            "Y. Liu",
            "E. Zwyssig",
            "T. Hain"
        ],
        "dcterms:description": "The Sheffield Wargames Corpus is a dataset designed for research in speech recognition and understanding in gaming contexts.",
        "dcterms:title": "Sheffield Wargames",
        "dcterms:issued": "2013",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Gaming Analysis"
        ],
        "dcat:keyword": [
            "Wargames corpus",
            "Speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Harper"
        ],
        "dcterms:description": "The ASpiRE challenge dataset focuses on automatic speech recognition in reverberant environments.",
        "dcterms:title": "ASpiRE",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Reverberant environments",
            "Speech recognition challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Automatic Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "L. Cristoforetti",
            "M. Ravanelli",
            "M. Omologo",
            "A. Sosi",
            "A. Abad",
            "M. Hagm√ºller",
            "P. Maragos"
        ],
        "dcterms:description": "The DIRHA simulated corpus is designed for research in distant speech recognition and includes various simulated acoustic conditions.",
        "dcterms:title": "DIRHA",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Simulated corpus",
            "Distant speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Distant Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "C. Richey",
            "M. A. Barrios",
            "Z. Armstrong",
            "C. Bartels",
            "H. Franco",
            "M. Graciarena",
            "A. Lawson",
            "M. K. Nandwana",
            "A. Stauffer",
            "J. van Hout"
        ],
        "dcterms:description": "The VOiCES corpus focuses on speech recognition in complex environmental settings.",
        "dcterms:title": "VOiCES",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1804.05053",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Complex environments",
            "Speech recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Van Segbroeck",
            "A. Zaid",
            "K. Kutsenko",
            "C. Huerta",
            "T. Nguyen",
            "X. Luo",
            "B. Hoffmeister",
            "J. Trmal",
            "M. Omologo",
            "R. Maas"
        ],
        "dcterms:description": "DiPCo is a dinner party corpus designed for research in conversational speech recognition.",
        "dcterms:title": "DiPCo",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1909.13447",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Dinner party corpus",
            "Conversational speech"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Conversational Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "K. Grauman",
            "A. Westbury",
            "E. Byrne",
            "Z. Chavis",
            "A. Furnari",
            "R. Girdhar",
            "J. Hamburger",
            "H. Jiang",
            "M. Liu",
            "X. Liu"
        ],
        "dcterms:description": "Ego4D is a large-scale dataset of egocentric video recordings designed for various computer vision tasks.",
        "dcterms:title": "Ego4D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Egocentric video",
            "Large-scale dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "F. Yu",
            "S. Zhang",
            "Y. Fu",
            "L. Xie",
            "S. Zheng",
            "Z. Du",
            "W. Huang",
            "P. Guo",
            "Z. Yan",
            "B. Ma"
        ],
        "dcterms:description": "AliMeeting is a dataset for multi-channel multi-party meeting transcription challenges.",
        "dcterms:title": "AliMeeting",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Multi-channel meetings",
            "Transcription challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Meeting Transcription"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Chen",
            "T. Yoshioka",
            "L. Lu",
            "T. Zhou",
            "Z. Meng",
            "Y. Luo",
            "J. Wu",
            "X. Xiao",
            "J. Li"
        ],
        "dcterms:description": "LibriCSS is a dataset for continuous speech separation and analysis.",
        "dcterms:title": "LibriCSS",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Separation"
        ],
        "dcat:keyword": [
            "Continuous speech separation",
            "Dataset analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Separation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Ma",
            "J. Barker",
            "H. Christensen",
            "P. Green"
        ],
        "dcterms:description": "The CHiME challenge datasets focus on distant microphone speech recognition in the presence of multiple sources.",
        "dcterms:title": "CHiME",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Distant microphone",
            "Speech recognition challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Distant Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "S. Cornell",
            "M. Wiesner",
            "S. Watanabe",
            "D. Raj",
            "X. Chang",
            "P. Garcia",
            "Y. Masuyama",
            "Z.-Q. Wang",
            "S. Squartini",
            "S. Khudanpur"
        ],
        "dcterms:description": "The CHiME-7 DASR challenge dataset focuses on distant meeting transcription with multiple devices in diverse scenarios.",
        "dcterms:title": "CHiME-7",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.13734",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Distant meeting transcription",
            "Multiple devices"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Distant Automatic Speech Recognition"
        ]
    }
]