[
    {
        "dcterms:creator": [
            "Yizhong Wang",
            "Swaroop Mishra",
            "Pegah Alipoormolabashi",
            "Yeganeh Kordi",
            "Amirreza Mirzaei",
            "Atharva Naik",
            "Arjun Ashok",
            "Arut Selvan Dhanasekaran",
            "Anjana Arunkumar",
            "David Stap",
            "Eshaan Pathak",
            "Giannis Karamanolakis",
            "Haizhi Lai",
            "Ishan Purohit",
            "Ishani Mondal",
            "Jacob Anderson",
            "Kirby Kuznia",
            "Krima Doshi",
            "Kuntal Kumar Pal",
            "Maitreya Patel",
            "Mehrad Moradshahi",
            "Mihir Parmar",
            "Mirali Purohit",
            "Neeraj Varshney",
            "Phani Rohitha Kaza",
            "Pulkit Verma",
            "Ravsehaj Singh Puri",
            "Rushang Karia",
            "Savan Doshi",
            "Shailaja Keyur Sampat",
            "Siddhartha Mishra",
            "Sujan Reddy A",
            "Sumanta Patro",
            "Tanay Dixit",
            "Xudong Shen"
        ],
        "dcterms:description": "The Super-NaturalInstructions dataset comprises 1,616 diverse NLP tasks, each containing task instructions, positive/negative examples, and instances. It serves as a source for creating pseudo-code prompts for various NLP tasks.",
        "dcterms:title": "Super-NaturalInstructions",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Dataset for NLP Tasks"
        ],
        "dcat:keyword": [
            "NLP tasks",
            "dataset",
            "instructions",
            "examples",
            "pseudo-code"
        ],
        "dcat:landingPage": "https://github.com/mayank31398/pseudo-code-instructions",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Classification",
            "Question Answering",
            "Language Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Daniel Khashabi",
            "Snigdha Chaturvedi",
            "Michael Roth",
            "Shyam Upadhyay",
            "Dan Roth"
        ],
        "dcterms:description": "MultiRC is a challenge set for reading comprehension over multiple sentences, focusing on understanding and reasoning across a set of sentences.",
        "dcterms:title": "MultiRC",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "reading comprehension",
            "multi-sentence",
            "challenge set"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Qiang Ning Ben Zhou",
            "Daniel Khashabi",
            "Dan Roth"
        ],
        "dcterms:description": "McTaco is a dataset that studies temporal commonsense understanding, focusing on the time it takes to perform various actions.",
        "dcterms:title": "McTaco",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "temporal reasoning",
            "commonsense understanding",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Wenhan Xiong",
            "Jiawei Wu",
            "Hong Wang",
            "Vivek Kulkarni",
            "Mo Yu",
            "Shiyu Chang",
            "Xiaoxiao Guo",
            "William Yang Wang"
        ],
        "dcterms:description": "TWEETQA is a social media focused question answering dataset that aims to evaluate models on their ability to answer questions based on tweets.",
        "dcterms:title": "TWEETQA",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Social Media"
        ],
        "dcat:keyword": [
            "question answering",
            "social media",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Dheeru Dua",
            "Yizhong Wang",
            "Pradeep Dasigi",
            "Gabriel Stanovsky",
            "Sameer Singh",
            "Matt Gardner"
        ],
        "dcterms:description": "DROP is a reading comprehension benchmark that requires discrete reasoning over paragraphs, focusing on understanding and reasoning based on provided text.",
        "dcterms:title": "DROP",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "reading comprehension",
            "discrete reasoning",
            "benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Jian Zhang",
            "Konstantin Lopyrev",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD is a large-scale dataset containing over 100,000 questions for machine comprehension of text, designed to evaluate models on their ability to answer questions based on provided passages.",
        "dcterms:title": "SQuAD",
        "dcterms:issued": "2016",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "machine comprehension",
            "question answering",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Matthew Kelcey",
            "Jacob Devlin",
            "Kenton Lee",
            "Kristina N. Toutanova",
            "Llion Jones",
            "Ming-Wei Chang",
            "Andrew Dai",
            "Jakob Uszkoreit",
            "Quoc Le",
            "Slav Petrov"
        ],
        "dcterms:description": "Natural Questions is a benchmark dataset for question answering research, focusing on natural questions and their corresponding answers.",
        "dcterms:title": "Natural Questions",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "question answering",
            "benchmark",
            "natural questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Warstadt",
            "Amanpreet Singh",
            "Samuel R. Bowman"
        ],
        "dcterms:description": "CoLA is a dataset for neural network acceptability judgments, focusing on the acceptability of sentences in English.",
        "dcterms:title": "CoLA",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Linguistic Acceptability",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "acceptability judgments",
            "linguistics",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Linguistic Acceptability"
        ]
    },
    {
        "dcterms:creator": [
            "Yanran Li",
            "Hui Su",
            "Xiaoyu Shen",
            "Wenjie Li",
            "Ziqiang Cao",
            "Shuzi Niu"
        ],
        "dcterms:description": "DailyDialog is a manually labelled multi-turn dialogue dataset that focuses on daily communication and conversation.",
        "dcterms:title": "DailyDialog",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "dialogue dataset",
            "multi-turn conversation",
            "daily communication"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Cynthia Van Hee",
            "Els Lefever",
            "VÃ©ronique Hoste"
        ],
        "dcterms:description": "SemEval2018-Task3 is a dataset for irony detection in English tweets, focusing on identifying ironic statements in social media.",
        "dcterms:title": "SemEval2018-Task3",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentiment Analysis",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "irony detection",
            "tweets",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentiment Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Alexis Conneau",
            "Douwe Kiela"
        ],
        "dcterms:description": "SentEval is an evaluation toolkit for universal sentence representations, designed to assess the quality of sentence embeddings.",
        "dcterms:title": "SentEval",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Sentence Representation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "sentence embeddings",
            "evaluation toolkit",
            "universal representations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence Representation Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Maarten Sap",
            "Ronan Le Bras",
            "Emily Allaway",
            "Chandra Bhagavatula",
            "Nicholas Lourie",
            "Hannah Rashkin",
            "Brendan Roof",
            "Noah A. Smith",
            "Yejin Choi"
        ],
        "dcterms:description": "ATOMIC is an atlas of machine commonsense for if-then reasoning, providing a structured dataset for commonsense reasoning tasks.",
        "dcterms:title": "ATOMIC",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "commonsense reasoning",
            "if-then reasoning",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Kai Sun",
            "Dian Yu",
            "Jianshu Chen",
            "Dong Yu",
            "Yejin Choi",
            "Claire Cardie"
        ],
        "dcterms:description": "DREAM is a challenge dataset and models for dialogue-based reading comprehension, focusing on understanding dialogues.",
        "dcterms:title": "DREAM",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Dialogue Systems",
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "dialogue comprehension",
            "reading comprehension",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "MultiNLI is a large annotated corpus for learning natural language inference, providing a diverse set of sentence pairs for inference tasks.",
        "dcterms:title": "MultiNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "natural language inference",
            "dataset",
            "sentence pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Samuel R. Bowman",
            "Gabor Angeli",
            "Christopher Potts",
            "Christopher D. Manning"
        ],
        "dcterms:description": "SNLI is a large annotated corpus for learning natural language inference, providing a diverse set of sentence pairs for inference tasks.",
        "dcterms:title": "SNLI",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "natural language inference",
            "dataset",
            "sentence pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "cjadams",
            "Daniel Borkan",
            "inversion",
            "Jeffrey Sorensen",
            "Lucas Dixon",
            "Lucy Vasserman",
            "nithum"
        ],
        "dcterms:description": "Jigsaw is a dataset focused on unintended bias in toxicity classification, aiming to evaluate models on their ability to classify toxic comments.",
        "dcterms:title": "Jigsaw",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Classification",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "toxicity classification",
            "bias",
            "dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Classification"
        ]
    }
]