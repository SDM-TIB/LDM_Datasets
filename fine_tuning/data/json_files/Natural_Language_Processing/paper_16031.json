[
    {
        "dcterms:creator": [],
        "dcterms:description": "A diverse mix instruction dataset created from multiple open-source datasets, containing 47,986 instructions and samples across 6,270 different tags.",
        "dcterms:title": "DIVINSTRUCT",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "instruction dataset",
            "diverse mix",
            "open-source"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Xuechen Li",
            "Tianyi Zhang",
            "Yann Dubois",
            "Rohan Taori",
            "Ishaan Gulrajani",
            "Carlos Guestrin",
            "Percy Liang",
            "Tatsunori B. Hashimoto"
        ],
        "dcterms:description": "An automatic evaluator of instruction-following models, consisting of 5 subsets from various evaluation sets.",
        "dcterms:title": "AlpacaEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/alpaca_eval",
        "dcat:theme": [],
        "dcat:keyword": [
            "evaluation",
            "instruction-following",
            "automatic evaluator"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/alpaca_eval",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Seonghyeon Ye",
            "Doyoung Kim",
            "Sungdong Kim",
            "Hyeonbin Hwang",
            "Seungone Kim",
            "Yongrae Jo",
            "James Thorne",
            "Juho Kim",
            "Minjoon Seo"
        ],
        "dcterms:description": "A fine-grained evaluation dataset for alignment across 10 domains.",
        "dcterms:title": "FLASK",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "evaluation",
            "alignment",
            "fine-grained"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Wei-Lin Chiang",
            "Zhuohan Li",
            "Zi Lin",
            "Ying Sheng",
            "Zhanghao Wu",
            "Hao Zhang",
            "Lianmin Zheng",
            "Siyuan Zhuang",
            "Yonghao Zhuang",
            "Joseph E. Gonzalez",
            "Ion Stoica",
            "Eric P. Xing"
        ],
        "dcterms:description": "A multi-turn evaluation benchmark across various aspects, including mathematics and coding.",
        "dcterms:title": "MT-Bench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "evaluation",
            "multi-turn",
            "benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A benchmark for measuring massive multitask language understanding.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "benchmark",
            "multitask",
            "language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano"
        ],
        "dcterms:description": "A dataset for training verifiers to solve math word problems.",
        "dcterms:title": "GSM8K",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.14168",
        "dcat:theme": [],
        "dcat:keyword": [
            "math",
            "word problems",
            "verifiers"
        ],
        "dcat:landingPage": "arXiv:2110.14168",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Mark Chen",
            "et al."
        ],
        "dcterms:description": "A dataset for evaluating large language models trained on code.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "evaluation",
            "code",
            "language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]