[
    {
        "dcterms:creator": [
            "D. Paperno",
            "G. Kruszewski",
            "A. Lazaridou",
            "Q. N. Pham",
            "R. Bernardi",
            "S. Pezzelle",
            "M. Baroni",
            "G. Boleda",
            "R. Fern√°ndez"
        ],
        "dcterms:description": "The LAMBADA dataset is designed for word prediction tasks that require a broad discourse context.",
        "dcterms:title": "LAMBADA",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1606.06031",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Word prediction",
            "Discourse context",
            "Language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word prediction"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Basart",
            "A. Zou",
            "M. Mazeika",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "MMLU is a benchmark for measuring massive multitask language understanding across various tasks.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [
            "Natural Language Processing",
            "Multitask Learning"
        ],
        "dcat:keyword": [
            "Multitask evaluation",
            "Language understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Multitask evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Talmor",
            "J. Herzig",
            "N. Lourie",
            "J. Berant"
        ],
        "dcterms:description": "Common Sense QA is a question answering challenge that targets commonsense knowledge.",
        "dcterms:title": "Common Sense QA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Commonsense knowledge",
            "Question answering",
            "Challenge"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question answering"
        ]
    },
    {
        "dcterms:creator": [
            "K. Sakaguchi",
            "R. Le Bras",
            "C. Bhagavatula",
            "Y. Choi"
        ],
        "dcterms:description": "WinoGrande is an adversarial challenge based on the Winograd schema, designed to test commonsense reasoning.",
        "dcterms:title": "WinoGrande",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Adversarial challenge",
            "Commonsense reasoning",
            "Winograd schema"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "S. Tata",
            "J. M. Patel"
        ],
        "dcterms:description": "PIQA is a dataset designed for querying protein data sets.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2003",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bioinformatics",
            "Data Querying"
        ],
        "dcat:keyword": [
            "Protein data",
            "Querying",
            "Bioinformatics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Data querying"
        ]
    },
    {
        "dcterms:creator": [
            "R. Zellers",
            "A. Holtzman",
            "Y. Bisk",
            "A. Farhadi",
            "Y. Choi"
        ],
        "dcterms:description": "HellaSwag is a dataset that challenges models to complete sentences in a coherent manner.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1905.07830",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Sentence completion",
            "Coherence",
            "Language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Sentence completion"
        ]
    },
    {
        "dcterms:creator": [
            "L. Gao",
            "S. Biderman",
            "S. Black",
            "L. Golding",
            "T. Hoppe",
            "C. Foster",
            "J. Phang",
            "H. He",
            "A. Thite",
            "N. Nabeshima"
        ],
        "dcterms:description": "The Pile is a large dataset of diverse text for language modeling.",
        "dcterms:title": "Pile",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2101.00027",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Diverse text",
            "Language modeling",
            "Large dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling"
        ]
    }
]