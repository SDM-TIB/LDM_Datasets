[
    {
        "dcterms:creator": [
            "Yuanyuan Mao",
            "Xin Lin",
            "Qin Ni",
            "Liang He"
        ],
        "dcterms:description": "BDIQA is a benchmark dataset designed to explore cognitive reasoning capabilities in Video Question Answering (VideoQA) models, focusing on Belief, Desire, and Intention (BDI) reasoning through a two-level structure inspired by children's cognitive development.",
        "dcterms:title": "BDIQA",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cognitive Reasoning",
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Cognitive Intelligence",
            "Theory of Mind",
            "VideoQA",
            "BDI Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Cognitive Reasoning",
            "Video Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "X. Puig",
            "T. Shu",
            "S. Li",
            "Z. Wang",
            "Y.-H. Liao",
            "J. B. Tenenbaum",
            "S. Fidler",
            "A. Torralba"
        ],
        "dcterms:description": "VirtualHome is a dataset used to generate videos for household activities, providing a rich environment for simulating human actions and interactions.",
        "dcterms:title": "VirtualHome",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Simulation",
            "Human Interaction"
        ],
        "dcat:keyword": [
            "Household Activities",
            "Video Generation",
            "Human Actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Generation",
            "Action Simulation"
        ]
    },
    {
        "dcterms:creator": [
            "K. Yi",
            "C. Gan",
            "Y. Li",
            "P. Kohli",
            "J. Wu",
            "A. Torralba",
            "J. B. Tenenbaum"
        ],
        "dcterms:description": "CLEVRER is a dataset designed for video representation and reasoning, focusing on collision events to enhance understanding of temporal dynamics in videos.",
        "dcterms:title": "CLEVRER",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1910.01442",
        "dcat:theme": [
            "Video Reasoning",
            "Temporal Dynamics"
        ],
        "dcat:keyword": [
            "Collision Events",
            "Video Representation",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Video Reasoning",
            "Temporal Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "J. Mao",
            "X. Yang",
            "X. Zhang",
            "N. Goodman",
            "J. Wu"
        ],
        "dcterms:description": "CLEVRER-Human is a dataset that describes physical and causal events from a human perspective, enhancing the understanding of human-like reasoning in video contexts.",
        "dcterms:title": "CLEVRER-Human",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Reasoning",
            "Causal Understanding"
        ],
        "dcat:keyword": [
            "Physical Events",
            "Causal Reasoning",
            "Human Perspective"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Causal Reasoning",
            "Human-like Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "A. Miech",
            "D. Zhukov",
            "J.-B. Alayrac",
            "M. Tapaswi",
            "I. Laptev",
            "J. Sivic"
        ],
        "dcterms:description": "HowTo100M is a large-scale dataset for learning text-video embeddings by watching narrated video clips, facilitating the understanding of video content through language.",
        "dcterms:title": "HowTo100M",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text-Video Learning",
            "Multimodal Learning"
        ],
        "dcat:keyword": [
            "Text-Video Embedding",
            "Narrated Videos",
            "Large-scale Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Text-Video Learning",
            "Multimodal Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "W. Kay",
            "J. Carreira",
            "K. Simonyan",
            "B. Zhang",
            "C. Hillier",
            "S. Vijayanarasimhan",
            "F. Viola",
            "T. Green",
            "T. Back",
            "P. Natsev"
        ],
        "dcterms:description": "Kinetics is a human action video dataset that provides a large collection of videos for action recognition tasks, focusing on diverse human activities.",
        "dcterms:title": "Kinetics",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1705.06950",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Human Actions",
            "Video Dataset",
            "Action Recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Video Classification"
        ]
    },
    {
        "dcterms:creator": [
            "K. Gandhi",
            "G. Stojnic",
            "B. M. Lake",
            "M. R. Dillon"
        ],
        "dcterms:description": "The Baby Intuitions Benchmark (BIB) is designed to discern the goals, preferences, and actions of others, providing insights into early cognitive development.",
        "dcterms:title": "Baby Intuitions Benchmark (BIB)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cognitive Development",
            "Psychological Reasoning"
        ],
        "dcat:keyword": [
            "Cognitive Development",
            "Intuition",
            "Psychological Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Cognitive Reasoning",
            "Psychological Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "T. Shu",
            "A. Bhandwaldar",
            "C. Gan",
            "K. Smith",
            "S. Liu",
            "D. Gutfreund",
            "E. Spelke",
            "J. Tenenbaum",
            "T. Ullman"
        ],
        "dcterms:description": "Agent is a benchmark for core psychological reasoning, focusing on understanding the mental states and reasoning processes of agents.",
        "dcterms:title": "Agent",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Psychological Reasoning",
            "Cognitive Science"
        ],
        "dcat:keyword": [
            "Core Psychological Reasoning",
            "Mental States",
            "Agent Understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Psychological Reasoning",
            "Cognitive Understanding"
        ]
    }
]