[
    {
        "dcterms:creator": [
            "Yixuan Li",
            "Lihan Jiang",
            "Linning Xu",
            "Yuanbo Xiangli",
            "Zhenzhi Wang",
            "Dahua Lin",
            "Bo Dai"
        ],
        "dcterms:description": "MatrixCity is a comprehensive and high-quality synthetic dataset for city-scale neural rendering, containing 67k aerial images and 452k street images from two city maps. It allows for flexible control over environmental factors like lighting and weather, and includes additional properties such as depth and normal maps.",
        "dcterms:title": "MatrixCity",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://city-super.github.io/matrixcity/",
        "dcat:theme": [
            "Neural Rendering",
            "Urban Scene Understanding"
        ],
        "dcat:keyword": [
            "Synthetic Dataset",
            "City-scale",
            "Neural Rendering",
            "Aerial Images",
            "Street Images",
            "Depth Maps",
            "Normal Maps"
        ],
        "dcat:landingPage": "https://city-super.github.io/matrixcity/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Neural Rendering",
            "Depth Estimation",
            "Inverse Rendering"
        ]
    },
    {
        "dcterms:creator": [
            "Matthew Tancik",
            "Vincent Casser",
            "Xinchen Yan",
            "Sabeek Pradhan",
            "Ben P. Mildenhall",
            "Pratul P. Srinivasan",
            "Jonathan T. Barron",
            "Henrik Kretzschmar"
        ],
        "dcterms:description": "Block-NeRF is a dataset that enables scalable large scene neural view synthesis, focusing on urban environments by dividing them into smaller blocks for better modeling.",
        "dcterms:title": "Block-NeRF",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Rendering",
            "Urban Scene Understanding"
        ],
        "dcat:keyword": [
            "Neural View Synthesis",
            "Urban Environments",
            "Block Modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Neural View Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Liqiang Lin",
            "Yilin Liu",
            "Yue Hu",
            "Xingguang Yan",
            "Ke Xie",
            "Hui Huang"
        ],
        "dcterms:description": "UrbanScene3D is a dataset that captures, reconstructs, and simulates urban environments, providing a benchmark for urban scene understanding.",
        "dcterms:title": "UrbanScene3D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Urban Scene Understanding",
            "3D Reconstruction"
        ],
        "dcat:keyword": [
            "Urban Environments",
            "3D Reconstruction",
            "Simulation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Urban Scene Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Yiyi Liao",
            "Jun Xie",
            "Andreas Geiger"
        ],
        "dcterms:description": "KITTI-360 is a novel dataset and benchmark for urban scene understanding in both 2D and 3D, providing comprehensive data for various tasks.",
        "dcterms:title": "KITTI-360",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Urban Scene Understanding",
            "Autonomous Driving"
        ],
        "dcat:keyword": [
            "Urban Scenes",
            "2D and 3D Benchmark",
            "Autonomous Driving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Urban Scene Understanding",
            "Autonomous Driving"
        ]
    },
    {
        "dcterms:creator": [
            "Holger Caesar",
            "Varun Bankiti",
            "Alex H Lang",
            "Sourabh Vora",
            "Venice Erin Liong",
            "Qiang Xu",
            "Anush Krishnan",
            "Yu Pan",
            "Giancarlo Baldan",
            "Oscar Beijbom"
        ],
        "dcterms:description": "NuScenes is a multi-modal dataset for autonomous driving, providing a rich set of data for various perception tasks.",
        "dcterms:title": "NuScenes",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Multi-modal Perception"
        ],
        "dcat:keyword": [
            "Autonomous Driving",
            "Multi-modal Dataset",
            "Perception Tasks"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Autonomous Driving"
        ]
    },
    {
        "dcterms:creator": [
            "Chongshan Lu",
            "Fukun Yin",
            "Xin Chen",
            "Tao Chen",
            "Gang Yu",
            "Jiayuan Fan"
        ],
        "dcterms:description": "OMMO is a large-scale outdoor multi-modal dataset and benchmark for novel view synthesis and implicit scene reconstruction.",
        "dcterms:title": "OMMO",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Novel View Synthesis",
            "Implicit Scene Reconstruction"
        ],
        "dcat:keyword": [
            "Outdoor Dataset",
            "Multi-modal",
            "Novel View Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Novel View Synthesis",
            "Scene Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "Arno Knapitsch",
            "Jaesik Park",
            "Qian-Yi Zhou",
            "Vladlen Koltun"
        ],
        "dcterms:description": "Mill 19 is a dataset used for benchmarking large-scale scene reconstruction, providing a set of challenging scenes for evaluation.",
        "dcterms:title": "Mill 19",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Scene Reconstruction",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Large-scale Scene",
            "Benchmarking",
            "Reconstruction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Scene Reconstruction"
        ]
    },
    {
        "dcterms:creator": [
            "David J. Crandall",
            "Andrew Owens",
            "Noah Snavely",
            "Daniel P. Huttenlocher"
        ],
        "dcterms:description": "Quad 6K is a dataset focused on large-scale structure from motion, providing a set of images for evaluating discrete-continuous optimization methods.",
        "dcterms:title": "Quad 6K",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Structure from Motion",
            "3D Reconstruction"
        ],
        "dcat:keyword": [
            "Structure from Motion",
            "Large-scale Dataset",
            "3D Reconstruction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Structure from Motion"
        ]
    }
]