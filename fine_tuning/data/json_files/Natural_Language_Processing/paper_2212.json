[
    {
        "dcterms:creator": [
            "J. Pennington",
            "R. Socher",
            "C. Manning"
        ],
        "dcterms:description": "The dataset is a shortening of Wikipedia Text and has 100MB in size. It includes five types of semantic questions and nine types of syntactic questions, creating a vocabulary of size 71290, 253854 unique words and 17005207 tokens.",
        "dcterms:title": "text8",
        "dcterms:issued": "2014",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Word Embeddings"
        ],
        "dcat:keyword": [
            "Text dataset",
            "Word representation",
            "Semantic questions",
            "Syntactic questions"
        ],
        "dcat:landingPage": "http://mattmahoney.net/dc/textdata.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word analogy task",
            "Text classification"
        ]
    }
]