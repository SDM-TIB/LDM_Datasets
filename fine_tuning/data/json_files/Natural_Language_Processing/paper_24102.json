[
    {
        "dcterms:creator": [
            "D. Vrandeˇci´c",
            "M. Krötzsch"
        ],
        "dcterms:description": "The Wikipedia dataset includes cleaned articles in various languages, sourced from Wikipedia dumps. Each language has a separate subset, with examples representing entire articles. The content is cleaned by removing markdown and extra sections.",
        "dcterms:title": "Wikipedia",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Text corpus",
            "Knowledge base"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Wenzek",
            "M.-A. Lachaux",
            "A. Conneau",
            "V. Chaudhary",
            "F. Guzmán",
            "A. Joulin",
            "E. Grave"
        ],
        "dcterms:description": "The Common Crawl corpus is a vast collection of web data accumulated over more than 10 years through web crawling. It includes raw web page data, metadata extracts, and text extracts. This non-curated dataset includes web pages in numerous languages, providing a rich source for multilingual pre-training.",
        "dcterms:title": "Common Crawl (CC) Corpus",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Web data",
            "Multilingual",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "H. Laurençon",
            "L. Saulnier",
            "T. Wang",
            "C. Akiki",
            "A. Villanova del Moral",
            "T. Le Scao",
            "BigScience Workshop"
        ],
        "dcterms:description": "The Responsible Open-science Open-collaboration Text Sources (ROOTS) corpus is a comprehensive dataset developed by the BigScience workshop, an international and multidisciplinary initiative focusing on researching and LLMs with an emphasis on ethics, harm, and governance. Spanning 1.6 terabytes, the ROOTS corpus serves as a foundational resource for training large-scale language models.",
        "dcterms:title": "ROOTS",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Open science",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "J. Abadji",
            "P. Ortiz Suarez",
            "L. Romary",
            "B. Sagot"
        ],
        "dcterms:description": "The OSCAR project is an open-source initiative aimed at providing web-based multilingual data for ML and AI applications. It offers large quantities of raw data obtained through high-performance data pipelines. OSCAR focuses on improving data quality, particularly for low-resource languages.",
        "dcterms:title": "OSCAR",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Web data",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Gao",
            "S. Biderman",
            "S. Black",
            "L. Golding",
            "T. Hoppe",
            "C. Foster"
        ],
        "dcterms:description": "OpenWebText2 is an improved version of the original OpenWebTextCorpus. It covers all Reddit posts from 2005 to April 2020, with additional months becoming available over time. This dataset is an additional contribution to the diverse training material for multilingual language models.",
        "dcterms:title": "WebText2",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Social media",
            "Text corpus",
            "Multilingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "T. Brown",
            "B. Mann",
            "N. Ryder",
            "M. Subbiah",
            "J. D. Kaplan",
            "P. Dhariwal"
        ],
        "dcterms:description": "Books1 and Books2 comprise internet-based book corpora, featuring a random sampling of public domain books, as well as modern published literature in e-book format. The contents are drawn from available online books, offering a mix of historical and contemporary literature.",
        "dcterms:title": "Books1 and Books2",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Books",
            "Literature",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "G. Wenzek",
            "M.-A. Lachaux",
            "A. Conneau",
            "V. Chaudhary",
            "F. Guzmán",
            "A. Joulin",
            "E. Grave"
        ],
        "dcterms:description": "CC25 is a dataset extracted from the Common Crawl, comprising of 25 languages and tokenized using the SentencePiece schema.",
        "dcterms:title": "CC25",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Web data",
            "Multilingual",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "C. Raffel",
            "N. Shazeer",
            "A. Roberts",
            "K. Lee",
            "S. Narang",
            "M. Matena"
        ],
        "dcterms:description": "C4 is a large-scale dataset designed for training language models, focusing on diverse text sources.",
        "dcterms:title": "C4",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Text corpus",
            "Diverse sources",
            "Multilingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "L. Xue",
            "N. Constant",
            "A. Roberts",
            "M. Kale",
            "R. Al-Rfou",
            "A. Siddhant"
        ],
        "dcterms:description": "mC4 is a multilingual dataset sampled from Common Crawl, comprising data in 101 languages.",
        "dcterms:title": "mC4",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multilingual",
            "Text corpus",
            "Common Crawl"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]