[
    {
        "dcterms:creator": [
            "T.W. Webb",
            "I. Sinha",
            "J.D. Cohen"
        ],
        "dcterms:description": "A deep neural network architecture inspired by the notion of role-filler variable binding in cognitive models of relational reasoning, enabling the rapid learning of relational patterns and generalization to novel inputs.",
        "dcterms:title": "Emergent Symbol Binding Network (ESBN)",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Relational Reasoning"
        ],
        "dcat:keyword": [
            "Symbol binding",
            "Relational reasoning",
            "Neural architecture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Relational Learning",
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "G. Kerg",
            "et al."
        ],
        "dcterms:description": "A neural architecture that computes a relation matrix over all pairs of object embeddings, enabling rapid learning and generalization of relational patterns.",
        "dcterms:title": "Compositional Relation Network (CoRelNet)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.48550/arXiv.2206.05056",
        "dcat:theme": [
            "Neural Networks",
            "Relational Reasoning"
        ],
        "dcat:keyword": [
            "Relation matrix",
            "Relational learning",
            "Neural architecture"
        ],
        "dcat:landingPage": "https://doi.org/10.48550/arXiv.2206.05056",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Relational Learning",
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Altabaa",
            "et al."
        ],
        "dcterms:description": "An architecture that implements relational cross-attention, allowing for the learning of relational patterns faster than traditional transformers.",
        "dcterms:title": "Abstractor",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Relational Reasoning"
        ],
        "dcat:keyword": [
            "Relational cross-attention",
            "Attention mechanism",
            "Neural architecture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Relational Learning",
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Santoro",
            "et al."
        ],
        "dcterms:description": "A neural network module designed for relational reasoning, focusing on pairwise comparisons between inputs.",
        "dcterms:title": "Relation Network",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Relational Reasoning"
        ],
        "dcat:keyword": [
            "Relational reasoning",
            "Neural architecture",
            "Pairwise comparison"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Relational Learning",
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "A. Graves",
            "G. Wayne",
            "I. Danihelka"
        ],
        "dcterms:description": "A neural network architecture that combines neural networks with external memory, enabling the model to learn and generalize from relational data.",
        "dcterms:title": "Neural Turing Machine (NTM)",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.48550/arXiv.1410.5401",
        "dcat:theme": [
            "Neural Networks",
            "Memory-Augmented Networks"
        ],
        "dcat:keyword": [
            "Neural Turing Machine",
            "Memory",
            "Relational learning"
        ],
        "dcat:landingPage": "https://doi.org/10.48550/arXiv.1410.5401",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Relational Learning",
            "Generalization"
        ]
    },
    {
        "dcterms:creator": [
            "S. Hochreiter",
            "J. Schmidhuber"
        ],
        "dcterms:description": "A type of recurrent neural network architecture that is capable of learning long-term dependencies.",
        "dcterms:title": "Long Short-Term Memory (LSTM)",
        "dcterms:issued": "1997",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Recurrent Neural Networks"
        ],
        "dcat:keyword": [
            "LSTM",
            "Recurrent neural network",
            "Long-term dependencies"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Sequence Learning",
            "Time Series Prediction"
        ]
    },
    {
        "dcterms:creator": [
            "A. Vaswani",
            "et al."
        ],
        "dcterms:description": "A neural network architecture that relies entirely on attention mechanisms, eliminating recurrence and convolutions.",
        "dcterms:title": "Transformer",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Neural Networks",
            "Attention Mechanisms"
        ],
        "dcat:keyword": [
            "Transformer",
            "Attention mechanism",
            "Neural architecture"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Neural Network Model",
        "mls:task": [
            "Sequence Learning",
            "Natural Language Processing"
        ]
    },
    {
        "dcterms:creator": [
            "T. Webb",
            "K.J. Holyoak",
            "H. Lu"
        ],
        "dcterms:description": "A dataset designed to evaluate emergent analogical reasoning capabilities in large language models.",
        "dcterms:title": "Visual Reasoning Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cognitive Science",
            "Visual Reasoning"
        ],
        "dcat:keyword": [
            "Visual reasoning",
            "Analogical reasoning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Reasoning",
            "Analogical Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Dulberg",
            "T. Webb",
            "J.D. Cohen"
        ],
        "dcterms:description": "A dataset used to model the development of counting in children, focusing on the give-N task.",
        "dcterms:title": "Give-N Task Dataset",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.48550/arXiv.2105.10577",
        "dcat:theme": [
            "Cognitive Science",
            "Developmental Psychology"
        ],
        "dcat:keyword": [
            "Counting",
            "Development",
            "Give-N task"
        ],
        "dcat:landingPage": "https://doi.org/10.48550/arXiv.2105.10577",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Counting",
            "Developmental Learning"
        ]
    }
]