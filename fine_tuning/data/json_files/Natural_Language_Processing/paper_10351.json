[
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset containing 27 medical dialogues in Chinese, designed to interact with large language models (LLMs) for evaluating their performance in medical contexts.",
        "dcterms:title": "Medical Dialogues Dataset",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Medical dialogues",
            "Chinese language",
            "Large language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue evaluation",
            "Medical response assessment"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset consisting of 7 case reports in Chinese, which includes detailed medical records and patient information for evaluating LLMs in medical scenarios.",
        "dcterms:title": "Case Reports Dataset",
        "dcterms:issued": "",
        "dcterms:language": "Chinese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medical",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Case reports",
            "Chinese language",
            "Large language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Case report evaluation",
            "Medical response assessment"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dataset-A is used to evaluate the adversarial success rate (ASR) of LLMs by rephrasing questions while maintaining their semantics.",
        "dcterms:title": "Dataset-A",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Adversarial success rate",
            "Robustness testing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robustness evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dataset-B is used to evaluate the noise success rate (NSR) of LLMs by rephrasing questions and changing their semantics.",
        "dcterms:title": "Dataset-B",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Noise success rate",
            "Robustness testing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robustness evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dataset-C is used to evaluate the input error success rate (IESR) of LLMs by introducing punctuation errors in the questions.",
        "dcterms:title": "Dataset-C",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Input error success rate",
            "Robustness testing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robustness evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dataset-D is used to evaluate the input error success rate (IESR) of LLMs by introducing grammatical errors in the questions.",
        "dcterms:title": "Dataset-D",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Input error success rate",
            "Robustness testing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robustness evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dataset-E is used to evaluate the input error success rate (IESR) of LLMs by introducing spelling errors in the questions.",
        "dcterms:title": "Dataset-E",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Input error success rate",
            "Robustness testing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Robustness evaluation"
        ]
    }
]