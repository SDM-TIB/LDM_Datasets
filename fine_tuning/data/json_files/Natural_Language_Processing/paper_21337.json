[
    {
        "dcterms:creator": [
            "Nils Reimers",
            "Iryna Gurevych"
        ],
        "dcterms:description": "Sentence Transformers are a type of model designed to convert sentences into high-dimensional vector representations, making them highly useful for a variety of natural language processing (NLP) tasks.",
        "dcterms:title": "Sentence Transformers",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/pdf/1908.10084.pdf",
        "dcat:theme": [
            "Natural Language Processing",
            "Sentence Embeddings"
        ],
        "dcat:keyword": [
            "Sentence embeddings",
            "NLP tasks",
            "Vector representations"
        ],
        "dcat:landingPage": "https://arxiv.org/pdf/1908.10084.pdf",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic similarity",
            "Information retrieval",
            "Clustering"
        ]
    },
    {
        "dcterms:creator": [
            "Jacob Devlin",
            "Ming-Wei Chang",
            "Kenton Lee",
            "Kristina Toutanova"
        ],
        "dcterms:description": "BERT is a deep learning model designed for natural language processing that learns contextual relations between words in a sentence.",
        "dcterms:title": "BERT",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1810.04805",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Deep learning",
            "Contextual relations",
            "Language model"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1810.04805",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Text classification"
        ]
    },
    {
        "dcterms:creator": [
            "Yinhan Liu",
            "Myle Ott",
            "Naman Goyal",
            "Jingfei Du",
            "Mandar Joshi",
            "Danqi Chen",
            "Omer Levy",
            "Mike Lewis",
            "Luke Zettlemoyer",
            "Veselin Stoyanov"
        ],
        "dcterms:description": "RoBERTa is a robustly optimized BERT pretraining approach that improves upon the original BERT model.",
        "dcterms:title": "RoBERTa",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1907.11692",
        "dcat:theme": [
            "Natural Language Processing",
            "Language Understanding"
        ],
        "dcat:keyword": [
            "Optimized BERT",
            "Pretraining",
            "Language model"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1907.11692",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Text classification"
        ]
    },
    {
        "dcterms:creator": [
            "Victor Sanh",
            "Lysandre Debut",
            "Julien Chaumond",
            "Thomas Wolf"
        ],
        "dcterms:description": "DistilBERT is a distilled version of BERT that is smaller, faster, cheaper, and lighter.",
        "dcterms:title": "DistilBERT",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1910.01108",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Optimization"
        ],
        "dcat:keyword": [
            "Distilled model",
            "Efficiency",
            "Language model"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1910.01108",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Text classification"
        ]
    },
    {
        "dcterms:creator": [
            "Zhenzhong Lan",
            "Mingda Chen",
            "Sebastian Goodman",
            "Kevin Gimpel",
            "Piyush Sharma",
            "Radu Soricut"
        ],
        "dcterms:description": "ALBERT is a lite version of BERT designed for self-supervised learning of language representations.",
        "dcterms:title": "ALBERT",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/1909.11942",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Optimization"
        ],
        "dcat:keyword": [
            "Lite model",
            "Self-supervised learning",
            "Language representation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1909.11942",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding",
            "Text classification"
        ]
    },
    {
        "dcterms:creator": [
            "Omar Khattab",
            "Matei Zaharia"
        ],
        "dcterms:description": "ColBERT is an efficient and effective passage search method that utilizes contextualized late interaction over BERT.",
        "dcterms:title": "ColBERT",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "https://arxiv.org/abs/2004.12832",
        "dcat:theme": [
            "Information Retrieval",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Passage search",
            "Contextualized interaction",
            "BERT"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2004.12832",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Information retrieval"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Facebook FAISS is a library for efficient similarity search and clustering of dense vectors.",
        "dcterms:title": "Facebook FAISS",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/facebookresearch/faiss",
        "dcat:theme": [
            "Data Management",
            "Similarity Search"
        ],
        "dcat:keyword": [
            "Vector database",
            "Similarity search",
            "Clustering"
        ],
        "dcat:landingPage": "https://github.com/facebookresearch/faiss",
        "dcterms:hasVersion": "",
        "dcterms:format": "Software",
        "mls:task": [
            "Similarity search",
            "Clustering"
        ]
    }
]