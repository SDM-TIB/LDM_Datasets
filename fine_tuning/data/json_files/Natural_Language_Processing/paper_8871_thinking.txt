To extract datasets from the research paper titled "Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?" by Wei Ma et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, methodology, and evaluation sections** to identify any datasets mentioned. The abstract mentions that the authors use two datasets, which indicates that I should look for their names and details.

In the **introduction**, the authors discuss the importance of code pre-trained models and their applications, but I need to find specific datasets. I will pay close attention to any references to datasets used for experiments.

Next, I will focus on the **evaluation setup** section, specifically **section 4.1 (Dataset and Pre-processing)**, where the authors summarize the datasets used:

1. **Java250**: This dataset is used for code classification and contains 75,000 training samples. The language is Java.

2. **POJ-104**: This dataset is used for code clone detection and is split into 32,000 training samples, 8,000 validation samples, and 12,000 test samples. The language is C/C++.

Now, I will check the **References section** to find the full citations for these datasets. The citations are crucial for proper attribution:

- For **Java250**, the citation is:
  > Ruchir Puri, David S Kung, Geert Janssen, Wei Zhang, Giacomo Domeniconi, Vladimir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey Decker, et al. *CodeNet: A large-scale AI for code dataset for learning a diversity of coding tasks*. arXiv preprint arXiv:2105.12655, 2021.

- For **POJ-104**, the citation is:
  > Lili Mou, Ge Li, Lu Zhang, Tao Wang, and Zhi Jin. *Convolutional neural networks over tree structures for programming language processing*. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence, pages 1287â€“1293, 2016.

After gathering this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will allow for a structured output that can be used for further analysis or integration into other systems.