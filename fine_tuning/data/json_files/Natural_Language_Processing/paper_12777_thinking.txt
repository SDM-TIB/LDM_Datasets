To extract datasets from the research paper titled "FAST: FONT-AGNOSTIC SCENE TEXT EDITING" by Alloy Das et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract provides a brief overview of the research, but the details about datasets are likely to be found in the experiments section.

Next, I will focus on **section 4 (Experiments)**, where the authors discuss the datasets used for training and evaluation. In this section, they mention two types of datasets:

1. **Synthetic Data**: The authors state that they utilized a dataset of 150,000 labeled images for supervised training, which is referenced from the work of Qu et al. Additionally, they mention the **Tamper-Syn2k dataset**, consisting of 2,000 paired images specifically designed for evaluation.

2. **Real Data**: The authors indicate that they used a dataset consisting of real scene images obtained from the **MOSTEL dataset**, which was generated using random cropped images from the ICDAR 2013, MLT-2017, and MLT-2019 datasets.

Now, I will look into the **References section** to find the full citations for these datasets:

- For the **Tamper-Syn2k dataset**, the citation is:
  > Yadong Qu, Qingfeng Tan, Hongtao Xie, Jianjun Xu, Yuxin Wang, and Yongdong Zhang. *Exploring stroke-level modifications for scene text editing*. arXiv preprint arXiv:2212.01982, 2022.

- For the **MOSTEL dataset**, the citation is:
  > Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, and Umapada Pal. *Stefann: scene text editor using font adaptive neural network*. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 13228–13237, 2020.

- For the **ICDAR 2013 dataset**, the citation is:
  > Dimosthenis Karatzas, Faisal Shafait, Seiichi Uchida, et al. *ICDAR 2013 robust reading competition*. In 2013 12th international conference on document analysis and recognition, pages 1484–1493. IEEE, 2013.

- For the **MLT-2017 dataset**, the citation is:
  > Nibal Nayef, Fei Yin, Imen Bizid, et al. *ICDAR2017 robust reading challenge on multi-lingual scene text detection and script identification-rrc-mlt*. In 2017 14th IAPR international conference on document analysis and recognition (ICDAR), volume 1, pages 1454–1459. IEEE, 2017.

- For the **MLT-2019 dataset**, the citation is:
  > Nibal Nayef, Yash Patel, Michal Busta, et al. *ICDAR2019 robust reading challenge on multi-lingual scene text detection and recognition—rrc-mlt-2019*. In 2019 International conference on document analysis and recognition (ICDAR), pages 1582–1587. IEEE, 2019.

After gathering all this information, I will compile the dataset entries, ensuring that each dataset is accurately described and properly cited. This will allow for a comprehensive understanding of the datasets used in the research paper.