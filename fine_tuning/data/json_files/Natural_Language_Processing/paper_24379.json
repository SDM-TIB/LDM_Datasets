[
    {
        "dcterms:creator": [
            "J. Zhou",
            "T. Lu",
            "S. Mishra",
            "S. Brahma",
            "S. Basu",
            "Y. Luan",
            "D. Zhou",
            "L. Hou"
        ],
        "dcterms:description": "A dataset for evaluating instruction-following capabilities of large language models, consisting of 541 verifiable instructions.",
        "dcterms:title": "IFEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction evaluation",
            "Language models",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "K. Cobbe",
            "V. Kosaraju",
            "M. Bavarian",
            "M. Chen",
            "H. Jun",
            "L. Kaiser",
            "M. Plappert",
            "J. Tworek",
            "J. Hilton",
            "R. Nakano"
        ],
        "dcterms:description": "A benchmark dataset for evaluating mathematical problem-solving capabilities of language models, focusing on math word problems.",
        "dcterms:title": "GSM8k",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Mathematics"
        ],
        "dcat:keyword": [
            "Mathematical reasoning",
            "Language models",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematics"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Kadavath",
            "A. Arora",
            "S. Basart",
            "E. Tang",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "A dataset designed to measure the mathematical problem-solving abilities of language models, focusing on various mathematical concepts.",
        "dcterms:title": "MATH",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Mathematics"
        ],
        "dcat:keyword": [
            "Mathematical reasoning",
            "Language models",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Mathematics"
        ]
    },
    {
        "dcterms:creator": [
            "M. Chen",
            "J. Tworek",
            "H. Jun",
            "Q. Yuan",
            "H. Ponde de Oliveira Pinto",
            "J. Kaplan",
            "H. Edwards",
            "Y. Burda",
            "N. Joseph",
            "G. Brockman"
        ],
        "dcterms:description": "A dataset for evaluating the coding capabilities of language models, containing 164 programming tasks designed by human experts.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Coding"
        ],
        "dcat:keyword": [
            "Code generation",
            "Language models",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Coding"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Wang",
            "Z. Long",
            "Z. Fan",
            "Z. Wei",
            "X. Huang"
        ],
        "dcterms:description": "A dataset aimed at aligning language models with self-generated instructions to improve their performance on various tasks.",
        "dcterms:title": "Self-Instruct",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Self-generated instructions",
            "Language models",
            "Alignment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "A. Yang",
            "Y. Zheng",
            "X. Huang"
        ],
        "dcterms:description": "A framework for optimizing prompts using reinforcement learning to enhance the performance of language models.",
        "dcterms:title": "OPRO",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Prompt Optimization"
        ],
        "dcat:keyword": [
            "Prompt optimization",
            "Reinforcement learning",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "P. Chao",
            "A. Robey",
            "E. Dobriban",
            "H. Hassani",
            "G. J. Pappas",
            "E. Wong"
        ],
        "dcterms:description": "A dataset designed for evaluating the robustness of language models against adversarial queries.",
        "dcterms:title": "PAIR",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Robustness Evaluation"
        ],
        "dcat:keyword": [
            "Adversarial queries",
            "Language models",
            "Robustness"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": []
    }
]