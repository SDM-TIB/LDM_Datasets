[
    {
        "dcterms:creator": [],
        "dcterms:description": "A comprehensive benchmark and dataset specifically designed for fine-grained multimodal entity knowledge editing, encompassing tasks like Vanilla Name Answering, Entity-Level Caption, and Complex-Scenario Recognition.",
        "dcterms:title": "MIKE",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Knowledge Editing"
        ],
        "dcat:keyword": [
            "Fine-grained entities",
            "Multimodal knowledge editing",
            "Entity recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Knowledge Editing",
            "Entity Recognition",
            "Image Captioning"
        ]
    },
    {
        "dcterms:creator": [
            "H. Hu",
            "D. Li",
            "S. Savarese",
            "S. C. Hoi"
        ],
        "dcterms:description": "A dataset for open-domain visual entity recognition aimed at recognizing millions of Wikipedia entities.",
        "dcterms:title": "OVEN dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "abs/2302.11154",
        "dcat:theme": [
            "Visual Recognition",
            "Entity Recognition"
        ],
        "dcat:keyword": [
            "Open-domain",
            "Visual entities",
            "Wikipedia entities"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Entity Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "T. Kwiatkowski",
            "J. Palomaki",
            "O. Redfield",
            "M. Collins",
            "A. P. Parikh",
            "C. Alberti",
            "D. Epstein",
            "I. Polosukhin",
            "J. Devlin",
            "K. Lee",
            "K. Toutanova",
            "L. Jones",
            "M. Kelcey",
            "M. W. Chang",
            "A. M. Dai",
            "J. Uszkoreit",
            "Q. Le",
            "S. Petrov"
        ],
        "dcterms:description": "A benchmark dataset for question answering research, providing a set of natural questions.",
        "dcterms:title": "NQ Dataset",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Natural questions",
            "Question answering",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Cheng",
            "B. Tian",
            "Q. Liu",
            "X. Chen",
            "Y. Wang",
            "H. Chen",
            "N. Zhang"
        ],
        "dcterms:description": "A benchmark for testing the editability of multimodal large language models, focusing on knowledge editing.",
        "dcterms:title": "MMEdit",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multimodal Learning",
            "Knowledge Editing"
        ],
        "dcat:keyword": [
            "Multimodal editing",
            "Knowledge editing",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Knowledge Editing"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Hu",
            "H. Hua",
            "Z. Yang",
            "W. Shi",
            "N. A. Smith",
            "J. Luo"
        ],
        "dcterms:description": "A dataset for visual question answering that allows models to answer questions based on images.",
        "dcterms:title": "VQA (Visual Question Answering)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering"
        ],
        "dcat:keyword": [
            "Visual questions",
            "Answering",
            "Image understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Li",
            "Y. Zhang",
            "L. Chen",
            "J. Wang",
            "J. Yang",
            "Z. Liu"
        ],
        "dcterms:description": "A dataset that facilitates bootstrapping language-image pre-training with frozen image encoders and large language models.",
        "dcterms:title": "Image Caption",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Image Captioning"
        ],
        "dcat:keyword": [
            "Image captioning",
            "Language-image pre-training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Image Captioning"
        ]
    }
]