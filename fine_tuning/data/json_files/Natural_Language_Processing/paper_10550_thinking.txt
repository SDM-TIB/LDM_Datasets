To extract datasets from the research paper titled "Scaling Multilingual Corpora and Language Models to 500 Languages" by Ayyoob Imani et al., I will follow a systematic approach to identify and document the datasets mentioned in the paper, ensuring to include full citations for each dataset.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets that are explicitly mentioned. The abstract indicates the creation of **Glot500-c**, a corpus covering 511 languages, which suggests that this is a significant dataset.

Next, I will look for specific sections that detail the datasets used, particularly focusing on **section 3 (Glot2000-c)** and **section 5 (Training Data: Glot500-c)**. In these sections, the authors describe the corpus collection process and the datasets involved:

1. **Glot2000-c**: This is a large corpus that includes data from approximately 150 sources, covering 2266 languages. It is mentioned that this dataset is crucial for training the multilingual model.

2. **Glot500-c**: A subset of Glot2000-c, this dataset consists of 511 languages and is specifically used for training the Glot500-m model. The authors mention that it includes more than 30,000 sentences per language-script, which is a key criterion for inclusion.

Additionally, I will check the **References section** to find full citations for the datasets mentioned. The paper does not provide specific citations for Glot2000-c or Glot500-c, as they are original datasets created by the authors. However, I will note that the authors have made the code, data, and models available at their GitHub repository, which serves as a reference point for accessing these datasets.

Now, I will summarize the datasets identified:

- **Glot2000-c**: A comprehensive corpus covering 2266 languages, collected from various sources.
- **Glot500-c**: A refined subset of Glot2000-c, consisting of 511 languages, used for training the Glot500-m model.

Since these datasets are original contributions of the authors, I will note that they can be accessed via the provided GitHub link.

Finally, I will compile the dataset entries into a structured format for clarity and future reference.