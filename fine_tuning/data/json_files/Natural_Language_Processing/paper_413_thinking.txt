To extract datasets from the research paper titled "Emotional Embeddings: Refining Word Embeddings to Capture Emotional Content of Words" by Armin Seyeditabari et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to identify any datasets mentioned. The abstract discusses the incorporation of emotional information into word embeddings, which suggests that there may be datasets related to emotional lexicons or word embeddings.

In the **introduction**, the authors mention the use of an emotional lexicon and a psychological model of basic emotions. This indicates that there might be specific datasets referenced later in the paper.

Next, I will focus on the **methodology and experiments sections**. In the methodology, the authors describe using the **NRC emotion lexicon**, which is a key dataset for their approach. They mention extracting over 8,000 pairs of (word, emotion) relations from this lexicon, which is crucial for understanding their experimental setup.

In the **experiments section**, the authors compare various word embeddings, including **Word2Vec, GloVe, fastText, and ConceptNet Numberbatch**. While these are not datasets in the traditional sense, they are important resources that the authors used to evaluate their emotional embeddings.

Now, I will check the **References section** to find full citations for the datasets mentioned:

1. **NRC Emotion Lexicon**:
   > Saif M. Mohammad and Peter D. Turney. *Crowdsourcing a word–emotion association lexicon*. Computational Intelligence, 29(3):436–465, 2013.

2. **Word2Vec**:
   > Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. *Distributed representations of words and phrases and their compositionality*. In Advances in Neural Information Processing Systems, pages 3111–3119, 2013.

3. **GloVe**:
   > Jeffrey Pennington, Richard Socher, and Christopher D. Manning. *GloVe: Global Vectors for Word Representation*. Proceedings of the Empirical Methods in Natural Language Processing (EMNLP), 2014.

4. **fastText**:
   > Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov. *Enriching Word Vectors with Subword Information*. Transactions of the Association for Computational Linguistics, 5:135–146, 2017.

5. **ConceptNet Numberbatch**:
   > Robert Speer, Joshua Chin, and Catherine Havasi. *ConceptNet 5.5: An open multilingual graph of general knowledge*. arXiv preprint arXiv:1612.03975, 2016.

After gathering this information, I will compile the dataset entries into a structured format that highlights the datasets used in the research, ensuring that each entry includes the full citation for reference.