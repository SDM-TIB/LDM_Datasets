[
    {
        "dcterms:creator": [
            "D. L. Chen",
            "W. B. Dolan"
        ],
        "dcterms:description": "A dataset for open-ended video question answering, containing video clips and corresponding questions.",
        "dcterms:title": "MSVD-QA",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Question answering",
            "Open-ended questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Open-Ended VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xu",
            "T. Mei",
            "T. Yao",
            "Y. Rui"
        ],
        "dcterms:description": "A large video description dataset designed to bridge video and language, used for various video understanding tasks.",
        "dcterms:title": "MSRVTT-QA",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Video description",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Open-Ended VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Li",
            "Y. Zhang",
            "O. Zohar",
            "S. Yeung-Levy"
        ],
        "dcterms:description": "A dataset and benchmark for animated GIF description, focusing on understanding and generating descriptions for GIFs.",
        "dcterms:title": "TGIF-QA",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "GIF dataset",
            "Animated GIFs",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "GIF",
        "mls:task": [
            "Open-Ended VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Yu",
            "D. Xu",
            "J. Yu",
            "T. Yu",
            "Z. Zhao",
            "Y. Zhuang",
            "D. Tao"
        ],
        "dcterms:description": "A dataset for understanding complex web videos through question answering, focusing on various activities.",
        "dcterms:title": "ActivityNet-QA (or ANet-QA)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Complex web videos",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Open-Ended VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "J. Xiao",
            "X. Shang",
            "A. Yao",
            "T.-S. Chua"
        ],
        "dcterms:description": "A dataset for next-phase question answering that explains temporal actions in videos.",
        "dcterms:title": "NExTQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Temporal actions",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multiple Choice VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "K. Mangalam",
            "R. Akshulakov",
            "J. Malik"
        ],
        "dcterms:description": "A diagnostic benchmark for very long-form video language understanding, focusing on egocentric videos.",
        "dcterms:title": "EgoSchema",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Video Question Answering"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Long-form videos",
            "Question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multiple Choice VideoQA"
        ]
    },
    {
        "dcterms:creator": [
            "M. Maaz",
            "H. Rasheed",
            "S. Khan",
            "F. Khan"
        ],
        "dcterms:description": "A dataset for evaluating video understanding capabilities, focusing on correctness, detail orientation, and contextual understanding.",
        "dcterms:title": "VCGBench",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Text Generation"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Text generation",
            "Evaluation benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Generation"
        ]
    }
]