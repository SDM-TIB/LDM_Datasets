[
    {
        "dcterms:creator": [
            "S. Fujimoto",
            "H. Hoof",
            "D. Meger"
        ],
        "dcterms:description": "A benchmark for continuous control tasks used to evaluate reinforcement learning algorithms.",
        "dcterms:title": "OpenAI Gym",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Control Tasks"
        ],
        "dcat:keyword": [
            "Continuous control",
            "Reinforcement learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "G. Tang",
            "N. Kumar",
            "R. Yoo",
            "K. Michmizos"
        ],
        "dcterms:description": "A deep reinforcement learning framework utilizing population-coded spiking neural networks for continuous control tasks.",
        "dcterms:title": "PopSAN",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Spiking Neural Networks"
        ],
        "dcat:keyword": [
            "Population coding",
            "Spiking neural networks",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "D. Zhang",
            "T. Zhang",
            "S. Jia",
            "B. Xu"
        ],
        "dcterms:description": "An improved spiking actor network for reinforcement learning that utilizes multiscale dynamic coding.",
        "dcterms:title": "MDC-SAN",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Spiking Neural Networks"
        ],
        "dcat:keyword": [
            "Dynamic coding",
            "Spiking actor network",
            "Reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "S. Fujimoto",
            "H. Hoof",
            "D. Meger"
        ],
        "dcterms:description": "A deep reinforcement learning framework addressing function approximation error in actor-critic methods.",
        "dcterms:title": "DAN",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Actor-Critic Methods"
        ],
        "dcat:keyword": [
            "Function approximation",
            "Actor-critic",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "L. Qin",
            "R. Yan",
            "H. Tang"
        ],
        "dcterms:description": "A low latency adaptive coding spiking framework for deep reinforcement learning.",
        "dcterms:title": "AC-BCQ",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reinforcement Learning",
            "Spiking Neural Networks"
        ],
        "dcat:keyword": [
            "Adaptive coding",
            "Spiking framework",
            "Deep reinforcement learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Continuous Control"
        ]
    },
    {
        "dcterms:creator": [
            "T. P. Lillicrap",
            "J. J. Hunt",
            "A. Pritzel",
            "N. Heess",
            "T. Erez",
            "Y. Tassa",
            "D. Silver",
            "D. Wierstra"
        ],
        "dcterms:description": "A benchmark for evaluating deep reinforcement learning algorithms using Atari games.",
        "dcterms:title": "Atari Games",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "http://arxiv.org/abs/1509.02971",
        "dcat:theme": [
            "Reinforcement Learning",
            "Game AI"
        ],
        "dcat:keyword": [
            "Atari",
            "Deep reinforcement learning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Game Playing"
        ]
    }
]