[
    {
        "dcterms:creator": [],
        "dcterms:description": "A custom dataset created for the study, with around 4000 images in 3 categories: slouching, writing, and sitting upright.",
        "dcterms:title": "Custom Dataset for Gesture and Posture Recognition",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Gesture Recognition",
            "Posture Recognition"
        ],
        "dcat:keyword": [
            "Custom dataset",
            "Gesture recognition",
            "Posture recognition",
            "Images"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Gesture Recognition",
            "Posture Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Marc Tonsen",
            "Xucong Zhang",
            "Yusuke Sugano",
            "Andreas Bulling"
        ],
        "dcterms:description": "A dataset for pupil detection algorithms, consisting of videos with labeled pupils in various conditions.",
        "dcterms:title": "Labelled Pupils in the Wild (LPW)",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "10.1145/2857491.2857520",
        "dcat:theme": [
            "Eye Tracking"
        ],
        "dcat:keyword": [
            "Pupil detection",
            "Eye tracking",
            "Video dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.1145/2857491.2857520",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Pupil Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Kyle Krafka",
            "Aditya Khosla",
            "Petr Kellnhofer",
            "Harini Kannan",
            "Suchendra Bhandarkar",
            "Wojciech Matusik",
            "Antonio Torralba"
        ],
        "dcterms:description": "A dataset created by MIT for building software that can be used via remote electronic devices for eye tracking.",
        "dcterms:title": "GazeCapture",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Eye Tracking"
        ],
        "dcat:keyword": [
            "Eye tracking",
            "Remote devices",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Eye Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Joohwan Kim",
            "Michael Stengel",
            "Alexander Majercik",
            "Shalini De Mello",
            "David Dunn",
            "Samuli Laine",
            "Morgan McGuire",
            "David Luebke"
        ],
        "dcterms:description": "An anatomically-informed dataset for low-latency, near-eye gaze estimation.",
        "dcterms:title": "NVGaze",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "10.1145/3290605.3300780",
        "dcat:theme": [
            "Eye Tracking"
        ],
        "dcat:keyword": [
            "Gaze estimation",
            "Near-eye tracking",
            "Dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.1145/3290605.3300780",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Gaze Estimation"
        ]
    },
    {
        "dcterms:creator": [
            "Ian J. Goodfellow",
            "Dumitru Erhan",
            "Pierre Luc Carrier",
            "Aaron Courville",
            "Mehdi Mirza",
            "Ben Hamner",
            "Will Cukierski",
            "Yichuan Tang",
            "David Thaler",
            "Dong-Hyun Lee",
            "Yingbo Zhou",
            "Chetan Ramaiah",
            "Fangxiang Feng",
            "Ruifan Li",
            "Xiaojie Wang",
            "Dimitris Athanasakis",
            "John Shawe-Taylor",
            "Maxim Milakov",
            "John Park",
            "Radu Ionescu",
            "Marius Popescu",
            "Cristian Grozea",
            "James Bergstra",
            "Jingjing Xie",
            "Lukasz Romaszko",
            "Bing Xu",
            "Zhang Chuang",
            "Yoshua Bengio"
        ],
        "dcterms:description": "A dataset providing a wide array of images classified into the 7 most commonly identified emotions for Emotion Recognition.",
        "dcterms:title": "FER2013",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Emotion recognition",
            "Facial expressions",
            "Image dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "M. Lyons",
            "S. Akamatsu",
            "M. Kamachi",
            "J. Gyoba"
        ],
        "dcterms:description": "A dataset consisting of facial expressions from Japanese women, used for emotion recognition.",
        "dcterms:title": "Japanese Female Facial Expressions (JAFFE)",
        "dcterms:issued": "1998",
        "dcterms:language": "",
        "dcterms:identifier": "10.1109/AFGR.1998.670949",
        "dcat:theme": [
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion recognition",
            "Japanese dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Patrick Lucey",
            "Jeffrey F. Cohn",
            "Takeo Kanade",
            "Jason Saragih",
            "Zara Ambadar",
            "Iain Matthews"
        ],
        "dcterms:description": "A complete dataset for action unit and emotion-specified expression, including both posed and non-posed expressions.",
        "dcterms:title": "Extended Cohn-Kanade (CK+) Dataset",
        "dcterms:issued": "2010",
        "dcterms:language": "",
        "dcterms:identifier": "10.1109/CVPRW.2010.5543262",
        "dcat:theme": [
            "Facial Recognition"
        ],
        "dcat:keyword": [
            "Facial expressions",
            "Emotion recognition",
            "Action units"
        ],
        "dcat:landingPage": "https://doi.org/10.1109/CVPRW.2010.5543262",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Facial Expression Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Carlos Busso",
            "Murtaza Bulut",
            "Chi-Chun Lee",
            "Abe Kazemzadeh",
            "Emily Mower",
            "Samuel Kim",
            "Jeannette N. Chang",
            "Sungbok Lee",
            "Shrikanth S. Narayanan"
        ],
        "dcterms:description": "An interactive emotional dyadic motion capture database consisting of approximately 12 hours of data, with 151 videos and recorded audio.",
        "dcterms:title": "Interactive Emotional Dyadic Motion Capture (IEMOCAP)",
        "dcterms:issued": "2008",
        "dcterms:language": "",
        "dcterms:identifier": "10.1007/s10579-008-9076-6",
        "dcat:theme": [
            "Emotion Recognition"
        ],
        "dcat:keyword": [
            "Emotion recognition",
            "Video dataset",
            "Audio dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.1007/s10579-008-9076-6",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Steven Livingstone",
            "Frank Russo"
        ],
        "dcterms:description": "A dynamic, multimodal set of facial and vocal expressions in North American English, consisting of 7356 audio files.",
        "dcterms:title": "Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS)",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "10.1371/journal.pone.0196391",
        "dcat:theme": [
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Emotional speech",
            "Audio dataset",
            "Multimodal expressions"
        ],
        "dcat:landingPage": "https://doi.org/10.1371/journal.pone.0196391",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speech Emotion Recognition"
        ]
    }
]