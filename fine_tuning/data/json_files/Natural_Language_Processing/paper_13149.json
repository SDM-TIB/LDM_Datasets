[
    {
        "dcterms:creator": [
            "Yanhong Bai",
            "Jiabao Zhao",
            "Jinxin Shi",
            "Tingjiang Wei",
            "Xingjiao Wu",
            "Liang He"
        ],
        "dcterms:description": "Edu-FairMonitor is a benchmark consisting of 12,632 open-ended questions designed to evaluate stereotypes and biases in large language models, particularly in the context of education. It covers nine sensitive factors and 26 educational scenarios.",
        "dcterms:title": "Edu-FairMonitor",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Education"
        ],
        "dcat:keyword": [
            "Stereotypes",
            "Biases",
            "Large Language Models",
            "Open-ended Questions",
            "Education"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Detection",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Nadeem",
            "A. Bethke",
            "S. Reddy"
        ],
        "dcterms:description": "StereoSet is a dataset designed to measure stereotypical bias in pretrained language models through various prompts that elicit biased responses.",
        "dcterms:title": "StereoSet",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2004.09456",
        "dcat:theme": [
            "Bias Detection",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Stereotypical Bias",
            "Language Models",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Measurement"
        ]
    },
    {
        "dcterms:creator": [
            "A. Parrish",
            "A. Chen",
            "N. Nangia",
            "V. Padmakumar",
            "J. Phang",
            "J. Thompson",
            "P. M. Htut",
            "S. R. Bowman"
        ],
        "dcterms:description": "BBQ is a hand-built bias benchmark for question answering that assesses the presence of biases in model responses to various questions.",
        "dcterms:title": "BBQ",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2110.08193",
        "dcat:theme": [
            "Bias Detection",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Bias Benchmark",
            "Question Answering",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Detection",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Dhamala",
            "T. Sun",
            "V. Kumar",
            "S. Krishna",
            "Y. Pruksachatkun",
            "K.-W. Chang",
            "R. Gupta"
        ],
        "dcterms:description": "CrowSPair is a dataset and metrics for measuring biases in open-ended language generation, focusing on the evaluation of biases in generated content.",
        "dcterms:title": "CrowSPair",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Detection",
            "Language Generation"
        ],
        "dcat:keyword": [
            "Bias Measurement",
            "Open-ended Generation",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Detection",
            "Language Generation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Socioeconomic status/Occupation Dataset is used to analyze biases related to socioeconomic status and occupations in language models.",
        "dcterms:title": "Socioeconomic status/Occupation Dataset",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "V. K. Felkner",
            "H.-C. H. Chang",
            "E. Jang",
            "J. May"
        ],
        "dcterms:description": "WinoQueer is a community-in-the-loop benchmark designed to evaluate anti-LGBTQ+ bias in large language models through various prompts.",
        "dcterms:title": "WinoQueer",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2306.15087",
        "dcat:theme": [
            "Bias Detection",
            "LGBTQ+ Issues"
        ],
        "dcat:keyword": [
            "Anti-LGBTQ+ Bias",
            "Language Models",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Detection"
        ]
    }
]