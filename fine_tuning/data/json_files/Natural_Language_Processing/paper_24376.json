[
    {
        "dcterms:creator": [
            "Anton Milan",
            "Laura Leal-Taixé",
            "Ian Reid",
            "Stefan Roth",
            "Konrad Schindler"
        ],
        "dcterms:description": "The MOT16 dataset is primarily composed of surveillance camera footage meant for tracking humans, with additional labels for cars, bicycles, and motorcycles used as occlusions when calculating precision and recall of human tracks.",
        "dcterms:title": "MOT16",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1603.00831",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Surveillance",
            "Human tracking",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Patrick Dendorfer",
            "Hamid Rezatofighi",
            "Anton Milan",
            "Javen Shi",
            "Daniel Cremers",
            "Ian Reid",
            "Stefan Roth",
            "Konrad Schindler",
            "Laura Leal-Taixé"
        ],
        "dcterms:description": "MOT17 is an extension of the MOT16 dataset, designed for multi-object tracking in crowded scenes, focusing on the challenges of tracking multiple objects over time.",
        "dcterms:title": "MOT17",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2003.09003",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Crowded scenes",
            "Object tracking",
            "Surveillance"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Patrick Dendorfer",
            "Hamid Rezatofighi",
            "Anton Milan",
            "Javen Shi",
            "Daniel Cremers",
            "Ian Reid",
            "Stefan Roth",
            "Konrad Schindler",
            "Laura Leal-Taixé"
        ],
        "dcterms:description": "MOT20 is another iteration of the MOT datasets, aimed at benchmarking multi-object tracking in crowded scenes, with a focus on improving tracking accuracy and robustness.",
        "dcterms:title": "MOT20",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2003.09003",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Crowded scenes",
            "Object tracking",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Fisher Yu",
            "Haofeng Chen",
            "Xin Wang",
            "Wenqi Xian",
            "Yingying Chen",
            "Fangchen Liu",
            "Vashisht Madhavan",
            "Trevor Darrell"
        ],
        "dcterms:description": "The Berkeley Deep Drive (BDD) dataset is a diverse driving dataset designed for heterogeneous multitask learning, providing a variety of driving scenarios and annotations.",
        "dcterms:title": "Berkeley Deep Drive (BDD)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Driving dataset",
            "Multitask learning",
            "Object detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Detection",
            "Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Geiger",
            "Philip Lenz",
            "Raquel Urtasun"
        ],
        "dcterms:description": "The KITTI dataset is a benchmark suite for autonomous driving, providing various tasks including stereo, optical flow, visual odometry, and 3D object detection.",
        "dcterms:title": "KITTI",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Autonomous Driving",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "3D object detection",
            "Stereo vision",
            "Optical flow"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Object Detection",
            "Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Achal Dave",
            "Tarasha Khurana",
            "Pavel Tokmakov",
            "Cordelia Schmid",
            "Deva Ramanan"
        ],
        "dcterms:description": "Track Any Object (TAO) is a large-scale benchmark for tracking any object, featuring a long-tailed distribution of object classes.",
        "dcterms:title": "Track Any Object (TAO)",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Object tracking",
            "Long-tailed distribution",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Yang Liu",
            "Idil Esen Zulfikar",
            "Jonathon Luiten",
            "Achal Dave",
            "Deva Ramanan",
            "Bastian Leibe",
            "Aljoša Ošep",
            "Laura Leal-Taixé"
        ],
        "dcterms:description": "TAO-Open World is an extension of the TAO dataset that includes novel objects, aiming to reflect real-world scenarios where models encounter unseen objects.",
        "dcterms:title": "TAO-Open World",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Open world tracking",
            "Novel objects",
            "Benchmarking"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Jinkun Cao",
            "Xinshuo Weng",
            "Rawal Khirodkar",
            "Jiangmiao Pang",
            "Kris Kitani"
        ],
        "dcterms:description": "DanceTrack is a dataset focused on tracking dancers in various performances, emphasizing robust multi-object tracking in challenging scenarios.",
        "dcterms:title": "DanceTrack",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Dance tracking",
            "Robust tracking",
            "Performance analysis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    },
    {
        "dcterms:creator": [
            "Pavel Tokmakov",
            "Jie Li",
            "Wolfram Burgard",
            "Adrien Gaidon"
        ],
        "dcterms:description": "ParallelDomain is a synthetic dataset designed to improve tracking through occlusions, providing ground truth labels for objects behind occlusions.",
        "dcterms:title": "ParallelDomain",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Object Tracking",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Occlusion tracking",
            "Synthetic dataset",
            "Object permanence"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Multi-Object Tracking"
        ]
    }
]