[
    {
        "dcterms:creator": [
            "M. Mathew",
            "D. Karatzas",
            "C. V. Jawahar"
        ],
        "dcterms:description": "DocVQA is a dataset for visual question answering on document images, requiring a comprehensive understanding of document layouts and textual information.",
        "dcterms:title": "DocVQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Document Understanding"
        ],
        "dcat:keyword": [
            "Document images",
            "Visual Question Answering",
            "Text recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Mishra",
            "S. Shekhar",
            "A. K. Singh",
            "A. Chakraborty"
        ],
        "dcterms:description": "OCRVQA consists of images featuring book covers and includes over 1 million question-answer pairs related to these images, focusing on visual question answering by reading text in images.",
        "dcterms:title": "OCRVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Text Recognition"
        ],
        "dcat:keyword": [
            "Book covers",
            "Visual Question Answering",
            "Text recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. F. Biten",
            "R. Tito",
            "A. Mafla",
            "L. Gomez",
            "M. Rusinol",
            "E. Valveny",
            "C. V. Jawahar",
            "D. Karatzas"
        ],
        "dcterms:description": "StVQA is a dataset for scene text visual question answering, where understanding textual details within a scene is essential for accurate responses.",
        "dcterms:title": "StVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Scene Text Recognition"
        ],
        "dcat:keyword": [
            "Scene text",
            "Visual Question Answering",
            "Text recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "A. Singh",
            "V. Natarjan",
            "M. Shah",
            "Y. Jiang",
            "X. Chen",
            "D. Parikh",
            "M. Rohrbach"
        ],
        "dcterms:description": "TextVQA is a dataset that requires models to read and reason about texts in images to answer questions, emphasizing the integration of textual and visual information.",
        "dcterms:title": "TextVQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Question Answering",
            "Text Recognition"
        ],
        "dcat:keyword": [
            "Text in images",
            "Visual Question Answering",
            "Text recognition"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Visual Question Answering"
        ]
    }
]