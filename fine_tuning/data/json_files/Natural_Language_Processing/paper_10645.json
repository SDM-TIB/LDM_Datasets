[
    {
        "dcterms:creator": [
            "K. Sakaguchi",
            "R. Le Bras",
            "C. Bhagavatula",
            "Y. Choi"
        ],
        "dcterms:description": "An adversarial winograd schema challenge at scale.",
        "dcterms:title": "winogrande",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Adversarial dataset",
            "Winograd schema",
            "Natural language understanding"
        ],
        "dcat:landingPage": "https://github.com/allenai/winogrande",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bisk",
            "A. Holtzman",
            "J. Zettlemoyer"
        ],
        "dcterms:description": "A new benchmark for natural language understanding and reasoning.",
        "dcterms:title": "piqa",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Understanding"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Natural language reasoning"
        ],
        "dcat:landingPage": "https://yonatanbisk.com/piqa/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "N. Mostafazadeh",
            "M. Roth",
            "A. Louis",
            "N. Chambers",
            "J. Allen"
        ],
        "dcterms:description": "The story cloze test.",
        "dcterms:title": "storycloze",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Cloze test",
            "Story completion"
        ],
        "dcat:landingPage": "https://github.com/UKPLab/lsdsem2017-story-cloze",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Nie",
            "A. Williams",
            "E. Dinan",
            "M. Bansal",
            "J. Weston",
            "D. Kiela"
        ],
        "dcterms:description": "A new benchmark for natural language understanding.",
        "dcterms:title": "anlir1",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Adversarial NLI",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Nie",
            "A. Williams",
            "E. Dinan",
            "M. Bansal",
            "J. Weston",
            "D. Kiela"
        ],
        "dcterms:description": "A new benchmark for natural language understanding.",
        "dcterms:title": "anlir2",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Adversarial NLI",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Nie",
            "A. Williams",
            "E. Dinan",
            "M. Bansal",
            "J. Weston",
            "D. Kiela"
        ],
        "dcterms:description": "A new benchmark for natural language understanding.",
        "dcterms:title": "anlir3",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Adversarial NLI",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "C. Clark",
            "K. Lee",
            "M.-W. Chang",
            "T. Kwiatkowski",
            "M. Collins",
            "K. Toutanova"
        ],
        "dcterms:description": "Exploring the surprising difficulty of natural yes/no questions.",
        "dcterms:title": "boolq",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Understanding"
        ],
        "dcat:keyword": [
            "Yes/No questions",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "R. Roemmele",
            "C. Adrian Bejan",
            "A. S. Gordon"
        ],
        "dcterms:description": "An evaluation of commonsense causal reasoning.",
        "dcterms:title": "copa",
        "dcterms:issued": "2011",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Causal reasoning",
            "Commonsense reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "A. Wang",
            "Y. Pruksachatkun",
            "N. Nangia",
            "A. Singh",
            "J. Michael",
            "F. Hill",
            "O. Levy",
            "S. Bowman"
        ],
        "dcterms:description": "A stickier benchmark for general-purpose language understanding systems.",
        "dcterms:title": "rte",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Inference"
        ],
        "dcat:keyword": [
            "Natural language inference",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Natural Language Inference"
        ]
    },
    {
        "dcterms:creator": [
            "M. Pilehvar",
            "J. Camacho-Collados"
        ],
        "dcterms:description": "The word-in-context dataset for evaluating context-sensitive meaning representations.",
        "dcterms:title": "wic",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Word Sense Disambiguation"
        ],
        "dcat:keyword": [
            "Contextual meaning",
            "Word sense"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Word Sense Disambiguation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Levesque",
            "E. Davis",
            "L. Morgenstern"
        ],
        "dcterms:description": "The winograd schema challenge.",
        "dcterms:title": "wsc",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Winograd schema",
            "Natural language understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "P. Clark",
            "I. Cowhey",
            "O. Etzioni",
            "T. Khot",
            "A. Sabharwal",
            "C. Schoenick",
            "O. Tafjord"
        ],
        "dcterms:description": "Think you have solved question answering? Try ARC, the AI2 reasoning challenge.",
        "dcterms:title": "arc_e",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Question answering",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "P. Clark",
            "I. Cowhey",
            "O. Etzioni",
            "T. Khot",
            "A. Sabharwal",
            "C. Schoenick",
            "O. Tafjord"
        ],
        "dcterms:description": "Think you have solved question answering? Try ARC, the AI2 reasoning challenge.",
        "dcterms:title": "arc_c",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Question answering",
            "Reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "G. Lai",
            "Q. Xie",
            "H. Liu",
            "Y. Yang",
            "E. Hovy"
        ],
        "dcterms:description": "Large-scale Reading comprehension dataset from examinations.",
        "dcterms:title": "raceh",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Examinations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "G. Lai",
            "Q. Xie",
            "H. Liu",
            "Y. Yang",
            "E. Hovy"
        ],
        "dcterms:description": "Large-scale Reading comprehension dataset from examinations.",
        "dcterms:title": "racem",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Examinations"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "P. Paperno",
            "G. Kruszewski",
            "A. Lazaridou",
            "N. Q. Pham",
            "R. Bernardi",
            "S. Pezzelle",
            "M. Baroni",
            "G. Boleda",
            "R. Fernández"
        ],
        "dcterms:description": "Word prediction requiring a broad discourse context.",
        "dcterms:title": "lambada",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Modeling"
        ],
        "dcat:keyword": [
            "Word prediction",
            "Discourse context"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language Modeling"
        ]
    },
    {
        "dcterms:creator": [
            "J. Berant",
            "A. Chou",
            "R. Frostig",
            "P. Liang"
        ],
        "dcterms:description": "Semantic parsing on Freebase from question-answer pairs.",
        "dcterms:title": "web_questions",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Semantic Parsing"
        ],
        "dcat:keyword": [
            "Question answering",
            "Semantic parsing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Semantic Parsing"
        ]
    },
    {
        "dcterms:creator": [
            "T. Kwiatkowski",
            "J. Palomaki",
            "O. Redfield",
            "M. Collins",
            "A. Parikh",
            "C. Alberti",
            "D. Epstein",
            "I. Polosukhin",
            "J. Devlin",
            "K. Lee",
            "K. Toutanova",
            "L. Jones",
            "M. Kelcey",
            "M.-W. Chang",
            "A. M. Dai",
            "J. Uszkoreit",
            "Q. Le",
            "S. Petrov"
        ],
        "dcterms:description": "A benchmark for question answering research.",
        "dcterms:title": "natural_questions",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "M. Joshi",
            "E. Choi",
            "D. Weld",
            "L. Zettlemoyer"
        ],
        "dcterms:description": "A large scale distantly supervised challenge dataset for reading comprehension.",
        "dcterms:title": "triviaqa_wiki",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Reading comprehension",
            "Distant supervision"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    },
    {
        "dcterms:creator": [
            "P. Rajpurkar",
            "R. Jia",
            "P. Liang"
        ],
        "dcterms:description": "Unanswerable questions for SQuAD.",
        "dcterms:title": "squad",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Unanswerable questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Narayan",
            "S. B. Cohen",
            "M. Lapata"
        ],
        "dcterms:description": "Topic-aware convolutional neural networks for extreme summarization.",
        "dcterms:title": "xsum",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Summarization"
        ],
        "dcat:keyword": [
            "Summarization",
            "Extreme summarization"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "F. Ladhak",
            "E. Durmus",
            "C. Cardie",
            "K. McKeown"
        ],
        "dcterms:description": "A new benchmark dataset for cross-lingual abstractive summarization.",
        "dcterms:title": "wikilingua",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cross-lingual Summarization"
        ],
        "dcat:keyword": [
            "Abstractive summarization",
            "Cross-lingual"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "M. Suzgun",
            "N. Scales",
            "N. Schärli",
            "S. Gehrmann",
            "Y. Tay",
            "H. W. Chung",
            "A. Chowdhery",
            "Q. V. Le",
            "E. H. Chi",
            "D. Zhou"
        ],
        "dcterms:description": "Challenging big-bench tasks and whether chain-of-thought can solve them.",
        "dcterms:title": "BIG-Bench Hard",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reasoning"
        ],
        "dcat:keyword": [
            "Challenging tasks",
            "Reasoning"
        ],
        "dcat:landingPage": "https://github.com/suzgunmirac/BIG-Bench-Hard/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reasoning"
        ]
    }
]