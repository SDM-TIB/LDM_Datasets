[
    {
        "dcterms:creator": [
            "D. Damen",
            "H. Doughty",
            "G. M. Farinella",
            "S. Fidler",
            "A. Furnari",
            "E. Kazakos",
            "D. Moltisanti",
            "J. Munro",
            "T. Perrett",
            "W. Price"
        ],
        "dcterms:description": "The EpicKitchens dataset is designed for egocentric vision research, containing videos of cooking activities recorded from a first-person perspective.",
        "dcterms:title": "EpicKitchens-50",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Egocentric Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Cooking",
            "Egocentric Video",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Damen",
            "H. Doughty",
            "G. M. Farinella",
            "A. Furnari",
            "E. Kazakos",
            "J. Ma",
            "D. Moltisanti",
            "J. Munro",
            "T. Perrett",
            "W. Price"
        ],
        "dcterms:description": "EpicKitchens-100 is an expanded version of the original EpicKitchens dataset, featuring a larger collection of egocentric videos of cooking activities.",
        "dcterms:title": "EpicKitchens-100",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Egocentric Vision",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Cooking",
            "Egocentric Video",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "H. Kuehne",
            "A. Arslan",
            "T. Serre"
        ],
        "dcterms:description": "The Breakfast dataset consists of videos of individuals preparing breakfast, focusing on fine-grained actions related to breakfast preparation.",
        "dcterms:title": "Breakfast",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cooking",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Breakfast Preparation",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Rohrbach",
            "S. Amin",
            "M. Andriluka",
            "B. Schiele"
        ],
        "dcterms:description": "50Salads is a dataset for fine-grained activity detection of cooking activities, featuring videos of individuals preparing salads.",
        "dcterms:title": "50Salads",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cooking",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Salad Preparation",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "K. Li",
            "J. Hu",
            "Y. Fu"
        ],
        "dcterms:description": "CAD-120 is a dataset that includes RGB-D action videos covering daily activities, captured using the Kinect sensor.",
        "dcterms:title": "CAD-120",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Daily Activities"
        ],
        "dcat:keyword": [
            "RGB-D Video",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "Y.-G. Jiang",
            "J. Liu",
            "A. R. Zamir",
            "G. Toderici",
            "I. Laptev",
            "M. Shah",
            "R. Sukthankar"
        ],
        "dcterms:description": "THUMOS14 is a benchmark dataset for action recognition and anticipation, containing sport videos annotated with various actions.",
        "dcterms:title": "THUMOS14",
        "dcterms:issued": "2014",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Sports"
        ],
        "dcat:keyword": [
            "Action Recognition",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "G. A. Sigurdsson",
            "G. Varol",
            "X. Wang",
            "A. Farhadi",
            "I. Laptev",
            "A. Gupta"
        ],
        "dcterms:description": "Charades is a dataset collected from crowdsourced data for understanding activities in home environments.",
        "dcterms:title": "Charades",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Home Activities"
        ],
        "dcat:keyword": [
            "Home Activities",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "K. Grauman",
            "A. Westbury",
            "E. Byrne",
            "Z. Chavis",
            "A. Furnari",
            "R. Girdhar"
        ],
        "dcterms:description": "Ego4D is a large-scale dataset of egocentric videos capturing diverse daily activities.",
        "dcterms:title": "Ego4D",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Egocentric Vision",
            "Daily Activities"
        ],
        "dcat:keyword": [
            "Egocentric Video",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "F. Sener",
            "D. Chatterjee",
            "D. Shelepov",
            "K. He",
            "D. Singhania",
            "R. Wang",
            "A. Yao"
        ],
        "dcterms:description": "Assembly101 is a large-scale dataset for understanding procedural activities, featuring multi-view recordings.",
        "dcterms:title": "Assembly101",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Procedural Activities",
            "Multi-View Video"
        ],
        "dcat:keyword": [
            "Assembly",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    },
    {
        "dcterms:creator": [
            "C. Gu",
            "C. Sun",
            "D. A. Ross",
            "C. Vondrick",
            "C. Pantofaru",
            "Y. Li",
            "S. Vijayanarasimhan",
            "G. Toderici",
            "S. Ricco",
            "R. Sukthankar"
        ],
        "dcterms:description": "AVA is a video dataset that focuses on spatio-temporally localized atomic visual actions.",
        "dcterms:title": "AVA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Action Recognition",
            "Video Analysis"
        ],
        "dcat:keyword": [
            "Atomic Actions",
            "Action Anticipation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition",
            "Action Anticipation"
        ]
    }
]