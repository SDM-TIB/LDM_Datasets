[
    {
        "dcterms:creator": [
            "Triantafyllos Afouras",
            "Joon Son Chung",
            "Andrew Zisserman"
        ],
        "dcterms:description": "LRS3 is a large-scale dataset for visual speech recognition, collecting 433 hours of transcribed English videos from TED & TEDx talks.",
        "dcterms:title": "LRS3",
        "dcterms:issued": "2018",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:1809.00496",
        "dcat:theme": [
            "Visual Speech Recognition",
            "Audio-Visual Speech Recognition"
        ],
        "dcat:keyword": [
            "Visual speech",
            "Speech recognition",
            "TED talks",
            "Transcribed videos"
        ],
        "dcat:landingPage": "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs3.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Joon Son Chung",
            "Andrew Senior",
            "Oriol Vinyals",
            "Andrew Zisserman"
        ],
        "dcterms:description": "LRS2 is a large-scale publicly available labeled audio-visual dataset consisting of 224 hours of video clips from BBC programs.",
        "dcterms:title": "LRS2",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Visual Speech Recognition",
            "Audio-Visual Speech Recognition"
        ],
        "dcat:keyword": [
            "Visual speech",
            "Speech recognition",
            "BBC programs",
            "Transcribed videos"
        ],
        "dcat:landingPage": "https://www.robots.ox.ac.uk/~vgg/data/lip_reading/lrs2.html",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Speech Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "David Snyder",
            "Guoguo Chen",
            "Daniel Povey"
        ],
        "dcterms:description": "MUSAN is a corpus that includes music, speech, and noise recordings, designed for training and evaluating speech recognition systems.",
        "dcterms:title": "MUSAN",
        "dcterms:issued": "2015",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1510.08484",
        "dcat:theme": [
            "Audio Processing",
            "Speech Recognition"
        ],
        "dcat:keyword": [
            "Noise corpus",
            "Speech recognition",
            "Music",
            "Environmental noise"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Noise Robustness"
        ]
    },
    {
        "dcterms:creator": [
            "Joachim Thiemann",
            "Nobutaka Ito",
            "Emmanuel Vincent"
        ],
        "dcterms:description": "DEMAND is a database of multichannel environmental noise recordings, designed for research in noise robustness.",
        "dcterms:title": "DEMAND",
        "dcterms:issued": "2013",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Environmental Noise",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "Noise database",
            "Environmental recordings",
            "Multichannel audio"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Noise Robustness"
        ]
    }
]