[
    {
        "dcterms:creator": [],
        "dcterms:description": "The first physics word problem dataset PhysQA, which contains over 1000 junior high school physics word problems covering various topics such as Kinematics, Mass&Density, Mechanics, Heat, and Electricity.",
        "dcterms:title": "PhysQA",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Physics word problems",
            "Junior high school",
            "Dataset",
            "Problem solving"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Problem solving",
            "Explanation",
            "Generation of new problems"
        ]
    },
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A dataset measuring massive multitask language understanding, which includes some physics questions among other tasks.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [],
        "dcat:keyword": [
            "Multitask learning",
            "Language understanding",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Yan Wang",
            "Xiaojiang Liu",
            "Shuming Shi"
        ],
        "dcterms:description": "A dataset for deep neural solvers for math word problems, primarily focused on elementary-level math.",
        "dcterms:title": "Math23K",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Math word problems",
            "Deep learning",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Danqing Huang",
            "Shuming Shi",
            "Chin-Yew Lin",
            "Jian Yin",
            "Wei-Ying Ma"
        ],
        "dcterms:description": "A large-scale dataset constructed to evaluate how well computers can solve math word problems.",
        "dcterms:title": "Dolphin18K",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Math word problems",
            "Evaluation",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Jiaqi Chen",
            "Jianheng Tang",
            "Jinghui Qin",
            "Xiaodan Liang",
            "Lingbo Liu",
            "Eric Xing",
            "Liang Lin"
        ],
        "dcterms:description": "A geometric question answering benchmark aimed at multimodal numerical reasoning.",
        "dcterms:title": "GeoQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Geometric questions",
            "Multimodal reasoning",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]