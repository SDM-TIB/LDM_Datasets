[
    {
        "dcterms:creator": [
            "Zhilin Wang",
            "Yi Dong",
            "Jiaqi Zeng",
            "Virginia Adams",
            "Makesh Narsimhan Sreedhar",
            "Daniel Egert",
            "Olivier Delalleau",
            "Jane Polak Scowcroft",
            "Neel Kant",
            "Aidan Swope",
            "Oleksii Kuchaiev"
        ],
        "dcterms:description": "HELPSTEER is a multi-attribute helpfulness dataset annotated for various aspects that make responses helpful, including correctness, coherence, complexity, and verbosity, with a total of 37k samples.",
        "dcterms:title": "HELPSTEER",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "https://huggingface.co/datasets/nvidia/HelpSteer",
        "dcat:theme": [
            "Natural Language Processing",
            "Dataset for Model Training"
        ],
        "dcat:keyword": [
            "Helpfulness",
            "Correctness",
            "Coherence",
            "Complexity",
            "Verbosity"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/nvidia/HelpSteer",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Evaluation",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [
            "Andreas Köpf",
            "Yannic Kilcher",
            "Dimitri von Rütte",
            "Sotiris Anagnostidis",
            "Zhi-Rui Tam",
            "Keith Stevens",
            "Abdullah Barhoum",
            "Nguyen Minh Duc",
            "Oliver Stanley",
            "Richárd Nagyfi",
            "Shahul ES",
            "Sameer Suri",
            "David Glushkov",
            "Arnav Dantuluri",
            "Andrew Maguire",
            "Christoph Schuhmann",
            "Huu Nguyen",
            "Alexander Mattick"
        ],
        "dcterms:description": "Open Assistant dataset contains helpfulness-relevant attributes labeled for each response, including quality, creativity, and humor, rated on a 5-point Likert scale.",
        "dcterms:title": "Open Assistant",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Dataset for Model Training"
        ],
        "dcat:keyword": [
            "Helpfulness",
            "Quality",
            "Creativity",
            "Humor"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Evaluation",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Bai",
            "A. Jones",
            "K. Ndousse",
            "A. Askell",
            "A. Chen",
            "N. DasSarma",
            "D. Drain",
            "S. Fort",
            "D. Ganguli",
            "T. Henighan",
            "N. Joseph",
            "S. Kadavath",
            "J. Kernion",
            "T. Conerly",
            "S. El-Showk",
            "N. Elhage",
            "Z. Hatfield-Dodds",
            "D. Hernandez",
            "T. Hume",
            "S. Johnston",
            "S. Kravec",
            "L. Lovitt",
            "N. Nanda",
            "C. Olsson",
            "D. Amodei",
            "T. Brown",
            "J. Clark",
            "S. McCandlish",
            "C. Olah",
            "B. Mann",
            "J. Kaplan"
        ],
        "dcterms:description": "HH-RLHF is a ranking-based dataset containing pairs of responses, one preferred and the other rejected, used for training models with reinforcement learning from human feedback.",
        "dcterms:title": "HH-RLHF",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Reinforcement Learning"
        ],
        "dcat:keyword": [
            "Ranking",
            "Reinforcement Learning",
            "Human Feedback"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Ranking",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [
            "S. Lin",
            "J. Hilton",
            "O. Evans"
        ],
        "dcterms:description": "TruthfulQA is a dataset designed to measure how models mimic human falsehoods, consisting of 817 questions across various categories.",
        "dcterms:title": "TruthfulQA",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Evaluation Dataset"
        ],
        "dcat:keyword": [
            "Truthfulness",
            "Falsehoods",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Factuality Evaluation",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "W.-L. Chiang",
            "Y. Sheng",
            "S. Zhuang",
            "Z. Wu",
            "Y. Zhuang",
            "Z. Lin",
            "Z. Li",
            "E. P. Xing",
            "H. Zhang",
            "J. E. Gonzalez",
            "I. Stoica"
        ],
        "dcterms:description": "MT Bench is a dataset used to evaluate the performance of language models across various tasks, consisting of multi-turn questions.",
        "dcterms:title": "MT Bench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Evaluation Dataset"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Multi-turn Questions",
            "Language Model Assessment"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation",
            "Task Assessment"
        ]
    },
    {
        "dcterms:creator": [
            "R. Nakano",
            "J. Hilton",
            "S. Balaji",
            "J. Wu",
            "L. Ouyang",
            "C. Kim",
            "C. Hesse",
            "S. Jain",
            "V. Kosaraju",
            "W. Saunders",
            "X. Jiang",
            "K. Cobbe",
            "T. Eloundou",
            "G. Krueger",
            "K. Button",
            "M. Knight",
            "B. Chess",
            "J. Schulman"
        ],
        "dcterms:description": "WebGPT is a dataset that enables browser-assisted question-answering with human feedback, designed to improve the performance of language models.",
        "dcterms:title": "WebGPT",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Web-based QA",
            "Human Feedback",
            "Language Model Training"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Model Training"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "OASST refers to the Open Assistant dataset, which contains helpfulness-relevant attributes labeled for each response.",
        "dcterms:title": "OASST",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]