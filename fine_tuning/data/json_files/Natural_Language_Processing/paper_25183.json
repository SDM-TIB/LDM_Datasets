[
    {
        "dcterms:creator": [
            "Jakub Macina",
            "Nico Daheim",
            "Manu Kapur",
            "Iryna Gurevych",
            "Mrinmaya Sachan"
        ],
        "dcterms:description": "A dataset of 1K stepwise math reasoning chains with the first error step annotated by teachers, aimed at improving dialog tutoring models by verifying student solutions.",
        "dcterms:title": "Stepwise Math Reasoning Chains",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/eth-lre/verify-then-generate",
        "dcat:theme": [
            "Education",
            "Mathematics",
            "Tutoring"
        ],
        "dcat:keyword": [
            "Math reasoning",
            "Stepwise verification",
            "Tutoring dataset"
        ],
        "dcat:landingPage": "https://github.com/eth-lre/verify-then-generate",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Verification of student solutions",
            "Response generation"
        ]
    },
    {
        "dcterms:creator": [
            "Jakub Macina",
            "Nico Daheim",
            "Sankalan Chowdhury",
            "Tanmay Sinha",
            "Manu Kapur",
            "Iryna Gurevych",
            "Mrinmaya Sachan"
        ],
        "dcterms:description": "A dialogue tutoring dataset with rich pedagogical properties grounded in math reasoning problems, used for evaluating dialog tutoring models.",
        "dcterms:title": "MathDial",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Education",
            "Mathematics",
            "Tutoring"
        ],
        "dcat:keyword": [
            "Dialogue tutoring",
            "Math reasoning",
            "Pedagogical dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue tutoring",
            "Math problem-solving"
        ]
    },
    {
        "dcterms:creator": [
            "Karl Cobbe",
            "Vineet Kosaraju",
            "Mohammad Bavarian",
            "Mark Chen",
            "Heewoo Jun",
            "Lukasz Kaiser",
            "Matthias Plappert",
            "Jerry Tworek",
            "Jacob Hilton",
            "Reiichiro Nakano"
        ],
        "dcterms:description": "A dataset of multi-step math word problems used for training verifiers to solve math problems.",
        "dcterms:title": "GSM8k",
        "dcterms:issued": "2021",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2110.14168",
        "dcat:theme": [
            "Education",
            "Mathematics",
            "Problem-solving"
        ],
        "dcat:keyword": [
            "Math word problems",
            "Verification",
            "Dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Math problem-solving",
            "Verification"
        ]
    },
    {
        "dcterms:creator": [
            "Olga Golovneva",
            "Moya Peng Chen",
            "Spencer Poff",
            "Martin Corredor",
            "Luke Zettlemoyer",
            "Maryam Fazel-Zarandi",
            "Asli Celikyilmaz"
        ],
        "dcterms:description": "A suite of metrics for scoring step-by-step reasoning, providing a framework for evaluating reasoning chains.",
        "dcterms:title": "Roscoe",
        "dcterms:issued": "",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Education",
            "Mathematics",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Reasoning metrics",
            "Evaluation framework",
            "Step-by-step reasoning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Evaluation of reasoning",
            "Scoring"
        ]
    }
]