[
    {
        "dcterms:creator": [
            "Rohan Taori",
            "Ishaan Gulrajani",
            "Tianyi Zhang",
            "Yann Dubois",
            "Xuechen Li",
            "Carlos Guestrin",
            "Percy Liang",
            "Tatsunori B. Hashimoto"
        ],
        "dcterms:description": "The Alpaca dataset is used for training models to follow instructions, providing a foundation for instruction-following tasks.",
        "dcterms:title": "Alpaca Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction-following",
            "Language models",
            "NLP"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "Others"
        ],
        "dcterms:description": "Chatbot Arena Conversations is a dataset containing crowdsourced data with user queries and responses from various LLMs.",
        "dcterms:title": "Chatbot Arena Conversations",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Conversational AI"
        ],
        "dcat:keyword": [
            "Crowdsourced data",
            "User queries",
            "LLM responses"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Conversational Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "Others"
        ],
        "dcterms:description": "MTBench is a benchmark dataset for evaluating language models with human-annotated preferences.",
        "dcterms:title": "MTBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Evaluation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Model evaluation",
            "Human annotation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Stiennon",
            "Others"
        ],
        "dcterms:description": "OpenAI Summary is a dataset used for training models to summarize text based on human feedback.",
        "dcterms:title": "OpenAI Summary",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Text Summarization"
        ],
        "dcat:keyword": [
            "Summarization",
            "Human feedback",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text Summarization"
        ]
    },
    {
        "dcterms:creator": [
            "R. Nakano",
            "Others"
        ],
        "dcterms:description": "OpenAI WebGPT is a dataset designed for training models to assist in question-answering using web browsing.",
        "dcterms:title": "OpenAI WebGPT",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Question answering",
            "Web browsing",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "K. Ethayarajh",
            "Others"
        ],
        "dcterms:description": "Stanford SHP is a dataset that helps understand dataset difficulty through human preferences.",
        "dcterms:title": "Stanford SHP",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Dataset Analysis"
        ],
        "dcat:keyword": [
            "Dataset difficulty",
            "Human preferences",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dataset Analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Havrilla"
        ],
        "dcterms:description": "Synthetic GPT-J is a dataset for training models with synthetic instruction pairs.",
        "dcterms:title": "Synthetic GPT-J",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise",
        "dcat:theme": [
            "Natural Language Processing",
            "Synthetic Data"
        ],
        "dcat:keyword": [
            "Synthetic data",
            "Instruction pairs",
            "NLP"
        ],
        "dcat:landingPage": "https://huggingface.co/datasets/Dahoas/synthetic-instruct-gptj-pairwise",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction Following"
        ]
    },
    {
        "dcterms:creator": [
            "J. Ji",
            "Others"
        ],
        "dcterms:description": "PKU-SafeRLHF is a dataset aimed at improving safety alignment of language models through human preferences.",
        "dcterms:title": "PKU-SafeRLHF",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Safety Alignment"
        ],
        "dcat:keyword": [
            "Safety alignment",
            "Human preferences",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Safety Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Zhang",
            "Others"
        ],
        "dcterms:description": "LLMEval2 is a large-scale evaluation benchmark for language models.",
        "dcterms:title": "LLMEval2",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation benchmark",
            "Language models",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "L. Zheng",
            "Others"
        ],
        "dcterms:description": "VicunaBench is a dataset for evaluating language models in various scenarios.",
        "dcterms:title": "VicunaBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Model Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Language models",
            "NLP"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Model Evaluation"
        ]
    }
]