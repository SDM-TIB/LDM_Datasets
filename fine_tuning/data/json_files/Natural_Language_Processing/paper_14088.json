[
    {
        "dcterms:creator": [
            "M. L. O. dos Santos",
            "C. E. C. Campelo"
        ],
        "dcterms:description": "A structured and validated database composed of 1,006 questions from the Brazilian National Secondary School Exam (ENEM), covering the period from 2010 to 2022, designed for evaluating language models.",
        "dcterms:title": "ENEM (Brazilian National Secondary School Exam) Questions Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "Portuguese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Education",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "ENEM",
            "Brazilian education",
            "language models",
            "question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Language Model Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "I. Team"
        ],
        "dcterms:description": "A dataset used for evaluating multilingual language models, including tasks related to understanding and generating text in multiple languages.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Multilingualism"
        ],
        "dcat:keyword": [
            "multilingual",
            "language understanding",
            "language generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Language Understanding",
            "Language Generation"
        ]
    },
    {
        "dcterms:creator": [
            "I. Team"
        ],
        "dcterms:description": "A dataset designed for evaluating the performance of language models on various tasks, including question answering and comprehension.",
        "dcterms:title": "AGIEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Evaluation"
        ],
        "dcat:keyword": [
            "evaluation",
            "language models",
            "question answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Evaluation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "I. Team"
        ],
        "dcterms:description": "A dataset used for evaluating language models on Chinese language tasks, focusing on comprehension and generation.",
        "dcterms:title": "C-Eval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Evaluation"
        ],
        "dcat:keyword": [
            "Chinese language",
            "evaluation",
            "language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Evaluation",
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "K. Singhal",
            "S. Azizi",
            "T. Tu",
            "S. S. Mahdavi",
            "J. Wei",
            "H. W. Chung",
            "N. Scales",
            "A. Tanwani",
            "H. Cole-Lewis",
            "S. Pfohl",
            "P. Payne",
            "M. Seneviratne",
            "P. Gamble",
            "C. Kelly",
            "N. Scharli",
            "A. Chowdhery",
            "P. Mansfield",
            "B. A. y Arcas",
            "D. Webster",
            "G. S. Corrado",
            "Y. Matias",
            "K. Chou",
            "J. Gottweis",
            "N. Tomasev",
            "Y. Liu",
            "A. Rajkomar",
            "J. Barral",
            "C. Semturs",
            "A. Karthikesalingam",
            "V. Natarajan"
        ],
        "dcterms:description": "A dataset used for evaluating language models in the medical domain, specifically designed for the United States Medical Licensing Examination (USMLE).",
        "dcterms:title": "USMLE (United States Medical Licensing Examination)",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Medicine",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "medical examination",
            "language models",
            "evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Medical Question Answering",
            "Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Nunes",
            "R. Primi",
            "R. Pires",
            "R. Lotufo",
            "R. Nogueira"
        ],
        "dcterms:description": "A dataset used for evaluating GPT models on Brazilian university admission exams, specifically the ENEM.",
        "dcterms:title": "ENEM (Brazilian National Secondary School Exam)",
        "dcterms:issued": "2023",
        "dcterms:language": "Portuguese",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Education",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "university admission",
            "language models",
            "evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering",
            "Model Evaluation"
        ]
    }
]