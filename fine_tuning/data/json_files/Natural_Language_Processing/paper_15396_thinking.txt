To extract datasets from the research paper titled "Virtual Accessory Try-On via Keypoint Hallucination" by Junhong Gou et al., I will follow a systematic approach to ensure I capture all relevant information, including full citations for each dataset.

First, I will read through the **abstract, introduction, and experiments sections** to identify any datasets mentioned. The abstract states that the authors conducted experiments on the **STRAT dataset**, which is a strong indication that this dataset is central to their research.

Next, I will focus on **section 4.1 (Dataset and Evaluation Metrics)**, where the authors provide a detailed description of the STRAT dataset. They mention that it consists of three sub-datasets: **STRAT-glasses, STRAT-hat, and STRAT-tie**. Each sub-dataset contains 2000 training tuples and 1000 test tuples, with each tuple comprising a foreground image with a mask, a background image, and the ground-truth composite image. This section confirms the existence of multiple datasets and provides specific details about their structure.

I will also check the **References section** to find the full citation for the STRAT dataset. The authors reference the dataset as follows:

- For the STRAT dataset, the citation is:
  > Bo Zhang, Yue Liu, Kaixin Lu, Li Niu, and Liqing Zhang. *Spatial transformation for image composition via correspondence learning*. arXiv preprint arXiv:2207.02398, 2022.

Since the STRAT dataset is the only dataset explicitly mentioned in the paper, I will compile the information into a structured format.

Now, I will summarize the findings for the STRAT dataset, ensuring to include the full citation as required. This will provide a clear and comprehensive overview of the dataset used in the research.