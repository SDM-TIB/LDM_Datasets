[
    {
        "dcterms:creator": [
            "Q. Kong",
            "Z. Wu",
            "Z. Deng",
            "M. Klinkigt",
            "B. Tong",
            "T. Murakami"
        ],
        "dcterms:description": "A large-scale dataset for cross modal human action understanding, consisting of 35 different human actions recorded on 4 different cameras in various room setups.",
        "dcterms:title": "MMAct",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Activity Recognition",
            "Multi-modal Learning"
        ],
        "dcat:keyword": [
            "Human actions",
            "IMU data",
            "Video dataset",
            "Cross-modal understanding"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Human Activity Recognition"
        ]
    }
]