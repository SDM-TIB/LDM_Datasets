[
    {
        "dcterms:creator": [
            "Stephen Merity",
            "Nikita Nangia",
            "Naman Goyal",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset used for evaluating language models, particularly focusing on perplexity and fluency.",
        "dcterms:title": "WikiText Dataset",
        "dcterms:issued": "2016",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1609.07843",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Language modeling",
            "Text dataset",
            "Perplexity evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling"
        ]
    },
    {
        "dcterms:creator": [
            "Leo Gao",
            "Zeynep Akata",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset designed for evaluating few-shot language models, focusing on zero-shot accuracy.",
        "dcterms:title": "LAMBADA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.5281/zenodo.5371628",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Few-shot evaluation",
            "Language modeling",
            "Zero-shot accuracy"
        ],
        "dcat:landingPage": "https://doi.org/10.5281/zenodo.5371628",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Leo Gao",
            "Zeynep Akata",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset used for evaluating language models in a commonsense reasoning context.",
        "dcterms:title": "HellaSwag",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.5281/zenodo.5371628",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Language modeling",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.5281/zenodo.5371628",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Leo Gao",
            "Zeynep Akata",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset for evaluating language models on physical reasoning tasks.",
        "dcterms:title": "PIQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.5281/zenodo.5371628",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Physical reasoning",
            "Language modeling",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.5281/zenodo.5371628",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Leo Gao",
            "Zeynep Akata",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset for evaluating language models on gendered pronoun resolution tasks.",
        "dcterms:title": "WinoGrande",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "https://doi.org/10.5281/zenodo.5371628",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Pronoun resolution",
            "Language modeling",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "https://doi.org/10.5281/zenodo.5371628",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Rohan Taori",
            "Tatsuya Kato",
            "M. Z. Zhu"
        ],
        "dcterms:description": "A dataset used for fine-tuning instruction-following models.",
        "dcterms:title": "Alpaca Dataset",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Instruction following",
            "Fine-tuning dataset",
            "Language modeling"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Fine-tuning"
        ]
    }
]