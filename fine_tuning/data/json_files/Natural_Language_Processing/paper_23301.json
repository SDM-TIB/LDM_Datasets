[
    {
        "dcterms:creator": [
            "Patrick Schramowski",
            "Manuel Brack",
            "Bj√∂rn Deiseroth",
            "Kristian Kersting"
        ],
        "dcterms:description": "A meta dataset containing safe prompts and their corresponding unsafe images, categorized into seven types based on harmful information.",
        "dcterms:title": "Meta Dataset (MD)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Safety Evaluation",
            "Generative Models"
        ],
        "dcat:keyword": [
            "safe prompts",
            "unsafe images",
            "toxic keywords",
            "harmful content"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [
            "Rohan Taori",
            "Ishaan Gulrajani",
            "Tianyi Zhang",
            "Yann Dubois",
            "Xuechen Li",
            "Carlos Guestrin",
            "Percy Liang",
            "Tatsunori B. Hashimoto"
        ],
        "dcterms:description": "A dataset designed for fine-tuning large language models (LLMs) to improve their ability to modify prompts based on instructions.",
        "dcterms:title": "LLM Dataset (LD)",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Language Modeling",
            "Prompt Modification"
        ],
        "dcat:keyword": [
            "prompt modification",
            "instruction following",
            "fine-tuning",
            "language models"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "A dataset for fine-tuning vision language models (VLMs) to understand the relationship between safe prompts and unsafe images.",
        "dcterms:title": "VLM Dataset (VD)",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "https://llama.meta.com/llama3/",
        "dcat:theme": [
            "Vision Language Modeling",
            "Image Generation"
        ],
        "dcat:keyword": [
            "image understanding",
            "prompt generation",
            "fine-tuning",
            "vision language models"
        ],
        "dcat:landingPage": "https://llama.meta.com/llama3/",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]