[
    {
        "dcterms:creator": [
            "P. Lu",
            "S. Mishra",
            "T. Xia",
            "L. Qiu",
            "K.-W. Chang",
            "S.-C. Zhu",
            "O. Tafjord",
            "P. Clark",
            "A. Kalyan"
        ],
        "dcterms:description": "A multimodal multiple choice dataset used to develop a faithful model clearly uncovering the multi-step reasoning process. It consists of approximately 21k questions with rich domain diversity, annotated with image and text context.",
        "dcterms:title": "ScienceQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Science Question Answering",
            "Multimodal Reasoning"
        ],
        "dcat:keyword": [
            "Multimodal dataset",
            "Reasoning",
            "Science questions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Knowledge Reasoning",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "S. Singh",
            "N. Wen",
            "Y. Hou",
            "P. Alipoormolabashi",
            "T.-L. Wu",
            "X. Ma",
            "N. Peng"
        ],
        "dcterms:description": "A commonsense reasoning dataset consisting of 4k sentence pairs annotated with true or false labels. It aims to systematically evaluate a modelâ€™s capability of commonsense knowledge understanding and reasoning.",
        "dcterms:title": "Com2Sense",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2106.00969",
        "dcat:theme": [
            "Commonsense Reasoning"
        ],
        "dcat:keyword": [
            "Commonsense reasoning",
            "Sentence pairs",
            "True/false labels"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Commonsense Reasoning"
        ]
    },
    {
        "dcterms:creator": [
            "C. Clark",
            "K. Lee",
            "M.-W. Chang",
            "T. Kwiatkowski",
            "M. Collins",
            "K. Toutanova"
        ],
        "dcterms:description": "A reading comprehension dataset labeled with yes/no questions. It consists of 16k questions paired with a paragraph from Wikipedia annotated as containing the answer.",
        "dcterms:title": "BoolQ",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:1905.10044",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Yes/no questions",
            "Reading comprehension",
            "Wikipedia"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]