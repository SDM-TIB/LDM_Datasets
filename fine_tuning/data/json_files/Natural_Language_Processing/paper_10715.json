[
    {
        "dcterms:creator": [
            "Shulin Cao",
            "Jiaxin Shi",
            "Liangming Pan",
            "Lunyiu Nie",
            "Yutong Xiang",
            "Lei Hou",
            "Juanzi Li",
            "Bin He",
            "Hanwang Zhang"
        ],
        "dcterms:description": "KQA Pro is a large scale complex QA dataset, including 120k diverse natural language questions up to 5 hops over a knowledge base. It provides the corresponding KoPL program for each question and simulates realistic scenarios by discarding half of the triples in its KB and supplementing with Wikipedia corpus.",
        "dcterms:title": "KQA Pro",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Knowledge Base"
        ],
        "dcat:keyword": [
            "Complex Questions",
            "Natural Language Processing",
            "Knowledge Base Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Harsh Trivedi",
            "Niranjan Balasubramanian",
            "Tushar Khot",
            "Ashish Sabharwal"
        ],
        "dcterms:description": "Musique is a multi-hop QA dataset over text, including 25k 2-4 hop questions. It is constructed from several single-hop QA datasets via manual composition and paraphrase, providing 20 paragraphs as the corpus for each complex question.",
        "dcterms:title": "Musique",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Text-based QA"
        ],
        "dcat:keyword": [
            "Multi-hop Questions",
            "Text Composition",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]