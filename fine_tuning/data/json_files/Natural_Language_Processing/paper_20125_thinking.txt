To extract datasets from the research paper titled "Point Mamba: A Novel Point Cloud Backbone Based on State Space Model with Octree-Based Ordering Strategy" by Jiuming Liu et al., I will follow a systematic approach.

First, I will read through the **abstract** to identify any datasets mentioned. The abstract states that the method achieves state-of-the-art performance on the **ModelNet40 classification dataset** and the **ScanNet semantic segmentation dataset**. This indicates that these two datasets are likely important for the research.

Next, I will examine the **introduction** section for further details about these datasets. The introduction discusses the challenges of point cloud processing and mentions the significance of the datasets used for evaluation, reinforcing the importance of ModelNet40 and ScanNet.

I will then look into **section 4.1 (Dataset)**, where the authors provide specific details about the datasets used:

1. **ModelNet40 Dataset**: This dataset is described as a widely used benchmark for 3D object classification, containing 12,311 CAD models across 40 categories. The authors mention the training and test splits, which is crucial for understanding how the dataset is utilized in their experiments.

2. **ScanNet Dataset**: This dataset consists of 1,513 scans from 707 indoor scenes, annotated with 20 parts labels. The average point number per scan is noted, which is relevant for understanding the dataset's scale and complexity.

In the **experiments section**, the authors confirm that they used both the **ModelNet40** and **ScanNet** datasets for their evaluations, which further validates their significance in the study.

Next, I will check the **References section** to find the full citations for these datasets:

- For the **ModelNet40 Dataset**, the citation is:
  > Zhirong Wu, Shuran Song, Aditya Khosla, Fisher Yu, Linguang Zhang, Xiaoou Tang, and Jianxiong Xiao. *3D ShapeNets: A Deep Representation for Volumetric Shapes*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 1912–1920, 2015.

- For the **ScanNet Dataset**, the citation is:
  > Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and Matthias Nießner. *ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes*. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 5828–5839, 2017.

Now that I have identified the datasets and their full citations, I will compile this information into a structured format for further processing or review.