[
    {
        "dcterms:creator": [
            "Dan Hendrycks",
            "Collin Burns",
            "Steven Basart",
            "Andy Zou",
            "Mantas Mazeika",
            "Dawn Song",
            "Jacob Steinhardt"
        ],
        "dcterms:description": "A multitask language understanding dataset, which includes 57 multi-choice question answering subtasks classified into categories such as humanities, social sciences, STEM, and others.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Language Understanding",
            "Multitask Learning"
        ],
        "dcat:keyword": [
            "Multichoice questions",
            "Language understanding",
            "Knowledge evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering",
            "Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Alex Mallen",
            "Akari Asai",
            "Victor Zhong",
            "Rajarshi Das",
            "Hannaneh Hajishirzi",
            "Daniel Khashabi"
        ],
        "dcterms:description": "An entity-centric question answering dataset that focuses on long-tail questions.",
        "dcterms:title": "PopQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering",
            "Entity-centric Tasks"
        ],
        "dcat:keyword": [
            "Long-tail questions",
            "Entity-centric QA",
            "Knowledge retrieval"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Question Answering"
        ]
    }
]