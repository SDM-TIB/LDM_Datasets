[
    {
        "dcterms:creator": [
            "Linyi Yang",
            "Shuibai Zhang",
            "Libo Qin",
            "Yafu Li",
            "Yidong Wang",
            "Hanmeng Liu",
            "Jindong Wang",
            "Xing Xie",
            "Yue Zhang"
        ],
        "dcterms:description": "GLUE-X is a benchmark for evaluating natural language understanding models, focusing on their performance in out-of-distribution scenarios.",
        "dcterms:title": "GLUE-X",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Understanding",
            "Out-of-Distribution Generalization"
        ],
        "dcat:keyword": [
            "benchmark",
            "natural language understanding",
            "out-of-distribution",
            "evaluation"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/2211.08073",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Natural Language Understanding"
        ]
    },
    {
        "dcterms:creator": [
            "Pranav Rajpurkar",
            "Robin Jia",
            "Percy Liang"
        ],
        "dcterms:description": "SQuAD 2.0 is a question answering dataset that includes unanswerable questions, designed to improve the robustness of models in understanding when no answer is available.",
        "dcterms:title": "SQuAD 2.0",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Question Answering"
        ],
        "dcat:keyword": [
            "question answering",
            "unanswerable questions",
            "dataset"
        ],
        "dcat:landingPage": "https://arxiv.org/abs/1806.03822",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Question Answering"
        ]
    }
]