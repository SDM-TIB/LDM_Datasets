[
    {
        "dcterms:creator": [
            "Relja Arandjelovic",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A dataset containing 31 human action classes selected from Kinetics dataset, with videos manually annotated for human action and cropped to 10 seconds long around the action.",
        "dcterms:title": "Kinetics-Sounds",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-modal Learning",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Audio-visual",
            "Human actions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Khurram Soomro",
            "Amir Roshan Zamir",
            "Mubarak Shah"
        ],
        "dcterms:description": "A dataset consisting of in-the-wild videos from 101 action classes, typically regarded as a multi-modal dataset with RGB and optical flow modalities.",
        "dcterms:title": "UCF101",
        "dcterms:issued": "2012",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-modal Learning",
            "Action Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Human actions",
            "Optical flow"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Action Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "Honglie Chen",
            "Weidi Xie",
            "Andrea Vedaldi",
            "Andrew Zisserman"
        ],
        "dcterms:description": "A large-scale video dataset that contains 309 classes, covering a wide range of audio events in everyday life, with audio-visual correspondence.",
        "dcterms:title": "VGGSound",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-modal Learning",
            "Audio-Visual Recognition"
        ],
        "dcat:keyword": [
            "Video dataset",
            "Audio events",
            "Everyday life"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Audio-Visual Recognition"
        ]
    }
]