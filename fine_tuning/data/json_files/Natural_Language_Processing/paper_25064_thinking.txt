To extract datasets from the research paper titled "Enhanced Model Robustness to Input Corruptions by Per-corruption Adaptation of Normalization Statistics" by Elena Camuffo et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, methodology, and experiments sections** to identify any datasets mentioned. The abstract indicates that the authors evaluated their method on "challenging real-world corrupted image datasets," which suggests that specific datasets will be detailed later in the paper.

Next, I will focus on the **experiments section** where the authors typically describe the datasets used for evaluation. In this section, they mention three datasets:

1. **OpenLORIS**: This dataset is designed for incremental recognition of common objects in office or home scenarios, addressing challenges like varying illumination conditions and occlusions.

2. **ExDARK**: This dataset consists of 7,363 low-light images captured in various conditions, annotated with object bounding boxes for indoor and outdoor object detection.

3. **ACDC**: The Adverse Conditions Dataset with Correspondences is a benchmark for semantic segmentation in adverse visual conditions, containing 4,006 images distributed across fog, nighttime, rain, and snow.

I will also check the **References section** to find the full citations for these datasets. The citations are as follows:

- For **OpenLORIS**:
  > Q. She, F. Feng, X. Hao, Q. Yang, C. Lan, V. Lomonaco, X. Shi, Z. Wang, Y. Guo, Y. Zhang, F. Qiao, and R. H. M. Chan. *OpenLORIS-Object: A robotic vision dataset and benchmark for lifelong deep learning*. In Proceedings of the IEEE International Conference on Robotics and Automation (ICRA), 2020.

- For **ExDARK**:
  > Y. P. Loh and C. S. Chan. *Getting to know low-light images with the exclusively dark dataset*. Computer Vision and Image Understanding (CVIU), 2019.

- For **ACDC**:
  > C. Sakaridis, D. Dai, and L. Van Gool. *ACDC: The adverse conditions dataset with correspondences for semantic driving scene understanding*. In Proceedings of the IEEE International Conference on Computer Vision (ICCV), 2021.

Now that I have identified the datasets and their citations, I will compile this information into a structured format for further processing or review.