[
    {
        "dcterms:creator": [
            "Yizhong Wang",
            "Yeganeh Kordi",
            "Swaroop Mishra",
            "Alisa Liu",
            "Noah A Smith",
            "Daniel Khashabi",
            "Hannaneh Hajishirzi"
        ],
        "dcterms:description": "A dataset containing self-generated instructions aligned with language models, aimed at improving instruction-following capabilities.",
        "dcterms:title": "Self-Instruct",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2212.10560",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction generation",
            "Language model alignment",
            "Synthetic data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following"
        ]
    },
    {
        "dcterms:creator": [
            "W. Zhang",
            "M. Zhu",
            "K. G. Derpanis"
        ],
        "dcterms:description": "A dataset containing diverse instructions generated by GPT-4 through prompt engineering, aimed at evaluating instruction-following capabilities.",
        "dcterms:title": "Vicuna",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Instruction generation",
            "GPT-4",
            "Prompt engineering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following"
        ]
    },
    {
        "dcterms:creator": [
            "G. Geng",
            "A. Gudibande",
            "H. Liu",
            "E. Wallace",
            "P. Abbeel",
            "S. Levine",
            "D. Song"
        ],
        "dcterms:description": "A dataset containing conversation-style real user instructions that were posted online, aimed at evaluating dialogue models.",
        "dcterms:title": "Koala",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Dialogue Systems"
        ],
        "dcat:keyword": [
            "Dialogue generation",
            "User instructions",
            "Conversational AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Dialogue generation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "C. Burns",
            "S. Basart",
            "A. Zou",
            "M. Mazeika",
            "D. Song",
            "J. Steinhardt"
        ],
        "dcterms:description": "A benchmark designed to measure the capability of language models across various subjects, covering a wide range of tasks.",
        "dcterms:title": "MMLU",
        "dcterms:issued": "2020",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2009.03300",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Multitask learning",
            "Language understanding",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding"
        ]
    },
    {
        "dcterms:creator": [
            "M. Suzgun",
            "N. Scales",
            "N. Sch√§rli",
            "S. Gehrmann",
            "Y. Tay",
            "H. W. Chung",
            "A. Chowdhery",
            "Q. V. Le",
            "E. H. Chi",
            "D. Zhou"
        ],
        "dcterms:description": "A dataset that includes challenging tasks designed to evaluate the performance of language models on complex benchmarks.",
        "dcterms:title": "BBH",
        "dcterms:issued": "2022",
        "dcterms:language": "English",
        "dcterms:identifier": "arXiv:2210.09261",
        "dcat:theme": [
            "Natural Language Processing",
            "Benchmarking"
        ],
        "dcat:keyword": [
            "Challenging tasks",
            "Language model evaluation",
            "Benchmark dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language understanding"
        ]
    },
    {
        "dcterms:creator": [
            "R. Taori",
            "I. Gulrajani",
            "T. Zhang",
            "Y. Dubois",
            "X. Li",
            "C. Guestrin",
            "P. Liang",
            "T. B. Hashimoto"
        ],
        "dcterms:description": "A dataset containing real-world human instructions from diverse sources, aimed at evaluating instruction-following capabilities.",
        "dcterms:title": "Evol-Instruct",
        "dcterms:issued": "2023",
        "dcterms:language": "English",
        "dcterms:identifier": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcat:theme": [
            "Natural Language Processing",
            "Instruction Following"
        ],
        "dcat:keyword": [
            "Human instructions",
            "Instruction following",
            "Evaluation dataset"
        ],
        "dcat:landingPage": "https://github.com/tatsu-lab/stanford_alpaca",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Instruction following"
        ]
    }
]