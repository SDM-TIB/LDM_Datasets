[
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee",
            "Kristina Toutanova",
            "Llion Jones",
            "Matthew Kelcey",
            "Ming-Wei Chang",
            "Andrew M. Dai",
            "Jakob Uszkoreit",
            "Quoc Le",
            "Slav Petrov"
        ],
        "dcterms:description": "NQ is constructed by Google Search queries along with annotated short answers or documents (long answers).",
        "dcterms:title": "Natural Questions (NQ)",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Open-domain Question Answering"
        ],
        "dcat:keyword": [
            "Question Answering",
            "Benchmark Dataset",
            "Natural Language Processing"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Open-domain Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mandar Joshi",
            "Eunsol Choi",
            "Daniel Weld",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "TriviaQA consists of trivia questions with annotated answers and corresponding evidence documents.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Open-domain Question Answering"
        ],
        "dcat:keyword": [
            "Trivia Questions",
            "Reading Comprehension",
            "Annotated Answers"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Open-domain Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D. Manning"
        ],
        "dcterms:description": "HotpotQA is a collection of question-answer pairs that require multi-hop reasoning, where the question-answer pairs are collected through Amazon Mechanical Turk.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Open-domain Question Answering"
        ],
        "dcat:keyword": [
            "Multi-hop Reasoning",
            "Question Answering",
            "Annotated Pairs"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Open-domain Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Adam Fisch",
            "Alon Talmor",
            "Robin Jia",
            "Minjoon Seo",
            "Eunsol Choi",
            "Danqi Chen"
        ],
        "dcterms:description": "MRQA is a shared task evaluating generalization in reading comprehension.",
        "dcterms:title": "MRQA",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Reading Comprehension"
        ],
        "dcat:keyword": [
            "Generalization",
            "Reading Comprehension",
            "Evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Reading Comprehension"
        ]
    }
]