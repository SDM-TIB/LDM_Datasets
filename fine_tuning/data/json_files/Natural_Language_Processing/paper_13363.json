[
    {
        "dcterms:creator": [
            "M. Baroni",
            "S. Bernardini",
            "A. Ferraresi",
            "E. Zanchetta"
        ],
        "dcterms:description": "A collection of very large linguistically processed web-crawled corpora.",
        "dcterms:title": "ukWac web-crawled corpus",
        "dcterms:issued": "2009",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Linguistic Resources",
            "Web Corpora"
        ],
        "dcat:keyword": [
            "Web corpus",
            "Linguistic processing",
            "Large dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Text analysis",
            "Linguistic research"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhu",
            "R. Kiros",
            "R. Zemel",
            "R. Salakhutdinov",
            "R. Urtasun",
            "A. Torralba",
            "S. Fidler"
        ],
        "dcterms:description": "A dataset consisting of over 11 thousand books used for training language models.",
        "dcterms:title": "BookCorpus",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Literature",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Books",
            "Language modeling",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling",
            "Text generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhu",
            "R. Kiros",
            "R. Zemel",
            "R. Salakhutdinov",
            "R. Urtasun",
            "A. Torralba",
            "S. Fidler"
        ],
        "dcterms:description": "A large-scale dataset derived from the English Wikipedia for training language models.",
        "dcterms:title": "English Wikipedia",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Encyclopedic Knowledge",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Wikipedia",
            "Text corpus",
            "Language modeling"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling",
            "Text analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhu",
            "R. Kiros",
            "R. Zemel",
            "R. Salakhutdinov",
            "R. Urtasun",
            "A. Torralba",
            "S. Fidler"
        ],
        "dcterms:description": "A dataset created from web crawling, used for training language models.",
        "dcterms:title": "Common Crawl",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Web Data",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Web corpus",
            "Language modeling",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling",
            "Text analysis"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Zhu",
            "R. Kiros",
            "R. Zemel",
            "R. Salakhutdinov",
            "R. Urtasun",
            "A. Torralba",
            "S. Fidler"
        ],
        "dcterms:description": "A dataset derived from web text for training language models.",
        "dcterms:title": "WebText2",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Web Data",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Web text",
            "Language modeling",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Language modeling",
            "Text analysis"
        ]
    },
    {
        "dcterms:creator": [
            "J. Dunn"
        ],
        "dcterms:description": "A dataset containing 1 billion words used for computational learning of Construction Grammars.",
        "dcterms:title": "1 billion word dataset",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Linguistic Resources",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Large dataset",
            "Construction Grammar",
            "Text corpus"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Construction Grammar analysis",
            "Text analysis"
        ]
    }
]