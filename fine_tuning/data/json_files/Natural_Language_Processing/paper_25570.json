[
    {
        "dcterms:creator": [
            "A. Zou",
            "Z. Wang",
            "N. Carlini",
            "M. Nasr",
            "J. Z. Kolter",
            "M. Fredrikson"
        ],
        "dcterms:description": "AdvBench is a dataset that includes highly formulaic responses to harmful prompts that always begin with 'Sure'. It consists of 416 training and 104 test prompt-response pairs.",
        "dcterms:title": "AdvBench",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Adversarial Attacks",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Adversarial prompts",
            "Harmful responses",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Adversarial Attack Optimization"
        ]
    },
    {
        "dcterms:creator": [
            "D. Ganguli",
            "L. Lovitt",
            "J. Kernion",
            "A. Askell",
            "Y. Bai",
            "S. Kadavath",
            "B. Mann",
            "E. Perez",
            "N. Schiefer",
            "K. Ndousse",
            "A. Jones",
            "S. Bowman",
            "A. Chen",
            "T. Conerly",
            "N. DasSarma",
            "D. Drain",
            "N. Elhage",
            "S. El-Showk",
            "S. Fort",
            "Z. Hatfield-Dodds",
            "T. Henighan",
            "D. Hernandez",
            "T. Hume",
            "J. Jacobson",
            "S. Johnston",
            "S. Kravec",
            "C. Olsson",
            "S. Ringer",
            "E. Tran-Johnson",
            "D. Amodei",
            "T. Brown",
            "N. Joseph",
            "S. McCandlish",
            "C. Olah",
            "J. Kaplan",
            "J. Clark"
        ],
        "dcterms:description": "The Anthropic HHH dataset contains human preference comparisons for helpful and harmless responses, modified to create a dataset of unhinged responses.",
        "dcterms:title": "Anthropic HHH",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Human Preference Evaluation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Human preference data",
            "Harmful responses",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Response Evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "The Generated dataset consists of synthetic prompts generated by Claude 3 Opus across 51 harmful topics and responses generated by Llama 3 Instruct.",
        "dcterms:title": "Generated",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Synthetic Data Generation",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Synthetic prompts",
            "Harmful topics",
            "Text dataset"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Prompt Generation"
        ]
    }
]