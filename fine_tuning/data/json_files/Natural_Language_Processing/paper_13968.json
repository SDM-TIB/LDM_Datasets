[
    {
        "dcterms:creator": [
            "Vassil Panayotov",
            "G. M. K. Derpanis",
            "E. M. K. Derpanis"
        ],
        "dcterms:description": "LibriSpeech is an ASR corpus based on public domain audio books, utilized for tasks such as speaker verification and spoken term detection.",
        "dcterms:title": "LibriSpeech",
        "dcterms:issued": "2015",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Recognition",
            "Audio Processing"
        ],
        "dcat:keyword": [
            "ASR corpus",
            "public domain",
            "speaker verification",
            "spoken term detection"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Speaker Verification",
            "Spoken Term Detection"
        ]
    },
    {
        "dcterms:creator": [
            "Keith Ito",
            "Linda Johnson"
        ],
        "dcterms:description": "LJSpeech is a dataset consisting of 13,100 short audio clips of a single speaker reading passages from books, primarily used for text-to-speech tasks.",
        "dcterms:title": "LJSpeech",
        "dcterms:issued": "2017",
        "dcterms:language": "English",
        "dcterms:identifier": "https://keithito.com/LJ-Speech-Dataset/",
        "dcat:theme": [
            "Text-to-Speech",
            "Speech Synthesis"
        ],
        "dcat:keyword": [
            "single speaker",
            "audio clips",
            "text-to-speech"
        ],
        "dcat:landingPage": "https://keithito.com/LJ-Speech-Dataset/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Audio",
        "mls:task": [
            "Text-to-Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "Junichi Yamagishi",
            "Christophe Veaux",
            "Kirsten MacDonald"
        ],
        "dcterms:description": "VCTK is an English multi-speaker corpus designed for voice cloning and speech synthesis tasks, featuring recordings from multiple speakers.",
        "dcterms:title": "VCTK",
        "dcterms:issued": "2019",
        "dcterms:language": "English",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Speech Synthesis",
            "Voice Cloning"
        ],
        "dcat:keyword": [
            "multi-speaker",
            "voice cloning",
            "speech synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "0.92",
        "dcterms:format": "Audio",
        "mls:task": [
            "Voice Cloning",
            "Speech Synthesis"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Dynamic-SUPERB-Train is a dataset created for training baselines in the Dynamic-SUPERB benchmark, facilitating the evaluation of various speech tasks.",
        "dcterms:title": "Dynamic-SUPERB-Train",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "training dataset",
            "baseline evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]