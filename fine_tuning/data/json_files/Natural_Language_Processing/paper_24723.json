[
    {
        "dcterms:creator": [
            "A. Parrish",
            "A. Chen",
            "N. Nangia",
            "V. Padmakumar",
            "J. Phang",
            "J. Thompson",
            "P. M. Htut",
            "S. Bowman"
        ],
        "dcterms:description": "BBQ provides a comprehensive set of question-answering (QA) pairs, each containing a stereotypical question and an ambiguous context that lacks sufficient information to definitively answer the question.",
        "dcterms:title": "BBQ",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Question Answering"
        ],
        "dcat:keyword": [
            "Bias",
            "Stereotyping",
            "Question Answering"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation",
            "Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "J. Zhao",
            "T. Wang",
            "M. Yatskar",
            "V. Ordonez",
            "K.-W. Chang"
        ],
        "dcterms:description": "WinoBias measures the gender bias in language models by identifying the dependency between output words and social groups.",
        "dcterms:title": "WinoBias",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Coreference Resolution"
        ],
        "dcat:keyword": [
            "Gender Bias",
            "Coreference Resolution"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation",
            "Coreference Resolution"
        ]
    },
    {
        "dcterms:creator": [
            "E. M. Smith",
            "M. Hall",
            "M. Kambadur",
            "E. Presani",
            "A. Williams"
        ],
        "dcterms:description": "HolisticBias assembles expert-annotated sentence prompts to measure the degree of bias in responses generated by LLMs.",
        "dcterms:title": "HolisticBias",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Language Models"
        ],
        "dcat:keyword": [
            "Bias Measurement",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "D. Dua",
            "C. Graff"
        ],
        "dcterms:description": "The Adult dataset is a collection of census data used for predicting whether an individual earns more than $50K per year.",
        "dcterms:title": "Adult",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Classification",
            "Socioeconomic Data"
        ],
        "dcat:keyword": [
            "Income Prediction",
            "Census Data"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Tabular",
        "mls:task": [
            "Classification"
        ]
    },
    {
        "dcterms:creator": [
            "I.-C. Yeh",
            "C.-h. Lien"
        ],
        "dcterms:description": "The Credit dataset is used for predicting the probability of default of credit card clients.",
        "dcterms:title": "Credit",
        "dcterms:issued": "2009",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Classification",
            "Financial Data"
        ],
        "dcat:keyword": [
            "Credit Default",
            "Financial Prediction"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Tabular",
        "mls:task": [
            "Classification"
        ]
    },
    {
        "dcterms:creator": [
            "D. Borkan",
            "J. Sorensen",
            "L. Dixon",
            "L. Vasserman",
            "Nithum"
        ],
        "dcterms:description": "Jigsaw dataset is used for evaluating toxicity in comments and includes various types of toxic content.",
        "dcterms:title": "Jigsaw",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Toxicity Evaluation",
            "Text Classification"
        ],
        "dcat:keyword": [
            "Toxicity",
            "Comment Classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Toxicity Classification"
        ]
    },
    {
        "dcterms:creator": [
            "M. Nadeem",
            "A. Bethke",
            "S. Reddy"
        ],
        "dcterms:description": "StereoSet measures stereotypical bias in pretrained language models.",
        "dcterms:title": "StereoSet",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Language Models"
        ],
        "dcat:keyword": [
            "Stereotypical Bias",
            "Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "N. Nangia",
            "C. Vania",
            "R. Bhalerao",
            "S. Bowman"
        ],
        "dcterms:description": "CrowS-Pairs is a challenge dataset for measuring social biases in masked language models.",
        "dcterms:title": "CrowS-Pairs",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Masked Language Models"
        ],
        "dcat:keyword": [
            "Social Bias",
            "Masked Language Models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Barikeri",
            "A. Lauscher",
            "I. Vulić",
            "G. Glavaš"
        ],
        "dcterms:description": "RedditBias is a resource for bias evaluation and debiasing of conversational language models.",
        "dcterms:title": "RedditBias",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Bias Evaluation",
            "Conversational Models"
        ],
        "dcat:keyword": [
            "Bias Evaluation",
            "Conversational AI"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Bias Evaluation"
        ]
    }
]