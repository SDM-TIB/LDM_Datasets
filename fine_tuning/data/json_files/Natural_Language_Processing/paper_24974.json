[
    {
        "dcterms:creator": [
            "R. Kosti",
            "J. M. Alvarez",
            "A. Recasens",
            "A. Lapedriza"
        ],
        "dcterms:description": "The EMOTIC dataset is a large-scale context-aware emotion recognition benchmark containing 23,571 images of 34,320 annotated subjects, primarily from unconstrained environments, providing rich data resources on different subjects in diverse context scenarios.",
        "dcterms:title": "EMOTIC",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Context-aware",
            "Emotion categories",
            "Multi-label classification",
            "Continuous dimensions"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "J. Lee",
            "S. Kim",
            "S. Kim",
            "J. Park",
            "K. Sohn"
        ],
        "dcterms:description": "CAER-S is a dataset containing 70k static images captured from video clips, featuring different subjects in indoor and outdoor scenarios from 79 TV shows, supporting multi-class classification of emotion labels.",
        "dcterms:title": "CAER-S",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Static images",
            "Multi-class classification",
            "Contextual elements"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Image",
        "mls:task": [
            "Emotion Recognition"
        ]
    },
    {
        "dcterms:creator": [
            "T. Mittal",
            "P. Guhan",
            "U. Bhattacharya",
            "R. Chandra",
            "A. Bera",
            "D. Manocha"
        ],
        "dcterms:description": "GroupWalk consists of 45 manually collected videos from real-world environments, focusing on understanding subjects' affective effluence in group interactions, with annotations for discrete emotion categories.",
        "dcterms:title": "GroupWalk",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Emotion Recognition",
            "Computer Vision"
        ],
        "dcat:keyword": [
            "Videos",
            "Group interactions",
            "Multi-label classification"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Video",
        "mls:task": [
            "Emotion Recognition"
        ]
    }
]