[
    {
        "dcterms:creator": [
            "Tom Kwiatkowski",
            "Jennimaria Palomaki",
            "Olivia Redfield",
            "Michael Collins",
            "Ankur Parikh",
            "Chris Alberti",
            "Danielle Epstein",
            "Illia Polosukhin",
            "Jacob Devlin",
            "Kenton Lee"
        ],
        "dcterms:description": "Natural Questions consists of questions aggregated from the Google search engine and the answers from the Wikipedia page in the top 5 search results. It is treated as a single-hop question answering task.",
        "dcterms:title": "Natural Questions",
        "dcterms:issued": "2019",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/google-research-datasets/natural-questions",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Open-domain QA",
            "Wikipedia",
            "Google Search"
        ],
        "dcat:landingPage": "https://github.com/google-research-datasets/natural-questions",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Closed-Book Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Mandar Joshi",
            "Eunsol Choi",
            "Daniel S Weld",
            "Luke Zettlemoyer"
        ],
        "dcterms:description": "TriviaQA dataset is constructed by collecting Trivia enthusiast authored question-answer pairs and their retrospectively collected evidence. It is evaluated in the single-hop 5-shot setting.",
        "dcterms:title": "TriviaQA",
        "dcterms:issued": "2017",
        "dcterms:language": "",
        "dcterms:identifier": "https://nlp.cs.washington.edu/triviaqa/",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Trivia Questions",
            "Reading Comprehension"
        ],
        "dcat:landingPage": "https://nlp.cs.washington.edu/triviaqa/",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Closed-Book Question Answering"
        ]
    },
    {
        "dcterms:creator": [
            "Zhilin Yang",
            "Peng Qi",
            "Saizheng Zhang",
            "Yoshua Bengio",
            "William Cohen",
            "Ruslan Salakhutdinov",
            "Christopher D Manning"
        ],
        "dcterms:description": "HotpotQA is designed to explicitly test QA systemsâ€™ ability to perform multi-hop reasoning. It is collected by explicitly composing questions requiring reasoning about multiple supporting context documents.",
        "dcterms:title": "HotpotQA",
        "dcterms:issued": "2018",
        "dcterms:language": "",
        "dcterms:identifier": "https://github.com/hotpotqa/hotpot",
        "dcat:theme": [
            "Question Answering",
            "Natural Language Processing"
        ],
        "dcat:keyword": [
            "Multi-hop QA",
            "Reasoning"
        ],
        "dcat:landingPage": "https://github.com/hotpotqa/hotpot",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Multi-hop Question Answering"
        ]
    }
]