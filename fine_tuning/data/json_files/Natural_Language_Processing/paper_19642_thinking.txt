To extract datasets from the research paper titled "Semantic change detection for Slovene language: a novel dataset and an approach based on optimal transport" by Marko Pranjić et al., I will follow a systematic approach.

First, I will read through the **abstract, introduction, and methodology sections** to identify any datasets mentioned. The abstract indicates that the authors present the **first Slovene dataset for evaluating semantic change detection systems**, which suggests that a dataset is indeed included.

Next, I will focus on **section 3 (Dataset construction)**, where the authors describe the dataset in detail. Here, they mention that the dataset consists of **105 target words with manually annotated aggregated semantic change scores**, derived from **3150 manually annotated sentence pairs**. This section provides crucial details about the dataset's structure and purpose.

In this section, the authors also reference the **Gigafida 2.0 corpus** as the source of their data, which is essential for understanding the dataset's context. They explain how they selected two time periods (1990-1997 and 2018) and the criteria for choosing target words, which adds depth to the dataset description.

Now, I will check the **References section** to find the full citation for the **Gigafida 2.0 corpus** since it is a significant component of the dataset. The citation provided in the paper is:
> Krek, S., Holdt, Š.A., Erjavec, T., Čibej, J., Repar, A., Gantar, P., Ljubešić, N., Kosem, I., Dobrovoljc, K. (2020). *Gigafida 2.0: the reference corpus of written standard Slovene*. In Proceedings of the 12th Language Resources and Evaluation Conference, pp. 3340–3345.

Additionally, I will note that the authors have made their dataset publicly available, which is an important detail for potential users.

Finally, I will compile the dataset information, including its name, description, and citations, ensuring that I provide complete and accurate references for each dataset mentioned in the paper.

After gathering all this information, I will prepare the dataset entries for further processing or review.