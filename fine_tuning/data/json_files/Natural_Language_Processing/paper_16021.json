[
    {
        "dcterms:creator": [
            "M. Liu",
            "Y. Wang",
            "J. Wu",
            "Y. Zhang",
            "J. Zhao"
        ],
        "dcterms:description": "A comprehensive benchmarking dataset for code understanding and generation, covering various programming languages and tasks.",
        "dcterms:title": "CodeXGLUE",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Understanding",
            "Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Code",
            "Understanding",
            "Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Understanding",
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Z. Zhu",
            "A. Jain",
            "S. K. Gupta"
        ],
        "dcterms:description": "A benchmark dataset for cross-lingual code intelligence, facilitating the evaluation of models across different programming languages.",
        "dcterms:title": "XLCoST",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Cross-Lingual Code Intelligence"
        ],
        "dcat:keyword": [
            "Cross-Lingual",
            "Code Intelligence",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Understanding",
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Chen",
            "A. Tworek",
            "J. Kaplan",
            "G. Brockman"
        ],
        "dcterms:description": "A dataset for evaluating large language models trained on code, containing programming problems and unit tests.",
        "dcterms:title": "HumanEval",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Generation"
        ],
        "dcat:keyword": [
            "Programming Problems",
            "Unit Tests"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Austin",
            "J. Gao",
            "M. I. Nye"
        ],
        "dcterms:description": "A dataset containing entry-level programming tasks designed for program synthesis with large language models.",
        "dcterms:title": "MBPP",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Program Synthesis"
        ],
        "dcat:keyword": [
            "Entry-Level Tasks",
            "Programming"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Program Synthesis"
        ]
    },
    {
        "dcterms:creator": [
            "D. Hendrycks",
            "S. Basart",
            "J. Steinhardt"
        ],
        "dcterms:description": "A dataset designed to measure coding challenge competence, providing a benchmark for evaluating coding skills.",
        "dcterms:title": "APPS",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Coding Challenges"
        ],
        "dcat:keyword": [
            "Competence",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Athiwaratkun",
            "S. K. Gouda",
            "Z. Wang"
        ],
        "dcterms:description": "A benchmark dataset for multi-language code generation, facilitating the evaluation of models across various programming languages.",
        "dcterms:title": "MBXP",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multi-Language Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Multi-Language"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "R. Puri",
            "D. S. Kung",
            "G. Domeniconi"
        ],
        "dcterms:description": "A large-scale dataset for learning a diversity of coding tasks, aimed at training AI models for code understanding and generation.",
        "dcterms:title": "CodeNet",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Understanding",
            "Code Generation"
        ],
        "dcat:keyword": [
            "Large-Scale Dataset",
            "AI for Code"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Understanding",
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "M. A. Khan",
            "M. S. Bari",
            "X. L. Do"
        ],
        "dcterms:description": "A large-scale multilingual multitask benchmark for code understanding, generation, translation, and retrieval.",
        "dcterms:title": "XCodeEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Multilingual Code Evaluation"
        ],
        "dcat:keyword": [
            "Multitask",
            "Benchmark"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Understanding",
            "Code Generation",
            "Code Translation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Lai",
            "C. Li",
            "Y. Wang"
        ],
        "dcterms:description": "A natural and reliable benchmark for data science code generation, providing a comprehensive evaluation framework.",
        "dcterms:title": "DS-1000",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Data Science Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Data Science"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "A. Austin",
            "J. Gao",
            "M. I. Nye"
        ],
        "dcterms:description": "A benchmark for mathematical problem solving, providing a dataset for evaluating code generation capabilities.",
        "dcterms:title": "MathQA",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Mathematical Problem Solving"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Mathematics"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "J. Du",
            "D. Guo",
            "S. Liu"
        ],
        "dcterms:description": "A manually-crafted benchmark for evaluating large language models on class-level code generation tasks.",
        "dcterms:title": "ClassEval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Class-Level Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Class-Level"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "Y. Hao",
            "G. Li",
            "Y. Liu"
        ],
        "dcterms:description": "A code generation benchmark dataset aimed at evaluating the performance of models in generating code.",
        "dcterms:title": "AiXBench",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Code Generation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "S. Ren",
            "D. Guo",
            "S. Liu"
        ],
        "dcterms:description": "A method for automatic evaluation of code synthesis, providing a benchmark for evaluating generated code.",
        "dcterms:title": "CodeBLEU",
        "dcterms:issued": "2020",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Synthesis Evaluation"
        ],
        "dcat:keyword": [
            "Evaluation",
            "Code Synthesis"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Chen",
            "A. Tworek",
            "G. Brockman"
        ],
        "dcterms:description": "A machine learning benchmark dataset for code understanding and generation, providing a comprehensive evaluation framework.",
        "dcterms:title": "CodexGLUE",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Understanding",
            "Code Generation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Machine Learning"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Understanding",
            "Code Generation"
        ]
    },
    {
        "dcterms:creator": [
            "M. Liu",
            "Y. Wang",
            "J. Zhao"
        ],
        "dcterms:description": "A transformer-based approach for code translation, providing a benchmark for evaluating code translation models.",
        "dcterms:title": "CodeTrans",
        "dcterms:issued": "2021",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Code Translation"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Code Translation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "Text",
        "mls:task": [
            "Code Translation"
        ]
    }
]