[
    {
        "dcterms:creator": [
            "Kaijie Zhu",
            "Jiaao Chen",
            "Jindong Wang",
            "Neil Zhenqiang Gong",
            "Diyi Yang",
            "Xing Xie"
        ],
        "dcterms:description": "DyVal is a graph-informed framework that dynamically generates formal logic templates for evaluating reasoning capabilities of large language models across different difficulty levels.",
        "dcterms:title": "DyVal",
        "dcterms:issued": "2024",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Dynamic evaluation",
            "Logic reasoning",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Logic reasoning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Abulhair Saparov",
            "He He"
        ],
        "dcterms:description": "PrOntoQA is a synthetic question-answering dataset designed to analyze the logical reasoning abilities of large language models.",
        "dcterms:title": "PrOntoQA",
        "dcterms:issued": "2022",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2210.01240",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Question answering",
            "Logical reasoning",
            "Language models"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Logical reasoning"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "ContextHub is a benchmark designed for evaluating the reasoning capabilities of large language models by disentangling logic from contextual information.",
        "dcterms:title": "ContextHub",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Benchmark",
            "Reasoning evaluation",
            "Contextual reasoning"
        ],
        "dcat:landingPage": "https://github.com/agiresearch/ContextHub",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reasoning evaluation"
        ]
    },
    {
        "dcterms:creator": [
            "Lizhou Fan",
            "Wenyue Hua",
            "Lingyao Li",
            "Haoyang Ling",
            "Yongfeng Zhang"
        ],
        "dcterms:description": "Nphardeval is a dynamic benchmark that assesses the reasoning abilities of large language models through various complexity classes.",
        "dcterms:title": "Nphardeval",
        "dcterms:issued": "2023",
        "dcterms:language": "",
        "dcterms:identifier": "arXiv:2312.14890",
        "dcat:theme": [
            "Natural Language Processing",
            "Machine Learning"
        ],
        "dcat:keyword": [
            "Dynamic benchmark",
            "Reasoning ability",
            "Complexity classes"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": [
            "Reasoning ability evaluation"
        ]
    },
    {
        "dcterms:creator": [],
        "dcterms:description": "Various instantiated logic datasets are generated as part of the ContextHub benchmark to evaluate reasoning capabilities of large language models.",
        "dcterms:title": "Various instantiated logic datasets",
        "dcterms:issued": "",
        "dcterms:language": "",
        "dcterms:identifier": "",
        "dcat:theme": [],
        "dcat:keyword": [
            "Instantiated logic",
            "Reasoning evaluation"
        ],
        "dcat:landingPage": "",
        "dcterms:hasVersion": "",
        "dcterms:format": "",
        "mls:task": []
    }
]